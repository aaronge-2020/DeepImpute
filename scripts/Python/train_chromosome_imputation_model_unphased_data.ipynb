{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQS Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_iqs_unphased(true_genotypes, imputed_dosages):\n",
    "    # Convert imputed dosages to discrete values\n",
    "    imputed_discrete = np.round(imputed_dosages).astype(int)\n",
    "\n",
    "    # Clip the imputed discrete values to be within the range of 0 to 2\n",
    "    imputed_discrete = np.clip(imputed_discrete, 0, 2)\n",
    "\n",
    "    # Create a contingency table\n",
    "    contingency_table = np.zeros((3, 3), dtype=int)\n",
    "\n",
    "    # Fill the contingency table\n",
    "    for true_geno, imputed_geno in zip(true_genotypes, imputed_discrete):\n",
    "        for true_allele, imputed_allele in zip(true_geno, imputed_geno):\n",
    "            contingency_table[int(true_allele), int(imputed_allele)] += 1\n",
    "\n",
    "    # Calculate the total number of genotypes\n",
    "    total_genotypes = np.sum(contingency_table)\n",
    "\n",
    "    # Calculate observed proportion of agreement (Po)\n",
    "    observed_agreement = np.trace(contingency_table) / total_genotypes\n",
    "\n",
    "    # Calculate marginal sums\n",
    "    row_marginals = np.sum(contingency_table, axis=1)\n",
    "    col_marginals = np.sum(contingency_table, axis=0)\n",
    "\n",
    "    # Calculate chance agreement (Pc)\n",
    "    chance_agreement = np.sum((row_marginals * col_marginals) / (total_genotypes ** 2))\n",
    "\n",
    "    # Calculate IQS\n",
    "    if chance_agreement == 1:  # To prevent division by zero in case of perfect chance agreement\n",
    "        iqs_score = 0\n",
    "    else:\n",
    "        iqs_score = (observed_agreement - chance_agreement) / (1 - chance_agreement)\n",
    "\n",
    "    return iqs_score\n",
    "\n",
    "# Example usage:\n",
    "true_genotypes = np.array([[0, 1, 2], [1, 2, 0], [2, 0, 1]])\n",
    "imputed_dosages = np.array([[0.1, 1.2, 1.9], [1.0, 1.8, 0.3], [2.0, 0.5, 1.4]])\n",
    "\n",
    "iqs_score = calculate_iqs_unphased(true_genotypes, imputed_dosages)\n",
    "print(f\"IQS Score: {iqs_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs:  929\n",
      "PRS313 SNPs:  30\n",
      "Total SNPs used for Training:  899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 14:21:51,261] Trial 86 finished with value: 0.10622426457703113 and parameters: {'learning_rate': 0.005190997400957485, 'l1_coef': 4.3763132874855275e-08, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.33527929693949376, 'num_epochs': 435}. Best is trial 49 with value: 0.10217271894216537.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 1 - Best hyperparameters: {'learning_rate': 0.004525680413232911, 'l1_coef': 1.4557748222420537e-06, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.2721642150080666, 'num_epochs': 367}\n",
      "Chr 1 - Best value: 0.1022\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/models_unphased/chr1/final_model_chr1.pth\n",
      "INPUTS [[0. 2. 0. ... 2. 1. 0.]\n",
      " [0. 2. 1. ... 2. 0. 0.]\n",
      " [0. 1. 0. ... 2. 0. 0.]\n",
      " ...\n",
      " [0. 2. 0. ... 2. 1. 0.]\n",
      " [0. 1. 0. ... 2. 1. 0.]\n",
      " [0. 0. 0. ... 2. 1. 0.]] [[ 0.21295525  1.1346838   0.02625206 ...  2.3359337  -0.04398361\n",
      "   0.04737796]\n",
      " [ 0.84804386  2.4524505   1.5537536  ...  2.359358    0.11665091\n",
      "  -0.02905133]\n",
      " [ 0.41301873  1.6406057  -0.12913103 ...  1.702893   -0.39570338\n",
      "  -0.00645405]\n",
      " ...\n",
      " [ 0.3019755   1.7119876   0.0105901  ...  2.058869    0.85444266\n",
      "   0.0405995 ]\n",
      " [-0.2700336   1.7962674  -0.04037734 ...  1.9678326   1.0011257\n",
      "   0.24637793]\n",
      " [ 0.36895612  1.7164937  -0.05849757 ...  1.4100678   0.7813533\n",
      "   0.22586088]]\n",
      "ROUND [[0. 2. 0. ... 2. 1. 0.]\n",
      " [0. 2. 1. ... 2. 0. 0.]\n",
      " [0. 1. 0. ... 2. 0. 0.]\n",
      " ...\n",
      " [0. 2. 0. ... 2. 1. 0.]\n",
      " [0. 1. 0. ... 2. 1. 0.]\n",
      " [0. 0. 0. ... 2. 1. 0.]] [[ 0.  1.  0. ...  2. -0.  0.]\n",
      " [ 1.  2.  2. ...  2.  0. -0.]\n",
      " [ 0.  2. -0. ...  2. -0. -0.]\n",
      " ...\n",
      " [ 0.  2.  0. ...  2.  1.  0.]\n",
      " [-0.  2. -0. ...  2.  1.  0.]\n",
      " [ 0.  2. -0. ...  1.  1.  0.]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 222\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    221\u001b[0m     test_outputs \u001b[38;5;241m=\u001b[39m model(X_test\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m--> 222\u001b[0m     test_r2 \u001b[38;5;241m=\u001b[39m sklearn_r2_score(y_test\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), test_outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    223\u001b[0m     test_iqs \u001b[38;5;241m=\u001b[39m calculate_chi_squared_unphased(y_test\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), test_outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    224\u001b[0m     test_accuracy \u001b[38;5;241m=\u001b[39m ((y_test \u001b[38;5;241m==\u001b[39m test_outputs\u001b[38;5;241m.\u001b[39mround())\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m (test_outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m test_outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[13], line 222\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    221\u001b[0m     test_outputs \u001b[38;5;241m=\u001b[39m model(X_test\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m--> 222\u001b[0m     test_r2 \u001b[38;5;241m=\u001b[39m sklearn_r2_score(y_test\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), test_outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    223\u001b[0m     test_iqs \u001b[38;5;241m=\u001b[39m calculate_chi_squared_unphased(y_test\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), test_outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    224\u001b[0m     test_accuracy \u001b[38;5;241m=\u001b[39m ((y_test \u001b[38;5;241m==\u001b[39m test_outputs\u001b[38;5;241m.\u001b[39mround())\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m (test_outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m test_outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mpydev_state \u001b[38;5;241m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_wait_suspend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score, accuracy_score\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Create folders for saving files\n",
    "output_folder = \"../../Data/model_results_unphased_all_PRS/linear_regression/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Create subfolders for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    os.makedirs(chr_model_folder, exist_ok=True)\n",
    "    os.makedirs(chr_csv_folder, exist_ok=True)\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.float32)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the linear regression model with L1 regularization\n",
    "    class LinearRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, l1_coef=0.0):\n",
    "            super(LinearRegression, self).__init__()\n",
    "            self.linear = nn.Linear(input_dim, output_dim)\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.linear(x)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * torch.norm(self.linear.weight, p=1)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set the hyperparameters for tuning\n",
    "    input_dim = X_train_val.shape[1]\n",
    "    output_dim = y_train_val.shape[1]\n",
    "    num_epochs = 500\n",
    "\n",
    "    # Define the objective function for Optuna with cross-validation and early stopping\n",
    "    def objective(trial):\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-1, log=True)\n",
    "        l1_coef = trial.suggest_float('l1_coef', 1e-10, 1e-1, log=True)\n",
    "        patience = trial.suggest_int('patience', 5, 20)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "        lr_factor = trial.suggest_float('lr_factor', 0.1, 0.9)\n",
    "        num_epochs = trial.suggest_int('num_epochs', 100, 500)\n",
    "\n",
    "        model = LinearRegression(input_dim, output_dim, l1_coef).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.MSELoss()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_factor, patience=patience, verbose=False)\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold_losses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_val)):\n",
    "            X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "            y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "            train_dataset = TensorDataset(X_train, y_train)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "            best_val_loss = float('inf')\n",
    "            counter = 0\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = 0.0\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                train_loss /= len(train_loader)\n",
    "\n",
    "                val_dataset = TensorDataset(X_val, y_val)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0.0\n",
    "                    for batch_X, batch_y in val_loader:\n",
    "                        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X)\n",
    "                        loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                    val_loss /= len(val_loader)\n",
    "                    scheduler.step(val_loss)\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= patience:\n",
    "                        break\n",
    "\n",
    "            fold_losses.append(best_val_loss)\n",
    "\n",
    "        return np.mean(fold_losses)\n",
    "    # Create the \"optuna_studies\" folder if it doesn't exist\n",
    "    os.makedirs(\"optuna_studies\", exist_ok=True)\n",
    "\n",
    "    # Create an Optuna study and optimize the hyperparameters\n",
    "    study_name = f\"unphased_full_23andMe_chr{chromosome_number}_study_linear_regression\"\n",
    "    storage_name = f\"sqlite:///optuna_studies/{study_name}.db\"\n",
    "\n",
    "    # Check if the study exists\n",
    "    current_dir = os.getcwd()\n",
    "    study_exists = os.path.exists(current_dir + f\"/optuna_studies/{study_name}.db\")\n",
    "\n",
    "    if study_exists:\n",
    "        # Load the existing study\n",
    "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "    else:\n",
    "        # Create a new study\n",
    "        study = optuna.create_study(direction='minimize', study_name=study_name, storage=storage_name)\n",
    "\n",
    "    study.optimize(objective, n_trials=1, n_jobs=-1)\n",
    "\n",
    "    # Print the best hyperparameters and best value\n",
    "    print(f\"Chr {chromosome_number} - Best hyperparameters: {study.best_params}\")\n",
    "    print(f\"Chr {chromosome_number} - Best value: {study.best_value:.4f}\")\n",
    "\n",
    "    # Train the final model with the best hyperparameters and early stopping\n",
    "    best_learning_rate = study.best_params['learning_rate']\n",
    "    best_l1_coef = study.best_params['l1_coef']\n",
    "    best_patience = study.best_params['patience']\n",
    "    best_batch_size = study.best_params['batch_size']\n",
    "    best_lr_factor = study.best_params['lr_factor']\n",
    "    best_num_epochs = study.best_params['num_epochs']\n",
    "\n",
    "    model = LinearRegression(input_dim, output_dim, best_l1_coef).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=best_lr_factor, patience=best_patience, verbose=False)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_val, y_train_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(best_num_epochs):\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            best_train_loss = train_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= best_patience:\n",
    "            break\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "    # Save the final model\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Final model saved at: {model_save_path}\")\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_accuracy = ((y_test == test_outputs.round()).sum() / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test.cpu().numpy()[:, i].reshape(-1, 1), test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "    # Create a DataFrame to store the performance metrics for each chromosome\n",
    "    performance_df = pd.DataFrame({\n",
    "        'Chromosome': list(range(start, chromosome_number + 1)),\n",
    "        'R2 Score': r2_scores,\n",
    "        'IQS Score': iqs_scores,\n",
    "        'Accuracy Score': accuracy_scores\n",
    "    })\n",
    "\n",
    "    # Save the performance metrics to a CSV file\n",
    "    performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "    performance_df.to_csv(performance_csv_file, index=False)\n",
    "    print(f\"Performance metrics saved at: {performance_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs:  929\n",
      "PRS313 SNPs:  30\n",
      "Total SNPs used for Training:  899\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr1/individual_r2_scores_chr1.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr1/individual_iqs_scores_chr1.csv\n",
      "Total SNPs:  629\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  608\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr2/individual_r2_scores_chr2.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr2/individual_iqs_scores_chr2.csv\n",
      "Total SNPs:  963\n",
      "PRS313 SNPs:  16\n",
      "Total SNPs used for Training:  947\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr3/individual_r2_scores_chr3.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr3/individual_iqs_scores_chr3.csv\n",
      "Total SNPs:  1261\n",
      "PRS313 SNPs:  11\n",
      "Total SNPs used for Training:  1250\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr4/individual_r2_scores_chr4.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr4/individual_iqs_scores_chr4.csv\n",
      "Total SNPs:  1289\n",
      "PRS313 SNPs:  34\n",
      "Total SNPs used for Training:  1255\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr5/individual_r2_scores_chr5.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr5/individual_iqs_scores_chr5.csv\n",
      "Total SNPs:  639\n",
      "PRS313 SNPs:  20\n",
      "Total SNPs used for Training:  619\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr6/individual_r2_scores_chr6.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr6/individual_iqs_scores_chr6.csv\n",
      "Total SNPs:  465\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  451\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr7/individual_r2_scores_chr7.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr7/individual_iqs_scores_chr7.csv\n",
      "Total SNPs:  454\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  433\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr8/individual_r2_scores_chr8.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr8/individual_iqs_scores_chr8.csv\n",
      "Total SNPs:  404\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  390\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr9/individual_r2_scores_chr9.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr9/individual_iqs_scores_chr9.csv\n",
      "Total SNPs:  608\n",
      "PRS313 SNPs:  18\n",
      "Total SNPs used for Training:  590\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr10/individual_r2_scores_chr10.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr10/individual_iqs_scores_chr10.csv\n",
      "Total SNPs:  919\n",
      "PRS313 SNPs:  19\n",
      "Total SNPs used for Training:  900\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr11/individual_r2_scores_chr11.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr11/individual_iqs_scores_chr11.csv\n",
      "Total SNPs:  641\n",
      "PRS313 SNPs:  17\n",
      "Total SNPs used for Training:  624\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr12/individual_r2_scores_chr12.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr12/individual_iqs_scores_chr12.csv\n",
      "Total SNPs:  112\n",
      "PRS313 SNPs:  5\n",
      "Total SNPs used for Training:  107\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr13/individual_r2_scores_chr13.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr13/individual_iqs_scores_chr13.csv\n",
      "Total SNPs:  164\n",
      "PRS313 SNPs:  8\n",
      "Total SNPs used for Training:  156\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr14/individual_r2_scores_chr14.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr14/individual_iqs_scores_chr14.csv\n",
      "Total SNPs:  200\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  193\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr15/individual_r2_scores_chr15.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr15/individual_iqs_scores_chr15.csv\n",
      "Total SNPs:  361\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  347\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr16/individual_r2_scores_chr16.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr16/individual_iqs_scores_chr16.csv\n",
      "Total SNPs:  188\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  179\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr17/individual_r2_scores_chr17.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr17/individual_iqs_scores_chr17.csv\n",
      "Total SNPs:  277\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  268\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr18/individual_r2_scores_chr18.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr18/individual_iqs_scores_chr18.csv\n",
      "Total SNPs:  288\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  281\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr19/individual_r2_scores_chr19.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr19/individual_iqs_scores_chr19.csv\n",
      "Total SNPs:  62\n",
      "PRS313 SNPs:  4\n",
      "Total SNPs used for Training:  58\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr20/individual_r2_scores_chr20.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr20/individual_iqs_scores_chr20.csv\n",
      "Total SNPs:  44\n",
      "PRS313 SNPs:  4\n",
      "Total SNPs used for Training:  40\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr21/individual_r2_scores_chr21.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr21/individual_iqs_scores_chr21.csv\n",
      "Total SNPs:  443\n",
      "PRS313 SNPs:  11\n",
      "Total SNPs used for Training:  432\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr22/individual_r2_scores_chr22.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr22/individual_iqs_scores_chr22.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/performance_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Folders for saved models and CSV files\n",
    "output_folder = \"../../Data/model_results_unphased_all_PRS/linear_regression/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Paths for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.float32)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the linear regression model with L1 regularization\n",
    "    class LinearRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, l1_coef=0.0):\n",
    "            super(LinearRegression, self).__init__()\n",
    "            self.linear = nn.Linear(input_dim, output_dim)\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.linear(x)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * torch.norm(self.linear.weight, p=1)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the final model\n",
    "    model = LinearRegression(X_train_val.shape[1], y_train_val.shape[1])\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_accuracy = ((y_test == test_outputs.round()).sum() / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test.cpu().numpy()[:, i].reshape(-1, 1), test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "# Create a DataFrame to store the performance metrics for each chromosome\n",
    "performance_df = pd.DataFrame({\n",
    "    'Chromosome': list(range(start, 23)),\n",
    "    'R2 Score': r2_scores,\n",
    "    'IQS Score': iqs_scores,\n",
    "    'Accuracy Score': accuracy_scores\n",
    "})\n",
    "\n",
    "# Save the performance metrics to a CSV file\n",
    "performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "performance_df.to_csv(performance_csv_file, index=False)\n",
    "print(f\"Performance metrics saved at: {performance_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs:  929\n",
      "PRS313 SNPs:  30\n",
      "Total SNPs used for Training:  899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 00:33:59,250] Trial 22 finished with value: 0.733684065937996 and parameters: {'learning_rate': 0.002220891376392196, 'l1_coef': 2.7694209571735434e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.3090166357776345, 'num_epochs': 359}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:34:00,673] Trial 17 finished with value: 0.745872899889946 and parameters: {'learning_rate': 0.002282542929228127, 'l1_coef': 1.7678189359217486e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.2898999112507365, 'num_epochs': 365}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:34:04,619] Trial 20 finished with value: 0.7228652864694596 and parameters: {'learning_rate': 0.00217582920731858, 'l1_coef': 2.533053034976939e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.3031199406133188, 'num_epochs': 355}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:34:11,111] Trial 21 finished with value: 0.7277507990598678 and parameters: {'learning_rate': 0.0017025763376658965, 'l1_coef': 1.0235052713572794e-07, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.30662958722945444, 'num_epochs': 359}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:34:15,458] Trial 25 finished with value: 0.7264238357543945 and parameters: {'learning_rate': 0.0019818232862864995, 'l1_coef': 1.9947597706414564e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.31211254820380124, 'num_epochs': 360}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:34:30,047] Trial 18 finished with value: 0.7009655147790909 and parameters: {'learning_rate': 0.0012181757024188361, 'l1_coef': 4.6378395544525675e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.30645973737258214, 'num_epochs': 360}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:34:30,585] Trial 19 finished with value: 0.7039346426725388 and parameters: {'learning_rate': 0.001365146998436572, 'l1_coef': 1.4810963075499889e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.3325793391766095, 'num_epochs': 359}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:34:35,407] Trial 23 finished with value: 0.6949808955192566 and parameters: {'learning_rate': 0.0011409283054426482, 'l1_coef': 5.511712534904975e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.3223903295211248, 'num_epochs': 358}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:34:44,302] Trial 16 finished with value: 0.6903671979904175 and parameters: {'learning_rate': 0.0012065054849334966, 'l1_coef': 3.067194172892281e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.3160301585763767, 'num_epochs': 356}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:35:04,399] Trial 24 finished with value: 0.6918565690517425 and parameters: {'learning_rate': 0.0015021783034640495, 'l1_coef': 1.4689854531414309e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.3296545065760391, 'num_epochs': 347}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:36:16,151] Trial 26 finished with value: 0.6925661981105804 and parameters: {'learning_rate': 0.0007081663648153441, 'l1_coef': 7.814463247132478e-09, 'patience': 17, 'batch_size': 128, 'lr_factor': 0.2840649729418717, 'num_epochs': 186}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:36:45,316] Trial 28 finished with value: 0.7934650897979736 and parameters: {'learning_rate': 4.720924263946498e-05, 'l1_coef': 6.373025842300328e-07, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.10481740340066037, 'num_epochs': 217}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:36:48,287] Trial 27 finished with value: 0.7743836075067521 and parameters: {'learning_rate': 6.198932480759604e-05, 'l1_coef': 1.0315609206103517e-06, 'patience': 17, 'batch_size': 128, 'lr_factor': 0.12784620670740365, 'num_epochs': 246}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:37:06,313] Trial 31 finished with value: 0.7423314554350717 and parameters: {'learning_rate': 0.0001237959288350582, 'l1_coef': 1.2988714339786355e-10, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.10032955935340115, 'num_epochs': 149}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:37:57,988] Trial 29 finished with value: 0.7656732252665928 and parameters: {'learning_rate': 5.3105967382013654e-05, 'l1_coef': 1.099380652760684e-10, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.42265616663683464, 'num_epochs': 229}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:38:05,232] Trial 30 finished with value: 0.7657341957092285 and parameters: {'learning_rate': 5.377263229733509e-05, 'l1_coef': 2.601642716107049e-10, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.10429601348895709, 'num_epochs': 231}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:39:20,474] Trial 40 finished with value: 0.8277414285219631 and parameters: {'learning_rate': 0.007775864928089771, 'l1_coef': 1.4870297858321275e-09, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.22318673079258702, 'num_epochs': 457}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:39:31,836] Trial 41 finished with value: 0.8533227948042063 and parameters: {'learning_rate': 0.008369939434715763, 'l1_coef': 2.2815161412027144e-09, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.20244435776907155, 'num_epochs': 463}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:42:37,299] Trial 39 finished with value: 0.6863056026972257 and parameters: {'learning_rate': 0.00022168746238930564, 'l1_coef': 6.95558514084956e-10, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.4228565419574323, 'num_epochs': 465}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:43:39,394] Trial 34 finished with value: 0.6966474047073952 and parameters: {'learning_rate': 8.969341331057334e-05, 'l1_coef': 9.03675577592456e-10, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.12482259934648907, 'num_epochs': 461}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:44:14,724] Trial 32 finished with value: 0.7002105126014122 and parameters: {'learning_rate': 7.554596254928891e-05, 'l1_coef': 1.2457339930344922e-09, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.11004240365043118, 'num_epochs': 464}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:44:18,526] Trial 33 finished with value: 0.703144407272339 and parameters: {'learning_rate': 6.506730075976124e-05, 'l1_coef': 9.494697094907282e-10, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.11927815587801928, 'num_epochs': 466}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:44:27,475] Trial 43 finished with value: 0.6827381344941946 and parameters: {'learning_rate': 0.00028442264677079853, 'l1_coef': 3.66368381132652e-09, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.5545508155975448, 'num_epochs': 393}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:44:40,828] Trial 35 finished with value: 0.7008787100131695 and parameters: {'learning_rate': 6.863285181045452e-05, 'l1_coef': 6.803376455864937e-10, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.11607816206298961, 'num_epochs': 461}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:44:42,156] Trial 36 finished with value: 0.6880419676120464 and parameters: {'learning_rate': 0.00010172482688438969, 'l1_coef': 1.0048805919602823e-10, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.14336390686579342, 'num_epochs': 466}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:45:09,385] Trial 38 finished with value: 0.6891522976068349 and parameters: {'learning_rate': 0.0001259168195291966, 'l1_coef': 1.052975936554341e-10, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.42952654272618024, 'num_epochs': 466}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:45:13,861] Trial 42 finished with value: 0.6791466236114502 and parameters: {'learning_rate': 0.00027115281349634346, 'l1_coef': 2.021329843726874e-09, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.22671247222310942, 'num_epochs': 393}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:46:15,520] Trial 37 finished with value: 0.6967270722756018 and parameters: {'learning_rate': 8.711230623214846e-05, 'l1_coef': 1.29229919925724e-10, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.42665967189521975, 'num_epochs': 462}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:46:48,035] Trial 44 finished with value: 0.6797083909694965 and parameters: {'learning_rate': 0.0003691446289347912, 'l1_coef': 4.284363176467175e-09, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.5396014603535947, 'num_epochs': 497}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:50:15,078] Trial 52 finished with value: 0.6826243373063894 and parameters: {'learning_rate': 0.0003435784135819148, 'l1_coef': 4.4327377779145645e-09, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.590961034043497, 'num_epochs': 397}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:50:28,756] Trial 46 finished with value: 0.6796678946568415 and parameters: {'learning_rate': 0.00026566850237214084, 'l1_coef': 4.625259842195379e-09, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.5603570592728664, 'num_epochs': 432}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:50:40,110] Trial 51 finished with value: 0.856351113319397 and parameters: {'learning_rate': 1.8201683638463684e-05, 'l1_coef': 7.443042293440812e-05, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.5241502591311495, 'num_epochs': 392}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:51:43,080] Trial 54 finished with value: 0.681171518105727 and parameters: {'learning_rate': 0.00038702742246582764, 'l1_coef': 5.902950813363441e-09, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.5895579844671913, 'num_epochs': 399}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:52:04,956] Trial 47 finished with value: 0.7840980768203736 and parameters: {'learning_rate': 0.00027929744000619025, 'l1_coef': 0.00015107901748903245, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.533744657437902, 'num_epochs': 428}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:53:28,828] Trial 48 finished with value: 0.7485093355178833 and parameters: {'learning_rate': 2.4035424706474727e-05, 'l1_coef': 2.229006692436023e-07, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.5819613161530626, 'num_epochs': 407}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:53:33,612] Trial 55 finished with value: 0.8161043643951416 and parameters: {'learning_rate': 2.5412775929881877e-05, 'l1_coef': 4.755881742868346e-09, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.5985226438078985, 'num_epochs': 425}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:53:53,092] Trial 50 finished with value: 0.7517402795644906 and parameters: {'learning_rate': 2.2554258278863775e-05, 'l1_coef': 4.9900291858878005e-09, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.5588762316748714, 'num_epochs': 393}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:56:10,363] Trial 59 finished with value: 0.6801940431961646 and parameters: {'learning_rate': 0.0006142368386202736, 'l1_coef': 2.2619845903397533e-07, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.6636105161105446, 'num_epochs': 323}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:56:51,063] Trial 61 finished with value: 0.6854704398375292 and parameters: {'learning_rate': 0.000760154983523781, 'l1_coef': 2.3943126722225733e-07, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.6813537522588302, 'num_epochs': 322}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:57:17,697] Trial 62 finished with value: 0.6804273852935204 and parameters: {'learning_rate': 0.0006929055620878557, 'l1_coef': 4.3153169121870964e-10, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.4822647906044733, 'num_epochs': 498}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:57:19,719] Trial 60 finished with value: 0.6843459285222566 and parameters: {'learning_rate': 0.000748483344095127, 'l1_coef': 6.388365312034985e-09, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.6874120656612767, 'num_epochs': 318}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 00:59:16,893] Trial 63 finished with value: 0.6888377143786503 and parameters: {'learning_rate': 0.0005899468559967988, 'l1_coef': 1.932107869088454e-07, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.6947676477653559, 'num_epochs': 329}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 01:00:05,267] Trial 56 finished with value: 0.9398724436759949 and parameters: {'learning_rate': 3.079775270525736e-05, 'l1_coef': 0.0011259988784684365, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.4915660851900559, 'num_epochs': 434}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 01:00:30,571] Trial 64 finished with value: 0.7092464327812195 and parameters: {'learning_rate': 0.0006599885128797249, 'l1_coef': 8.489111197158014e-06, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.6591790954431646, 'num_epochs': 331}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 01:00:42,167] Trial 58 finished with value: 0.7419157908512996 and parameters: {'learning_rate': 2.5968566679820713e-05, 'l1_coef': 1.4261486366753665e-07, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.4798782553488994, 'num_epochs': 430}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 01:01:51,759] Trial 45 finished with value: 0.8324374849979694 and parameters: {'learning_rate': 2.036093970722638e-05, 'l1_coef': 0.00024199386642824084, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.5735190344838293, 'num_epochs': 432}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 01:02:05,580] Trial 53 finished with value: 0.837464936879965 and parameters: {'learning_rate': 2.3245630531150602e-05, 'l1_coef': 0.00027778518927498773, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.5305415721276978, 'num_epochs': 401}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 01:02:05,868] Trial 49 finished with value: 0.9475607358492336 and parameters: {'learning_rate': 2.0904447921362695e-05, 'l1_coef': 0.0026403999917001164, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.5398523569945143, 'num_epochs': 429}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 01:04:10,248] Trial 57 finished with value: 0.8238157840875479 and parameters: {'learning_rate': 1.743359721249785e-06, 'l1_coef': 2.0979499650690914e-07, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.7027565357793288, 'num_epochs': 427}. Best is trial 12 with value: 0.6769969142400301.\n",
      "[I 2024-05-23 01:04:27,799] Trial 65 finished with value: 0.8272719915096577 and parameters: {'learning_rate': 2.0684721316579023e-06, 'l1_coef': 2.6553497350637125e-06, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.47958129405897126, 'num_epochs': 483}. Best is trial 12 with value: 0.6769969142400301.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 1 - Best hyperparameters: {'learning_rate': 0.0003659720828647503, 'l1_coef': 2.2917141824697583e-08, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.3973506534926021, 'num_epochs': 386}\n",
      "Chr 1 - Best value: 0.6770\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr1/final_model_chr1.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr1/individual_r2_scores_chr1.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr1/individual_iqs_scores_chr1.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  629\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 01:06:23,934] Trial 12 finished with value: 1.6472469466073172 and parameters: {'learning_rate': 0.07619744115418815, 'l1_coef': 0.0025746994774138057, 'patience': 12, 'batch_size': 64, 'lr_factor': 0.8290381863688072, 'num_epochs': 130}. Best is trial 2 with value: 0.7424067212985113.\n",
      "[I 2024-05-23 01:07:25,388] Trial 17 finished with value: 0.9643306629998344 and parameters: {'learning_rate': 0.03319278550826355, 'l1_coef': 7.475199555377638e-07, 'patience': 10, 'batch_size': 64, 'lr_factor': 0.46163221633999585, 'num_epochs': 161}. Best is trial 2 with value: 0.7424067212985113.\n",
      "[I 2024-05-23 01:08:26,448] Trial 14 finished with value: 1.814862275123596 and parameters: {'learning_rate': 0.02812313145521612, 'l1_coef': 0.03017157290208268, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.20656640855761435, 'num_epochs': 111}. Best is trial 2 with value: 0.7424067212985113.\n",
      "[I 2024-05-23 01:09:30,310] Trial 11 finished with value: 0.7786299815544716 and parameters: {'learning_rate': 0.010335532721430276, 'l1_coef': 3.836052030904084e-06, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.41323021307979346, 'num_epochs': 217}. Best is trial 2 with value: 0.7424067212985113.\n",
      "[I 2024-05-23 01:09:39,220] Trial 8 finished with value: 1.209352231025696 and parameters: {'learning_rate': 2.4500988205016794e-06, 'l1_coef': 0.00038929937218560456, 'patience': 19, 'batch_size': 128, 'lr_factor': 0.16100924098657582, 'num_epochs': 103}. Best is trial 2 with value: 0.7424067212985113.\n",
      "[I 2024-05-23 01:10:21,065] Trial 18 finished with value: 1.9110570852573097 and parameters: {'learning_rate': 0.0067449689697676625, 'l1_coef': 0.08067412081452335, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.6860203210633535, 'num_epochs': 158}. Best is trial 2 with value: 0.7424067212985113.\n",
      "[I 2024-05-23 01:10:40,489] Trial 13 finished with value: 0.7138215286391121 and parameters: {'learning_rate': 0.0002275121862646268, 'l1_coef': 7.096525315862768e-06, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.42693967874875205, 'num_epochs': 367}. Best is trial 13 with value: 0.7138215286391121.\n",
      "[I 2024-05-23 01:11:14,315] Trial 15 finished with value: 0.8309684425592423 and parameters: {'learning_rate': 1.7807963091939435e-05, 'l1_coef': 1.4981472473138652e-06, 'patience': 19, 'batch_size': 128, 'lr_factor': 0.6255186691057502, 'num_epochs': 319}. Best is trial 13 with value: 0.7138215286391121.\n",
      "[I 2024-05-23 01:12:10,483] Trial 16 finished with value: 1.1213027532284077 and parameters: {'learning_rate': 0.0033413327151615943, 'l1_coef': 0.04738105833409439, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.35432311373180203, 'num_epochs': 305}. Best is trial 13 with value: 0.7138215286391121.\n",
      "[I 2024-05-23 01:13:04,115] Trial 9 finished with value: 1.1563086986541746 and parameters: {'learning_rate': 2.933900342499893e-06, 'l1_coef': 0.0007944513711796001, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.6495246041200057, 'num_epochs': 129}. Best is trial 13 with value: 0.7138215286391121.\n",
      "[I 2024-05-23 01:13:26,279] Trial 20 finished with value: 0.682320316021259 and parameters: {'learning_rate': 0.0003290042164860426, 'l1_coef': 2.9062544036475797e-10, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.5815932958872317, 'num_epochs': 229}. Best is trial 20 with value: 0.682320316021259.\n",
      "[I 2024-05-23 01:14:30,228] Trial 22 finished with value: 0.6804780455736015 and parameters: {'learning_rate': 0.00043637540939698427, 'l1_coef': 2.8284088661635826e-10, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.4538463561081919, 'num_epochs': 224}. Best is trial 22 with value: 0.6804780455736015.\n",
      "[I 2024-05-23 01:15:08,893] Trial 23 finished with value: 0.6726012816795934 and parameters: {'learning_rate': 0.0005129273804989615, 'l1_coef': 2.8446215035565983e-10, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.46478713313245634, 'num_epochs': 227}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:15:15,049] Trial 24 finished with value: 0.6809799964611347 and parameters: {'learning_rate': 0.0003693421627586389, 'l1_coef': 1.2020135104679086e-10, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.5704860046674599, 'num_epochs': 259}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:15:35,682] Trial 26 finished with value: 0.6905381441116333 and parameters: {'learning_rate': 0.0005182149676449277, 'l1_coef': 1.0886831285480549e-10, 'patience': 8, 'batch_size': 64, 'lr_factor': 0.5392697913267311, 'num_epochs': 245}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:16:35,689] Trial 25 finished with value: 0.7424622966692997 and parameters: {'learning_rate': 0.0004714026344578256, 'l1_coef': 8.065403272290031e-05, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.3621481912521859, 'num_epochs': 249}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:16:40,388] Trial 19 finished with value: 0.9414238423109055 and parameters: {'learning_rate': 2.962120978385216e-05, 'l1_coef': 0.0012397770178390727, 'patience': 5, 'batch_size': 128, 'lr_factor': 0.535412129164995, 'num_epochs': 461}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:16:58,552] Trial 28 finished with value: 0.6978438683918544 and parameters: {'learning_rate': 0.00036420224731077515, 'l1_coef': 2.103752457113114e-10, 'patience': 7, 'batch_size': 64, 'lr_factor': 0.540185628787769, 'num_epochs': 259}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:17:23,426] Trial 32 finished with value: 0.6895227111302888 and parameters: {'learning_rate': 0.0010545905834830453, 'l1_coef': 9.277047083656714e-10, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.5148223229453257, 'num_epochs': 263}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:18:18,931] Trial 27 finished with value: 0.6785446634659401 and parameters: {'learning_rate': 0.00040416717723611287, 'l1_coef': 1.1754010216935482e-10, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.5486579582060012, 'num_epochs': 459}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:18:45,945] Trial 31 finished with value: 0.6783276126934932 and parameters: {'learning_rate': 0.0005727701717998377, 'l1_coef': 1.2002137667349351e-10, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.5379068824908902, 'num_epochs': 258}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:19:11,248] Trial 30 finished with value: 0.6796436658272377 and parameters: {'learning_rate': 0.0005503342838268875, 'l1_coef': 1.0927040029928101e-10, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.5333914197263893, 'num_epochs': 257}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:19:13,690] Trial 10 finished with value: 0.9457114219665528 and parameters: {'learning_rate': 8.481697804764203e-06, 'l1_coef': 0.0004771296321182444, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.700322144146703, 'num_epochs': 327}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:19:22,757] Trial 29 finished with value: 0.6759977771685673 and parameters: {'learning_rate': 0.00043815041232110174, 'l1_coef': 2.4104855856509807e-10, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.5808405337001901, 'num_epochs': 238}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:21:29,255] Trial 35 finished with value: 0.7384904072834895 and parameters: {'learning_rate': 8.660357264542785e-05, 'l1_coef': 1.3685964980516782e-09, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.33370235466235143, 'num_epochs': 205}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:21:41,016] Trial 36 finished with value: 0.7396578339430002 and parameters: {'learning_rate': 9.001013574443682e-05, 'l1_coef': 2.113568989592882e-09, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.31119987896090867, 'num_epochs': 194}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:21:58,011] Trial 33 finished with value: 0.7239703866151663 and parameters: {'learning_rate': 8.655916101883082e-05, 'l1_coef': 1.135200417893768e-09, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.5133892558703752, 'num_epochs': 273}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:22:04,739] Trial 34 finished with value: 0.7124680372384878 and parameters: {'learning_rate': 0.00011335023929393129, 'l1_coef': 1.0382253849440864e-09, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.4674606811085782, 'num_epochs': 265}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:22:32,150] Trial 37 finished with value: 0.7325468329282907 and parameters: {'learning_rate': 0.0001027948534904615, 'l1_coef': 2.034542775501885e-09, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.33190429776631003, 'num_epochs': 189}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:22:49,968] Trial 21 finished with value: 0.7981289799396809 and parameters: {'learning_rate': 0.0003661017369377023, 'l1_coef': 0.00035652554075111566, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.4686603619501292, 'num_epochs': 226}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:22:55,670] Trial 38 finished with value: 0.7366833090782166 and parameters: {'learning_rate': 9.28965811715543e-05, 'l1_coef': 2.6487108762199424e-09, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.3340196339451077, 'num_epochs': 186}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:23:34,945] Trial 40 finished with value: 0.750195898459508 and parameters: {'learning_rate': 7.386395098838288e-05, 'l1_coef': 2.634022516624515e-09, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.35278283437794844, 'num_epochs': 194}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:24:21,874] Trial 45 finished with value: 0.6883695185184479 and parameters: {'learning_rate': 0.0013754362263213248, 'l1_coef': 4.841984366078444e-08, 'patience': 9, 'batch_size': 256, 'lr_factor': 0.5966299177736066, 'num_epochs': 290}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:24:22,556] Trial 43 finished with value: 0.677871509698721 and parameters: {'learning_rate': 0.0013101395491284377, 'l1_coef': 1.1667886934978581e-07, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.6122780870527221, 'num_epochs': 438}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:24:34,272] Trial 44 finished with value: 0.6858020544052124 and parameters: {'learning_rate': 0.001616313946365554, 'l1_coef': 3.4263822947713465e-08, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.6001777083713609, 'num_epochs': 500}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:24:50,639] Trial 46 finished with value: 0.7001552820205689 and parameters: {'learning_rate': 0.0012779206634050693, 'l1_coef': 1.1411403823642808e-07, 'patience': 9, 'batch_size': 256, 'lr_factor': 0.6083194271361221, 'num_epochs': 289}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:24:54,503] Trial 42 finished with value: 0.692023556966048 and parameters: {'learning_rate': 0.0017504925766452647, 'l1_coef': 6.86789546102951e-08, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.6053317807928157, 'num_epochs': 422}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:25:41,792] Trial 49 finished with value: 0.6875182807445526 and parameters: {'learning_rate': 0.001529755868398332, 'l1_coef': 7.463702054562051e-08, 'patience': 6, 'batch_size': 256, 'lr_factor': 0.6112620973629305, 'num_epochs': 425}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:26:09,565] Trial 52 finished with value: 0.6946532726287842 and parameters: {'learning_rate': 0.002554217759725229, 'l1_coef': 2.2069406426798894e-07, 'patience': 6, 'batch_size': 256, 'lr_factor': 0.7489302276227447, 'num_epochs': 426}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:26:12,707] Trial 48 finished with value: 0.6782127737998962 and parameters: {'learning_rate': 0.0016634809420156863, 'l1_coef': 1.551181290243117e-07, 'patience': 9, 'batch_size': 256, 'lr_factor': 0.6126626424214918, 'num_epochs': 424}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:26:29,902] Trial 51 finished with value: 0.6936141793544476 and parameters: {'learning_rate': 0.0017895924935440414, 'l1_coef': 7.548046468833084e-08, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.7467046819468728, 'num_epochs': 420}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:26:31,658] Trial 53 finished with value: 0.6912373762864333 and parameters: {'learning_rate': 0.0029879867166556304, 'l1_coef': 1.040809160505392e-08, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.7545285255245622, 'num_epochs': 421}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:26:42,185] Trial 50 finished with value: 0.6905962467193604 and parameters: {'learning_rate': 0.002022345916264548, 'l1_coef': 7.202929286156514e-08, 'patience': 9, 'batch_size': 256, 'lr_factor': 0.74101135579842, 'num_epochs': 442}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:26:51,915] Trial 57 finished with value: 0.8309283971786499 and parameters: {'learning_rate': 0.01236245009333424, 'l1_coef': 8.984738080940394e-09, 'patience': 11, 'batch_size': 256, 'lr_factor': 0.6618419697447071, 'num_epochs': 345}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:26:54,793] Trial 55 finished with value: 0.7254737743964562 and parameters: {'learning_rate': 0.0030033791267254574, 'l1_coef': 1.2200271866907783e-08, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.6605579289596563, 'num_epochs': 350}. Best is trial 23 with value: 0.6726012816795934.\n",
      "[I 2024-05-23 01:26:59,513] Trial 47 finished with value: 0.6719442578462453 and parameters: {'learning_rate': 0.001813751389499825, 'l1_coef': 7.793207352687452e-08, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.6069847013701387, 'num_epochs': 423}. Best is trial 47 with value: 0.6719442578462453.\n",
      "[I 2024-05-23 01:27:12,520] Trial 41 finished with value: 0.6929553398719202 and parameters: {'learning_rate': 0.00011266112163925096, 'l1_coef': 3.1908194215854114e-09, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.613558800485732, 'num_epochs': 426}. Best is trial 47 with value: 0.6719442578462453.\n",
      "[I 2024-05-23 01:27:13,058] Trial 39 finished with value: 0.6997032633194555 and parameters: {'learning_rate': 9.156539364948003e-05, 'l1_coef': 1.752632934849604e-07, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.3542442471454752, 'num_epochs': 442}. Best is trial 47 with value: 0.6719442578462453.\n",
      "[I 2024-05-23 01:27:19,294] Trial 54 finished with value: 0.7048058372277479 and parameters: {'learning_rate': 0.00020004371680567158, 'l1_coef': 8.993024578761414e-09, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.6629799384877396, 'num_epochs': 414}. Best is trial 47 with value: 0.6719442578462453.\n",
      "[I 2024-05-23 01:27:29,785] Trial 56 finished with value: 0.6871821586902325 and parameters: {'learning_rate': 0.000215962848709746, 'l1_coef': 8.967322456227495e-09, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.656087137374175, 'num_epochs': 348}. Best is trial 47 with value: 0.6719442578462453.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 2 - Best hyperparameters: {'learning_rate': 0.001813751389499825, 'l1_coef': 7.793207352687452e-08, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.6069847013701387, 'num_epochs': 423}\n",
      "Chr 2 - Best value: 0.6719\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr2/final_model_chr2.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr2/individual_r2_scores_chr2.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr2/individual_iqs_scores_chr2.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  963\n",
      "PRS313 SNPs:  16\n",
      "Total SNPs used for Training:  947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 01:28:51,153] Trial 11 finished with value: 0.8762602269649505 and parameters: {'learning_rate': 0.059531359725103664, 'l1_coef': 3.004383384943592e-06, 'patience': 6, 'batch_size': 256, 'lr_factor': 0.19610770016997386, 'num_epochs': 227}. Best is trial 2 with value: 0.6965232074260712.\n",
      "[I 2024-05-23 01:29:05,881] Trial 14 finished with value: 0.8786559939384461 and parameters: {'learning_rate': 0.05911358604497834, 'l1_coef': 5.599094683443257e-07, 'patience': 7, 'batch_size': 256, 'lr_factor': 0.19793238738417537, 'num_epochs': 256}. Best is trial 2 with value: 0.6965232074260712.\n",
      "[I 2024-05-23 01:29:30,541] Trial 8 finished with value: 0.9674327043386606 and parameters: {'learning_rate': 0.05416042859861109, 'l1_coef': 0.0005462608969859107, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.6626547979039249, 'num_epochs': 191}. Best is trial 2 with value: 0.6965232074260712.\n",
      "[I 2024-05-23 01:29:51,721] Trial 10 finished with value: 0.6561497896909714 and parameters: {'learning_rate': 0.0008964250270869018, 'l1_coef': 1.1920108911949582e-10, 'patience': 10, 'batch_size': 128, 'lr_factor': 0.6786565923803025, 'num_epochs': 436}. Best is trial 10 with value: 0.6561497896909714.\n",
      "[I 2024-05-23 01:30:04,893] Trial 6 finished with value: 0.9360469112029441 and parameters: {'learning_rate': 0.04498670065418437, 'l1_coef': 0.0005171197382042394, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.4246635684851868, 'num_epochs': 390}. Best is trial 10 with value: 0.6561497896909714.\n",
      "[I 2024-05-23 01:31:23,749] Trial 7 finished with value: 0.6661469310522079 and parameters: {'learning_rate': 0.00040754838443553384, 'l1_coef': 1.929409023840465e-05, 'patience': 8, 'batch_size': 128, 'lr_factor': 0.779387438135835, 'num_epochs': 363}. Best is trial 10 with value: 0.6561497896909714.\n",
      "[I 2024-05-23 01:31:27,720] Trial 15 finished with value: 1.2454706192016602 and parameters: {'learning_rate': 0.08501810627914083, 'l1_coef': 0.0014982406580200454, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.6595943175361851, 'num_epochs': 311}. Best is trial 10 with value: 0.6561497896909714.\n",
      "[I 2024-05-23 01:32:18,381] Trial 18 finished with value: 0.7180061042308807 and parameters: {'learning_rate': 0.00012307483957975685, 'l1_coef': 2.039445096951231e-06, 'patience': 6, 'batch_size': 256, 'lr_factor': 0.5906530976036439, 'num_epochs': 312}. Best is trial 10 with value: 0.6561497896909714.\n",
      "[I 2024-05-23 01:32:52,963] Trial 19 finished with value: 0.6403008937835694 and parameters: {'learning_rate': 0.001149587173656793, 'l1_coef': 7.248869996670865e-10, 'patience': 15, 'batch_size': 128, 'lr_factor': 0.8965533461636112, 'num_epochs': 484}. Best is trial 19 with value: 0.6403008937835694.\n",
      "[I 2024-05-23 01:32:57,700] Trial 9 finished with value: 0.7123487770557404 and parameters: {'learning_rate': 5.053142724050183e-05, 'l1_coef': 4.188791901861692e-10, 'patience': 9, 'batch_size': 128, 'lr_factor': 0.12338014047210058, 'num_epochs': 270}. Best is trial 19 with value: 0.6403008937835694.\n",
      "[I 2024-05-23 01:33:04,613] Trial 20 finished with value: 0.6719448238611221 and parameters: {'learning_rate': 0.0027200534525395293, 'l1_coef': 4.837824510364032e-10, 'patience': 14, 'batch_size': 128, 'lr_factor': 0.8893377166426438, 'num_epochs': 473}. Best is trial 19 with value: 0.6403008937835694.\n",
      "[I 2024-05-23 01:33:14,944] Trial 17 finished with value: 0.6571308035116928 and parameters: {'learning_rate': 0.0021919203075641417, 'l1_coef': 1.1927186847171197e-07, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.328000792912591, 'num_epochs': 116}. Best is trial 19 with value: 0.6403008937835694.\n",
      "[I 2024-05-23 01:33:23,900] Trial 21 finished with value: 0.6821334391832352 and parameters: {'learning_rate': 0.0026657170762844165, 'l1_coef': 2.0548082277315705e-09, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.8978313718122924, 'num_epochs': 498}. Best is trial 19 with value: 0.6403008937835694.\n",
      "[I 2024-05-23 01:33:46,668] Trial 13 finished with value: 0.6745472834660458 and parameters: {'learning_rate': 0.00022032771032527387, 'l1_coef': 4.6516634834482346e-05, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.8041074474175808, 'num_epochs': 262}. Best is trial 19 with value: 0.6403008937835694.\n",
      "[I 2024-05-23 01:34:05,645] Trial 22 finished with value: 0.6577966332435607 and parameters: {'learning_rate': 0.0025940031150153125, 'l1_coef': 4.531660203213479e-09, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.8789181991610521, 'num_epochs': 478}. Best is trial 19 with value: 0.6403008937835694.\n",
      "[I 2024-05-23 01:34:37,639] Trial 25 finished with value: 0.6722662836313248 and parameters: {'learning_rate': 0.0025215411946489267, 'l1_coef': 1.2293482664042414e-08, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.8740364639174352, 'num_epochs': 500}. Best is trial 19 with value: 0.6403008937835694.\n",
      "[I 2024-05-23 01:34:47,616] Trial 23 finished with value: 0.6516996473073959 and parameters: {'learning_rate': 0.002177732253539287, 'l1_coef': 2.5648961181311836e-10, 'patience': 14, 'batch_size': 128, 'lr_factor': 0.8984847473240616, 'num_epochs': 482}. Best is trial 19 with value: 0.6403008937835694.\n",
      "[I 2024-05-23 01:35:16,370] Trial 26 finished with value: 0.6950317621231079 and parameters: {'learning_rate': 0.003955188430604488, 'l1_coef': 1.5417315959000366e-08, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.8896796367535822, 'num_epochs': 500}. Best is trial 19 with value: 0.6403008937835694.\n",
      "[I 2024-05-23 01:35:21,605] Trial 29 finished with value: 0.8170934915542603 and parameters: {'learning_rate': 0.012779844680484584, 'l1_coef': 3.213493177264395e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.7400947902815106, 'num_epochs': 425}. Best is trial 19 with value: 0.6403008937835694.\n",
      "[I 2024-05-23 01:35:49,539] Trial 28 finished with value: 3.2221251845359804 and parameters: {'learning_rate': 0.01098959562755125, 'l1_coef': 0.07249711324078092, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.7423680208207208, 'num_epochs': 441}. Best is trial 19 with value: 0.6403008937835694.\n",
      "[I 2024-05-23 01:36:21,101] Trial 31 finished with value: 0.8127091139554977 and parameters: {'learning_rate': 0.011029971488010552, 'l1_coef': 1.186737783467841e-08, 'patience': 15, 'batch_size': 128, 'lr_factor': 0.7600978389134803, 'num_epochs': 431}. Best is trial 19 with value: 0.6403008937835694.\n",
      "[I 2024-05-23 01:36:47,742] Trial 27 finished with value: 0.6363860309123993 and parameters: {'learning_rate': 0.0009614113860471687, 'l1_coef': 1.1362223038455439e-08, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.7789653009697641, 'num_epochs': 440}. Best is trial 27 with value: 0.6363860309123993.\n",
      "[I 2024-05-23 01:37:13,532] Trial 24 finished with value: 0.7217566192150116 and parameters: {'learning_rate': 0.00343693844742995, 'l1_coef': 2.2593270943093927e-08, 'patience': 14, 'batch_size': 128, 'lr_factor': 0.8875730428631305, 'num_epochs': 485}. Best is trial 27 with value: 0.6363860309123993.\n",
      "[I 2024-05-23 01:37:43,204] Trial 30 finished with value: 0.8570888060789841 and parameters: {'learning_rate': 0.011559432730131445, 'l1_coef': 4.364251055349845e-08, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.42346365602977853, 'num_epochs': 103}. Best is trial 27 with value: 0.6363860309123993.\n",
      "[I 2024-05-23 01:39:40,179] Trial 32 finished with value: 0.627088439464569 and parameters: {'learning_rate': 0.0006177640035526218, 'l1_coef': 1.0720147237841658e-10, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.7608171896512039, 'num_epochs': 431}. Best is trial 32 with value: 0.627088439464569.\n",
      "[I 2024-05-23 01:40:03,462] Trial 33 finished with value: 0.6251402241843087 and parameters: {'learning_rate': 0.00068978303889016, 'l1_coef': 1.087167384351527e-10, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.7095087008622978, 'num_epochs': 439}. Best is trial 33 with value: 0.6251402241843087.\n",
      "[I 2024-05-23 01:41:01,190] Trial 34 finished with value: 0.6318010466439383 and parameters: {'learning_rate': 0.0007897999058365114, 'l1_coef': 8.760840568952064e-10, 'patience': 14, 'batch_size': 64, 'lr_factor': 0.6912516288901771, 'num_epochs': 444}. Best is trial 33 with value: 0.6251402241843087.\n",
      "[I 2024-05-23 01:41:09,771] Trial 16 finished with value: 0.9255294233560563 and parameters: {'learning_rate': 0.00021343751764473954, 'l1_coef': 0.00919382298571781, 'patience': 11, 'batch_size': 128, 'lr_factor': 0.6412890314639539, 'num_epochs': 275}. Best is trial 33 with value: 0.6251402241843087.\n",
      "[I 2024-05-23 01:41:50,252] Trial 37 finished with value: 0.6257824608257838 and parameters: {'learning_rate': 0.0007169162311367174, 'l1_coef': 1.4422223407933771e-09, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.8266696745203327, 'num_epochs': 454}. Best is trial 33 with value: 0.6251402241843087.\n",
      "[I 2024-05-23 01:42:11,603] Trial 35 finished with value: 0.6310009990419662 and parameters: {'learning_rate': 0.0006819885254595134, 'l1_coef': 1.0411205490458839e-10, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.6726051778819423, 'num_epochs': 444}. Best is trial 33 with value: 0.6251402241843087.\n",
      "[I 2024-05-23 01:42:18,455] Trial 38 finished with value: 0.6267409001077924 and parameters: {'learning_rate': 0.0005450709053188164, 'l1_coef': 1.7683782395142565e-09, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.814389670214982, 'num_epochs': 407}. Best is trial 33 with value: 0.6251402241843087.\n",
      "[I 2024-05-23 01:43:39,686] Trial 36 finished with value: 0.6217222213745117 and parameters: {'learning_rate': 0.0007147549431054957, 'l1_coef': 1.1615645615549191e-09, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.8183630129393342, 'num_epochs': 458}. Best is trial 36 with value: 0.6217222213745117.\n",
      "[I 2024-05-23 01:44:21,254] Trial 40 finished with value: 0.6341199500220163 and parameters: {'learning_rate': 0.0007938397240787842, 'l1_coef': 1.6211412390004548e-09, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.8062044015085259, 'num_epochs': 456}. Best is trial 36 with value: 0.6217222213745117.\n",
      "[I 2024-05-23 01:46:29,426] Trial 39 finished with value: 0.6202970828328814 and parameters: {'learning_rate': 0.0006989678900510476, 'l1_coef': 2.0534905375348637e-09, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.8205783039238171, 'num_epochs': 455}. Best is trial 39 with value: 0.6202970828328814.\n",
      "[I 2024-05-23 01:46:29,909] Trial 41 finished with value: 0.617128506728581 and parameters: {'learning_rate': 0.0005072672357316685, 'l1_coef': 1.699273456405907e-09, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.5940147204294185, 'num_epochs': 344}. Best is trial 41 with value: 0.617128506728581.\n",
      "[I 2024-05-23 01:46:34,844] Trial 42 finished with value: 0.615878507069179 and parameters: {'learning_rate': 0.0005975393104293414, 'l1_coef': 1.8829824683234204e-09, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.8284959194436654, 'num_epochs': 341}. Best is trial 42 with value: 0.615878507069179.\n",
      "[I 2024-05-23 01:47:19,788] Trial 43 finished with value: 0.6188729456492832 and parameters: {'learning_rate': 0.0004630659051673888, 'l1_coef': 1.7216988905636553e-09, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.7061857163645295, 'num_epochs': 339}. Best is trial 42 with value: 0.615878507069179.\n",
      "[I 2024-05-23 01:51:42,209] Trial 48 finished with value: 0.6630669695990428 and parameters: {'learning_rate': 9.922976246133816e-05, 'l1_coef': 1.1349609135415092e-07, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.8313509145500065, 'num_epochs': 339}. Best is trial 42 with value: 0.615878507069179.\n",
      "[I 2024-05-23 01:53:01,165] Trial 44 finished with value: 0.7107029318809509 and parameters: {'learning_rate': 2.2500160390193414e-05, 'l1_coef': 2.8374125579863076e-09, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.8323912233779959, 'num_epochs': 400}. Best is trial 42 with value: 0.615878507069179.\n",
      "[I 2024-05-23 01:54:00,302] Trial 46 finished with value: 0.705836352280208 and parameters: {'learning_rate': 2.5525120346790127e-05, 'l1_coef': 2.7083287654762878e-09, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.8180701566492148, 'num_epochs': 384}. Best is trial 42 with value: 0.615878507069179.\n",
      "[I 2024-05-23 01:54:57,431] Trial 47 finished with value: 0.7081417271069118 and parameters: {'learning_rate': 2.3766698353215824e-05, 'l1_coef': 3.256847986475578e-09, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.819726552403816, 'num_epochs': 398}. Best is trial 42 with value: 0.615878507069179.\n",
      "[I 2024-05-23 01:55:18,241] Trial 5 finished with value: 0.7902935926730815 and parameters: {'learning_rate': 2.9910422393143706e-06, 'l1_coef': 2.568303580594125e-09, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.5477373932353057, 'num_epochs': 283}. Best is trial 42 with value: 0.615878507069179.\n",
      "[I 2024-05-23 01:55:26,515] Trial 50 finished with value: 0.7206370966775077 and parameters: {'learning_rate': 2.3270121021097907e-05, 'l1_coef': 5.306444448332578e-09, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.567543787646376, 'num_epochs': 333}. Best is trial 42 with value: 0.615878507069179.\n",
      "[I 2024-05-23 01:55:28,425] Trial 49 finished with value: 0.7146887830325536 and parameters: {'learning_rate': 2.444724664521848e-05, 'l1_coef': 3.209564480089055e-09, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.5298765850837863, 'num_epochs': 336}. Best is trial 42 with value: 0.615878507069179.\n",
      "[I 2024-05-23 01:55:55,877] Trial 51 finished with value: 0.718698946067265 and parameters: {'learning_rate': 2.3625058177353012e-05, 'l1_coef': 1.474042133846455e-07, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.6108651902579829, 'num_epochs': 338}. Best is trial 42 with value: 0.615878507069179.\n",
      "[I 2024-05-23 01:56:35,215] Trial 53 finished with value: 0.623463009084974 and parameters: {'learning_rate': 0.0003256047748429899, 'l1_coef': 4.628237026462463e-09, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.5871290469195699, 'num_epochs': 348}. Best is trial 42 with value: 0.615878507069179.\n",
      "[I 2024-05-23 01:56:46,601] Trial 54 finished with value: 0.6319404465811593 and parameters: {'learning_rate': 0.0003175086109243453, 'l1_coef': 6.179140812721082e-09, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.5978925065507832, 'num_epochs': 340}. Best is trial 42 with value: 0.615878507069179.\n",
      "[I 2024-05-23 01:57:17,091] Trial 45 finished with value: 0.7630714433533805 and parameters: {'learning_rate': 6.779875342243227e-06, 'l1_coef': 3.4571159612758144e-09, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.8252611003887733, 'num_epochs': 398}. Best is trial 42 with value: 0.615878507069179.\n",
      "[I 2024-05-23 01:57:30,434] Trial 12 finished with value: 1.0125591333095845 and parameters: {'learning_rate': 9.529499769403326e-06, 'l1_coef': 0.035613094482846025, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.6175230140612346, 'num_epochs': 372}. Best is trial 42 with value: 0.615878507069179.\n",
      "[I 2024-05-23 01:58:12,523] Trial 52 finished with value: 0.7929189222199575 and parameters: {'learning_rate': 4.050850034050107e-06, 'l1_coef': 4.446623471824391e-09, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.524844679887797, 'num_epochs': 381}. Best is trial 42 with value: 0.615878507069179.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 3 - Best hyperparameters: {'learning_rate': 0.0005975393104293414, 'l1_coef': 1.8829824683234204e-09, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.8284959194436654, 'num_epochs': 341}\n",
      "Chr 3 - Best value: 0.6159\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr3/final_model_chr3.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr3/individual_r2_scores_chr3.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr3/individual_iqs_scores_chr3.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  1261\n",
      "PRS313 SNPs:  11\n",
      "Total SNPs used for Training:  1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 02:00:33,174] Trial 11 finished with value: 2.4931845903396606 and parameters: {'learning_rate': 0.011245290580186019, 'l1_coef': 0.039325845432566106, 'patience': 15, 'batch_size': 256, 'lr_factor': 0.8565831216668033, 'num_epochs': 103}. Best is trial 2 with value: 0.708555577482496.\n",
      "[I 2024-05-23 02:01:02,844] Trial 7 finished with value: 1.0018303215503692 and parameters: {'learning_rate': 0.007727287316716521, 'l1_coef': 0.004856178056202063, 'patience': 19, 'batch_size': 256, 'lr_factor': 0.108760016441415, 'num_epochs': 257}. Best is trial 2 with value: 0.708555577482496.\n",
      "[I 2024-05-23 02:01:45,801] Trial 14 finished with value: 0.9755349576473236 and parameters: {'learning_rate': 0.04068351138985178, 'l1_coef': 0.006803986206437246, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.10579023596064392, 'num_epochs': 312}. Best is trial 2 with value: 0.708555577482496.\n",
      "[I 2024-05-23 02:02:27,836] Trial 8 finished with value: 1.0626657247543334 and parameters: {'learning_rate': 0.00040054055304013, 'l1_coef': 0.02200223002039567, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.5897342474052517, 'num_epochs': 109}. Best is trial 2 with value: 0.708555577482496.\n",
      "[I 2024-05-23 02:03:13,861] Trial 12 finished with value: 0.7716108083724975 and parameters: {'learning_rate': 0.015667827251684547, 'l1_coef': 5.486480231948181e-06, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.19383835825201104, 'num_epochs': 414}. Best is trial 2 with value: 0.708555577482496.\n",
      "[I 2024-05-23 02:03:26,777] Trial 15 finished with value: 0.6997047339166913 and parameters: {'learning_rate': 0.0005277486554131234, 'l1_coef': 9.718568325254402e-10, 'patience': 12, 'batch_size': 64, 'lr_factor': 0.7232559350940458, 'num_epochs': 173}. Best is trial 15 with value: 0.6997047339166913.\n",
      "[I 2024-05-23 02:04:08,886] Trial 5 finished with value: 0.9025268733501435 and parameters: {'learning_rate': 1.4671462101106936e-05, 'l1_coef': 6.77965976956072e-05, 'patience': 13, 'batch_size': 256, 'lr_factor': 0.4132398107278996, 'num_epochs': 370}. Best is trial 15 with value: 0.6997047339166913.\n",
      "[I 2024-05-23 02:04:16,191] Trial 6 finished with value: 1.0205358862876894 and parameters: {'learning_rate': 0.06328780610803783, 'l1_coef': 8.40904215299798e-09, 'patience': 14, 'batch_size': 64, 'lr_factor': 0.8824478901917221, 'num_epochs': 137}. Best is trial 15 with value: 0.6997047339166913.\n",
      "[I 2024-05-23 02:04:47,528] Trial 10 finished with value: 1.017899542588454 and parameters: {'learning_rate': 0.0643492613933613, 'l1_coef': 1.594208782680602e-08, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.8662081015669952, 'num_epochs': 108}. Best is trial 15 with value: 0.6997047339166913.\n",
      "[I 2024-05-23 02:06:51,989] Trial 20 finished with value: 0.9847425273486546 and parameters: {'learning_rate': 0.06361145702965527, 'l1_coef': 3.6261108347129846e-09, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.4165190193632835, 'num_epochs': 493}. Best is trial 15 with value: 0.6997047339166913.\n",
      "[I 2024-05-23 02:07:16,682] Trial 22 finished with value: 0.699705217565809 and parameters: {'learning_rate': 0.0004778670658032333, 'l1_coef': 1.9806042607532111e-10, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.6657475355791449, 'num_epochs': 193}. Best is trial 15 with value: 0.6997047339166913.\n",
      "[I 2024-05-23 02:07:29,067] Trial 19 finished with value: 0.7998571813106536 and parameters: {'learning_rate': 6.750430092584557e-05, 'l1_coef': 5.199632907288873e-10, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.49442693240932734, 'num_epochs': 267}. Best is trial 15 with value: 0.6997047339166913.\n",
      "[I 2024-05-23 02:07:56,807] Trial 23 finished with value: 0.6934243440628052 and parameters: {'learning_rate': 0.0006123063118511881, 'l1_coef': 1.483356743507346e-10, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.6430215930500488, 'num_epochs': 208}. Best is trial 23 with value: 0.6934243440628052.\n",
      "[I 2024-05-23 02:08:32,124] Trial 18 finished with value: 1.090661484003067 and parameters: {'learning_rate': 1.3066965857185963e-05, 'l1_coef': 0.08407465170569402, 'patience': 6, 'batch_size': 128, 'lr_factor': 0.487631503307543, 'num_epochs': 387}. Best is trial 23 with value: 0.6934243440628052.\n",
      "[I 2024-05-23 02:09:51,915] Trial 24 finished with value: 0.7058935591152736 and parameters: {'learning_rate': 0.0012351399671312938, 'l1_coef': 2.9134444626744294e-10, 'patience': 10, 'batch_size': 64, 'lr_factor': 0.6326416037905487, 'num_epochs': 193}. Best is trial 23 with value: 0.6934243440628052.\n",
      "[I 2024-05-23 02:12:18,943] Trial 25 finished with value: 0.7577207207679748 and parameters: {'learning_rate': 6.965595803259108e-05, 'l1_coef': 1.1949028534579393e-10, 'patience': 8, 'batch_size': 64, 'lr_factor': 0.6776764903126861, 'num_epochs': 188}. Best is trial 23 with value: 0.6934243440628052.\n",
      "[I 2024-05-23 02:14:05,370] Trial 17 finished with value: 0.9654308378696441 and parameters: {'learning_rate': 1.2188478014607994e-06, 'l1_coef': 4.0553007748208686e-07, 'patience': 11, 'batch_size': 128, 'lr_factor': 0.5930984224846435, 'num_epochs': 280}. Best is trial 23 with value: 0.6934243440628052.\n",
      "[I 2024-05-23 02:14:40,176] Trial 9 finished with value: 0.8877811551094055 and parameters: {'learning_rate': 4.2804220855076236e-06, 'l1_coef': 7.793516514479289e-10, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.6078921893922171, 'num_epochs': 255}. Best is trial 23 with value: 0.6934243440628052.\n",
      "[I 2024-05-23 02:14:48,883] Trial 16 finished with value: 0.8951808367456708 and parameters: {'learning_rate': 4.4138234659480584e-06, 'l1_coef': 1.4413776166186315e-08, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.6531773007087174, 'num_epochs': 219}. Best is trial 23 with value: 0.6934243440628052.\n",
      "[I 2024-05-23 02:15:04,883] Trial 13 finished with value: 1.0940560340881347 and parameters: {'learning_rate': 6.4828527785753325e-06, 'l1_coef': 0.029628727400768707, 'patience': 19, 'batch_size': 128, 'lr_factor': 0.37878542004891447, 'num_epochs': 375}. Best is trial 23 with value: 0.6934243440628052.\n",
      "[I 2024-05-23 02:15:51,464] Trial 21 finished with value: 0.9664967945643832 and parameters: {'learning_rate': 1.3525759411069805e-06, 'l1_coef': 3.0631684423522266e-10, 'patience': 8, 'batch_size': 64, 'lr_factor': 0.7287514343160181, 'num_epochs': 188}. Best is trial 23 with value: 0.6934243440628052.\n",
      "[I 2024-05-23 02:17:28,251] Trial 34 finished with value: 0.7158474854060582 and parameters: {'learning_rate': 0.00031524587343053425, 'l1_coef': 7.507681537178167e-08, 'patience': 8, 'batch_size': 64, 'lr_factor': 0.7554850383709935, 'num_epochs': 162}. Best is trial 23 with value: 0.6934243440628052.\n",
      "[I 2024-05-23 02:17:29,482] Trial 32 finished with value: 0.6802440898759023 and parameters: {'learning_rate': 0.00039798697327114734, 'l1_coef': 7.559889040032319e-08, 'patience': 8, 'batch_size': 64, 'lr_factor': 0.7301102557055886, 'num_epochs': 197}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:18:28,254] Trial 33 finished with value: 0.6954864575312687 and parameters: {'learning_rate': 0.00038971112242043555, 'l1_coef': 8.69048879441252e-08, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.7720540200809586, 'num_epochs': 161}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:18:50,240] Trial 31 finished with value: 0.7243902169741117 and parameters: {'learning_rate': 7.34223655211584e-05, 'l1_coef': 7.469760786406702e-08, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.7696455709237225, 'num_epochs': 221}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:19:02,240] Trial 26 finished with value: 0.9683166095188686 and parameters: {'learning_rate': 1.2627124159430425e-06, 'l1_coef': 1.0145783545669141e-10, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.6855307573609986, 'num_epochs': 188}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:19:22,383] Trial 27 finished with value: 0.9068550961358206 and parameters: {'learning_rate': 3.864874361487724e-06, 'l1_coef': 1.0896327456701939e-07, 'patience': 10, 'batch_size': 64, 'lr_factor': 0.7342101277064096, 'num_epochs': 188}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:19:24,643] Trial 35 finished with value: 0.6902440089445847 and parameters: {'learning_rate': 0.00024704184718520787, 'l1_coef': 1.5418835507888528e-07, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.7700286498858806, 'num_epochs': 155}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:19:26,834] Trial 28 finished with value: 0.9551129988261632 and parameters: {'learning_rate': 1.3758604744932118e-06, 'l1_coef': 6.607639061410363e-08, 'patience': 10, 'batch_size': 64, 'lr_factor': 0.7366292679074241, 'num_epochs': 179}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:20:39,845] Trial 37 finished with value: 0.7292816859025221 and parameters: {'learning_rate': 0.00012615717596819586, 'l1_coef': 9.715545531247858e-08, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.7869928201334614, 'num_epochs': 143}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:21:37,863] Trial 41 finished with value: 0.7334178667802077 and parameters: {'learning_rate': 0.002131812070886744, 'l1_coef': 9.772694873844379e-07, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.8096975025952946, 'num_epochs': 146}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:21:43,932] Trial 39 finished with value: 0.7179020927502558 and parameters: {'learning_rate': 0.00015376030867108624, 'l1_coef': 6.48683874097053e-06, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.8173479312065216, 'num_epochs': 135}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:21:56,361] Trial 38 finished with value: 0.7157958287459154 and parameters: {'learning_rate': 0.00012273097317486772, 'l1_coef': 1.767725109947227e-07, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.8091933162182472, 'num_epochs': 163}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:22:00,470] Trial 40 finished with value: 0.731248913361476 and parameters: {'learning_rate': 0.0001321001120289731, 'l1_coef': 1.4718307032690657e-06, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.7837620741868265, 'num_epochs': 139}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:22:22,350] Trial 36 finished with value: 0.7017109265694252 and parameters: {'learning_rate': 0.0003957787533960147, 'l1_coef': 1.6740798778747624e-09, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.7797593648209982, 'num_epochs': 227}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:22:27,431] Trial 42 finished with value: 0.7178365579018227 and parameters: {'learning_rate': 0.00019198747458897333, 'l1_coef': 2.7190740788833424e-06, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.8051030769954044, 'num_epochs': 145}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:22:28,234] Trial 43 finished with value: 0.7134315096415007 and parameters: {'learning_rate': 0.0001635839399828028, 'l1_coef': 2.4412941672017064e-06, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.8116670074216676, 'num_epochs': 144}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:23:54,566] Trial 47 finished with value: 0.732940007173098 and parameters: {'learning_rate': 0.003971836966471483, 'l1_coef': 2.0839818460651278e-05, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.5532886801804693, 'num_epochs': 230}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:24:06,064] Trial 49 finished with value: 0.7423873589589045 and parameters: {'learning_rate': 0.005418695075155145, 'l1_coef': 3.809555706127774e-05, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.8919923433494253, 'num_epochs': 216}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:25:07,235] Trial 44 finished with value: 0.6968485116958618 and parameters: {'learning_rate': 0.001449689368157183, 'l1_coef': 2.6098474578252935e-06, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.8028295547161882, 'num_epochs': 220}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:25:10,957] Trial 46 finished with value: 0.7152188191047082 and parameters: {'learning_rate': 0.0011259428862297255, 'l1_coef': 2.5857682703455905e-05, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.5767198486170987, 'num_epochs': 224}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:25:14,934] Trial 48 finished with value: 0.7261827633931086 and parameters: {'learning_rate': 0.000989786594651358, 'l1_coef': 5.5722284466361924e-05, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.542867730245909, 'num_epochs': 225}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:25:20,198] Trial 50 finished with value: 0.7296067302043622 and parameters: {'learning_rate': 0.0011546447913511316, 'l1_coef': 6.836348759208326e-05, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.5520797983841367, 'num_epochs': 235}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:25:36,521] Trial 51 finished with value: 0.7557316367442792 and parameters: {'learning_rate': 0.0010636180122437261, 'l1_coef': 0.0002319441365457792, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.5429361101800046, 'num_epochs': 212}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:25:46,269] Trial 45 finished with value: 0.6890845399636489 and parameters: {'learning_rate': 0.0001917428502453021, 'l1_coef': 7.8668932265121e-06, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.8269047892847746, 'num_epochs': 213}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:26:00,508] Trial 53 finished with value: 0.6912476709910801 and parameters: {'learning_rate': 0.0009668212257345393, 'l1_coef': 3.036330159206641e-09, 'patience': 12, 'batch_size': 64, 'lr_factor': 0.7075304235322849, 'num_epochs': 172}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:26:03,251] Trial 30 finished with value: 0.9162872919669518 and parameters: {'learning_rate': 2.0625269965087227e-06, 'l1_coef': 7.825250199268564e-08, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.7473368698073433, 'num_epochs': 158}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:26:03,673] Trial 52 finished with value: 0.7211400066103255 and parameters: {'learning_rate': 0.0009637437689106631, 'l1_coef': 6.657256154768573e-09, 'patience': 12, 'batch_size': 64, 'lr_factor': 0.702868454629191, 'num_epochs': 208}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:26:07,804] Trial 29 finished with value: 0.9097138707454387 and parameters: {'learning_rate': 1.9801764968984262e-06, 'l1_coef': 1.4355169125588892e-07, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.7300051880948211, 'num_epochs': 191}. Best is trial 32 with value: 0.6802440898759023.\n",
      "[I 2024-05-23 02:26:08,276] Trial 54 finished with value: 0.7328988469563997 and parameters: {'learning_rate': 0.0009632728723433833, 'l1_coef': 0.00011338223867737599, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.8489766363656439, 'num_epochs': 279}. Best is trial 32 with value: 0.6802440898759023.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 4 - Best hyperparameters: {'learning_rate': 0.00039798697327114734, 'l1_coef': 7.559889040032319e-08, 'patience': 8, 'batch_size': 64, 'lr_factor': 0.7301102557055886, 'num_epochs': 197}\n",
      "Chr 4 - Best value: 0.6802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 02:26:19,283] A new study created in RDB with name: unphased_full_23andMe_chr5_study_logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr4/final_model_chr4.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr4/individual_r2_scores_chr4.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr4/individual_iqs_scores_chr4.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  1289\n",
      "PRS313 SNPs:  34\n",
      "Total SNPs used for Training:  1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 02:27:21,202] Trial 3 finished with value: 0.9277197003364563 and parameters: {'learning_rate': 0.05518587130574987, 'l1_coef': 1.6028956002860537e-09, 'patience': 11, 'batch_size': 256, 'lr_factor': 0.37386405450917326, 'num_epochs': 346}. Best is trial 3 with value: 0.9277197003364563.\n",
      "[I 2024-05-23 02:27:37,772] Trial 2 finished with value: 0.7720308808180001 and parameters: {'learning_rate': 0.0029887488601876497, 'l1_coef': 2.1965620760789075e-10, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.15267135289836695, 'num_epochs': 439}. Best is trial 2 with value: 0.7720308808180001.\n",
      "[I 2024-05-23 02:27:48,502] Trial 1 finished with value: 0.8217635035514832 and parameters: {'learning_rate': 7.817552333659174e-05, 'l1_coef': 2.5149723674784266e-07, 'patience': 8, 'batch_size': 128, 'lr_factor': 0.5902199729484313, 'num_epochs': 109}. Best is trial 2 with value: 0.7720308808180001.\n",
      "[I 2024-05-23 02:28:03,345] Trial 7 finished with value: 1.2789726495742797 and parameters: {'learning_rate': 0.04795016185314418, 'l1_coef': 0.00171968347965705, 'patience': 6, 'batch_size': 128, 'lr_factor': 0.19253778010122452, 'num_epochs': 221}. Best is trial 2 with value: 0.7720308808180001.\n",
      "[I 2024-05-23 02:29:00,774] Trial 6 finished with value: 0.8989979445934295 and parameters: {'learning_rate': 0.012044381121559745, 'l1_coef': 7.262403100547825e-07, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.22320903296338568, 'num_epochs': 388}. Best is trial 2 with value: 0.7720308808180001.\n",
      "[I 2024-05-23 02:30:34,021] Trial 13 finished with value: 0.7096261233091354 and parameters: {'learning_rate': 0.001142427175863052, 'l1_coef': 1.0716782146779068e-08, 'patience': 8, 'batch_size': 128, 'lr_factor': 0.3091965303655769, 'num_epochs': 442}. Best is trial 13 with value: 0.7096261233091354.\n",
      "[I 2024-05-23 02:31:27,795] Trial 8 finished with value: 0.8873181223869324 and parameters: {'learning_rate': 4.60223262418476e-06, 'l1_coef': 1.182099147863135e-10, 'patience': 6, 'batch_size': 256, 'lr_factor': 0.349029729792493, 'num_epochs': 335}. Best is trial 13 with value: 0.7096261233091354.\n",
      "[I 2024-05-23 02:31:46,651] Trial 0 finished with value: 0.7283795101302011 and parameters: {'learning_rate': 0.0003443632280068717, 'l1_coef': 1.172506945135667e-05, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.7730346960929614, 'num_epochs': 324}. Best is trial 13 with value: 0.7096261233091354.\n",
      "[I 2024-05-23 02:32:36,142] Trial 10 finished with value: 0.8138892441987992 and parameters: {'learning_rate': 2.717484388249537e-05, 'l1_coef': 8.510984287248608e-07, 'patience': 19, 'batch_size': 128, 'lr_factor': 0.8576995681178871, 'num_epochs': 245}. Best is trial 13 with value: 0.7096261233091354.\n",
      "[I 2024-05-23 02:33:18,246] Trial 18 finished with value: 0.8607129335403443 and parameters: {'learning_rate': 0.010926676406545707, 'l1_coef': 5.971931559168606e-08, 'patience': 7, 'batch_size': 128, 'lr_factor': 0.3177979137354415, 'num_epochs': 129}. Best is trial 13 with value: 0.7096261233091354.\n",
      "[I 2024-05-23 02:34:14,849] Trial 17 finished with value: 0.8335305690765381 and parameters: {'learning_rate': 0.009185025297364707, 'l1_coef': 0.00022251552973311936, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.37378813838739544, 'num_epochs': 264}. Best is trial 13 with value: 0.7096261233091354.\n",
      "[I 2024-05-23 02:34:18,009] Trial 11 finished with value: 0.886025893688202 and parameters: {'learning_rate': 3.4317173306232325e-06, 'l1_coef': 1.3706543714386642e-09, 'patience': 7, 'batch_size': 256, 'lr_factor': 0.22674892139104916, 'num_epochs': 481}. Best is trial 13 with value: 0.7096261233091354.\n",
      "[I 2024-05-23 02:35:14,004] Trial 16 finished with value: 0.9916694368634905 and parameters: {'learning_rate': 0.07658064472912818, 'l1_coef': 1.6393858899083218e-06, 'patience': 16, 'batch_size': 64, 'lr_factor': 0.27523838190215894, 'num_epochs': 300}. Best is trial 13 with value: 0.7096261233091354.\n",
      "[I 2024-05-23 02:37:23,751] Trial 5 finished with value: 0.7082975424253023 and parameters: {'learning_rate': 5.756919066786952e-05, 'l1_coef': 7.885255954874306e-08, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.1775203964121741, 'num_epochs': 455}. Best is trial 5 with value: 0.7082975424253023.\n",
      "[I 2024-05-23 02:39:55,721] Trial 19 finished with value: 0.8229784522737775 and parameters: {'learning_rate': 0.0008553014810998426, 'l1_coef': 0.00029503067767174787, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.5348492968821953, 'num_epochs': 497}. Best is trial 5 with value: 0.7082975424253023.\n",
      "[I 2024-05-23 02:40:17,398] Trial 20 finished with value: 0.7665398699896675 and parameters: {'learning_rate': 0.0006286372941988328, 'l1_coef': 7.250548085968817e-05, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.6924582368873231, 'num_epochs': 489}. Best is trial 5 with value: 0.7082975424253023.\n",
      "[I 2024-05-23 02:40:20,310] Trial 21 finished with value: 0.7549375431878227 and parameters: {'learning_rate': 0.0006106027866901721, 'l1_coef': 5.367496793378701e-05, 'patience': 16, 'batch_size': 64, 'lr_factor': 0.6623545049890398, 'num_epochs': 417}. Best is trial 5 with value: 0.7082975424253023.\n",
      "[I 2024-05-23 02:40:52,709] Trial 22 finished with value: 0.7686635511262077 and parameters: {'learning_rate': 0.0007064022986855492, 'l1_coef': 7.945736820299859e-05, 'patience': 14, 'batch_size': 64, 'lr_factor': 0.6466649320873434, 'num_epochs': 413}. Best is trial 5 with value: 0.7082975424253023.\n",
      "[I 2024-05-23 02:41:29,667] Trial 12 finished with value: 1.084565457701683 and parameters: {'learning_rate': 2.295264949979012e-06, 'l1_coef': 0.0003949276291618843, 'patience': 14, 'batch_size': 128, 'lr_factor': 0.13402410186179337, 'num_epochs': 293}. Best is trial 5 with value: 0.7082975424253023.\n",
      "[I 2024-05-23 02:43:45,280] Trial 23 finished with value: 0.6746991249231191 and parameters: {'learning_rate': 0.0006592376275912017, 'l1_coef': 3.3296515576665647e-08, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.5144965326188866, 'num_epochs': 499}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 02:44:28,043] Trial 14 finished with value: 0.8424971433786246 and parameters: {'learning_rate': 5.001077764923083e-06, 'l1_coef': 1.2173630338152038e-05, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.5951839352535973, 'num_epochs': 349}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 02:49:30,806] Trial 27 finished with value: 0.7138274229489839 and parameters: {'learning_rate': 5.767069370657062e-05, 'l1_coef': 2.6841405141694506e-08, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.10201901513153194, 'num_epochs': 375}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 02:49:51,325] Trial 24 finished with value: 0.7102884659400354 and parameters: {'learning_rate': 5.5965029657416466e-05, 'l1_coef': 2.3578198343383337e-08, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.1174602808380501, 'num_epochs': 416}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 02:49:55,112] Trial 25 finished with value: 0.7032823810210596 and parameters: {'learning_rate': 6.845186832336609e-05, 'l1_coef': 2.2489534226925525e-08, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.46056315891052013, 'num_epochs': 422}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 02:51:09,563] Trial 9 finished with value: 0.9465166739055089 and parameters: {'learning_rate': 1.0569971529898548e-05, 'l1_coef': 0.0005417054548829154, 'patience': 14, 'batch_size': 64, 'lr_factor': 0.471275618060665, 'num_epochs': 371}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 02:51:27,286] Trial 4 finished with value: 1.0931845017841884 and parameters: {'learning_rate': 2.9226292134313763e-06, 'l1_coef': 0.018743384044340203, 'patience': 7, 'batch_size': 64, 'lr_factor': 0.5921393006106006, 'num_epochs': 374}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 02:51:41,026] Trial 28 finished with value: 0.702032707287715 and parameters: {'learning_rate': 6.493896975456543e-05, 'l1_coef': 4.5073299642372074e-08, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.4485453580630126, 'num_epochs': 445}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 02:52:58,721] Trial 29 finished with value: 0.7111622012578526 and parameters: {'learning_rate': 6.263721135897182e-05, 'l1_coef': 3.6671668587012863e-08, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.47061758131809855, 'num_epochs': 392}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 02:53:00,035] Trial 32 finished with value: 0.7576236825722914 and parameters: {'learning_rate': 0.00272665957448973, 'l1_coef': 5.638813523243521e-09, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.4422865391756601, 'num_epochs': 466}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 02:54:39,691] Trial 30 finished with value: 0.6973885086866526 and parameters: {'learning_rate': 7.2790716436427e-05, 'l1_coef': 2.0235415848130436e-08, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.45451289334734896, 'num_epochs': 453}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 02:56:22,389] Trial 15 finished with value: 0.9899171045848302 and parameters: {'learning_rate': 8.698775004954376e-06, 'l1_coef': 0.001310128559265361, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.8455606180255493, 'num_epochs': 391}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:00:15,880] Trial 34 finished with value: 0.6782235328967754 and parameters: {'learning_rate': 0.0001875598505291829, 'l1_coef': 4.336604851392529e-09, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.46073132511974874, 'num_epochs': 463}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:01:32,553] Trial 37 finished with value: 0.6797947865266065 and parameters: {'learning_rate': 0.0001980103205851602, 'l1_coef': 3.6836787077487867e-09, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.42227926859872383, 'num_epochs': 472}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:01:57,710] Trial 35 finished with value: 0.6820148733945993 and parameters: {'learning_rate': 0.00013257625468324295, 'l1_coef': 1.5729985339890493e-07, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.49032027380671894, 'num_epochs': 459}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:02:06,113] Trial 26 finished with value: 0.9643288878294138 and parameters: {'learning_rate': 6.150020001890075e-05, 'l1_coef': 0.08534637579665688, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.45839686983626193, 'num_epochs': 390}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:02:14,818] Trial 36 finished with value: 0.6758178802636954 and parameters: {'learning_rate': 0.00017324656513940663, 'l1_coef': 3.824374763393097e-09, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.44925302413388024, 'num_epochs': 469}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:03:25,383] Trial 38 finished with value: 0.708347237110138 and parameters: {'learning_rate': 0.00029240179522424346, 'l1_coef': 9.291877106087785e-06, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.4232222035308766, 'num_epochs': 464}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:05:09,565] Trial 40 finished with value: 0.6850960383048423 and parameters: {'learning_rate': 0.00021857136481654078, 'l1_coef': 1.9408688699299763e-07, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.42980629724466257, 'num_epochs': 437}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:05:10,684] Trial 31 finished with value: 0.9458727029653696 and parameters: {'learning_rate': 0.00010998487131006953, 'l1_coef': 0.05238104968516173, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.41883787552573626, 'num_epochs': 447}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:05:16,105] Trial 39 finished with value: 0.7072433444169851 and parameters: {'learning_rate': 0.00019678532705346273, 'l1_coef': 5.9594164402319155e-06, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.7674686688542971, 'num_epochs': 462}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:05:42,009] Trial 33 finished with value: 0.96030814739374 and parameters: {'learning_rate': 0.00013291675872275694, 'l1_coef': 0.0381470239457301, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.4468094314948444, 'num_epochs': 472}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:07:23,994] Trial 49 finished with value: 0.7100278317928315 and parameters: {'learning_rate': 0.001785138701669516, 'l1_coef': 6.700324435026601e-10, 'patience': 11, 'batch_size': 256, 'lr_factor': 0.5255711665985382, 'num_epochs': 498}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:07:46,860] Trial 47 finished with value: 0.735719027886024 and parameters: {'learning_rate': 0.0018904749497736693, 'l1_coef': 8.539083504467904e-10, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.5453676137713679, 'num_epochs': 478}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:07:47,453] Trial 48 finished with value: 0.7223874046252324 and parameters: {'learning_rate': 0.0019252060141767555, 'l1_coef': 6.654063999349215e-10, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.5157317934326392, 'num_epochs': 479}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:08:33,969] Trial 41 finished with value: 0.678869119974283 and parameters: {'learning_rate': 0.00023751125825765773, 'l1_coef': 1.7763977711183662e-07, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.523753151702112, 'num_epochs': 467}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:08:49,995] Trial 45 finished with value: 0.6770601006654593 and parameters: {'learning_rate': 0.00024059050160330845, 'l1_coef': 9.778488215888965e-10, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.540449301320588, 'num_epochs': 498}. Best is trial 23 with value: 0.6746991249231191.\n",
      "[I 2024-05-23 03:08:52,043] Trial 44 finished with value: 0.6736023572775034 and parameters: {'learning_rate': 0.0002151788812086546, 'l1_coef': 9.172285960688132e-10, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.5201558908781635, 'num_epochs': 472}. Best is trial 44 with value: 0.6736023572775034.\n",
      "[I 2024-05-23 03:08:55,469] Trial 42 finished with value: 0.6761788111466627 and parameters: {'learning_rate': 0.00021593895402173953, 'l1_coef': 8.870059423057632e-10, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.5310185378868041, 'num_epochs': 500}. Best is trial 44 with value: 0.6736023572775034.\n",
      "[I 2024-05-23 03:09:00,420] Trial 43 finished with value: 0.6774579790922312 and parameters: {'learning_rate': 0.0002098549599195537, 'l1_coef': 1.01068920013869e-09, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.5214414065931237, 'num_epochs': 477}. Best is trial 44 with value: 0.6736023572775034.\n",
      "[I 2024-05-23 03:09:14,036] Trial 46 finished with value: 0.6771469849806566 and parameters: {'learning_rate': 0.00017161657194856648, 'l1_coef': 6.932662962915364e-10, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.5354500372190486, 'num_epochs': 500}. Best is trial 44 with value: 0.6736023572775034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 5 - Best hyperparameters: {'learning_rate': 0.0002151788812086546, 'l1_coef': 9.172285960688132e-10, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.5201558908781635, 'num_epochs': 472}\n",
      "Chr 5 - Best value: 0.6736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 03:10:25,115] A new study created in RDB with name: unphased_full_23andMe_chr6_study_logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr5/final_model_chr5.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr5/individual_r2_scores_chr5.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr5/individual_iqs_scores_chr5.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  639\n",
      "PRS313 SNPs:  20\n",
      "Total SNPs used for Training:  619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 03:13:16,491] Trial 3 finished with value: 0.8941717880112785 and parameters: {'learning_rate': 0.03801522976806271, 'l1_coef': 0.00021693737321302141, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.29432075164849697, 'num_epochs': 408}. Best is trial 3 with value: 0.8941717880112785.\n",
      "[I 2024-05-23 03:13:32,124] Trial 1 finished with value: 0.8724246233701706 and parameters: {'learning_rate': 0.0012349034493688996, 'l1_coef': 0.0007052941734562021, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.6686653510126879, 'num_epochs': 158}. Best is trial 1 with value: 0.8724246233701706.\n",
      "[I 2024-05-23 03:13:34,479] Trial 8 finished with value: 2.8905107002991897 and parameters: {'learning_rate': 0.023940212974579947, 'l1_coef': 0.08500791924257381, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.5551303884607407, 'num_epochs': 390}. Best is trial 1 with value: 0.8724246233701706.\n",
      "[I 2024-05-23 03:14:01,770] Trial 10 finished with value: 0.9867209076881409 and parameters: {'learning_rate': 0.08423108054557688, 'l1_coef': 9.020599464437557e-10, 'patience': 10, 'batch_size': 64, 'lr_factor': 0.42182483231075785, 'num_epochs': 224}. Best is trial 1 with value: 0.8724246233701706.\n",
      "[I 2024-05-23 03:14:11,781] Trial 5 finished with value: 0.8276149868965149 and parameters: {'learning_rate': 3.236706942057442e-05, 'l1_coef': 1.12335033626385e-06, 'patience': 8, 'batch_size': 128, 'lr_factor': 0.798713720829521, 'num_epochs': 397}. Best is trial 5 with value: 0.8276149868965149.\n",
      "[I 2024-05-23 03:14:45,117] Trial 9 finished with value: 0.7144773811101913 and parameters: {'learning_rate': 0.0004559105501788491, 'l1_coef': 9.512298685383205e-08, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.6755731492101149, 'num_epochs': 438}. Best is trial 9 with value: 0.7144773811101913.\n",
      "[I 2024-05-23 03:15:37,514] Trial 14 finished with value: 3.6661906038011822 and parameters: {'learning_rate': 0.014778749940074786, 'l1_coef': 0.07881739898368328, 'patience': 7, 'batch_size': 64, 'lr_factor': 0.7303058515847519, 'num_epochs': 138}. Best is trial 9 with value: 0.7144773811101913.\n",
      "[I 2024-05-23 03:15:49,982] Trial 6 finished with value: 0.6938380654041584 and parameters: {'learning_rate': 0.0007051753092118109, 'l1_coef': 1.1976935141112294e-06, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.20759789864222322, 'num_epochs': 412}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:16:19,316] Trial 4 finished with value: 0.7387672083718436 and parameters: {'learning_rate': 0.00038280649776679325, 'l1_coef': 2.592437478206401e-05, 'patience': 14, 'batch_size': 64, 'lr_factor': 0.8891312834526479, 'num_epochs': 416}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:16:22,413] Trial 2 finished with value: 0.8632793852261134 and parameters: {'learning_rate': 0.000457965329736272, 'l1_coef': 0.0005695396512962399, 'patience': 17, 'batch_size': 64, 'lr_factor': 0.6297803301641088, 'num_epochs': 213}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:16:28,286] Trial 16 finished with value: 0.879090221111591 and parameters: {'learning_rate': 0.007246637287601412, 'l1_coef': 2.562591796058618e-07, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.802995854241121, 'num_epochs': 286}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:16:45,271] Trial 13 finished with value: 0.7501289674213953 and parameters: {'learning_rate': 0.0005997777079976861, 'l1_coef': 1.998624499483088e-05, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.5074692846105892, 'num_epochs': 173}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:18:54,516] Trial 17 finished with value: 0.724997702240944 and parameters: {'learning_rate': 0.001242314320248606, 'l1_coef': 7.989397805213601e-06, 'patience': 11, 'batch_size': 128, 'lr_factor': 0.7193695483378784, 'num_epochs': 478}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:20:53,339] Trial 11 finished with value: 0.9358830630779267 and parameters: {'learning_rate': 4.109918678707996e-06, 'l1_coef': 1.9630274448609192e-08, 'patience': 7, 'batch_size': 128, 'lr_factor': 0.263393107714802, 'num_epochs': 167}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:21:20,499] Trial 21 finished with value: 0.8495002627372742 and parameters: {'learning_rate': 3.15528775368892e-05, 'l1_coef': 7.448783157723112e-09, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.15872979268454024, 'num_epochs': 461}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:21:49,959] Trial 7 finished with value: 0.9981263548135757 and parameters: {'learning_rate': 7.928311939135885e-05, 'l1_coef': 0.004685477524189489, 'patience': 14, 'batch_size': 128, 'lr_factor': 0.8796038209754224, 'num_epochs': 261}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:22:21,586] Trial 18 finished with value: 0.934291023015976 and parameters: {'learning_rate': 2.539051710979494e-06, 'l1_coef': 5.222810331020344e-07, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.664471008173771, 'num_epochs': 138}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:23:50,601] Trial 20 finished with value: 0.8724470376968384 and parameters: {'learning_rate': 1.0760425659244003e-05, 'l1_coef': 1.5485968697071412e-08, 'patience': 18, 'batch_size': 256, 'lr_factor': 0.12923252056776538, 'num_epochs': 499}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:24:19,682] Trial 25 finished with value: 0.7151566578791692 and parameters: {'learning_rate': 0.0036303996375088177, 'l1_coef': 1.6885707421492333e-07, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.3657160662331203, 'num_epochs': 343}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:24:42,756] Trial 23 finished with value: 0.8141516149044037 and parameters: {'learning_rate': 5.9480524892200105e-05, 'l1_coef': 3.61656697090636e-08, 'patience': 19, 'batch_size': 256, 'lr_factor': 0.18191894812145812, 'num_epochs': 480}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:24:57,339] Trial 26 finished with value: 0.7615657751376812 and parameters: {'learning_rate': 0.003713142739252476, 'l1_coef': 6.45835310646588e-08, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.40572957129304016, 'num_epochs': 349}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:25:35,854] Trial 15 finished with value: 1.0065202832221984 and parameters: {'learning_rate': 0.0007410466352006862, 'l1_coef': 0.06315885094633708, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.3469027996073096, 'num_epochs': 498}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:26:02,638] Trial 22 finished with value: 0.833366060256958 and parameters: {'learning_rate': 2.5263473590292517e-05, 'l1_coef': 1.7069645034519778e-08, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.1349220855255246, 'num_epochs': 491}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:26:43,902] Trial 0 finished with value: 0.9468502704913799 and parameters: {'learning_rate': 0.0003310329200486522, 'l1_coef': 0.010617647910248391, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.5561855755759967, 'num_epochs': 488}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:26:59,242] Trial 27 finished with value: 0.7265654050386869 and parameters: {'learning_rate': 0.0033183954999037985, 'l1_coef': 1.194621675212721e-10, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.3979553627142159, 'num_epochs': 333}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:27:10,006] Trial 30 finished with value: 0.7241986201359675 and parameters: {'learning_rate': 0.0028724794652403777, 'l1_coef': 2.2342610172241652e-10, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.33676025609315086, 'num_epochs': 339}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:28:33,865] Trial 32 finished with value: 0.7118209948906532 and parameters: {'learning_rate': 0.0029799827403189753, 'l1_coef': 1.3781340064539358e-09, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.2492715910767959, 'num_epochs': 337}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:28:39,782] Trial 24 finished with value: 0.7569811665094817 and parameters: {'learning_rate': 5.032987825050777e-05, 'l1_coef': 1.4197494669870706e-07, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.3704045666273684, 'num_epochs': 330}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:28:55,081] Trial 33 finished with value: 0.768971509199876 and parameters: {'learning_rate': 0.004027724060094665, 'l1_coef': 2.2438468991278283e-09, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.25194924934059476, 'num_epochs': 339}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:29:08,349] Trial 31 finished with value: 0.7409526036335871 and parameters: {'learning_rate': 0.0030561360335526633, 'l1_coef': 3.437013569281974e-10, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.26757532896262576, 'num_epochs': 336}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:31:10,246] Trial 28 finished with value: 0.7030894371179434 and parameters: {'learning_rate': 0.0001804043899653686, 'l1_coef': 1.2827378378670243e-10, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.42595862316328614, 'num_epochs': 337}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:32:08,924] Trial 29 finished with value: 0.7100485462408799 and parameters: {'learning_rate': 0.00015134449500863226, 'l1_coef': 1.0575001301254026e-10, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.4187439205168405, 'num_epochs': 341}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:33:11,830] Trial 39 finished with value: 0.7466255187988281 and parameters: {'learning_rate': 0.00015934921255406328, 'l1_coef': 2.546202214427411e-06, 'patience': 10, 'batch_size': 128, 'lr_factor': 0.460032089454906, 'num_epochs': 443}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:36:04,142] Trial 19 finished with value: 0.8145213393064645 and parameters: {'learning_rate': 7.104518342049358e-06, 'l1_coef': 6.21933079888594e-09, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.11798399736121179, 'num_epochs': 499}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:36:05,803] Trial 34 finished with value: 0.7167865001238309 and parameters: {'learning_rate': 0.00015748629197655822, 'l1_coef': 1.471350164980597e-07, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.22349815112376303, 'num_epochs': 438}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:36:07,016] Trial 35 finished with value: 0.7022209259179922 and parameters: {'learning_rate': 0.00013090307375485233, 'l1_coef': 1.9213212897821003e-09, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.4746543923215354, 'num_epochs': 442}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:36:13,783] Trial 38 finished with value: 0.717528472496913 and parameters: {'learning_rate': 0.00018853791697034678, 'l1_coef': 2.5603091954203017e-09, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.23243318941710625, 'num_epochs': 439}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:37:17,919] Trial 37 finished with value: 0.7019155667378352 and parameters: {'learning_rate': 0.00014552715629809575, 'l1_coef': 3.734826480623699e-09, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.22403614670305178, 'num_epochs': 433}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:37:22,891] Trial 36 finished with value: 0.7213895962788508 and parameters: {'learning_rate': 9.950186750766638e-05, 'l1_coef': 1.3552412703781428e-09, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.23125812082299974, 'num_epochs': 439}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:39:19,936] Trial 41 finished with value: 0.7127943231509282 and parameters: {'learning_rate': 0.00020625633428780467, 'l1_coef': 1.7155377266762519e-09, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.20854409973189536, 'num_epochs': 367}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:39:49,408] Trial 40 finished with value: 0.7082576274871826 and parameters: {'learning_rate': 0.0001427533580649412, 'l1_coef': 7.102342247836264e-10, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.4749989805486321, 'num_epochs': 444}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:40:50,345] Trial 42 finished with value: 0.6981313118567833 and parameters: {'learning_rate': 0.00019293559404581523, 'l1_coef': 1.9592298481201006e-09, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.19472966243821527, 'num_epochs': 375}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:41:24,573] Trial 48 finished with value: 0.8338581928840052 and parameters: {'learning_rate': 0.0011250674572323284, 'l1_coef': 0.0004078427327400458, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.5226661927728504, 'num_epochs': 386}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:41:37,749] Trial 49 finished with value: 0.8465056410202614 and parameters: {'learning_rate': 0.0012724150577797968, 'l1_coef': 0.00046165605857938246, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.5691876104459515, 'num_epochs': 384}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:41:51,651] Trial 43 finished with value: 0.7189528263532199 and parameters: {'learning_rate': 0.0001951123423834876, 'l1_coef': 7.453840791000784e-10, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.19761347660937295, 'num_epochs': 301}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:42:16,749] Trial 45 finished with value: 0.7024374301616961 and parameters: {'learning_rate': 0.00019148754280811598, 'l1_coef': 4.754654606648844e-10, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.5537329302542493, 'num_epochs': 380}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:42:19,171] Trial 44 finished with value: 0.7094720033498911 and parameters: {'learning_rate': 0.00013163203607542841, 'l1_coef': 8.398959478312466e-10, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.2025248938162087, 'num_epochs': 369}. Best is trial 6 with value: 0.6938380654041584.\n",
      "[I 2024-05-23 03:42:20,454] Trial 46 finished with value: 0.6921252764188326 and parameters: {'learning_rate': 0.00022597360973217369, 'l1_coef': 5.909997824309047e-10, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.532536940963171, 'num_epochs': 374}. Best is trial 46 with value: 0.6921252764188326.\n",
      "[I 2024-05-23 03:42:27,600] Trial 47 finished with value: 0.7003898391356834 and parameters: {'learning_rate': 0.00024296737140431656, 'l1_coef': 3.6075530945471654e-10, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.578784613234097, 'num_epochs': 391}. Best is trial 46 with value: 0.6921252764188326.\n",
      "[I 2024-05-23 03:43:15,683] Trial 12 finished with value: 0.908792625940763 and parameters: {'learning_rate': 1.2517933040089856e-06, 'l1_coef': 3.217324569627882e-08, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.5354282780429979, 'num_epochs': 474}. Best is trial 46 with value: 0.6921252764188326.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 6 - Best hyperparameters: {'learning_rate': 0.00022597360973217369, 'l1_coef': 5.909997824309047e-10, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.532536940963171, 'num_epochs': 374}\n",
      "Chr 6 - Best value: 0.6921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 03:43:47,956] A new study created in RDB with name: unphased_full_23andMe_chr7_study_logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr6/final_model_chr6.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr6/individual_r2_scores_chr6.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr6/individual_iqs_scores_chr6.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  465\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 03:45:22,278] Trial 0 finished with value: 0.755464893579483 and parameters: {'learning_rate': 0.00768282871367125, 'l1_coef': 7.302863992907644e-08, 'patience': 15, 'batch_size': 256, 'lr_factor': 0.741545578577424, 'num_epochs': 258}. Best is trial 0 with value: 0.755464893579483.\n",
      "[I 2024-05-23 03:45:24,852] Trial 3 finished with value: 0.7537903666496277 and parameters: {'learning_rate': 0.007789656489822903, 'l1_coef': 2.2554315741102037e-08, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.7089128354911581, 'num_epochs': 207}. Best is trial 3 with value: 0.7537903666496277.\n",
      "[I 2024-05-23 03:45:48,505] Trial 9 finished with value: 0.739409139752388 and parameters: {'learning_rate': 0.0004377182685502889, 'l1_coef': 1.3809648905258546e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.5874415016831616, 'num_epochs': 163}. Best is trial 9 with value: 0.739409139752388.\n",
      "[I 2024-05-23 03:46:10,211] Trial 5 finished with value: 0.7089438429245583 and parameters: {'learning_rate': 0.0026234724524268936, 'l1_coef': 3.601164072508047e-08, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.22297330991663902, 'num_epochs': 377}. Best is trial 5 with value: 0.7089438429245583.\n",
      "[I 2024-05-23 03:46:33,402] Trial 2 finished with value: 0.7495867162942886 and parameters: {'learning_rate': 0.0018546955227005388, 'l1_coef': 0.00012721772808928163, 'patience': 11, 'batch_size': 128, 'lr_factor': 0.1866514309385149, 'num_epochs': 373}. Best is trial 5 with value: 0.7089438429245583.\n",
      "[I 2024-05-23 03:46:47,548] Trial 12 finished with value: 0.7253335684537887 and parameters: {'learning_rate': 0.0016443352311797529, 'l1_coef': 3.4330508359862362e-09, 'patience': 6, 'batch_size': 128, 'lr_factor': 0.6254392827038572, 'num_epochs': 223}. Best is trial 5 with value: 0.7089438429245583.\n",
      "[I 2024-05-23 03:46:55,857] Trial 6 finished with value: 0.737277604983403 and parameters: {'learning_rate': 0.007719530492748537, 'l1_coef': 9.036539770738656e-06, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.7672247813432477, 'num_epochs': 446}. Best is trial 5 with value: 0.7089438429245583.\n",
      "[I 2024-05-23 03:47:36,189] Trial 4 finished with value: 0.6932867352779095 and parameters: {'learning_rate': 0.003435634423713063, 'l1_coef': 1.0360756732203215e-05, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.4259770133314841, 'num_epochs': 198}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 03:47:44,701] Trial 16 finished with value: 0.7633426666259766 and parameters: {'learning_rate': 0.015243419881610102, 'l1_coef': 3.038012110741216e-08, 'patience': 9, 'batch_size': 256, 'lr_factor': 0.19488201819975562, 'num_epochs': 117}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 03:48:31,919] Trial 15 finished with value: 0.9456791549921035 and parameters: {'learning_rate': 0.02576633230238525, 'l1_coef': 0.0027909849392681284, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.43117083348009777, 'num_epochs': 453}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 03:48:52,069] Trial 10 finished with value: 0.7247834205627441 and parameters: {'learning_rate': 0.00043630426935783583, 'l1_coef': 1.0501684452631152e-08, 'patience': 15, 'batch_size': 256, 'lr_factor': 0.8571100810720474, 'num_epochs': 438}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 03:49:17,637] Trial 11 finished with value: 0.6938997353826251 and parameters: {'learning_rate': 0.0006361693300268127, 'l1_coef': 7.221552188052459e-07, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.8074063089433093, 'num_epochs': 257}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 03:51:05,874] Trial 13 finished with value: 0.7766517419081467 and parameters: {'learning_rate': 8.10497076263886e-05, 'l1_coef': 2.88753147556995e-05, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.3525892276458763, 'num_epochs': 120}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 03:55:11,045] Trial 18 finished with value: 0.7535419014784006 and parameters: {'learning_rate': 5.834883121622008e-05, 'l1_coef': 2.8221444656358886e-10, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.21646995289223128, 'num_epochs': 181}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 03:56:55,934] Trial 1 finished with value: 0.745508506664863 and parameters: {'learning_rate': 3.556339664334411e-05, 'l1_coef': 6.230607569553045e-10, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.38249798364739684, 'num_epochs': 350}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 03:57:32,887] Trial 7 finished with value: 0.8634329649118276 and parameters: {'learning_rate': 0.0003929122287241488, 'l1_coef': 0.0018630993977978981, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.8788776098944339, 'num_epochs': 236}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 04:00:06,837] Trial 17 finished with value: 0.8910795092582703 and parameters: {'learning_rate': 2.5836963702507963e-05, 'l1_coef': 0.0006445271434452338, 'patience': 10, 'batch_size': 256, 'lr_factor': 0.8890507539267444, 'num_epochs': 471}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 04:03:28,098] Trial 14 finished with value: 0.8831449776887894 and parameters: {'learning_rate': 2.391121516483884e-06, 'l1_coef': 4.6377074471534935e-06, 'patience': 15, 'batch_size': 128, 'lr_factor': 0.7233800752791993, 'num_epochs': 397}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 04:04:29,660] Trial 21 finished with value: 0.8333485313824245 and parameters: {'learning_rate': 9.155051580582944e-06, 'l1_coef': 3.058919427789871e-06, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.41272507994279467, 'num_epochs': 317}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 04:05:50,483] Trial 22 finished with value: 0.8554928132465909 and parameters: {'learning_rate': 5.566111327854725e-06, 'l1_coef': 3.0287266254210993e-06, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.4846258295356564, 'num_epochs': 309}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 04:07:10,733] Trial 28 finished with value: 6.664733123779297 and parameters: {'learning_rate': 0.09565009135676843, 'l1_coef': 0.07084233346137443, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.540650311968102, 'num_epochs': 279}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 04:08:02,971] Trial 19 finished with value: 1.0495998416628156 and parameters: {'learning_rate': 1.0299551614877384e-05, 'l1_coef': 0.04258103267400269, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.40345585605376716, 'num_epochs': 332}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 04:08:04,326] Trial 20 finished with value: 0.7805841776040884 and parameters: {'learning_rate': 1.4403493673324578e-05, 'l1_coef': 1.1441645050216898e-10, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.36836193012063034, 'num_epochs': 340}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 04:08:55,142] Trial 29 finished with value: 2.739842716285161 and parameters: {'learning_rate': 0.04322577664375465, 'l1_coef': 0.07142938828781094, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.3147887787178808, 'num_epochs': 256}. Best is trial 4 with value: 0.6932867352779095.\n",
      "[I 2024-05-23 04:09:45,738] Trial 30 finished with value: 0.6848117777279445 and parameters: {'learning_rate': 0.0014809050361325922, 'l1_coef': 3.3631460853699174e-07, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.2927313475634629, 'num_epochs': 337}. Best is trial 30 with value: 0.6848117777279445.\n",
      "[I 2024-05-23 04:11:20,092] Trial 32 finished with value: 0.6813753210581266 and parameters: {'learning_rate': 0.0011808424855143608, 'l1_coef': 2.427773569387186e-07, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.10117853552871267, 'num_epochs': 273}. Best is trial 32 with value: 0.6813753210581266.\n",
      "[I 2024-05-23 04:12:06,403] Trial 33 finished with value: 0.6739356435262239 and parameters: {'learning_rate': 0.0022237866335424418, 'l1_coef': 3.794179071696948e-07, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.2935334038071338, 'num_epochs': 156}. Best is trial 33 with value: 0.6739356435262239.\n",
      "[I 2024-05-23 04:12:13,137] Trial 31 finished with value: 0.672291521842663 and parameters: {'learning_rate': 0.0014389180416373723, 'l1_coef': 1.9883792202845838e-07, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.10494538456876484, 'num_epochs': 280}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:12:41,833] Trial 23 finished with value: 0.8841894950185504 and parameters: {'learning_rate': 1.9348796261031655e-06, 'l1_coef': 1.2513001447560661e-06, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.5066908950875437, 'num_epochs': 298}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:13:14,809] Trial 8 finished with value: 0.8740780977102427 and parameters: {'learning_rate': 1.2993568075694134e-06, 'l1_coef': 4.5785085351420417e-07, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.43060779339155786, 'num_epochs': 325}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:13:58,287] Trial 34 finished with value: 0.7511176994868688 and parameters: {'learning_rate': 0.0001352147281630398, 'l1_coef': 4.261850921656506e-07, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.2833863115526401, 'num_epochs': 160}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:14:32,147] Trial 24 finished with value: 0.8755591630935669 and parameters: {'learning_rate': 2.5170242443343722e-06, 'l1_coef': 5.625349070031671e-07, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.5284992198308968, 'num_epochs': 300}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:15:09,018] Trial 25 finished with value: 0.8770579508372716 and parameters: {'learning_rate': 2.3929077934075798e-06, 'l1_coef': 8.141730115369128e-07, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.5179988512551117, 'num_epochs': 302}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:15:12,096] Trial 35 finished with value: 0.7677045657084538 and parameters: {'learning_rate': 0.0001340582697101001, 'l1_coef': 3.8006883473042053e-05, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.11631839840899041, 'num_epochs': 161}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:16:06,502] Trial 26 finished with value: 5.693486172812326 and parameters: {'learning_rate': 1.7861034996222173e-06, 'l1_coef': 0.07351456591277644, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.5183555447139645, 'num_epochs': 293}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:16:29,803] Trial 38 finished with value: 0.7355744031759408 and parameters: {'learning_rate': 0.00016459667574936787, 'l1_coef': 3.951558909260894e-07, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.10336574595173675, 'num_epochs': 161}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:17:12,778] Trial 39 finished with value: 0.7367984184852012 and parameters: {'learning_rate': 0.00015858532283689907, 'l1_coef': 9.945944246039011e-08, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.11803048294205498, 'num_epochs': 170}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:17:43,957] Trial 40 finished with value: 0.6778390866059524 and parameters: {'learning_rate': 0.0012185377875855313, 'l1_coef': 1.4297241188077098e-07, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.13350351321128562, 'num_epochs': 281}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:18:07,635] Trial 36 finished with value: 0.7169787627000075 and parameters: {'learning_rate': 0.0001362372815671263, 'l1_coef': 2.085907475395468e-07, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.10028141936491214, 'num_epochs': 289}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:18:09,885] Trial 37 finished with value: 0.7166431289452773 and parameters: {'learning_rate': 0.00014154632961032302, 'l1_coef': 1.8211442210161344e-07, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.11197335309237862, 'num_epochs': 284}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:18:32,074] Trial 43 finished with value: 0.6785646456938522 and parameters: {'learning_rate': 0.0013328581587530083, 'l1_coef': 1.2093282348437162e-07, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.10654148338402558, 'num_epochs': 370}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:18:51,668] Trial 41 finished with value: 0.6747582068810096 and parameters: {'learning_rate': 0.00116186294360038, 'l1_coef': 1.1010094374640555e-07, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.10583620443960684, 'num_epochs': 277}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:19:07,579] Trial 42 finished with value: 0.6768580931883592 and parameters: {'learning_rate': 0.0009938690969061932, 'l1_coef': 1.1143607604060199e-07, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.1015032255695794, 'num_epochs': 357}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:19:35,712] Trial 47 finished with value: 0.7275987881880541 and parameters: {'learning_rate': 0.004224238365682738, 'l1_coef': 3.696008663746095e-09, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.154456332372464, 'num_epochs': 371}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:19:43,309] Trial 44 finished with value: 0.678078768803523 and parameters: {'learning_rate': 0.0010861110494400734, 'l1_coef': 9.989340456205427e-08, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.11338461330949653, 'num_epochs': 359}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:19:47,984] Trial 49 finished with value: 0.7321232749865605 and parameters: {'learning_rate': 0.004320867596298413, 'l1_coef': 3.466017740868354e-09, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.16963929401284578, 'num_epochs': 368}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:19:48,412] Trial 48 finished with value: 0.7197456800020658 and parameters: {'learning_rate': 0.004296235775406579, 'l1_coef': 2.9052335135869774e-09, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.1788112196704324, 'num_epochs': 232}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:19:50,287] Trial 45 finished with value: 0.6817222595214842 and parameters: {'learning_rate': 0.0009981779420151317, 'l1_coef': 1.086317369441254e-07, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.14019126759576422, 'num_epochs': 352}. Best is trial 31 with value: 0.672291521842663.\n",
      "[I 2024-05-23 04:19:53,132] Trial 46 finished with value: 0.6721075048813454 and parameters: {'learning_rate': 0.0015564356529101401, 'l1_coef': 1.0715102665777893e-07, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.26891139915486995, 'num_epochs': 353}. Best is trial 46 with value: 0.6721075048813454.\n",
      "[I 2024-05-23 04:19:54,122] Trial 27 finished with value: 4.330317987714495 and parameters: {'learning_rate': 1.345686699579495e-06, 'l1_coef': 0.03639561485352683, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.5105196166372156, 'num_epochs': 311}. Best is trial 46 with value: 0.6721075048813454.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 7 - Best hyperparameters: {'learning_rate': 0.0015564356529101401, 'l1_coef': 1.0715102665777893e-07, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.26891139915486995, 'num_epochs': 353}\n",
      "Chr 7 - Best value: 0.6721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 04:20:21,554] A new study created in RDB with name: unphased_full_23andMe_chr8_study_logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr7/final_model_chr7.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr7/individual_r2_scores_chr7.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr7/individual_iqs_scores_chr7.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  454\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 04:21:22,163] Trial 3 finished with value: 0.969415831565857 and parameters: {'learning_rate': 0.012018709560853219, 'l1_coef': 0.003117091899813757, 'patience': 7, 'batch_size': 128, 'lr_factor': 0.24378659252839388, 'num_epochs': 240}. Best is trial 3 with value: 0.969415831565857.\n",
      "[I 2024-05-23 04:21:37,619] Trial 6 finished with value: 0.8478156447410583 and parameters: {'learning_rate': 0.01667804012715168, 'l1_coef': 2.369671618699824e-06, 'patience': 19, 'batch_size': 256, 'lr_factor': 0.2760323751345609, 'num_epochs': 307}. Best is trial 6 with value: 0.8478156447410583.\n",
      "[I 2024-05-23 04:21:47,549] Trial 7 finished with value: 0.7764997541904449 and parameters: {'learning_rate': 0.006827578446725621, 'l1_coef': 1.166749818008427e-10, 'patience': 15, 'batch_size': 256, 'lr_factor': 0.7454650135814935, 'num_epochs': 471}. Best is trial 7 with value: 0.7764997541904449.\n",
      "[I 2024-05-23 04:21:48,527] Trial 4 finished with value: 0.952445125579834 and parameters: {'learning_rate': 0.0805237063383621, 'l1_coef': 3.809343087183448e-05, 'patience': 12, 'batch_size': 256, 'lr_factor': 0.8633140833079651, 'num_epochs': 250}. Best is trial 7 with value: 0.7764997541904449.\n",
      "[I 2024-05-23 04:21:52,846] Trial 10 finished with value: 0.9024217792919703 and parameters: {'learning_rate': 0.013437351780972762, 'l1_coef': 1.7283956272532656e-09, 'patience': 5, 'batch_size': 64, 'lr_factor': 0.7664301866550293, 'num_epochs': 389}. Best is trial 7 with value: 0.7764997541904449.\n",
      "[I 2024-05-23 04:22:13,960] Trial 0 finished with value: 0.8742306470870972 and parameters: {'learning_rate': 0.011916294059326604, 'l1_coef': 0.0007086442542578857, 'patience': 8, 'batch_size': 256, 'lr_factor': 0.27407967525594035, 'num_epochs': 357}. Best is trial 7 with value: 0.7764997541904449.\n",
      "[I 2024-05-23 04:22:55,164] Trial 5 finished with value: 0.8291481584310532 and parameters: {'learning_rate': 0.00010201552639297708, 'l1_coef': 1.1262549995187347e-10, 'patience': 17, 'batch_size': 128, 'lr_factor': 0.4734901428028313, 'num_epochs': 116}. Best is trial 7 with value: 0.7764997541904449.\n",
      "[I 2024-05-23 04:24:32,939] Trial 2 finished with value: 0.8335639953613281 and parameters: {'learning_rate': 5.519369852729253e-05, 'l1_coef': 1.883718871463618e-05, 'patience': 8, 'batch_size': 64, 'lr_factor': 0.7055032581776799, 'num_epochs': 262}. Best is trial 7 with value: 0.7764997541904449.\n",
      "[I 2024-05-23 04:26:17,827] Trial 15 finished with value: 0.8246876801763261 and parameters: {'learning_rate': 8.165837040236718e-05, 'l1_coef': 6.615490422204186e-06, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.8546760514804672, 'num_epochs': 103}. Best is trial 7 with value: 0.7764997541904449.\n",
      "[I 2024-05-23 04:29:48,374] Trial 14 finished with value: 0.8589818945297829 and parameters: {'learning_rate': 0.0006567852038856931, 'l1_coef': 0.0006108107320436267, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.8750613232576653, 'num_epochs': 427}. Best is trial 7 with value: 0.7764997541904449.\n",
      "[I 2024-05-23 04:29:58,609] Trial 1 finished with value: 0.8494869487626213 and parameters: {'learning_rate': 1.7910719080403684e-05, 'l1_coef': 2.424523051409948e-05, 'patience': 16, 'batch_size': 64, 'lr_factor': 0.4185225391157078, 'num_epochs': 367}. Best is trial 7 with value: 0.7764997541904449.\n",
      "[I 2024-05-23 04:30:29,638] Trial 12 finished with value: 0.8644980430603028 and parameters: {'learning_rate': 1.2740216148345189e-05, 'l1_coef': 5.712842004788342e-06, 'patience': 19, 'batch_size': 128, 'lr_factor': 0.6416606497658169, 'num_epochs': 320}. Best is trial 7 with value: 0.7764997541904449.\n",
      "[I 2024-05-23 04:32:55,895] Trial 8 finished with value: 0.9462880713599068 and parameters: {'learning_rate': 0.00044319756958862365, 'l1_coef': 0.04030637352347329, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.6120430014649111, 'num_epochs': 439}. Best is trial 7 with value: 0.7764997541904449.\n",
      "[I 2024-05-23 04:34:40,836] Trial 17 finished with value: 0.9469953179359436 and parameters: {'learning_rate': 1.4578659175613772e-06, 'l1_coef': 2.3035094101248643e-05, 'patience': 17, 'batch_size': 128, 'lr_factor': 0.23678254000183616, 'num_epochs': 234}. Best is trial 7 with value: 0.7764997541904449.\n",
      "[I 2024-05-23 04:37:21,941] Trial 22 finished with value: 0.7370588330122141 and parameters: {'learning_rate': 0.0007537501156359938, 'l1_coef': 8.290150885476138e-08, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.7762112273208196, 'num_epochs': 493}. Best is trial 22 with value: 0.7370588330122141.\n",
      "[I 2024-05-23 04:37:24,093] Trial 23 finished with value: 0.7541481678302471 and parameters: {'learning_rate': 0.0018969935871033985, 'l1_coef': 8.292873356680634e-08, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.7914167130687709, 'num_epochs': 119}. Best is trial 22 with value: 0.7370588330122141.\n",
      "[I 2024-05-23 04:40:18,417] Trial 25 finished with value: 0.7281932225594154 and parameters: {'learning_rate': 0.0015038688916002082, 'l1_coef': 1.0467031640055659e-07, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.5706429757133247, 'num_epochs': 170}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:40:42,239] Trial 24 finished with value: 0.730641598884876 and parameters: {'learning_rate': 0.0015388162365969908, 'l1_coef': 3.807918280525277e-08, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.5668021497155633, 'num_epochs': 480}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:40:47,677] Trial 18 finished with value: 1.6664779305458068 and parameters: {'learning_rate': 2.157096889226046e-06, 'l1_coef': 0.0023527503353276903, 'patience': 19, 'batch_size': 256, 'lr_factor': 0.6364379185826599, 'num_epochs': 423}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:41:59,311] Trial 13 finished with value: 0.9266842450414385 and parameters: {'learning_rate': 4.691368694410976e-06, 'l1_coef': 0.0001662377993711816, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.4638986576876599, 'num_epochs': 336}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:42:41,833] Trial 28 finished with value: 0.7679329542013316 and parameters: {'learning_rate': 0.004181122006811622, 'l1_coef': 8.216341902156938e-08, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.10117984584096162, 'num_epochs': 174}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:42:56,747] Trial 26 finished with value: 0.7356029987335205 and parameters: {'learning_rate': 0.002086422463107392, 'l1_coef': 6.906282479907888e-08, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.5531066924858122, 'num_epochs': 179}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:42:59,838] Trial 27 finished with value: 0.7573527620388911 and parameters: {'learning_rate': 0.0027480623969121554, 'l1_coef': 6.850636875197028e-08, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.5771440605474957, 'num_epochs': 180}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:44:58,530] Trial 30 finished with value: 0.7546238743341886 and parameters: {'learning_rate': 0.001565782901556272, 'l1_coef': 1.118709124748628e-07, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.5547524798503574, 'num_epochs': 491}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:45:07,551] Trial 29 finished with value: 0.7347919821739197 and parameters: {'learning_rate': 0.0012255141796405455, 'l1_coef': 9.223603225314328e-08, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.11941675949782216, 'num_epochs': 184}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:45:34,599] Trial 32 finished with value: 0.7341617125731248 and parameters: {'learning_rate': 0.0012794461470951688, 'l1_coef': 7.022136162600853e-09, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.5551562736981118, 'num_epochs': 170}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:45:55,094] Trial 31 finished with value: 0.7287821283707252 and parameters: {'learning_rate': 0.0018038032787010727, 'l1_coef': 9.302166924633247e-09, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.5534953448630567, 'num_epochs': 185}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:47:30,752] Trial 16 finished with value: 1.0603892769132341 and parameters: {'learning_rate': 6.032074671706359e-06, 'l1_coef': 0.006979774368326801, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.5824816852765479, 'num_epochs': 415}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:48:41,269] Trial 35 finished with value: 0.7787090714161213 and parameters: {'learning_rate': 0.00018020346737606866, 'l1_coef': 6.582129058822172e-09, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.3829012640061653, 'num_epochs': 139}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:48:43,905] Trial 34 finished with value: 0.7713017142735994 and parameters: {'learning_rate': 0.00017160501763896065, 'l1_coef': 6.437317127531145e-09, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.3879321267119581, 'num_epochs': 154}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:49:04,950] Trial 33 finished with value: 0.7658102741608254 and parameters: {'learning_rate': 0.00017593336322658, 'l1_coef': 5.579817705345512e-09, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.38241610717779095, 'num_epochs': 184}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:50:03,309] Trial 9 finished with value: 0.8513192497766934 and parameters: {'learning_rate': 4.01647073689581e-06, 'l1_coef': 5.7603987889619875e-08, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.8995031743659297, 'num_epochs': 403}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:51:13,022] Trial 40 finished with value: 0.7692776982600872 and parameters: {'learning_rate': 0.005456026187696949, 'l1_coef': 9.184280508931855e-07, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.6748443140755958, 'num_epochs': 215}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:51:27,088] Trial 36 finished with value: 0.7410450440186721 and parameters: {'learning_rate': 0.00024302312048465614, 'l1_coef': 5.8271431434836225e-09, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.4087502702357162, 'num_epochs': 275}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:51:58,141] Trial 39 finished with value: 0.9566420206656823 and parameters: {'learning_rate': 0.04279093774224481, 'l1_coef': 9.595315054614984e-07, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.6961973754959307, 'num_epochs': 215}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:52:03,000] Trial 42 finished with value: 0.9543748259544372 and parameters: {'learning_rate': 0.044503712407954005, 'l1_coef': 9.312957192167389e-10, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.5082117357328034, 'num_epochs': 212}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:52:10,854] Trial 43 finished with value: 0.9548030844101539 and parameters: {'learning_rate': 0.03527706679433814, 'l1_coef': 7.110467065783279e-10, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.516481358919407, 'num_epochs': 277}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:52:23,263] Trial 37 finished with value: 0.7430589575033921 and parameters: {'learning_rate': 0.0002506418323595995, 'l1_coef': 3.534677885192098e-09, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.36524049243108114, 'num_epochs': 212}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:53:01,417] Trial 41 finished with value: 1.0041158666977514 and parameters: {'learning_rate': 0.027335407153808475, 'l1_coef': 4.699302575911246e-07, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.5159765287216513, 'num_epochs': 210}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:53:50,014] Trial 46 finished with value: 0.7654495239257812 and parameters: {'learning_rate': 0.0008792702285074829, 'l1_coef': 3.707051214874027e-07, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.4533080997157563, 'num_epochs': 143}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:54:10,754] Trial 38 finished with value: 0.9909539002638598 and parameters: {'learning_rate': 0.06274280607728232, 'l1_coef': 7.236633708816774e-07, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.3576854459802242, 'num_epochs': 213}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:54:33,796] Trial 44 finished with value: 0.7394914141068092 and parameters: {'learning_rate': 0.0008248955964700275, 'l1_coef': 1.5370354856385513e-09, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.505259179911749, 'num_epochs': 282}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:54:34,285] Trial 48 finished with value: 0.7663058429956436 and parameters: {'learning_rate': 0.0009211484880455238, 'l1_coef': 2.062863000234478e-08, 'patience': 9, 'batch_size': 128, 'lr_factor': 0.4589464430562519, 'num_epochs': 147}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:54:37,035] Trial 49 finished with value: 0.7962519764900208 and parameters: {'learning_rate': 0.00789643334085725, 'l1_coef': 1.6238520940793608e-08, 'patience': 9, 'batch_size': 256, 'lr_factor': 0.3266319584107388, 'num_epochs': 368}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:55:01,077] Trial 11 finished with value: 0.8791867879720835 and parameters: {'learning_rate': 3.5492948445016154e-06, 'l1_coef': 2.4517135661370042e-05, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.23511875126771908, 'num_epochs': 459}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:55:33,940] Trial 47 finished with value: 0.8590559601783753 and parameters: {'learning_rate': 3.1330325756199535e-05, 'l1_coef': 2.3220683508528424e-08, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.4538680983390437, 'num_epochs': 142}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:57:04,546] Trial 45 finished with value: 0.7978628571216877 and parameters: {'learning_rate': 3.13690996130125e-05, 'l1_coef': 4.6411746693321566e-07, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.5182772862879952, 'num_epochs': 275}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:57:53,122] Trial 21 finished with value: 0.8828580709604117 and parameters: {'learning_rate': 1.5744836880701492e-06, 'l1_coef': 1.2470578223496384e-08, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.5963179304234328, 'num_epochs': 498}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:58:30,071] Trial 19 finished with value: 0.9091137134111845 and parameters: {'learning_rate': 1.0444602875559547e-06, 'l1_coef': 3.456420481383767e-08, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.5660451653836069, 'num_epochs': 484}. Best is trial 25 with value: 0.7281932225594154.\n",
      "[I 2024-05-23 04:58:35,161] Trial 20 finished with value: 0.9088630850498494 and parameters: {'learning_rate': 1.0220852774099351e-06, 'l1_coef': 6.675687970303766e-08, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.6706006033576232, 'num_epochs': 497}. Best is trial 25 with value: 0.7281932225594154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 8 - Best hyperparameters: {'learning_rate': 0.0015038688916002082, 'l1_coef': 1.0467031640055659e-07, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.5706429757133247, 'num_epochs': 170}\n",
      "Chr 8 - Best value: 0.7282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 04:58:47,556] A new study created in RDB with name: unphased_full_23andMe_chr9_study_logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr8/final_model_chr8.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr8/individual_r2_scores_chr8.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr8/individual_iqs_scores_chr8.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  404\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 05:02:13,774] Trial 4 finished with value: 0.7749934166669845 and parameters: {'learning_rate': 0.00021270511256418585, 'l1_coef': 1.2233759985017966e-05, 'patience': 6, 'batch_size': 128, 'lr_factor': 0.5724853514870011, 'num_epochs': 373}. Best is trial 4 with value: 0.7749934166669845.\n",
      "[I 2024-05-23 05:03:02,681] Trial 7 finished with value: 0.8270303964614868 and parameters: {'learning_rate': 0.00027753357450268886, 'l1_coef': 0.00026972103227476235, 'patience': 6, 'batch_size': 128, 'lr_factor': 0.8374079049380806, 'num_epochs': 453}. Best is trial 4 with value: 0.7749934166669845.\n",
      "[I 2024-05-23 05:03:16,766] Trial 1 finished with value: 0.7851683882566599 and parameters: {'learning_rate': 8.224134563426584e-05, 'l1_coef': 1.195948800075714e-07, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.5488202133798293, 'num_epochs': 197}. Best is trial 4 with value: 0.7749934166669845.\n",
      "[I 2024-05-23 05:03:27,556] Trial 0 finished with value: 0.7338852579777058 and parameters: {'learning_rate': 0.00045300061263196405, 'l1_coef': 5.903675614221835e-07, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.7429840146584329, 'num_epochs': 420}. Best is trial 0 with value: 0.7338852579777058.\n",
      "[I 2024-05-23 05:03:28,262] Trial 10 finished with value: 0.8519759740148272 and parameters: {'learning_rate': 0.013200407627786633, 'l1_coef': 4.807640671363478e-08, 'patience': 10, 'batch_size': 64, 'lr_factor': 0.4870008957771573, 'num_epochs': 113}. Best is trial 0 with value: 0.7338852579777058.\n",
      "[I 2024-05-23 05:04:00,609] Trial 9 finished with value: 0.8702435523271561 and parameters: {'learning_rate': 9.315712745427851e-06, 'l1_coef': 1.5301538565382724e-06, 'patience': 10, 'batch_size': 128, 'lr_factor': 0.5903382637888893, 'num_epochs': 194}. Best is trial 0 with value: 0.7338852579777058.\n",
      "[I 2024-05-23 05:05:43,292] Trial 15 finished with value: 0.869451829791069 and parameters: {'learning_rate': 0.00955753616709803, 'l1_coef': 0.0010572646216267935, 'patience': 11, 'batch_size': 128, 'lr_factor': 0.5365378740635928, 'num_epochs': 313}. Best is trial 0 with value: 0.7338852579777058.\n",
      "[I 2024-05-23 05:07:51,708] Trial 11 finished with value: 0.9115037560462952 and parameters: {'learning_rate': 6.376779849669984e-06, 'l1_coef': 2.3894306157748812e-08, 'patience': 5, 'batch_size': 256, 'lr_factor': 0.3444610371231025, 'num_epochs': 137}. Best is trial 0 with value: 0.7338852579777058.\n",
      "[I 2024-05-23 05:08:13,857] Trial 16 finished with value: 0.9335356932419996 and parameters: {'learning_rate': 0.08201303590215346, 'l1_coef': 5.673479287015647e-07, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.6174698703291475, 'num_epochs': 362}. Best is trial 0 with value: 0.7338852579777058.\n",
      "[I 2024-05-23 05:09:16,879] Trial 13 finished with value: 0.8660871088504791 and parameters: {'learning_rate': 1.321582368859733e-05, 'l1_coef': 4.133388419739425e-06, 'patience': 7, 'batch_size': 256, 'lr_factor': 0.2873459880716278, 'num_epochs': 398}. Best is trial 0 with value: 0.7338852579777058.\n",
      "[I 2024-05-23 05:09:25,762] Trial 3 finished with value: 0.7615741555507366 and parameters: {'learning_rate': 5.614348142553106e-05, 'l1_coef': 8.453912078293733e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.24124915576747175, 'num_epochs': 499}. Best is trial 0 with value: 0.7338852579777058.\n",
      "[I 2024-05-23 05:10:07,995] Trial 6 finished with value: 0.8787934690713882 and parameters: {'learning_rate': 4.8743332877847974e-06, 'l1_coef': 3.908358817036687e-05, 'patience': 20, 'batch_size': 128, 'lr_factor': 0.5821514075042573, 'num_epochs': 422}. Best is trial 0 with value: 0.7338852579777058.\n",
      "[I 2024-05-23 05:11:59,054] Trial 18 finished with value: 0.798961877822876 and parameters: {'learning_rate': 7.917014404235525e-05, 'l1_coef': 6.9821785774068e-07, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.8533068253782344, 'num_epochs': 254}. Best is trial 0 with value: 0.7338852579777058.\n",
      "[I 2024-05-23 05:12:03,898] Trial 19 finished with value: 0.7241409008319561 and parameters: {'learning_rate': 0.0026060863025384705, 'l1_coef': 1.061671496973752e-10, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.8983444146123916, 'num_epochs': 489}. Best is trial 19 with value: 0.7241409008319561.\n",
      "[I 2024-05-23 05:12:30,841] Trial 21 finished with value: 0.7257181341831501 and parameters: {'learning_rate': 0.0023207100641858985, 'l1_coef': 1.2414240677590852e-10, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.13750916176899, 'num_epochs': 473}. Best is trial 19 with value: 0.7241409008319561.\n",
      "[I 2024-05-23 05:13:00,878] Trial 8 finished with value: 0.8242613877568926 and parameters: {'learning_rate': 1.4292433529517293e-05, 'l1_coef': 1.3738527696677709e-09, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.4908012119478058, 'num_epochs': 416}. Best is trial 19 with value: 0.7241409008319561.\n",
      "[I 2024-05-23 05:13:24,320] Trial 20 finished with value: 0.7236008634934059 and parameters: {'learning_rate': 0.0013501426425090164, 'l1_coef': 2.458078368196278e-10, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.11225060781400817, 'num_epochs': 495}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:14:27,581] Trial 23 finished with value: 0.740457442173591 and parameters: {'learning_rate': 0.0019304471548113435, 'l1_coef': 1.2101074554293565e-10, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.7475269353407835, 'num_epochs': 491}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:14:58,833] Trial 22 finished with value: 0.7261894556192251 and parameters: {'learning_rate': 0.0017592723954452207, 'l1_coef': 2.862397267875615e-10, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.1375942177418336, 'num_epochs': 489}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:15:01,570] Trial 24 finished with value: 0.7369616966981154 and parameters: {'learning_rate': 0.0029860006259871826, 'l1_coef': 1.6788158050750702e-10, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.12760008890384134, 'num_epochs': 477}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:15:48,375] Trial 29 finished with value: 0.9417259275913239 and parameters: {'learning_rate': 0.09728706445295425, 'l1_coef': 2.3834839404315334e-09, 'patience': 19, 'batch_size': 256, 'lr_factor': 0.39197411274251936, 'num_epochs': 323}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:16:09,792] Trial 5 finished with value: 0.8973290630749293 and parameters: {'learning_rate': 5.991254589936544e-06, 'l1_coef': 0.00024341122921880593, 'patience': 17, 'batch_size': 64, 'lr_factor': 0.8938132470285245, 'num_epochs': 425}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:16:12,290] Trial 25 finished with value: 0.723874610203963 and parameters: {'learning_rate': 0.0017820099220554754, 'l1_coef': 1.3957446279315218e-10, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.17117195855072198, 'num_epochs': 500}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:16:16,741] Trial 2 finished with value: 0.882487326008933 and parameters: {'learning_rate': 2.5429598098865964e-06, 'l1_coef': 5.338041507147385e-09, 'patience': 10, 'batch_size': 64, 'lr_factor': 0.8297802029873991, 'num_epochs': 292}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:16:30,909] Trial 12 finished with value: 0.9256033360958099 and parameters: {'learning_rate': 1.491323871687905e-06, 'l1_coef': 3.008130946837878e-10, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.6643839842901231, 'num_epochs': 379}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:17:28,149] Trial 14 finished with value: 0.9205471192087445 and parameters: {'learning_rate': 0.00021929034599467502, 'l1_coef': 0.01968185047638159, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.7715654356423887, 'num_epochs': 233}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:17:48,199] Trial 32 finished with value: 0.8513562468382029 and parameters: {'learning_rate': 0.010292607119106997, 'l1_coef': 2.372848061501592e-09, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.22028210048663294, 'num_epochs': 451}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:18:30,705] Trial 26 finished with value: 0.9691843372124891 and parameters: {'learning_rate': 0.0014126064352778477, 'l1_coef': 0.0378173479022346, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.38979207446099584, 'num_epochs': 326}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:18:31,039] Trial 31 finished with value: 0.7779630752710196 and parameters: {'learning_rate': 0.00800338911051081, 'l1_coef': 1.5910134760889789e-09, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.23637635028030096, 'num_epochs': 453}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:18:58,808] Trial 34 finished with value: 0.7950689141566937 and parameters: {'learning_rate': 0.009569335323130302, 'l1_coef': 1.1088018807412153e-09, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.2108928145783353, 'num_epochs': 449}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:19:11,759] Trial 30 finished with value: 1.406320780974168 and parameters: {'learning_rate': 0.00591643906284792, 'l1_coef': 0.09015187663223063, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.20941939284132374, 'num_epochs': 454}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:19:54,791] Trial 27 finished with value: 0.9382135822222782 and parameters: {'learning_rate': 0.0015385623941623046, 'l1_coef': 0.021931498108126054, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.393570373205652, 'num_epochs': 311}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:21:19,537] Trial 37 finished with value: 0.9066182604202858 and parameters: {'learning_rate': 0.027588950240598615, 'l1_coef': 7.426609939216598e-10, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.22076478940518196, 'num_epochs': 464}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:21:20,565] Trial 35 finished with value: 0.7268983831772436 and parameters: {'learning_rate': 0.0006852692087302901, 'l1_coef': 1.008603161501049e-09, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.21043611195637815, 'num_epochs': 448}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:21:58,049] Trial 17 finished with value: 0.8737140268087387 and parameters: {'learning_rate': 4.697801507959394e-06, 'l1_coef': 8.065407747011327e-09, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.5148224091630178, 'num_epochs': 414}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:22:14,672] Trial 36 finished with value: 0.725346172772921 and parameters: {'learning_rate': 0.0009656331647552761, 'l1_coef': 8.04913996688517e-10, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.41965896065219743, 'num_epochs': 450}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:23:09,449] Trial 38 finished with value: 0.729069011944991 and parameters: {'learning_rate': 0.0006683903590422193, 'l1_coef': 4.82057247404138e-10, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.19067393620881873, 'num_epochs': 443}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:23:16,811] Trial 33 finished with value: 0.9114725378843452 and parameters: {'learning_rate': 0.000717228342015583, 'l1_coef': 0.01522614089570066, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.21129206094263453, 'num_epochs': 459}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:23:46,067] Trial 39 finished with value: 0.728417893556448 and parameters: {'learning_rate': 0.0006703199006322565, 'l1_coef': 1.7760582112742436e-08, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.6969798667179158, 'num_epochs': 499}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:24:28,040] Trial 41 finished with value: 0.7274920261823213 and parameters: {'learning_rate': 0.000720855586187154, 'l1_coef': 5.879330378060628e-10, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.10138326645988789, 'num_epochs': 473}. Best is trial 20 with value: 0.7236008634934059.\n",
      "[I 2024-05-23 05:24:49,871] Trial 40 finished with value: 0.7190232652884262 and parameters: {'learning_rate': 0.0005610104704348546, 'l1_coef': 4.538924770932336e-10, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.10080004105490664, 'num_epochs': 474}. Best is trial 40 with value: 0.7190232652884262.\n",
      "[I 2024-05-23 05:25:04,623] Trial 42 finished with value: 0.728513765335083 and parameters: {'learning_rate': 0.0007617110653094682, 'l1_coef': 1.1442812398967517e-08, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.1563824311286996, 'num_epochs': 500}. Best is trial 40 with value: 0.7190232652884262.\n",
      "[I 2024-05-23 05:25:38,440] Trial 47 finished with value: 0.7628301391234765 and parameters: {'learning_rate': 0.0037452737177202777, 'l1_coef': 1.7213425959842508e-07, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.10357562880351767, 'num_epochs': 499}. Best is trial 40 with value: 0.7190232652884262.\n",
      "[I 2024-05-23 05:26:16,695] Trial 49 finished with value: 0.7446098602735078 and parameters: {'learning_rate': 0.0038356061708688877, 'l1_coef': 1.1219809982787898e-07, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.2796600181414264, 'num_epochs': 346}. Best is trial 40 with value: 0.7190232652884262.\n",
      "[I 2024-05-23 05:26:17,331] Trial 45 finished with value: 0.7201788737223698 and parameters: {'learning_rate': 0.0008185415217779262, 'l1_coef': 2.239474783580398e-08, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.10532071274446765, 'num_epochs': 500}. Best is trial 40 with value: 0.7190232652884262.\n",
      "[I 2024-05-23 05:26:21,414] Trial 48 finished with value: 0.7148208333895758 and parameters: {'learning_rate': 0.003945975320552042, 'l1_coef': 1.1350497111602681e-07, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.3147097641342668, 'num_epochs': 349}. Best is trial 48 with value: 0.7148208333895758.\n",
      "[I 2024-05-23 05:26:23,459] Trial 43 finished with value: 0.7194208768697885 and parameters: {'learning_rate': 0.0004624827849520069, 'l1_coef': 9.491265181082486e-09, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.10196455546625688, 'num_epochs': 495}. Best is trial 48 with value: 0.7148208333895758.\n",
      "[I 2024-05-23 05:26:30,724] Trial 44 finished with value: 0.7107835256136381 and parameters: {'learning_rate': 0.0005508673474804207, 'l1_coef': 1.4606349508630406e-10, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.10763367266399207, 'num_epochs': 500}. Best is trial 44 with value: 0.7107835256136381.\n",
      "[I 2024-05-23 05:26:43,749] Trial 46 finished with value: 0.7071907767882715 and parameters: {'learning_rate': 0.00047974507044833283, 'l1_coef': 2.169265599662327e-08, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.29558580994695216, 'num_epochs': 495}. Best is trial 46 with value: 0.7071907767882715.\n",
      "[I 2024-05-23 05:27:34,443] Trial 28 finished with value: 1.4240551801828238 and parameters: {'learning_rate': 1.2569516076139544e-06, 'l1_coef': 0.011841786152346833, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.38846956038925573, 'num_epochs': 332}. Best is trial 46 with value: 0.7071907767882715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 9 - Best hyperparameters: {'learning_rate': 0.00047974507044833283, 'l1_coef': 2.169265599662327e-08, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.29558580994695216, 'num_epochs': 495}\n",
      "Chr 9 - Best value: 0.7072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 05:28:07,282] A new study created in RDB with name: unphased_full_23andMe_chr10_study_logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr9/final_model_chr9.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr9/individual_r2_scores_chr9.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr9/individual_iqs_scores_chr9.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  608\n",
      "PRS313 SNPs:  18\n",
      "Total SNPs used for Training:  590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 05:30:11,452] Trial 7 finished with value: 2.7592803120613096 and parameters: {'learning_rate': 0.09241951751028042, 'l1_coef': 0.010173613598039984, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.6888787740522878, 'num_epochs': 106}. Best is trial 7 with value: 2.7592803120613096.\n",
      "[I 2024-05-23 05:30:23,474] Trial 6 finished with value: 1.0573031693696975 and parameters: {'learning_rate': 0.005401511989987147, 'l1_coef': 0.030002285153082616, 'patience': 9, 'batch_size': 128, 'lr_factor': 0.16174068349319218, 'num_epochs': 429}. Best is trial 6 with value: 1.0573031693696975.\n",
      "[I 2024-05-23 05:30:33,297] Trial 4 finished with value: 8.76876319371737 and parameters: {'learning_rate': 0.0644391813135624, 'l1_coef': 0.0675139528703857, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.6759059960410283, 'num_epochs': 490}. Best is trial 6 with value: 1.0573031693696975.\n",
      "[I 2024-05-23 05:30:56,236] Trial 10 finished with value: 0.7538234889507294 and parameters: {'learning_rate': 0.00510190880639157, 'l1_coef': 3.0751204228982686e-07, 'patience': 6, 'batch_size': 256, 'lr_factor': 0.23206375183556036, 'num_epochs': 333}. Best is trial 10 with value: 0.7538234889507294.\n",
      "[I 2024-05-23 05:31:04,132] Trial 5 finished with value: 0.7142485095904424 and parameters: {'learning_rate': 0.004120142632668721, 'l1_coef': 5.861581011638753e-10, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.12805809547475616, 'num_epochs': 181}. Best is trial 5 with value: 0.7142485095904424.\n",
      "[I 2024-05-23 05:32:36,391] Trial 13 finished with value: 0.8744643926620483 and parameters: {'learning_rate': 0.020927159382581613, 'l1_coef': 7.019509394870568e-10, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.30965059766768477, 'num_epochs': 491}. Best is trial 5 with value: 0.7142485095904424.\n",
      "[I 2024-05-23 05:32:44,923] Trial 11 finished with value: 0.8047895976475308 and parameters: {'learning_rate': 0.016272875092571068, 'l1_coef': 1.2279626671482205e-06, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.5701694927700908, 'num_epochs': 439}. Best is trial 5 with value: 0.7142485095904424.\n",
      "[I 2024-05-23 05:33:02,715] Trial 0 finished with value: 1.050370543736678 and parameters: {'learning_rate': 0.008682216110857363, 'l1_coef': 0.00943807730165464, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.5090379739735015, 'num_epochs': 489}. Best is trial 5 with value: 0.7142485095904424.\n",
      "[I 2024-05-23 05:33:20,889] Trial 3 finished with value: 0.7188327039991107 and parameters: {'learning_rate': 0.00014290743925180692, 'l1_coef': 6.8055760297743665e-09, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.47711563679939684, 'num_epochs': 351}. Best is trial 5 with value: 0.7142485095904424.\n",
      "[I 2024-05-23 05:33:32,877] Trial 8 finished with value: 0.8901332974433899 and parameters: {'learning_rate': 0.0009790270341977594, 'l1_coef': 0.0013155373033049847, 'patience': 17, 'batch_size': 256, 'lr_factor': 0.2807656783293516, 'num_epochs': 199}. Best is trial 5 with value: 0.7142485095904424.\n",
      "[I 2024-05-23 05:33:43,326] Trial 18 finished with value: 0.8790782302618027 and parameters: {'learning_rate': 0.026532149677958857, 'l1_coef': 9.09275750865136e-10, 'patience': 5, 'batch_size': 128, 'lr_factor': 0.465339814933062, 'num_epochs': 485}. Best is trial 5 with value: 0.7142485095904424.\n",
      "[I 2024-05-23 05:34:33,211] Trial 1 finished with value: 0.9687227189540863 and parameters: {'learning_rate': 1.5687803364253035e-05, 'l1_coef': 0.0004365669586740517, 'patience': 15, 'batch_size': 256, 'lr_factor': 0.14272828982064878, 'num_epochs': 183}. Best is trial 5 with value: 0.7142485095904424.\n",
      "[I 2024-05-23 05:34:39,967] Trial 16 finished with value: 0.7198601722717285 and parameters: {'learning_rate': 0.0023491173181796675, 'l1_coef': 1.026535416670087e-10, 'patience': 11, 'batch_size': 256, 'lr_factor': 0.7319121237726465, 'num_epochs': 454}. Best is trial 5 with value: 0.7142485095904424.\n",
      "[I 2024-05-23 05:35:46,345] Trial 2 finished with value: 0.7906788915395737 and parameters: {'learning_rate': 3.3935694722405715e-05, 'l1_coef': 3.848801788467979e-06, 'patience': 10, 'batch_size': 128, 'lr_factor': 0.4373578162167783, 'num_epochs': 415}. Best is trial 5 with value: 0.7142485095904424.\n",
      "[I 2024-05-23 05:36:48,150] Trial 15 finished with value: 0.683709858931028 and parameters: {'learning_rate': 0.0015055754441732937, 'l1_coef': 1.8577031267158372e-06, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.2192719423677364, 'num_epochs': 395}. Best is trial 15 with value: 0.683709858931028.\n",
      "[I 2024-05-23 05:39:08,641] Trial 22 finished with value: 0.7465193322726659 and parameters: {'learning_rate': 8.912834326362071e-05, 'l1_coef': 5.121113786047454e-08, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.8818759986676847, 'num_epochs': 322}. Best is trial 15 with value: 0.683709858931028.\n",
      "[I 2024-05-23 05:39:44,897] Trial 17 finished with value: 0.977494353055954 and parameters: {'learning_rate': 0.0002606676442986929, 'l1_coef': 0.09890957521618926, 'patience': 9, 'batch_size': 128, 'lr_factor': 0.12455759895190521, 'num_epochs': 366}. Best is trial 15 with value: 0.683709858931028.\n",
      "[I 2024-05-23 05:39:57,557] Trial 23 finished with value: 0.7175018089158194 and parameters: {'learning_rate': 0.00020464736381061124, 'l1_coef': 2.257589646551371e-08, 'patience': 14, 'batch_size': 64, 'lr_factor': 0.8962613812601292, 'num_epochs': 293}. Best is trial 15 with value: 0.683709858931028.\n",
      "[I 2024-05-23 05:41:01,283] Trial 12 finished with value: 0.867821553349495 and parameters: {'learning_rate': 8.302602575230569e-06, 'l1_coef': 1.0401181640511425e-10, 'patience': 19, 'batch_size': 128, 'lr_factor': 0.2871494599258604, 'num_epochs': 245}. Best is trial 15 with value: 0.683709858931028.\n",
      "[I 2024-05-23 05:41:15,005] Trial 21 finished with value: 0.7394585251808167 and parameters: {'learning_rate': 5.4693877865775623e-05, 'l1_coef': 2.5411430634558028e-08, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.8512963376598606, 'num_epochs': 320}. Best is trial 15 with value: 0.683709858931028.\n",
      "[I 2024-05-23 05:43:08,350] Trial 14 finished with value: 0.836026018006461 and parameters: {'learning_rate': 1.1732924979832702e-05, 'l1_coef': 2.1883614006949993e-10, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.15203783092234763, 'num_epochs': 213}. Best is trial 15 with value: 0.683709858931028.\n",
      "[I 2024-05-23 05:44:57,482] Trial 20 finished with value: 0.7572290869859548 and parameters: {'learning_rate': 2.8569779546940997e-05, 'l1_coef': 2.628861931394276e-08, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.8738807331310721, 'num_epochs': 288}. Best is trial 15 with value: 0.683709858931028.\n",
      "[I 2024-05-23 05:45:59,024] Trial 30 finished with value: 0.7182031117952786 and parameters: {'learning_rate': 0.0009055669586664129, 'l1_coef': 1.3921118312442886e-05, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.3642961230328607, 'num_epochs': 280}. Best is trial 15 with value: 0.683709858931028.\n",
      "[I 2024-05-23 05:47:06,384] Trial 31 finished with value: 0.7217528939247131 and parameters: {'learning_rate': 0.0010300059852459094, 'l1_coef': 1.2727184453491112e-05, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.3715578272861194, 'num_epochs': 134}. Best is trial 15 with value: 0.683709858931028.\n",
      "[I 2024-05-23 05:49:35,316] Trial 32 finished with value: 0.6815372439531179 and parameters: {'learning_rate': 0.0008792002630912595, 'l1_coef': 4.063116079963295e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.21846658606072733, 'num_epochs': 146}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 05:50:48,983] Trial 29 finished with value: 0.908571223112253 and parameters: {'learning_rate': 2.104538564229928e-06, 'l1_coef': 1.093846708586419e-05, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.3652141982479357, 'num_epochs': 109}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 05:52:08,946] Trial 28 finished with value: 0.911715748676887 and parameters: {'learning_rate': 1.8998911964398319e-06, 'l1_coef': 2.3021231149969806e-05, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.22059497942710715, 'num_epochs': 127}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 05:53:22,370] Trial 19 finished with value: 0.8773615937966568 and parameters: {'learning_rate': 4.782581224140376e-06, 'l1_coef': 8.448255757398477e-05, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.8887482775623419, 'num_epochs': 222}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 05:54:37,724] Trial 9 finished with value: 0.8686800113091102 and parameters: {'learning_rate': 2.793928619838821e-06, 'l1_coef': 2.2569923617933586e-05, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.764954989190962, 'num_epochs': 294}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 05:54:45,630] Trial 35 finished with value: 0.6964443096747764 and parameters: {'learning_rate': 0.0005339971345976552, 'l1_coef': 3.5759354022766522e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.2096853231329767, 'num_epochs': 152}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 05:56:20,564] Trial 36 finished with value: 0.6868651087467488 and parameters: {'learning_rate': 0.0005402174799370857, 'l1_coef': 3.1375390740063075e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.2385734757557622, 'num_epochs': 166}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 05:56:23,607] Trial 37 finished with value: 0.6911950606566208 and parameters: {'learning_rate': 0.0017027283319623792, 'l1_coef': 2.2140891242124474e-09, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.2093699914880261, 'num_epochs': 168}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 05:57:49,998] Trial 38 finished with value: 0.6990687883817233 and parameters: {'learning_rate': 0.002634758924877027, 'l1_coef': 2.4635275231863607e-09, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.2034538610580957, 'num_epochs': 169}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 05:58:45,909] Trial 39 finished with value: 0.7021107270167424 and parameters: {'learning_rate': 0.00045033462287187646, 'l1_coef': 3.6074047694058003e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.21833713435708146, 'num_epochs': 155}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 05:59:06,184] Trial 24 finished with value: 0.8874802947044372 and parameters: {'learning_rate': 1.4188090257262517e-06, 'l1_coef': 3.849492471332862e-08, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.36312198134923546, 'num_epochs': 252}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 05:59:19,894] Trial 27 finished with value: 0.9004155855912428 and parameters: {'learning_rate': 1.6239235446412396e-06, 'l1_coef': 2.00004926637556e-05, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.3377262689325212, 'num_epochs': 220}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 06:00:08,986] Trial 41 finished with value: 0.6877372310711788 and parameters: {'learning_rate': 0.0019227484750527755, 'l1_coef': 1.7586800054420567e-07, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.18997220278640223, 'num_epochs': 158}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 06:00:15,461] Trial 40 finished with value: 0.6857877107766959 and parameters: {'learning_rate': 0.0005116022511851968, 'l1_coef': 2.7887227195538514e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.22191624591740822, 'num_epochs': 150}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 06:02:23,838] Trial 45 finished with value: 0.6875670662293066 and parameters: {'learning_rate': 0.002119917583832912, 'l1_coef': 1.1209239244259002e-07, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.5638810705850686, 'num_epochs': 383}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 06:02:27,108] Trial 34 finished with value: 0.8909481919728792 and parameters: {'learning_rate': 2.1581083446105904e-06, 'l1_coef': 2.386439933159333e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.19152855956299097, 'num_epochs': 156}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 06:02:29,083] Trial 42 finished with value: 0.6948361048331628 and parameters: {'learning_rate': 0.0004708081766355114, 'l1_coef': 2.9365104890158354e-07, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.26895239544600547, 'num_epochs': 254}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 06:02:29,788] Trial 26 finished with value: 0.9053111443152794 and parameters: {'learning_rate': 1.1485402606861317e-06, 'l1_coef': 2.451205154138621e-05, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.3663440252949607, 'num_epochs': 258}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 06:02:29,857] Trial 44 finished with value: 0.6838120185411893 and parameters: {'learning_rate': 0.0017097347191570612, 'l1_coef': 1.7312428786441233e-07, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.5449177877261651, 'num_epochs': 399}. Best is trial 32 with value: 0.6815372439531179.\n",
      "[I 2024-05-23 06:02:36,087] Trial 43 finished with value: 0.6794253642742449 and parameters: {'learning_rate': 0.0014297627276479063, 'l1_coef': 5.751396258572685e-07, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.5495149199689441, 'num_epochs': 391}. Best is trial 43 with value: 0.6794253642742449.\n",
      "[I 2024-05-23 06:02:37,939] Trial 25 finished with value: 0.9233773790873014 and parameters: {'learning_rate': 1.0913453420221296e-06, 'l1_coef': 1.5097300779736664e-05, 'patience': 8, 'batch_size': 32, 'lr_factor': 0.1107376813794352, 'num_epochs': 269}. Best is trial 43 with value: 0.6794253642742449.\n",
      "[I 2024-05-23 06:03:23,891] Trial 47 finished with value: 0.7216056924599867 and parameters: {'learning_rate': 0.0001385095743901544, 'l1_coef': 8.611029762123012e-07, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.10080923497962818, 'num_epochs': 189}. Best is trial 43 with value: 0.6794253642742449.\n",
      "[I 2024-05-23 06:03:54,433] Trial 49 finished with value: 0.721396305010869 and parameters: {'learning_rate': 0.00014864184178025962, 'l1_coef': 7.669587734833677e-07, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.10334262276079519, 'num_epochs': 189}. Best is trial 43 with value: 0.6794253642742449.\n",
      "[I 2024-05-23 06:04:08,323] Trial 46 finished with value: 0.6966327713086055 and parameters: {'learning_rate': 0.00013564964271314787, 'l1_coef': 4.1079220846857577e-07, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.10434609986998475, 'num_epochs': 377}. Best is trial 43 with value: 0.6794253642742449.\n",
      "[I 2024-05-23 06:04:25,721] Trial 48 finished with value: 0.712259775858659 and parameters: {'learning_rate': 0.00010681378071711937, 'l1_coef': 6.020772394447456e-07, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.1048302890761531, 'num_epochs': 404}. Best is trial 43 with value: 0.6794253642742449.\n",
      "[I 2024-05-23 06:05:12,611] Trial 33 finished with value: 0.8584561366301315 and parameters: {'learning_rate': 1.939709875458919e-06, 'l1_coef': 6.163299299317478e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.2197673346718772, 'num_epochs': 395}. Best is trial 43 with value: 0.6794253642742449.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 10 - Best hyperparameters: {'learning_rate': 0.0014297627276479063, 'l1_coef': 5.751396258572685e-07, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.5495149199689441, 'num_epochs': 391}\n",
      "Chr 10 - Best value: 0.6794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 06:05:44,833] A new study created in RDB with name: unphased_full_23andMe_chr11_study_logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr10/final_model_chr10.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr10/individual_r2_scores_chr10.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr10/individual_iqs_scores_chr10.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  919\n",
      "PRS313 SNPs:  19\n",
      "Total SNPs used for Training:  900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 06:06:32,489] Trial 2 finished with value: 0.9868497763361249 and parameters: {'learning_rate': 0.04212134888797371, 'l1_coef': 3.9274155203967995e-05, 'patience': 5, 'batch_size': 64, 'lr_factor': 0.8082387699370034, 'num_epochs': 316}. Best is trial 2 with value: 0.9868497763361249.\n",
      "[I 2024-05-23 06:07:41,391] Trial 8 finished with value: 0.730195426940918 and parameters: {'learning_rate': 0.005429112649009058, 'l1_coef': 1.6177027169406028e-07, 'patience': 17, 'batch_size': 256, 'lr_factor': 0.614085616813263, 'num_epochs': 195}. Best is trial 8 with value: 0.730195426940918.\n",
      "[I 2024-05-23 06:07:53,463] Trial 3 finished with value: 0.6941146135330201 and parameters: {'learning_rate': 0.0013217720859759767, 'l1_coef': 1.180256392364302e-07, 'patience': 11, 'batch_size': 128, 'lr_factor': 0.2534027365830232, 'num_epochs': 184}. Best is trial 3 with value: 0.6941146135330201.\n",
      "[I 2024-05-23 06:08:01,709] Trial 0 finished with value: 0.7457976043224335 and parameters: {'learning_rate': 0.00047195754547587785, 'l1_coef': 3.572365985265098e-05, 'patience': 15, 'batch_size': 256, 'lr_factor': 0.6073391163202444, 'num_epochs': 251}. Best is trial 3 with value: 0.6941146135330201.\n",
      "[I 2024-05-23 06:08:57,131] Trial 6 finished with value: 0.7785409450531006 and parameters: {'learning_rate': 0.012186004278129403, 'l1_coef': 5.1746434051076056e-06, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.284534766572371, 'num_epochs': 139}. Best is trial 3 with value: 0.6941146135330201.\n",
      "[I 2024-05-23 06:09:28,173] Trial 9 finished with value: 0.7451064092772347 and parameters: {'learning_rate': 8.252861183638165e-05, 'l1_coef': 1.5027412750006793e-10, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.6118461853049697, 'num_epochs': 239}. Best is trial 3 with value: 0.6941146135330201.\n",
      "[I 2024-05-23 06:11:34,740] Trial 12 finished with value: 0.9391667604446411 and parameters: {'learning_rate': 1.6370914882981243e-06, 'l1_coef': 2.0990528644440458e-08, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.8509366921446861, 'num_epochs': 105}. Best is trial 3 with value: 0.6941146135330201.\n",
      "[I 2024-05-23 06:12:12,687] Trial 1 finished with value: 0.7745182956968035 and parameters: {'learning_rate': 3.925220061397335e-05, 'l1_coef': 3.070650819783414e-07, 'patience': 16, 'batch_size': 64, 'lr_factor': 0.2825418307892006, 'num_epochs': 137}. Best is trial 3 with value: 0.6941146135330201.\n",
      "[I 2024-05-23 06:13:12,823] Trial 4 finished with value: 4.336774075031281 and parameters: {'learning_rate': 5.030388932632272e-06, 'l1_coef': 0.05325562611687033, 'patience': 8, 'batch_size': 256, 'lr_factor': 0.11708412218715392, 'num_epochs': 400}. Best is trial 3 with value: 0.6941146135330201.\n",
      "[I 2024-05-23 06:16:07,747] Trial 7 finished with value: 0.8203769155911036 and parameters: {'learning_rate': 1.1175349860381145e-05, 'l1_coef': 1.205592272245072e-06, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.47140672936072436, 'num_epochs': 163}. Best is trial 3 with value: 0.6941146135330201.\n",
      "[I 2024-05-23 06:16:14,368] Trial 17 finished with value: 0.8969977525564339 and parameters: {'learning_rate': 0.06172009807812901, 'l1_coef': 1.9391131882123713e-05, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.4923506057069267, 'num_epochs': 248}. Best is trial 3 with value: 0.6941146135330201.\n",
      "[I 2024-05-23 06:16:23,285] Trial 18 finished with value: 0.7544300407171249 and parameters: {'learning_rate': 7.643462571171407e-05, 'l1_coef': 8.200472524571898e-08, 'patience': 15, 'batch_size': 128, 'lr_factor': 0.6780470690907592, 'num_epochs': 295}. Best is trial 3 with value: 0.6941146135330201.\n",
      "[I 2024-05-23 06:16:44,226] Trial 15 finished with value: 0.6569763788810142 and parameters: {'learning_rate': 0.0002049573453798199, 'l1_coef': 1.5319602157005045e-09, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.37427194659938057, 'num_epochs': 324}. Best is trial 15 with value: 0.6569763788810142.\n",
      "[I 2024-05-23 06:17:01,615] Trial 10 finished with value: 0.8273523032665253 and parameters: {'learning_rate': 5.426776923062292e-05, 'l1_coef': 0.00021785356195676842, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.8005512747940071, 'num_epochs': 319}. Best is trial 15 with value: 0.6569763788810142.\n",
      "[I 2024-05-23 06:18:48,742] Trial 11 finished with value: 0.9223217538424899 and parameters: {'learning_rate': 3.101671893402121e-06, 'l1_coef': 0.00012106819809563782, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.6313026724320147, 'num_epochs': 176}. Best is trial 15 with value: 0.6569763788810142.\n",
      "[I 2024-05-23 06:18:52,692] Trial 21 finished with value: 0.6896285444498063 and parameters: {'learning_rate': 0.0021438021946414997, 'l1_coef': 1.550083506780759e-09, 'patience': 19, 'batch_size': 128, 'lr_factor': 0.35203144045842144, 'num_epochs': 197}. Best is trial 15 with value: 0.6569763788810142.\n",
      "[I 2024-05-23 06:19:15,803] Trial 20 finished with value: 0.6784548699855805 and parameters: {'learning_rate': 0.001497274415216195, 'l1_coef': 6.289120401136775e-09, 'patience': 19, 'batch_size': 128, 'lr_factor': 0.33329362655316386, 'num_epochs': 486}. Best is trial 15 with value: 0.6569763788810142.\n",
      "[I 2024-05-23 06:19:22,676] Trial 5 finished with value: 0.7880443368639265 and parameters: {'learning_rate': 1.395749039982174e-05, 'l1_coef': 5.669779574981474e-09, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.27404019681038944, 'num_epochs': 253}. Best is trial 15 with value: 0.6569763788810142.\n",
      "[I 2024-05-23 06:19:37,871] Trial 19 finished with value: 0.6786484688520431 and parameters: {'learning_rate': 0.0010803039957191477, 'l1_coef': 1.1622073734232352e-09, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.10098689430734101, 'num_epochs': 489}. Best is trial 15 with value: 0.6569763788810142.\n",
      "[I 2024-05-23 06:20:05,521] Trial 16 finished with value: 0.8451102048158645 and parameters: {'learning_rate': 4.088951135461431e-06, 'l1_coef': 3.240398327468383e-08, 'patience': 8, 'batch_size': 128, 'lr_factor': 0.5312019558293279, 'num_epochs': 468}. Best is trial 15 with value: 0.6569763788810142.\n",
      "[I 2024-05-23 06:20:50,743] Trial 23 finished with value: 0.6724258601665497 and parameters: {'learning_rate': 0.001013698083454822, 'l1_coef': 8.936243214376399e-10, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.3350147043727863, 'num_epochs': 421}. Best is trial 15 with value: 0.6569763788810142.\n",
      "[I 2024-05-23 06:23:05,403] Trial 24 finished with value: 0.6630719304084778 and parameters: {'learning_rate': 0.0006997473854748145, 'l1_coef': 1.4247831661683401e-09, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.3444566515202281, 'num_epochs': 450}. Best is trial 15 with value: 0.6569763788810142.\n",
      "[I 2024-05-23 06:23:54,375] Trial 25 finished with value: 0.6916990720308744 and parameters: {'learning_rate': 0.001830981930658644, 'l1_coef': 6.148025065222881e-10, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.40288064450965233, 'num_epochs': 497}. Best is trial 15 with value: 0.6569763788810142.\n",
      "[I 2024-05-23 06:28:16,245] Trial 29 finished with value: 0.6641653922887949 and parameters: {'learning_rate': 0.00031660953875207765, 'l1_coef': 1.9502067296390262e-10, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.39976326398949147, 'num_epochs': 396}. Best is trial 15 with value: 0.6569763788810142.\n",
      "[I 2024-05-23 06:28:41,473] Trial 28 finished with value: 0.6628511777290932 and parameters: {'learning_rate': 0.0001947851940847243, 'l1_coef': 1.1769894918548928e-10, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.4052545495522976, 'num_epochs': 488}. Best is trial 15 with value: 0.6569763788810142.\n",
      "[I 2024-05-23 06:28:54,400] Trial 30 finished with value: 0.6573033736302303 and parameters: {'learning_rate': 0.00026180927498971654, 'l1_coef': 1.2844286068634595e-10, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.4130308854386271, 'num_epochs': 421}. Best is trial 15 with value: 0.6569763788810142.\n",
      "[I 2024-05-23 06:29:11,494] Trial 26 finished with value: 0.638959631553063 and parameters: {'learning_rate': 0.0002962230706837187, 'l1_coef': 3.075206801283935e-09, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.39523935573010427, 'num_epochs': 489}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:29:27,012] Trial 27 finished with value: 0.6574339188062227 and parameters: {'learning_rate': 0.00023194739841406143, 'l1_coef': 1.700787283507994e-10, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.41694953640792487, 'num_epochs': 499}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:29:57,173] Trial 13 finished with value: 0.8349452889882603 and parameters: {'learning_rate': 2.988026820554903e-06, 'l1_coef': 1.7353891979834781e-06, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.7843686977046784, 'num_epochs': 231}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:30:29,419] Trial 22 finished with value: 0.6607382535934448 and parameters: {'learning_rate': 0.0010685581500112925, 'l1_coef': 8.939635139129711e-10, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.2880363558136634, 'num_epochs': 411}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:31:22,403] Trial 31 finished with value: 0.6562274749462421 and parameters: {'learning_rate': 0.0003209385858467064, 'l1_coef': 1.24062161412268e-10, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.3977534561402953, 'num_epochs': 406}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:32:10,401] Trial 32 finished with value: 0.6562661363528325 and parameters: {'learning_rate': 0.0003459172554779278, 'l1_coef': 1.0442244823865167e-10, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.1941943245596068, 'num_epochs': 411}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:35:15,297] Trial 14 finished with value: 0.8631227970123291 and parameters: {'learning_rate': 2.1741255484880045e-06, 'l1_coef': 1.2355367502580132e-05, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.4086251550319675, 'num_epochs': 433}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:35:32,849] Trial 36 finished with value: 0.9092590377880976 and parameters: {'learning_rate': 0.0002024161935769037, 'l1_coef': 0.003093855549667485, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.18991342710372433, 'num_epochs': 370}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:35:54,674] Trial 33 finished with value: 0.6595644409839924 and parameters: {'learning_rate': 0.0002622805863321845, 'l1_coef': 1.4115824964571644e-10, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.1878921504681238, 'num_epochs': 369}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:36:30,957] Trial 37 finished with value: 0.7314465733674858 and parameters: {'learning_rate': 3.173940337812857e-05, 'l1_coef': 6.0561898235272135e-09, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.5254454378443812, 'num_epochs': 357}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:36:42,265] Trial 38 finished with value: 0.675452080139747 and parameters: {'learning_rate': 0.00017173232101354356, 'l1_coef': 7.75459852351698e-09, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.5330097988829349, 'num_epochs': 341}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:36:50,645] Trial 35 finished with value: 0.6608216368235075 and parameters: {'learning_rate': 0.00021240714410694552, 'l1_coef': 7.654835627266578e-09, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.2002590403441226, 'num_epochs': 434}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:37:37,217] Trial 39 finished with value: 0.6705585626455454 and parameters: {'learning_rate': 0.0001326076430609091, 'l1_coef': 7.79618887184359e-09, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.2089810951804823, 'num_epochs': 362}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:37:50,557] Trial 45 finished with value: 0.7200472198999845 and parameters: {'learning_rate': 0.0033040874025291813, 'l1_coef': 1.4821720954873199e-08, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.46782624696085756, 'num_epochs': 345}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:38:49,799] Trial 40 finished with value: 0.6649762382874123 and parameters: {'learning_rate': 0.00012320152235531013, 'l1_coef': 7.095981966849259e-09, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.20434266273815585, 'num_epochs': 363}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:39:15,248] Trial 34 finished with value: 0.8822141399750343 and parameters: {'learning_rate': 0.0001756821769388315, 'l1_coef': 0.0021717016376249757, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.20507951615351178, 'num_epochs': 439}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:39:28,064] Trial 41 finished with value: 0.6692639167492207 and parameters: {'learning_rate': 0.00014756591250814947, 'l1_coef': 7.58967125946202e-09, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.22914210965555223, 'num_epochs': 362}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:39:40,876] Trial 47 finished with value: 0.7200279923585746 and parameters: {'learning_rate': 0.003701549451973695, 'l1_coef': 4.760485506894807e-10, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.23203337022472087, 'num_epochs': 388}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:39:58,295] Trial 46 finished with value: 0.7774122687486502 and parameters: {'learning_rate': 0.006126444998010135, 'l1_coef': 4.5009302311442455e-10, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.19674645054213769, 'num_epochs': 447}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:40:20,884] Trial 42 finished with value: 0.6710467017613925 and parameters: {'learning_rate': 0.00015361579680733367, 'l1_coef': 1.4604347552131714e-08, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.19846349821381215, 'num_epochs': 360}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:40:54,668] Trial 48 finished with value: 0.657050412434798 and parameters: {'learning_rate': 0.0004837748497030737, 'l1_coef': 3.847944195308511e-10, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.15220196832161878, 'num_epochs': 282}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:40:57,583] Trial 49 finished with value: 0.6590705495614272 and parameters: {'learning_rate': 0.0005294237795863462, 'l1_coef': 3.4006975954427836e-07, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.2432160222887952, 'num_epochs': 282}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:41:33,850] Trial 44 finished with value: 0.7186621418366066 and parameters: {'learning_rate': 2.3011051117739267e-05, 'l1_coef': 5.9619780252902435e-09, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.2020675045332009, 'num_epochs': 348}. Best is trial 26 with value: 0.638959631553063.\n",
      "[I 2024-05-23 06:41:33,928] Trial 43 finished with value: 0.7043650553776667 and parameters: {'learning_rate': 3.23145437441336e-05, 'l1_coef': 1.0132664038425222e-08, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.19304909332495174, 'num_epochs': 360}. Best is trial 26 with value: 0.638959631553063.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 11 - Best hyperparameters: {'learning_rate': 0.0002962230706837187, 'l1_coef': 3.075206801283935e-09, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.39523935573010427, 'num_epochs': 489}\n",
      "Chr 11 - Best value: 0.6390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 06:42:20,116] A new study created in RDB with name: unphased_full_23andMe_chr12_study_logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr11/final_model_chr11.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr11/individual_r2_scores_chr11.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr11/individual_iqs_scores_chr11.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  641\n",
      "PRS313 SNPs:  17\n",
      "Total SNPs used for Training:  624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 06:43:21,562] Trial 1 finished with value: 0.8408280730247497 and parameters: {'learning_rate': 0.022623939934942532, 'l1_coef': 1.7020997140797295e-09, 'patience': 18, 'batch_size': 256, 'lr_factor': 0.7614753515256472, 'num_epochs': 388}. Best is trial 1 with value: 0.8408280730247497.\n",
      "[I 2024-05-23 06:43:37,818] Trial 9 finished with value: 0.8957166612148285 and parameters: {'learning_rate': 0.025136787150366068, 'l1_coef': 0.0010696011678808964, 'patience': 12, 'batch_size': 256, 'lr_factor': 0.772329093850791, 'num_epochs': 308}. Best is trial 1 with value: 0.8408280730247497.\n",
      "[I 2024-05-23 06:44:11,364] Trial 2 finished with value: 0.8070221781730652 and parameters: {'learning_rate': 0.011305424631940576, 'l1_coef': 2.715060730658116e-10, 'patience': 17, 'batch_size': 64, 'lr_factor': 0.6108290958293232, 'num_epochs': 356}. Best is trial 2 with value: 0.8070221781730652.\n",
      "[I 2024-05-23 06:44:17,094] Trial 10 finished with value: 0.7559893369674683 and parameters: {'learning_rate': 0.0015808387150208043, 'l1_coef': 3.5401406119263736e-07, 'patience': 5, 'batch_size': 128, 'lr_factor': 0.524272019239862, 'num_epochs': 422}. Best is trial 10 with value: 0.7559893369674683.\n",
      "[I 2024-05-23 06:44:30,784] Trial 3 finished with value: 0.7461059004068374 and parameters: {'learning_rate': 0.00209862104559365, 'l1_coef': 2.4972339869717196e-05, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.7843721989328214, 'num_epochs': 273}. Best is trial 3 with value: 0.7461059004068374.\n",
      "[I 2024-05-23 06:44:33,069] Trial 6 finished with value: 0.9229443669319153 and parameters: {'learning_rate': 0.04979755217127364, 'l1_coef': 0.0005325087473329027, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.47177153495937596, 'num_epochs': 413}. Best is trial 3 with value: 0.7461059004068374.\n",
      "[I 2024-05-23 06:44:57,562] Trial 5 finished with value: 0.7857201337814331 and parameters: {'learning_rate': 0.00014305766450541986, 'l1_coef': 7.440501568889178e-06, 'patience': 20, 'batch_size': 128, 'lr_factor': 0.2636968357940205, 'num_epochs': 203}. Best is trial 3 with value: 0.7461059004068374.\n",
      "[I 2024-05-23 06:45:08,431] Trial 12 finished with value: 0.826543893132891 and parameters: {'learning_rate': 0.00977525827307604, 'l1_coef': 4.192964420402401e-08, 'patience': 12, 'batch_size': 64, 'lr_factor': 0.21944355185792733, 'num_epochs': 363}. Best is trial 3 with value: 0.7461059004068374.\n",
      "[I 2024-05-23 06:45:16,331] Trial 8 finished with value: 0.716919606072562 and parameters: {'learning_rate': 0.0007803921835659621, 'l1_coef': 2.4360768812131997e-07, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.8343061413070235, 'num_epochs': 150}. Best is trial 8 with value: 0.716919606072562.\n",
      "[I 2024-05-23 06:45:34,444] Trial 15 finished with value: 0.8439069062471389 and parameters: {'learning_rate': 0.01855790367023691, 'l1_coef': 0.0005225326485419217, 'patience': 10, 'batch_size': 128, 'lr_factor': 0.899682121904837, 'num_epochs': 104}. Best is trial 8 with value: 0.716919606072562.\n",
      "[I 2024-05-23 06:45:59,556] Trial 0 finished with value: 0.8249623060226441 and parameters: {'learning_rate': 0.00011809454202709307, 'l1_coef': 0.00013889347111115994, 'patience': 19, 'batch_size': 256, 'lr_factor': 0.6026026371134279, 'num_epochs': 435}. Best is trial 8 with value: 0.716919606072562.\n",
      "[I 2024-05-23 06:46:16,890] Trial 11 finished with value: 0.723846760392189 and parameters: {'learning_rate': 0.001676896965625865, 'l1_coef': 8.004066699326526e-09, 'patience': 19, 'batch_size': 128, 'lr_factor': 0.6539518828801997, 'num_epochs': 344}. Best is trial 8 with value: 0.716919606072562.\n",
      "[I 2024-05-23 06:46:37,976] Trial 13 finished with value: 0.859535893372127 and parameters: {'learning_rate': 0.019843527404244058, 'l1_coef': 0.0006364905475267113, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.7731391735481656, 'num_epochs': 115}. Best is trial 8 with value: 0.716919606072562.\n",
      "[I 2024-05-23 06:48:06,115] Trial 17 finished with value: 0.8152900069952012 and parameters: {'learning_rate': 5.6496036277833394e-05, 'l1_coef': 3.160087156959225e-09, 'patience': 15, 'batch_size': 128, 'lr_factor': 0.4242859089107708, 'num_epochs': 103}. Best is trial 8 with value: 0.716919606072562.\n",
      "[I 2024-05-23 06:50:19,496] Trial 16 finished with value: 0.719571498462132 and parameters: {'learning_rate': 0.0001731796809139669, 'l1_coef': 7.101114382581614e-09, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.8556740499541959, 'num_epochs': 364}. Best is trial 8 with value: 0.716919606072562.\n",
      "[I 2024-05-23 06:54:14,898] Trial 4 finished with value: 0.7839913828032358 and parameters: {'learning_rate': 0.00024068868272316202, 'l1_coef': 0.00029616760435150554, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.7979109136224568, 'num_epochs': 459}. Best is trial 8 with value: 0.716919606072562.\n",
      "[I 2024-05-23 06:59:43,356] Trial 7 finished with value: 0.8374575504889854 and parameters: {'learning_rate': 2.8421134262351195e-06, 'l1_coef': 2.2976495219384437e-06, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.7584198198963493, 'num_epochs': 305}. Best is trial 8 with value: 0.716919606072562.\n",
      "[I 2024-05-23 07:00:13,177] Trial 18 finished with value: 0.7922131639260511 and parameters: {'learning_rate': 1.61844104741211e-05, 'l1_coef': 2.405940626519617e-05, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.4524044707628553, 'num_epochs': 384}. Best is trial 8 with value: 0.716919606072562.\n",
      "[I 2024-05-23 07:01:35,364] Trial 21 finished with value: 0.8401105321370638 and parameters: {'learning_rate': 3.623487988854403e-06, 'l1_coef': 2.4006679942518864e-08, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.864997807664823, 'num_epochs': 170}. Best is trial 8 with value: 0.716919606072562.\n",
      "[I 2024-05-23 07:02:24,964] Trial 22 finished with value: 0.8146712000553424 and parameters: {'learning_rate': 7.312771367536364e-06, 'l1_coef': 1.6312962666698206e-08, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.8991753996642897, 'num_epochs': 214}. Best is trial 8 with value: 0.716919606072562.\n",
      "[I 2024-05-23 07:03:24,642] Trial 27 finished with value: 0.7094255191939217 and parameters: {'learning_rate': 0.000546815598315524, 'l1_coef': 2.3314447574714152e-07, 'patience': 8, 'batch_size': 64, 'lr_factor': 0.8972214303058472, 'num_epochs': 234}. Best is trial 27 with value: 0.7094255191939217.\n",
      "[I 2024-05-23 07:04:00,138] Trial 23 finished with value: 0.8317040525949917 and parameters: {'learning_rate': 3.971265115362122e-06, 'l1_coef': 1.9712994708292157e-07, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.6448989413908759, 'num_epochs': 216}. Best is trial 27 with value: 0.7094255191939217.\n",
      "[I 2024-05-23 07:05:21,062] Trial 20 finished with value: 1.0688379196020272 and parameters: {'learning_rate': 4.414039056138258e-06, 'l1_coef': 0.0627580037768862, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.892943342181853, 'num_epochs': 213}. Best is trial 27 with value: 0.7094255191939217.\n",
      "[I 2024-05-23 07:05:53,848] Trial 30 finished with value: 0.7079871007374354 and parameters: {'learning_rate': 0.0008139447876193605, 'l1_coef': 1.9373438241036138e-07, 'patience': 7, 'batch_size': 64, 'lr_factor': 0.6820146971306893, 'num_epochs': 239}. Best is trial 30 with value: 0.7079871007374354.\n",
      "[I 2024-05-23 07:06:03,731] Trial 31 finished with value: 0.736886157308306 and parameters: {'learning_rate': 0.0005983025140881585, 'l1_coef': 5.646166682187496e-07, 'patience': 7, 'batch_size': 64, 'lr_factor': 0.7039268288196241, 'num_epochs': 260}. Best is trial 30 with value: 0.7079871007374354.\n",
      "[I 2024-05-23 07:06:26,095] Trial 14 finished with value: 1.0553514957427979 and parameters: {'learning_rate': 4.577478695564631e-06, 'l1_coef': 0.010782777146409602, 'patience': 5, 'batch_size': 64, 'lr_factor': 0.696082719352641, 'num_epochs': 368}. Best is trial 30 with value: 0.7079871007374354.\n",
      "[I 2024-05-23 07:07:22,086] Trial 29 finished with value: 0.9504577091761999 and parameters: {'learning_rate': 0.0006225561167322985, 'l1_coef': 0.06266722194556618, 'patience': 6, 'batch_size': 64, 'lr_factor': 0.33935860405723245, 'num_epochs': 258}. Best is trial 30 with value: 0.7079871007374354.\n",
      "[I 2024-05-23 07:07:34,904] Trial 26 finished with value: 0.8135333793503898 and parameters: {'learning_rate': 1.592026450177347e-05, 'l1_coef': 7.338070225958196e-08, 'patience': 7, 'batch_size': 64, 'lr_factor': 0.8913163849959542, 'num_epochs': 216}. Best is trial 30 with value: 0.7079871007374354.\n",
      "[I 2024-05-23 07:08:19,639] Trial 33 finished with value: 0.7216107998575483 and parameters: {'learning_rate': 0.0006251722402532119, 'l1_coef': 4.214919472691978e-07, 'patience': 7, 'batch_size': 64, 'lr_factor': 0.7029792182565416, 'num_epochs': 260}. Best is trial 30 with value: 0.7079871007374354.\n",
      "[I 2024-05-23 07:08:37,305] Trial 34 finished with value: 0.7240048050880432 and parameters: {'learning_rate': 0.0005996141637012622, 'l1_coef': 1.4944766314574843e-06, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.707139997614757, 'num_epochs': 173}. Best is trial 30 with value: 0.7079871007374354.\n",
      "[I 2024-05-23 07:08:41,706] Trial 32 finished with value: 0.707468683379037 and parameters: {'learning_rate': 0.0006155078074723796, 'l1_coef': 3.8774472895354083e-07, 'patience': 7, 'batch_size': 64, 'lr_factor': 0.7007255392256676, 'num_epochs': 268}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:08:45,058] Trial 35 finished with value: 0.7273666484015328 and parameters: {'learning_rate': 0.000743198772193309, 'l1_coef': 1.0582128985523059e-07, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.5448420657529327, 'num_epochs': 151}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:08:57,245] Trial 36 finished with value: 0.7620536633900235 and parameters: {'learning_rate': 0.0044644310123079485, 'l1_coef': 9.824058052624501e-08, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.8223204558127292, 'num_epochs': 160}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:09:02,440] Trial 37 finished with value: 0.7268522875649588 and parameters: {'learning_rate': 0.0033486660809703963, 'l1_coef': 1.0660590050560896e-06, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.10906837299860372, 'num_epochs': 158}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:09:42,027] Trial 38 finished with value: 0.7296589314937592 and parameters: {'learning_rate': 0.0033080713398788014, 'l1_coef': 3.0322522228288203e-06, 'patience': 9, 'batch_size': 256, 'lr_factor': 0.5499280073265755, 'num_epochs': 153}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:09:46,633] Trial 39 finished with value: 0.7692589461803436 and parameters: {'learning_rate': 0.0038315357560465735, 'l1_coef': 5.877705130610339e-10, 'patience': 9, 'batch_size': 256, 'lr_factor': 0.5737651324630424, 'num_epochs': 146}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:09:50,292] Trial 40 finished with value: 0.7407213500567845 and parameters: {'learning_rate': 0.004179763971421572, 'l1_coef': 1.1761831770743657e-07, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.5498090597623949, 'num_epochs': 148}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:10:27,365] Trial 41 finished with value: 0.729130220413208 and parameters: {'learning_rate': 0.005177250362160945, 'l1_coef': 5.880044478176312e-06, 'patience': 10, 'batch_size': 256, 'lr_factor': 0.8203269981993162, 'num_epochs': 237}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:12:02,752] Trial 44 finished with value: 0.8027867138385772 and parameters: {'learning_rate': 9.365951823883884e-05, 'l1_coef': 8.147879565745389e-10, 'patience': 11, 'batch_size': 256, 'lr_factor': 0.823500977916127, 'num_epochs': 282}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:12:10,476] Trial 43 finished with value: 0.8156791865825653 and parameters: {'learning_rate': 6.358823711718311e-05, 'l1_coef': 1.807129811360199e-10, 'patience': 8, 'batch_size': 256, 'lr_factor': 0.5791442784044959, 'num_epochs': 281}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:12:57,477] Trial 42 finished with value: 0.8020315170288086 and parameters: {'learning_rate': 7.274408832382713e-05, 'l1_coef': 5.805139302981202e-10, 'patience': 10, 'batch_size': 256, 'lr_factor': 0.5875035538128064, 'num_epochs': 284}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:13:42,326] Trial 45 finished with value: 0.7943458761487688 and parameters: {'learning_rate': 5.845268050211583e-05, 'l1_coef': 9.789860913462285e-06, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.827705672300364, 'num_epochs': 238}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:13:51,775] Trial 46 finished with value: 0.7808312773704529 and parameters: {'learning_rate': 6.630508863690864e-05, 'l1_coef': 1.2476319767249377e-05, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.836325310075003, 'num_epochs': 285}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:14:08,451] Trial 25 finished with value: 1.037129194002885 and parameters: {'learning_rate': 9.497396686867769e-06, 'l1_coef': 0.09472493002956271, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.8826010182937413, 'num_epochs': 218}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:14:16,645] Trial 48 finished with value: 0.7739002091544015 and parameters: {'learning_rate': 0.0002928759299270681, 'l1_coef': 4.9716558401093095e-05, 'patience': 6, 'batch_size': 64, 'lr_factor': 0.6114007122684526, 'num_epochs': 188}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:14:31,757] Trial 47 finished with value: 0.7832548141479492 and parameters: {'learning_rate': 5.602580275251238e-05, 'l1_coef': 1.2547253829881967e-05, 'patience': 6, 'batch_size': 64, 'lr_factor': 0.6103084527570081, 'num_epochs': 331}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:14:34,697] Trial 19 finished with value: 1.0667901481900897 and parameters: {'learning_rate': 4.80092693612218e-06, 'l1_coef': 0.09685288423089856, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.3921774146175258, 'num_epochs': 500}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:14:42,008] Trial 49 finished with value: 0.7576120785304479 and parameters: {'learning_rate': 0.0002121887459436121, 'l1_coef': 2.3141121799720128e-05, 'patience': 6, 'batch_size': 64, 'lr_factor': 0.7458898646278477, 'num_epochs': 330}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:16:09,747] Trial 28 finished with value: 0.982616775376456 and parameters: {'learning_rate': 1.94160039909608e-05, 'l1_coef': 0.08568781837444296, 'patience': 7, 'batch_size': 64, 'lr_factor': 0.32275054168547124, 'num_epochs': 498}. Best is trial 32 with value: 0.707468683379037.\n",
      "[I 2024-05-23 07:16:32,980] Trial 24 finished with value: 1.026177854721363 and parameters: {'learning_rate': 4.8499381589249274e-06, 'l1_coef': 0.08746027977636912, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.8982940495301157, 'num_epochs': 493}. Best is trial 32 with value: 0.707468683379037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 12 - Best hyperparameters: {'learning_rate': 0.0006155078074723796, 'l1_coef': 3.8774472895354083e-07, 'patience': 7, 'batch_size': 64, 'lr_factor': 0.7007255392256676, 'num_epochs': 268}\n",
      "Chr 12 - Best value: 0.7075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 07:16:41,195] A new study created in RDB with name: unphased_full_23andMe_chr13_study_logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr12/final_model_chr12.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr12/individual_r2_scores_chr12.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr12/individual_iqs_scores_chr12.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  112\n",
      "PRS313 SNPs:  5\n",
      "Total SNPs used for Training:  107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 07:17:59,634] Trial 9 finished with value: 0.8241600375909073 and parameters: {'learning_rate': 0.02913786817115034, 'l1_coef': 0.014049887133628135, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.8461631236005889, 'num_epochs': 454}. Best is trial 9 with value: 0.8241600375909073.\n",
      "[I 2024-05-23 07:18:03,145] Trial 1 finished with value: 0.6552356064319611 and parameters: {'learning_rate': 0.004877840654457323, 'l1_coef': 2.975729152584155e-05, 'patience': 8, 'batch_size': 128, 'lr_factor': 0.7870862888839673, 'num_epochs': 363}. Best is trial 1 with value: 0.6552356064319611.\n",
      "[I 2024-05-23 07:18:04,558] Trial 0 finished with value: 0.6513668230601719 and parameters: {'learning_rate': 0.0038384317177056755, 'l1_coef': 4.066016467461078e-10, 'patience': 7, 'batch_size': 64, 'lr_factor': 0.1931670550618998, 'num_epochs': 495}. Best is trial 0 with value: 0.6513668230601719.\n",
      "[I 2024-05-23 07:18:42,441] Trial 6 finished with value: 0.6522824672552255 and parameters: {'learning_rate': 0.001611724069577809, 'l1_coef': 1.9097309398564166e-06, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.47671292775711926, 'num_epochs': 337}. Best is trial 0 with value: 0.6513668230601719.\n",
      "[I 2024-05-23 07:18:46,768] Trial 3 finished with value: 0.6534708768129349 and parameters: {'learning_rate': 0.0018521949415272172, 'l1_coef': 1.7923406747420996e-09, 'patience': 10, 'batch_size': 128, 'lr_factor': 0.3844282802590784, 'num_epochs': 269}. Best is trial 0 with value: 0.6513668230601719.\n",
      "[I 2024-05-23 07:20:17,455] Trial 10 finished with value: 0.6518667890475347 and parameters: {'learning_rate': 0.005269510943201002, 'l1_coef': 2.9585057529800475e-05, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.23296461944870528, 'num_epochs': 194}. Best is trial 0 with value: 0.6513668230601719.\n",
      "[I 2024-05-23 07:22:46,607] Trial 4 finished with value: 0.7018481731414795 and parameters: {'learning_rate': 0.00010114812670463629, 'l1_coef': 1.5001754970728595e-08, 'patience': 6, 'batch_size': 256, 'lr_factor': 0.7551663775787695, 'num_epochs': 437}. Best is trial 0 with value: 0.6513668230601719.\n",
      "[I 2024-05-23 07:23:27,793] Trial 15 finished with value: 0.6686208265168326 and parameters: {'learning_rate': 0.004124654158498256, 'l1_coef': 0.00023712429501257287, 'patience': 14, 'batch_size': 64, 'lr_factor': 0.49505333575659183, 'num_epochs': 246}. Best is trial 0 with value: 0.6513668230601719.\n",
      "[I 2024-05-23 07:23:31,080] Trial 5 finished with value: 0.6792610943317413 and parameters: {'learning_rate': 0.00022195111355305104, 'l1_coef': 3.823865538046212e-06, 'patience': 8, 'batch_size': 256, 'lr_factor': 0.4324292056240422, 'num_epochs': 482}. Best is trial 0 with value: 0.6513668230601719.\n",
      "[I 2024-05-23 07:23:57,985] Trial 7 finished with value: 0.7807216984885079 and parameters: {'learning_rate': 1.4023161677157921e-05, 'l1_coef': 6.121805345806229e-07, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.2534442635154158, 'num_epochs': 126}. Best is trial 0 with value: 0.6513668230601719.\n",
      "[I 2024-05-23 07:24:29,050] Trial 12 finished with value: 0.7565790891647339 and parameters: {'learning_rate': 0.00019052588616697103, 'l1_coef': 0.0011402635709415816, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.724573490553995, 'num_epochs': 186}. Best is trial 0 with value: 0.6513668230601719.\n",
      "[I 2024-05-23 07:24:42,317] Trial 18 finished with value: 0.669513315813882 and parameters: {'learning_rate': 0.03839984409104245, 'l1_coef': 0.00019021755104029853, 'patience': 12, 'batch_size': 64, 'lr_factor': 0.41373531529289254, 'num_epochs': 401}. Best is trial 0 with value: 0.6513668230601719.\n",
      "[I 2024-05-23 07:25:03,508] Trial 13 finished with value: 0.7247837126255036 and parameters: {'learning_rate': 0.00010344140786716103, 'l1_coef': 0.00010422177943509122, 'patience': 9, 'batch_size': 256, 'lr_factor': 0.7708549854957473, 'num_epochs': 297}. Best is trial 0 with value: 0.6513668230601719.\n",
      "[I 2024-05-23 07:25:20,555] Trial 11 finished with value: 0.6499750522466806 and parameters: {'learning_rate': 0.00041311567216335913, 'l1_coef': 9.430700923925392e-10, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.8521018399874372, 'num_epochs': 368}. Best is trial 11 with value: 0.6499750522466806.\n",
      "[I 2024-05-23 07:25:45,004] Trial 16 finished with value: 0.6609072655439376 and parameters: {'learning_rate': 0.0006457689277012881, 'l1_coef': 2.054895470088227e-08, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.33749871644695095, 'num_epochs': 323}. Best is trial 11 with value: 0.6499750522466806.\n",
      "[I 2024-05-23 07:26:53,495] Trial 21 finished with value: 0.7135993306453412 and parameters: {'learning_rate': 0.060633046706354804, 'l1_coef': 3.342189467630044e-10, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.1541856103947672, 'num_epochs': 204}. Best is trial 11 with value: 0.6499750522466806.\n",
      "[I 2024-05-23 07:26:54,959] Trial 20 finished with value: 0.6678508657675523 and parameters: {'learning_rate': 0.07358387269115255, 'l1_coef': 1.9914200501297235e-10, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.11725165767655663, 'num_epochs': 193}. Best is trial 11 with value: 0.6499750522466806.\n",
      "[I 2024-05-23 07:27:23,590] Trial 17 finished with value: 0.647574125803434 and parameters: {'learning_rate': 0.0015014126430451193, 'l1_coef': 1.76899612906306e-08, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.49453084454201235, 'num_epochs': 322}. Best is trial 17 with value: 0.647574125803434.\n",
      "[I 2024-05-23 07:33:44,827] Trial 22 finished with value: 0.8859387388596168 and parameters: {'learning_rate': 1.15679972943421e-06, 'l1_coef': 1.4289996831557155e-10, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.11709024335447292, 'num_epochs': 105}. Best is trial 17 with value: 0.647574125803434.\n",
      "[I 2024-05-23 07:40:05,896] Trial 8 finished with value: 0.9413732262758108 and parameters: {'learning_rate': 1.0622213381230928e-06, 'l1_coef': 0.002229033939537835, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.4074062401122446, 'num_epochs': 277}. Best is trial 17 with value: 0.647574125803434.\n",
      "[I 2024-05-23 07:40:54,114] Trial 2 finished with value: 0.7648076204153207 and parameters: {'learning_rate': 4.328560140001074e-06, 'l1_coef': 1.841318900743435e-05, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.22230715813730956, 'num_epochs': 287}. Best is trial 17 with value: 0.647574125803434.\n",
      "[I 2024-05-23 07:41:41,379] Trial 14 finished with value: 0.7916187478945806 and parameters: {'learning_rate': 1.105728482637686e-06, 'l1_coef': 1.3768192643974061e-06, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.14038896738438542, 'num_epochs': 272}. Best is trial 17 with value: 0.647574125803434.\n",
      "[I 2024-05-23 07:45:38,642] Trial 19 finished with value: 0.8045276079859052 and parameters: {'learning_rate': 1.6073261274575734e-06, 'l1_coef': 1.3872290911700724e-10, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.11417977541053706, 'num_epochs': 388}. Best is trial 17 with value: 0.647574125803434.\n",
      "[I 2024-05-23 07:45:49,039] Trial 30 finished with value: 0.6523187501089913 and parameters: {'learning_rate': 0.0006779229478983015, 'l1_coef': 2.8401519717194894e-08, 'patience': 17, 'batch_size': 64, 'lr_factor': 0.621310112962853, 'num_epochs': 377}. Best is trial 17 with value: 0.647574125803434.\n",
      "[I 2024-05-23 07:46:38,286] Trial 31 finished with value: 0.6527888791901726 and parameters: {'learning_rate': 0.000676329362136699, 'l1_coef': 2.7639512670799426e-08, 'patience': 17, 'batch_size': 64, 'lr_factor': 0.60812355329476, 'num_epochs': 394}. Best is trial 17 with value: 0.647574125803434.\n",
      "[I 2024-05-23 07:47:01,230] Trial 24 finished with value: 0.8217127817017691 and parameters: {'learning_rate': 1.2993891128129004e-06, 'l1_coef': 1.062360730109099e-10, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.12398394432730431, 'num_epochs': 400}. Best is trial 17 with value: 0.647574125803434.\n",
      "[I 2024-05-23 07:47:20,063] Trial 33 finished with value: 0.6455320596694947 and parameters: {'learning_rate': 0.013256211061815097, 'l1_coef': 3.478607009962036e-09, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.5929673578896678, 'num_epochs': 492}. Best is trial 33 with value: 0.6455320596694947.\n",
      "[I 2024-05-23 07:47:40,915] Trial 32 finished with value: 0.6448345150266375 and parameters: {'learning_rate': 0.011426792766034996, 'l1_coef': 3.1943984725361415e-08, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.5694895936227456, 'num_epochs': 497}. Best is trial 32 with value: 0.6448345150266375.\n",
      "[I 2024-05-23 07:48:28,310] Trial 25 finished with value: 0.7865980301584516 and parameters: {'learning_rate': 1.9550117457336246e-06, 'l1_coef': 1.8994409955597064e-10, 'patience': 17, 'batch_size': 64, 'lr_factor': 0.601164007604847, 'num_epochs': 385}. Best is trial 32 with value: 0.6448345150266375.\n",
      "[I 2024-05-23 07:48:54,808] Trial 35 finished with value: 0.6675810116987961 and parameters: {'learning_rate': 0.014523807007079845, 'l1_coef': 1.912627413376221e-09, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.632311806987369, 'num_epochs': 435}. Best is trial 32 with value: 0.6448345150266375.\n",
      "[I 2024-05-23 07:49:18,463] Trial 37 finished with value: 0.6424803921154567 and parameters: {'learning_rate': 0.02452264812309542, 'l1_coef': 1.6825247098958544e-07, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.6085456184030417, 'num_epochs': 453}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:49:19,377] Trial 36 finished with value: 0.6431113756619967 and parameters: {'learning_rate': 0.017325225493966576, 'l1_coef': 2.3954042393953278e-09, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.607905469774767, 'num_epochs': 446}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:50:00,132] Trial 38 finished with value: 0.667784515448979 and parameters: {'learning_rate': 0.01605687796686021, 'l1_coef': 1.7794576801764592e-07, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.5605159918475439, 'num_epochs': 494}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:50:45,078] Trial 39 finished with value: 0.6661517568996974 and parameters: {'learning_rate': 0.012657966861400652, 'l1_coef': 1.513144185312841e-07, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.5346360844249209, 'num_epochs': 488}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:50:47,371] Trial 41 finished with value: 0.6460933004106794 and parameters: {'learning_rate': 0.012106492169232328, 'l1_coef': 1.4708758261567767e-07, 'patience': 16, 'batch_size': 64, 'lr_factor': 0.5568721886221549, 'num_epochs': 499}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:50:50,642] Trial 40 finished with value: 0.6679578764098032 and parameters: {'learning_rate': 0.013583269918644154, 'l1_coef': 2.0812402879719307e-07, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.5468426516876239, 'num_epochs': 500}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:51:09,602] Trial 28 finished with value: 0.6963162312140831 and parameters: {'learning_rate': 2.74010168889741e-05, 'l1_coef': 6.145185739579368e-08, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.6376518660789267, 'num_epochs': 377}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:51:45,647] Trial 42 finished with value: 0.6456934537206378 and parameters: {'learning_rate': 0.010348531022499928, 'l1_coef': 1.7284631373176996e-07, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.6828467882778712, 'num_epochs': 467}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:52:23,689] Trial 44 finished with value: 0.6471528857946396 and parameters: {'learning_rate': 0.007168613649880702, 'l1_coef': 4.781975289327928e-09, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.6655748961403796, 'num_epochs': 460}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:52:23,690] Trial 43 finished with value: 0.6464808374643326 and parameters: {'learning_rate': 0.00663663737253265, 'l1_coef': 3.894263333545017e-09, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.6906889819571715, 'num_epochs': 462}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:52:29,978] Trial 45 finished with value: 0.6482183039188385 and parameters: {'learning_rate': 0.00599000055421581, 'l1_coef': 3.150874843804469e-09, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.6698626115666433, 'num_epochs': 458}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:52:43,339] Trial 47 finished with value: 0.712651714682579 and parameters: {'learning_rate': 0.028883082361407856, 'l1_coef': 3.882097231726905e-09, 'patience': 15, 'batch_size': 128, 'lr_factor': 0.6936081926542569, 'num_epochs': 427}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:52:47,970] Trial 46 finished with value: 0.6467251181602478 and parameters: {'learning_rate': 0.0068068826822277086, 'l1_coef': 4.8956394131426026e-09, 'patience': 19, 'batch_size': 128, 'lr_factor': 0.691419270712475, 'num_epochs': 456}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:52:54,219] Trial 23 finished with value: 0.7697432637214661 and parameters: {'learning_rate': 3.4329986041508816e-06, 'l1_coef': 1.1661844009475616e-10, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.10605086200284625, 'num_epochs': 491}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:53:13,381] Trial 48 finished with value: 0.646148145198822 and parameters: {'learning_rate': 0.02863653766694264, 'l1_coef': 9.019505273944202e-06, 'patience': 19, 'batch_size': 256, 'lr_factor': 0.3270727961276497, 'num_epochs': 429}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:53:43,745] Trial 26 finished with value: 0.7682146106447492 and parameters: {'learning_rate': 3.6724843084547345e-06, 'l1_coef': 2.2759082849870175e-08, 'patience': 17, 'batch_size': 64, 'lr_factor': 0.6207391931010404, 'num_epochs': 498}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:53:44,808] Trial 49 finished with value: 0.649832034111023 and parameters: {'learning_rate': 0.002512748438663436, 'l1_coef': 5.3902088083044984e-06, 'patience': 19, 'batch_size': 256, 'lr_factor': 0.45236526203982463, 'num_epochs': 430}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:54:31,139] Trial 27 finished with value: 0.7835799813270569 and parameters: {'learning_rate': 1.6729771684780644e-06, 'l1_coef': 7.601996325263257e-08, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.6111041096063188, 'num_epochs': 386}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:54:55,228] Trial 29 finished with value: 0.6952620891424326 and parameters: {'learning_rate': 2.4834329122519602e-05, 'l1_coef': 9.428694976048135e-08, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.6048878737290059, 'num_epochs': 386}. Best is trial 37 with value: 0.6424803921154567.\n",
      "[I 2024-05-23 07:54:56,132] Trial 34 finished with value: 0.6807540893554688 and parameters: {'learning_rate': 3.484286786316049e-05, 'l1_coef': 1.482932312418395e-09, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.5818954040184796, 'num_epochs': 496}. Best is trial 37 with value: 0.6424803921154567.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 13 - Best hyperparameters: {'learning_rate': 0.02452264812309542, 'l1_coef': 1.6825247098958544e-07, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.6085456184030417, 'num_epochs': 453}\n",
      "Chr 13 - Best value: 0.6425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 07:54:59,293] A new study created in RDB with name: unphased_full_23andMe_chr14_study_logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr13/final_model_chr13.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr13/individual_r2_scores_chr13.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr13/individual_iqs_scores_chr13.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  164\n",
      "PRS313 SNPs:  8\n",
      "Total SNPs used for Training:  156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 07:56:14,672] Trial 0 finished with value: 0.7962499499320984 and parameters: {'learning_rate': 0.001529138659454937, 'l1_coef': 6.604992067547774e-05, 'patience': 15, 'batch_size': 256, 'lr_factor': 0.2180695235894331, 'num_epochs': 106}. Best is trial 0 with value: 0.7962499499320984.\n",
      "[I 2024-05-23 07:56:29,530] Trial 1 finished with value: 0.7576070725917816 and parameters: {'learning_rate': 0.005564733034604567, 'l1_coef': 3.3056141780205077e-09, 'patience': 19, 'batch_size': 256, 'lr_factor': 0.5398223844700974, 'num_epochs': 125}. Best is trial 1 with value: 0.7576070725917816.\n",
      "[I 2024-05-23 07:57:23,515] Trial 9 finished with value: 0.765370374917984 and parameters: {'learning_rate': 0.0014000061217567356, 'l1_coef': 1.3875062281694439e-08, 'patience': 11, 'batch_size': 256, 'lr_factor': 0.29036852712560235, 'num_epochs': 381}. Best is trial 1 with value: 0.7576070725917816.\n",
      "[I 2024-05-23 07:57:54,341] Trial 6 finished with value: 0.7572415278508113 and parameters: {'learning_rate': 0.024767681354500463, 'l1_coef': 9.055524094148582e-07, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.1666169855893999, 'num_epochs': 412}. Best is trial 6 with value: 0.7572415278508113.\n",
      "[I 2024-05-23 08:00:09,799] Trial 3 finished with value: 0.8239532470703125 and parameters: {'learning_rate': 8.646595497908146e-05, 'l1_coef': 8.355125519720837e-10, 'patience': 13, 'batch_size': 256, 'lr_factor': 0.8520964820520583, 'num_epochs': 230}. Best is trial 6 with value: 0.7572415278508113.\n",
      "[I 2024-05-23 08:00:50,657] Trial 14 finished with value: 0.8799085021018982 and parameters: {'learning_rate': 0.08363936694828973, 'l1_coef': 1.815901423339637e-07, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.1403366797183453, 'num_epochs': 387}. Best is trial 6 with value: 0.7572415278508113.\n",
      "[I 2024-05-23 08:01:27,887] Trial 2 finished with value: 0.8111094749890843 and parameters: {'learning_rate': 0.00012504137337810808, 'l1_coef': 0.00023857187360187848, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.6342299228072582, 'num_epochs': 165}. Best is trial 6 with value: 0.7572415278508113.\n",
      "[I 2024-05-23 08:03:24,600] Trial 8 finished with value: 1.0292983889579772 and parameters: {'learning_rate': 0.00010862506392861204, 'l1_coef': 0.012463783060346435, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.6516570703827482, 'num_epochs': 241}. Best is trial 6 with value: 0.7572415278508113.\n",
      "[I 2024-05-23 08:03:33,235] Trial 11 finished with value: 1.020608478784561 and parameters: {'learning_rate': 6.766266310185478e-06, 'l1_coef': 0.0007005401576634634, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.3594810476721606, 'num_epochs': 196}. Best is trial 6 with value: 0.7572415278508113.\n",
      "[I 2024-05-23 08:04:48,613] Trial 17 finished with value: 0.7607852518558502 and parameters: {'learning_rate': 0.003976621505472963, 'l1_coef': 1.4686971573394152e-07, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.29377291647468906, 'num_epochs': 256}. Best is trial 6 with value: 0.7572415278508113.\n",
      "[I 2024-05-23 08:05:16,832] Trial 7 finished with value: 0.8015390379088266 and parameters: {'learning_rate': 4.613054771755762e-05, 'l1_coef': 2.252001997584555e-06, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.43897194414366314, 'num_epochs': 301}. Best is trial 6 with value: 0.7572415278508113.\n",
      "[I 2024-05-23 08:06:46,161] Trial 10 finished with value: 0.8237044402531216 and parameters: {'learning_rate': 4.4552969994167544e-05, 'l1_coef': 1.1538271920052112e-07, 'patience': 6, 'batch_size': 64, 'lr_factor': 0.702867944085262, 'num_epochs': 286}. Best is trial 6 with value: 0.7572415278508113.\n",
      "[I 2024-05-23 08:07:05,758] Trial 4 finished with value: 0.8971555083990097 and parameters: {'learning_rate': 1.079464866069231e-05, 'l1_coef': 2.93881325980813e-09, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.15329870501359943, 'num_epochs': 275}. Best is trial 6 with value: 0.7572415278508113.\n",
      "[I 2024-05-23 08:07:24,462] Trial 20 finished with value: 0.8601835434253399 and parameters: {'learning_rate': 0.044382824898949354, 'l1_coef': 1.3105604832275631e-10, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.6019395078588631, 'num_epochs': 472}. Best is trial 6 with value: 0.7572415278508113.\n",
      "[I 2024-05-23 08:08:08,597] Trial 19 finished with value: 0.8012517076272232 and parameters: {'learning_rate': 0.062046384570460134, 'l1_coef': 3.244476211751963e-06, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.43242974502724774, 'num_epochs': 488}. Best is trial 6 with value: 0.7572415278508113.\n",
      "[I 2024-05-23 08:09:09,736] Trial 22 finished with value: 0.8379009393545298 and parameters: {'learning_rate': 0.03374397717543462, 'l1_coef': 1.0037062234650272e-10, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.5359046628192935, 'num_epochs': 486}. Best is trial 6 with value: 0.7572415278508113.\n",
      "[I 2024-05-23 08:09:16,651] Trial 21 finished with value: 0.7723487927363468 and parameters: {'learning_rate': 0.034110161288072635, 'l1_coef': 4.3170355831695733e-10, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.5086802817239648, 'num_epochs': 494}. Best is trial 6 with value: 0.7572415278508113.\n",
      "[I 2024-05-23 08:09:22,115] Trial 24 finished with value: 0.754011383652687 and parameters: {'learning_rate': 0.010700133573403476, 'l1_coef': 2.732660869695556e-06, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.5299102366866987, 'num_epochs': 363}. Best is trial 24 with value: 0.754011383652687.\n",
      "[I 2024-05-23 08:09:47,209] Trial 18 finished with value: 0.9305986583232879 and parameters: {'learning_rate': 8.631113607793778e-06, 'l1_coef': 9.549712123996747e-08, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.10615083905276555, 'num_epochs': 144}. Best is trial 24 with value: 0.754011383652687.\n",
      "[I 2024-05-23 08:09:58,170] Trial 12 finished with value: 9.535429859161377 and parameters: {'learning_rate': 1.3259676098991414e-06, 'l1_coef': 0.0854035280664262, 'patience': 10, 'batch_size': 128, 'lr_factor': 0.45964997467257074, 'num_epochs': 286}. Best is trial 24 with value: 0.754011383652687.\n",
      "[I 2024-05-23 08:10:09,452] Trial 23 finished with value: 0.7551729624087995 and parameters: {'learning_rate': 0.009891183266520338, 'l1_coef': 5.797378983186723e-06, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.4902036100194831, 'num_epochs': 486}. Best is trial 24 with value: 0.754011383652687.\n",
      "[I 2024-05-23 08:10:29,829] Trial 26 finished with value: 0.7594053447246552 and parameters: {'learning_rate': 0.007715489225186951, 'l1_coef': 5.281320384186765e-06, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.8164738190505445, 'num_epochs': 367}. Best is trial 24 with value: 0.754011383652687.\n",
      "[I 2024-05-23 08:10:43,604] Trial 25 finished with value: 0.756690290570259 and parameters: {'learning_rate': 0.010819686965020664, 'l1_coef': 2.8331365920573947e-06, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.7739402466453549, 'num_epochs': 350}. Best is trial 24 with value: 0.754011383652687.\n",
      "[I 2024-05-23 08:10:55,793] Trial 27 finished with value: 0.7578817784786225 and parameters: {'learning_rate': 0.008889780956243392, 'l1_coef': 6.811768725140109e-06, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.7724936752599688, 'num_epochs': 361}. Best is trial 24 with value: 0.754011383652687.\n",
      "[I 2024-05-23 08:11:03,346] Trial 28 finished with value: 0.760402861237526 and parameters: {'learning_rate': 0.011704283189750982, 'l1_coef': 9.923833358812718e-06, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.8852764108661282, 'num_epochs': 377}. Best is trial 24 with value: 0.754011383652687.\n",
      "[I 2024-05-23 08:11:21,929] Trial 5 finished with value: 0.8627045571804046 and parameters: {'learning_rate': 3.1542583212069334e-05, 'l1_coef': 6.726334885994522e-09, 'patience': 15, 'batch_size': 256, 'lr_factor': 0.37943892002024515, 'num_epochs': 460}. Best is trial 24 with value: 0.754011383652687.\n",
      "[I 2024-05-23 08:11:26,264] Trial 30 finished with value: 0.7611848503351212 and parameters: {'learning_rate': 0.009053738538370635, 'l1_coef': 6.470019294543386e-06, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.7836737900697095, 'num_epochs': 416}. Best is trial 24 with value: 0.754011383652687.\n",
      "[I 2024-05-23 08:11:26,797] Trial 16 finished with value: 0.8010212608746119 and parameters: {'learning_rate': 3.875984437118855e-05, 'l1_coef': 1.3268451958351774e-08, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.1658944980579502, 'num_epochs': 481}. Best is trial 24 with value: 0.754011383652687.\n",
      "[I 2024-05-23 08:11:33,455] Trial 29 finished with value: 0.754712826013565 and parameters: {'learning_rate': 0.011267630285714219, 'l1_coef': 3.2456176348443217e-06, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.8331501365345122, 'num_epochs': 360}. Best is trial 24 with value: 0.754011383652687.\n",
      "[I 2024-05-23 08:13:04,825] Trial 31 finished with value: 0.7534553454472469 and parameters: {'learning_rate': 0.013418255778350308, 'l1_coef': 2.2264136461525066e-05, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.38397927743701044, 'num_epochs': 435}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:13:15,204] Trial 36 finished with value: 0.7794503092765808 and parameters: {'learning_rate': 0.0012189109705621904, 'l1_coef': 3.0659310564856505e-05, 'patience': 11, 'batch_size': 128, 'lr_factor': 0.7254544360552796, 'num_epochs': 329}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:14:06,876] Trial 32 finished with value: 0.7714995741844177 and parameters: {'learning_rate': 0.0007766490552412448, 'l1_coef': 1.7436942708562746e-05, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.7729115720725691, 'num_epochs': 323}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:14:32,509] Trial 33 finished with value: 0.7781506419181824 and parameters: {'learning_rate': 0.000811108254034516, 'l1_coef': 4.524651698203241e-05, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.7296558514468807, 'num_epochs': 439}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:14:33,963] Trial 34 finished with value: 0.7833459049463272 and parameters: {'learning_rate': 0.0006467695352171021, 'l1_coef': 5.256734325235408e-05, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.7649052019807369, 'num_epochs': 324}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:14:49,764] Trial 15 finished with value: 0.9346274256706237 and parameters: {'learning_rate': 3.2252725081071226e-06, 'l1_coef': 1.8635673968848794e-10, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.6581340908623048, 'num_epochs': 321}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:14:52,328] Trial 35 finished with value: 0.7764621824026108 and parameters: {'learning_rate': 0.0006544216848828163, 'l1_coef': 3.0178616134370938e-05, 'patience': 17, 'batch_size': 128, 'lr_factor': 0.7667397101492126, 'num_epochs': 329}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:15:00,256] Trial 37 finished with value: 0.7838873237371444 and parameters: {'learning_rate': 0.0005636343981495112, 'l1_coef': 4.974853794877044e-05, 'patience': 19, 'batch_size': 128, 'lr_factor': 0.6972340601800151, 'num_epochs': 327}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:15:06,028] Trial 38 finished with value: 0.7784866124391556 and parameters: {'learning_rate': 0.0008653350969592893, 'l1_coef': 4.88026507287983e-05, 'patience': 19, 'batch_size': 128, 'lr_factor': 0.7013800410664155, 'num_epochs': 323}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:15:33,822] Trial 13 finished with value: 0.8843661844730377 and parameters: {'learning_rate': 1.4543582849304222e-05, 'l1_coef': 1.0790716894679146e-07, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.3211199516930228, 'num_epochs': 498}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:16:24,057] Trial 39 finished with value: 0.7806586295366287 and parameters: {'learning_rate': 0.0006246076413926851, 'l1_coef': 3.80084575491058e-05, 'patience': 17, 'batch_size': 128, 'lr_factor': 0.23644998237453352, 'num_epochs': 318}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:17:39,921] Trial 41 finished with value: 0.7843440120036785 and parameters: {'learning_rate': 0.003283318783974641, 'l1_coef': 0.00012953630509620064, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.5874836662871623, 'num_epochs': 439}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:18:08,989] Trial 47 finished with value: 0.8211204262880178 and parameters: {'learning_rate': 0.002679612115911599, 'l1_coef': 0.0009033110963986241, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.5938474804470908, 'num_epochs': 448}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:18:14,537] Trial 44 finished with value: 0.7931907369540288 and parameters: {'learning_rate': 0.0031532884100046177, 'l1_coef': 0.00023607145434485186, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.5795309482260356, 'num_epochs': 441}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:18:28,283] Trial 46 finished with value: 0.8075502010492178 and parameters: {'learning_rate': 0.004193507314834216, 'l1_coef': 0.00048381443290348324, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.5606976874002423, 'num_epochs': 436}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:18:31,317] Trial 40 finished with value: 0.7751844626206619 and parameters: {'learning_rate': 0.0006736038194494757, 'l1_coef': 6.014375887062391e-05, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.5811454175816761, 'num_epochs': 440}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:18:44,882] Trial 42 finished with value: 0.8047983664732712 and parameters: {'learning_rate': 0.0031810631082156956, 'l1_coef': 0.00044951430725552433, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.593289673088577, 'num_epochs': 438}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:18:53,478] Trial 48 finished with value: 0.826031730725215 and parameters: {'learning_rate': 0.002716181764603717, 'l1_coef': 0.0009481304901752821, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.5893572694270566, 'num_epochs': 440}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:18:54,218] Trial 45 finished with value: 0.793081583426549 and parameters: {'learning_rate': 0.0027512009126259593, 'l1_coef': 0.0002461847065138201, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.6005563768746051, 'num_epochs': 439}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:18:59,409] Trial 43 finished with value: 0.7913671621909508 and parameters: {'learning_rate': 0.002958593153804866, 'l1_coef': 0.0003146619094045938, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.5927887462419595, 'num_epochs': 442}. Best is trial 31 with value: 0.7534553454472469.\n",
      "[I 2024-05-23 08:19:05,202] Trial 49 finished with value: 0.8467581372994643 and parameters: {'learning_rate': 0.002566595257448545, 'l1_coef': 0.0015454717108129108, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.5569447229567697, 'num_epochs': 444}. Best is trial 31 with value: 0.7534553454472469.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 14 - Best hyperparameters: {'learning_rate': 0.013418255778350308, 'l1_coef': 2.2264136461525066e-05, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.38397927743701044, 'num_epochs': 435}\n",
      "Chr 14 - Best value: 0.7535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 08:19:10,002] A new study created in RDB with name: unphased_full_23andMe_chr15_study_logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr14/final_model_chr14.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr14/individual_r2_scores_chr14.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr14/individual_iqs_scores_chr14.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  200\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 08:19:56,021] Trial 9 finished with value: 0.7004202893802097 and parameters: {'learning_rate': 0.015674177707208754, 'l1_coef': 9.372450031975693e-10, 'patience': 7, 'batch_size': 64, 'lr_factor': 0.4177496754239264, 'num_epochs': 231}. Best is trial 9 with value: 0.7004202893802097.\n",
      "[I 2024-05-23 08:21:22,315] Trial 8 finished with value: 0.7491939097642899 and parameters: {'learning_rate': 0.0001672836925532961, 'l1_coef': 1.9964233179089297e-07, 'patience': 8, 'batch_size': 128, 'lr_factor': 0.25447372161156356, 'num_epochs': 216}. Best is trial 9 with value: 0.7004202893802097.\n",
      "[I 2024-05-23 08:21:31,284] Trial 7 finished with value: 0.9459374053137642 and parameters: {'learning_rate': 0.07819935290297857, 'l1_coef': 0.006483446741401309, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.38229536993411084, 'num_epochs': 235}. Best is trial 9 with value: 0.7004202893802097.\n",
      "[I 2024-05-23 08:21:38,467] Trial 6 finished with value: 0.7884516775608063 and parameters: {'learning_rate': 0.00022393885507946445, 'l1_coef': 0.00021991465190716332, 'patience': 5, 'batch_size': 256, 'lr_factor': 0.13443342754070375, 'num_epochs': 111}. Best is trial 9 with value: 0.7004202893802097.\n",
      "[I 2024-05-23 08:22:11,023] Trial 10 finished with value: 0.7005618728124179 and parameters: {'learning_rate': 0.005533517035278641, 'l1_coef': 4.6327695669939985e-08, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.5199765717735736, 'num_epochs': 314}. Best is trial 9 with value: 0.7004202893802097.\n",
      "[I 2024-05-23 08:22:35,413] Trial 11 finished with value: 0.9033130943775177 and parameters: {'learning_rate': 0.08335437120295607, 'l1_coef': 0.004114641358335467, 'patience': 13, 'batch_size': 256, 'lr_factor': 0.7255940494321402, 'num_epochs': 204}. Best is trial 9 with value: 0.7004202893802097.\n",
      "[I 2024-05-23 08:23:02,613] Trial 2 finished with value: 0.7483400583267212 and parameters: {'learning_rate': 0.0001303344098975264, 'l1_coef': 1.1434123636323232e-09, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.19617380397818868, 'num_epochs': 263}. Best is trial 9 with value: 0.7004202893802097.\n",
      "[I 2024-05-23 08:23:37,311] Trial 14 finished with value: 0.6829961248806545 and parameters: {'learning_rate': 0.006441254872350247, 'l1_coef': 4.736852237902997e-08, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.6395471131162321, 'num_epochs': 220}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:23:42,369] Trial 13 finished with value: 0.7040875383785792 and parameters: {'learning_rate': 0.004708750307373481, 'l1_coef': 6.633411035998555e-05, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.7428730238272668, 'num_epochs': 108}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:23:43,637] Trial 12 finished with value: 0.7349534818104335 and parameters: {'learning_rate': 0.011582440104790113, 'l1_coef': 0.0004100141356030784, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.3303556036283406, 'num_epochs': 152}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:24:48,911] Trial 0 finished with value: 0.6932908654212951 and parameters: {'learning_rate': 0.0002840992359144189, 'l1_coef': 1.8255837879308695e-09, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.12548976140356205, 'num_epochs': 397}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:25:11,651] Trial 1 finished with value: 0.8821009104068462 and parameters: {'learning_rate': 0.0004982714536613327, 'l1_coef': 0.07677821384114243, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.34458740313749225, 'num_epochs': 184}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:27:04,870] Trial 17 finished with value: 0.8260771542787552 and parameters: {'learning_rate': 0.0003910503328445037, 'l1_coef': 0.0015530049006882453, 'patience': 14, 'batch_size': 128, 'lr_factor': 0.24223985596626144, 'num_epochs': 197}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:28:51,083] Trial 4 finished with value: 0.9381256784711566 and parameters: {'learning_rate': 5.9066348145052995e-05, 'l1_coef': 0.013070940950404309, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.6605347262232336, 'num_epochs': 272}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:28:57,611] Trial 15 finished with value: 0.8549800481115069 and parameters: {'learning_rate': 0.0008488513227182053, 'l1_coef': 0.005755830134054477, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.2512498321212651, 'num_epochs': 292}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:32:46,863] Trial 18 finished with value: 0.7160911202430725 and parameters: {'learning_rate': 6.635821988127624e-05, 'l1_coef': 3.641382143126515e-05, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.5670121096888251, 'num_epochs': 451}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:43:39,293] Trial 16 finished with value: 0.8464031040668487 and parameters: {'learning_rate': 2.853399397919331e-06, 'l1_coef': 2.157152878498796e-09, 'patience': 8, 'batch_size': 128, 'lr_factor': 0.549554546967634, 'num_epochs': 478}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:46:56,004] Trial 3 finished with value: 0.8288374423980713 and parameters: {'learning_rate': 3.1622180134626807e-06, 'l1_coef': 6.123575779084895e-09, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.6954308617862761, 'num_epochs': 474}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:47:12,207] Trial 5 finished with value: 0.9698376893997193 and parameters: {'learning_rate': 2.049927746649129e-05, 'l1_coef': 0.01757621231903662, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.7068002281932649, 'num_epochs': 481}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:49:39,569] Trial 20 finished with value: 0.847107538155147 and parameters: {'learning_rate': 4.507798897628689e-06, 'l1_coef': 6.884636376690752e-08, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.5876165658616418, 'num_epochs': 425}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:49:55,590] Trial 28 finished with value: 0.6871264278888702 and parameters: {'learning_rate': 0.001357721785077668, 'l1_coef': 1.0348046779955814e-10, 'patience': 11, 'batch_size': 256, 'lr_factor': 0.856738618296712, 'num_epochs': 358}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:50:16,208] Trial 21 finished with value: 0.825395461491176 and parameters: {'learning_rate': 2.920987045700311e-06, 'l1_coef': 4.513628031010904e-08, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.57829924156821, 'num_epochs': 429}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:51:26,027] Trial 22 finished with value: 0.8451904313904899 and parameters: {'learning_rate': 4.408238915235669e-06, 'l1_coef': 5.948651154416768e-08, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.5921492747747334, 'num_epochs': 418}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:51:55,078] Trial 30 finished with value: 0.6942640900611877 and parameters: {'learning_rate': 0.0014154092241997793, 'l1_coef': 1.6661089631640802e-10, 'patience': 11, 'batch_size': 256, 'lr_factor': 0.8994566205105459, 'num_epochs': 381}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:52:02,227] Trial 29 finished with value: 0.6902472972869873 and parameters: {'learning_rate': 0.001732544223824344, 'l1_coef': 4.900041500352893e-06, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.8639027729422246, 'num_epochs': 362}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:52:14,960] Trial 31 finished with value: 0.694127368927002 and parameters: {'learning_rate': 0.0013996099823139591, 'l1_coef': 1.0961563379205113e-10, 'patience': 10, 'batch_size': 256, 'lr_factor': 0.8571462371717803, 'num_epochs': 359}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:52:33,001] Trial 23 finished with value: 0.827289172581264 and parameters: {'learning_rate': 4.400345607387457e-06, 'l1_coef': 5.806027928510174e-08, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.8461383707641309, 'num_epochs': 407}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:53:26,565] Trial 24 finished with value: 0.8116581184523447 and parameters: {'learning_rate': 4.932299789148803e-06, 'l1_coef': 3.62762741755551e-08, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.8832583455950931, 'num_epochs': 421}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:53:51,987] Trial 35 finished with value: 0.687610125541687 and parameters: {'learning_rate': 0.004043248242430727, 'l1_coef': 3.1856629884230843e-06, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.8063884576232141, 'num_epochs': 334}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:54:35,698] Trial 32 finished with value: 0.6878540754318238 and parameters: {'learning_rate': 0.0014975154261642647, 'l1_coef': 1.0758414515813739e-10, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.8870213266218412, 'num_epochs': 356}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:54:36,390] Trial 33 finished with value: 0.6858912110328674 and parameters: {'learning_rate': 0.0022647325889880057, 'l1_coef': 1.6244333619868968e-06, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.8323867162316521, 'num_epochs': 347}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:54:38,080] Trial 38 finished with value: 0.7862084150314331 and parameters: {'learning_rate': 0.03429817799868999, 'l1_coef': 9.62165780703397e-07, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.7917784970556804, 'num_epochs': 333}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:54:40,345] Trial 36 finished with value: 0.6864454925060273 and parameters: {'learning_rate': 0.0033654648474324266, 'l1_coef': 4.83549388551027e-06, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.7931993198899544, 'num_epochs': 339}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:54:58,032] Trial 34 finished with value: 0.6878845453262329 and parameters: {'learning_rate': 0.002067054280485165, 'l1_coef': 5.405632093157938e-06, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.8866303756555267, 'num_epochs': 338}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:55:21,230] Trial 25 finished with value: 0.8643039260591779 and parameters: {'learning_rate': 1.4469019144476781e-06, 'l1_coef': 1.0646116000632952e-10, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.8553143157182485, 'num_epochs': 385}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:55:30,571] Trial 39 finished with value: 0.8057214558124542 and parameters: {'learning_rate': 0.030206424062431608, 'l1_coef': 6.354762758254313e-07, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.7945117984394809, 'num_epochs': 310}. Best is trial 14 with value: 0.6829961248806545.\n",
      "[I 2024-05-23 08:55:42,476] Trial 37 finished with value: 0.6821547150611877 and parameters: {'learning_rate': 0.003169700933344413, 'l1_coef': 1.6081616664498045e-06, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.8055740078095053, 'num_epochs': 345}. Best is trial 37 with value: 0.6821547150611877.\n",
      "[I 2024-05-23 08:56:17,263] Trial 41 finished with value: 0.686519056558609 and parameters: {'learning_rate': 0.003771998054254581, 'l1_coef': 5.023553330925548e-06, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.7939391548053724, 'num_epochs': 316}. Best is trial 37 with value: 0.6821547150611877.\n",
      "[I 2024-05-23 08:56:18,917] Trial 43 finished with value: 0.7168159306049346 and parameters: {'learning_rate': 0.01022499501437048, 'l1_coef': 6.355698350696663e-07, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.7910066709145125, 'num_epochs': 302}. Best is trial 37 with value: 0.6821547150611877.\n",
      "[I 2024-05-23 08:56:36,690] Trial 40 finished with value: 0.6833174109458924 and parameters: {'learning_rate': 0.004024681508632276, 'l1_coef': 1.6651474950358136e-06, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.7845258048935452, 'num_epochs': 328}. Best is trial 37 with value: 0.6821547150611877.\n",
      "[I 2024-05-23 08:56:50,663] Trial 45 finished with value: 0.6911406815052032 and parameters: {'learning_rate': 0.009753206848216317, 'l1_coef': 1.8251651846376513e-05, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.6671119947981561, 'num_epochs': 266}. Best is trial 37 with value: 0.6821547150611877.\n",
      "[I 2024-05-23 08:57:01,625] Trial 42 finished with value: 0.683344179391861 and parameters: {'learning_rate': 0.003104600600490895, 'l1_coef': 5.644747057406235e-07, 'patience': 17, 'batch_size': 256, 'lr_factor': 0.7841867942220191, 'num_epochs': 296}. Best is trial 37 with value: 0.6821547150611877.\n",
      "[I 2024-05-23 08:57:07,601] Trial 44 finished with value: 0.6778145372867584 and parameters: {'learning_rate': 0.009888091592593224, 'l1_coef': 7.464983038107919e-07, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.6547700087831452, 'num_epochs': 299}. Best is trial 44 with value: 0.6778145372867584.\n",
      "[I 2024-05-23 08:57:36,377] Trial 46 finished with value: 0.7023223409285911 and parameters: {'learning_rate': 0.009544718106888107, 'l1_coef': 1.1236067311542808e-06, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.641845406173948, 'num_epochs': 256}. Best is trial 44 with value: 0.6778145372867584.\n",
      "[I 2024-05-23 08:57:45,459] Trial 47 finished with value: 0.7038342430041385 and parameters: {'learning_rate': 0.010163313023977336, 'l1_coef': 7.142339655491014e-07, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.6512603196917762, 'num_epochs': 263}. Best is trial 44 with value: 0.6778145372867584.\n",
      "[I 2024-05-23 08:58:32,851] Trial 26 finished with value: 0.7791933809007918 and parameters: {'learning_rate': 1.576671408693809e-05, 'l1_coef': 5.2188727026411315e-08, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.6099929169462603, 'num_epochs': 352}. Best is trial 44 with value: 0.6778145372867584.\n",
      "[I 2024-05-23 08:58:50,777] Trial 19 finished with value: 0.7959466576576233 and parameters: {'learning_rate': 3.5420286800832705e-06, 'l1_coef': 8.796551805503346e-07, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.8951336889231964, 'num_epochs': 425}. Best is trial 44 with value: 0.6778145372867584.\n",
      "[I 2024-05-23 08:58:52,868] Trial 49 finished with value: 0.6804087648024926 and parameters: {'learning_rate': 0.0006518548769758812, 'l1_coef': 1.3691863237914459e-08, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.6457330755582495, 'num_epochs': 259}. Best is trial 44 with value: 0.6778145372867584.\n",
      "[I 2024-05-23 08:58:55,115] Trial 48 finished with value: 0.6939135322204002 and parameters: {'learning_rate': 0.000539393583094491, 'l1_coef': 2.9515002340460024e-05, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.6426785996964718, 'num_epochs': 254}. Best is trial 44 with value: 0.6778145372867584.\n",
      "[I 2024-05-23 08:59:00,516] Trial 27 finished with value: 0.7639975343431745 and parameters: {'learning_rate': 2.0329428405943242e-05, 'l1_coef': 1.0489330574337667e-10, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.8777448542779358, 'num_epochs': 360}. Best is trial 44 with value: 0.6778145372867584.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 15 - Best hyperparameters: {'learning_rate': 0.009888091592593224, 'l1_coef': 7.464983038107919e-07, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.6547700087831452, 'num_epochs': 299}\n",
      "Chr 15 - Best value: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 08:59:06,769] A new study created in RDB with name: unphased_full_23andMe_chr16_study_logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr15/final_model_chr15.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr15/individual_r2_scores_chr15.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr15/individual_iqs_scores_chr15.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  361\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 09:00:59,786] Trial 0 finished with value: 0.69707270860672 and parameters: {'learning_rate': 0.0018920934899933782, 'l1_coef': 2.9108171228366007e-06, 'patience': 7, 'batch_size': 256, 'lr_factor': 0.19056401661879177, 'num_epochs': 233}. Best is trial 0 with value: 0.69707270860672.\n",
      "[I 2024-05-23 09:01:16,600] Trial 7 finished with value: 0.6740764945745468 and parameters: {'learning_rate': 0.0019651437478597554, 'l1_coef': 2.406786095016464e-08, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.6556104120779929, 'num_epochs': 193}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:02:29,388] Trial 11 finished with value: 0.8744076933179581 and parameters: {'learning_rate': 0.05368696544032561, 'l1_coef': 3.6899636070861323e-09, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.11709738612968518, 'num_epochs': 219}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:02:46,850] Trial 2 finished with value: 0.6817042396618771 and parameters: {'learning_rate': 0.000680931698836169, 'l1_coef': 6.091914083162296e-09, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.45727919941717854, 'num_epochs': 114}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:03:03,848] Trial 1 finished with value: 0.9775494933128357 and parameters: {'learning_rate': 0.0008008226252567141, 'l1_coef': 0.062464951867220356, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.6681972533851158, 'num_epochs': 115}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:03:14,302] Trial 8 finished with value: 7.081234073638916 and parameters: {'learning_rate': 2.5875481095367475e-06, 'l1_coef': 0.01952701997170522, 'patience': 13, 'batch_size': 256, 'lr_factor': 0.44936611126744386, 'num_epochs': 117}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:03:34,753] Trial 13 finished with value: 0.846214234828949 and parameters: {'learning_rate': 0.027742861684794305, 'l1_coef': 1.3439941792135797e-08, 'patience': 15, 'batch_size': 256, 'lr_factor': 0.4283401899117605, 'num_epochs': 467}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:04:57,256] Trial 12 finished with value: 0.8063277900218964 and parameters: {'learning_rate': 0.003759647855995044, 'l1_coef': 0.0009860995923392792, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.20768633553187074, 'num_epochs': 273}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:06:46,689] Trial 9 finished with value: 0.7326102247604956 and parameters: {'learning_rate': 5.769352520998267e-05, 'l1_coef': 1.9487075489961708e-10, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.3586323443999472, 'num_epochs': 134}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:08:04,961] Trial 6 finished with value: 0.9140575289726257 and parameters: {'learning_rate': 0.00020274592773519408, 'l1_coef': 0.0237347396606075, 'patience': 6, 'batch_size': 64, 'lr_factor': 0.27421499846693986, 'num_epochs': 231}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:08:56,784] Trial 17 finished with value: 0.6766046753296485 and parameters: {'learning_rate': 0.0014579335822334683, 'l1_coef': 2.4119107810697724e-09, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.33931079787324003, 'num_epochs': 198}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:09:13,480] Trial 10 finished with value: 0.6939134478569031 and parameters: {'learning_rate': 0.00013297933534890948, 'l1_coef': 1.316467524644404e-10, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.13852445873030464, 'num_epochs': 385}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:10:27,172] Trial 14 finished with value: 0.7789444991520472 and parameters: {'learning_rate': 4.205138213786665e-05, 'l1_coef': 4.805847693795047e-09, 'patience': 12, 'batch_size': 64, 'lr_factor': 0.5519242111720047, 'num_epochs': 123}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:10:37,640] Trial 21 finished with value: 0.7073228865861892 and parameters: {'learning_rate': 0.008007812421347585, 'l1_coef': 2.0556842036376943e-06, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.8808013907128787, 'num_epochs': 324}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:11:04,583] Trial 20 finished with value: 0.7046708762645721 and parameters: {'learning_rate': 0.0069868595513590745, 'l1_coef': 7.223936380972097e-07, 'patience': 20, 'batch_size': 128, 'lr_factor': 0.8617062436582691, 'num_epochs': 360}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:11:37,227] Trial 22 finished with value: 0.7808855175971985 and parameters: {'learning_rate': 0.012568697981974712, 'l1_coef': 2.1955869185710743e-07, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.8681425513965539, 'num_epochs': 320}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:11:39,044] Trial 5 finished with value: 0.8154173714773997 and parameters: {'learning_rate': 7.002554319003524e-06, 'l1_coef': 1.6908530789936129e-09, 'patience': 5, 'batch_size': 64, 'lr_factor': 0.31899673457517796, 'num_epochs': 335}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:12:30,441] Trial 23 finished with value: 0.7690138376676119 and parameters: {'learning_rate': 0.00561784152573782, 'l1_coef': 1.9880009418838736e-07, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.6709173165384731, 'num_epochs': 184}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:13:18,986] Trial 18 finished with value: 0.9118061661720276 and parameters: {'learning_rate': 2.811644536400882e-06, 'l1_coef': 3.099702972519007e-10, 'patience': 18, 'batch_size': 256, 'lr_factor': 0.6483395078307278, 'num_epochs': 187}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:14:29,044] Trial 4 finished with value: 1.7520181834697723 and parameters: {'learning_rate': 2.9187399384653747e-06, 'l1_coef': 0.009997940165350763, 'patience': 20, 'batch_size': 128, 'lr_factor': 0.7720697102251369, 'num_epochs': 353}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:14:58,669] Trial 15 finished with value: 0.805396682024002 and parameters: {'learning_rate': 1.4048503195311633e-05, 'l1_coef': 1.040485508429174e-06, 'patience': 9, 'batch_size': 128, 'lr_factor': 0.6388489546362786, 'num_epochs': 443}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:15:26,709] Trial 26 finished with value: 0.7040235684468196 and parameters: {'learning_rate': 0.0013087558163741497, 'l1_coef': 5.196732907170305e-05, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.6288529152082504, 'num_epochs': 187}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:16:27,490] Trial 28 finished with value: 0.7437077568127559 and parameters: {'learning_rate': 0.001348244741678415, 'l1_coef': 0.0002355890986845839, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.7559165724050173, 'num_epochs': 272}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:17:06,206] Trial 27 finished with value: 0.7575149820401118 and parameters: {'learning_rate': 0.0010349602934783652, 'l1_coef': 0.00030667489449606755, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.5816437307824469, 'num_epochs': 182}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:19:01,323] Trial 30 finished with value: 0.678814537708576 and parameters: {'learning_rate': 0.0005610737512608226, 'l1_coef': 3.571084462630868e-08, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.4972270114993032, 'num_epochs': 160}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:19:09,408] Trial 29 finished with value: 0.7077503268535321 and parameters: {'learning_rate': 0.0008537973586455931, 'l1_coef': 6.283213824871912e-05, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.5471664566333712, 'num_epochs': 267}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:19:25,828] Trial 31 finished with value: 0.6940318951239952 and parameters: {'learning_rate': 0.00045940644109409743, 'l1_coef': 4.499852964034788e-08, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.5267378755368665, 'num_epochs': 158}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:20:15,777] Trial 16 finished with value: 1.0662878036499024 and parameters: {'learning_rate': 2.5618441419834647e-06, 'l1_coef': 0.0012121750857280954, 'patience': 10, 'batch_size': 128, 'lr_factor': 0.8999154189140929, 'num_epochs': 388}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:20:30,176] Trial 32 finished with value: 0.6827439885873061 and parameters: {'learning_rate': 0.00047104324704663666, 'l1_coef': 3.524323663240079e-08, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.5354538972518575, 'num_epochs': 160}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:21:01,149] Trial 19 finished with value: 0.7938250362873077 and parameters: {'learning_rate': 1.6596806422977987e-05, 'l1_coef': 4.553873916406485e-06, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.839463708655011, 'num_epochs': 374}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:21:07,565] Trial 33 finished with value: 0.6840368399253258 and parameters: {'learning_rate': 0.0003995139608030003, 'l1_coef': 3.105357525498204e-08, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.49099316241330726, 'num_epochs': 158}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:22:23,269] Trial 38 finished with value: 0.688638037443161 and parameters: {'learning_rate': 0.002900275705217154, 'l1_coef': 8.37857136769302e-10, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.39342026629701304, 'num_epochs': 216}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:22:47,536] Trial 39 finished with value: 0.689235121011734 and parameters: {'learning_rate': 0.0029186049888295274, 'l1_coef': 6.620192380924848e-10, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.4064958969539971, 'num_epochs': 217}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:22:57,211] Trial 3 finished with value: 0.8718519023486546 and parameters: {'learning_rate': 1.022800602555177e-06, 'l1_coef': 6.255412171317807e-07, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.8159123083689036, 'num_epochs': 404}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:23:03,360] Trial 35 finished with value: 0.6890720853438743 and parameters: {'learning_rate': 0.00032582654731137334, 'l1_coef': 2.8115752385666627e-08, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.3899196536878983, 'num_epochs': 147}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:23:57,214] Trial 37 finished with value: 0.7014674296745886 and parameters: {'learning_rate': 0.0002850936738637532, 'l1_coef': 3.677763783909071e-08, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.39122185424244277, 'num_epochs': 148}. Best is trial 7 with value: 0.6740764945745468.\n",
      "[I 2024-05-23 09:24:20,538] Trial 40 finished with value: 0.6661687704233022 and parameters: {'learning_rate': 0.0027327652688185064, 'l1_coef': 1.1652235791867994e-09, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.42476204408159174, 'num_epochs': 101}. Best is trial 40 with value: 0.6661687704233022.\n",
      "[I 2024-05-23 09:24:58,491] Trial 34 finished with value: 0.6703387278776902 and parameters: {'learning_rate': 0.0003694584992884041, 'l1_coef': 4.261470712559062e-08, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.5251642571346231, 'num_epochs': 269}. Best is trial 40 with value: 0.6661687704233022.\n",
      "[I 2024-05-23 09:25:41,045] Trial 36 finished with value: 0.7106522844387935 and parameters: {'learning_rate': 0.00010281738850694015, 'l1_coef': 3.406183155433253e-08, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.38639790598910184, 'num_epochs': 156}. Best is trial 40 with value: 0.6661687704233022.\n",
      "[I 2024-05-23 09:26:24,342] Trial 46 finished with value: 0.8200820821982164 and parameters: {'learning_rate': 0.01668826282500599, 'l1_coef': 1.7736187796796322e-09, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.277697915680769, 'num_epochs': 104}. Best is trial 40 with value: 0.6661687704233022.\n",
      "[I 2024-05-23 09:26:58,029] Trial 41 finished with value: 0.7175323073680584 and parameters: {'learning_rate': 0.00013052319643029714, 'l1_coef': 8.927778885868918e-09, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.44686198794920684, 'num_epochs': 102}. Best is trial 40 with value: 0.6661687704233022.\n",
      "[I 2024-05-23 09:27:16,349] Trial 24 finished with value: 0.7835454894946172 and parameters: {'learning_rate': 1.2541017013706478e-05, 'l1_coef': 1.0394107126404858e-07, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.6325822403061865, 'num_epochs': 183}. Best is trial 40 with value: 0.6661687704233022.\n",
      "[I 2024-05-23 09:27:22,640] Trial 42 finished with value: 0.7311629203649668 and parameters: {'learning_rate': 8.642361956608692e-05, 'l1_coef': 7.666867364854706e-09, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.2750199364289074, 'num_epochs': 103}. Best is trial 40 with value: 0.6661687704233022.\n",
      "[I 2024-05-23 09:27:29,325] Trial 47 finished with value: 0.8524689701887278 and parameters: {'learning_rate': 0.016398618235727174, 'l1_coef': 2.033778895931936e-09, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.2981078823843222, 'num_epochs': 104}. Best is trial 40 with value: 0.6661687704233022.\n",
      "[I 2024-05-23 09:27:31,499] Trial 43 finished with value: 0.7222414190952595 and parameters: {'learning_rate': 0.0001242026661375527, 'l1_coef': 8.195570610579579e-09, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.4859366745373614, 'num_epochs': 102}. Best is trial 40 with value: 0.6661687704233022.\n",
      "[I 2024-05-23 09:27:33,558] Trial 25 finished with value: 0.8106877326965332 and parameters: {'learning_rate': 6.745640125920656e-06, 'l1_coef': 8.693545039309761e-08, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.6440261062619225, 'num_epochs': 182}. Best is trial 40 with value: 0.6661687704233022.\n",
      "[I 2024-05-23 09:27:47,831] Trial 44 finished with value: 0.7222231819079473 and parameters: {'learning_rate': 0.00013461511604361234, 'l1_coef': 7.045389898076307e-09, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.46416793689954483, 'num_epochs': 100}. Best is trial 40 with value: 0.6661687704233022.\n",
      "[I 2024-05-23 09:27:48,612] Trial 45 finished with value: 0.7194790941018324 and parameters: {'learning_rate': 0.00012281598852492584, 'l1_coef': 3.867923161995621e-09, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.2637567673719706, 'num_epochs': 107}. Best is trial 40 with value: 0.6661687704233022.\n",
      "[I 2024-05-23 09:27:49,770] Trial 48 finished with value: 0.6784542037890506 and parameters: {'learning_rate': 0.0020124940676476124, 'l1_coef': 2.177127460443743e-09, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.2947225767273839, 'num_epochs': 104}. Best is trial 40 with value: 0.6661687704233022.\n",
      "[I 2024-05-23 09:27:53,892] Trial 49 finished with value: 0.6603530270712716 and parameters: {'learning_rate': 0.0020175034839549004, 'l1_coef': 1.649422460381251e-07, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.7240335076638379, 'num_epochs': 248}. Best is trial 49 with value: 0.6603530270712716.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 16 - Best hyperparameters: {'learning_rate': 0.0020175034839549004, 'l1_coef': 1.649422460381251e-07, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.7240335076638379, 'num_epochs': 248}\n",
      "Chr 16 - Best value: 0.6604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 09:28:05,729] A new study created in RDB with name: unphased_full_23andMe_chr17_study_logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr16/final_model_chr16.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr16/individual_r2_scores_chr16.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr16/individual_iqs_scores_chr16.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  188\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 09:29:05,925] Trial 1 finished with value: 0.8422214090824127 and parameters: {'learning_rate': 0.05662851731080405, 'l1_coef': 0.0071650759766779286, 'patience': 8, 'batch_size': 128, 'lr_factor': 0.3947102172561444, 'num_epochs': 411}. Best is trial 1 with value: 0.8422214090824127.\n",
      "[I 2024-05-23 09:29:56,150] Trial 6 finished with value: 0.6812757061077999 and parameters: {'learning_rate': 0.010181808270071877, 'l1_coef': 1.9861497695612812e-05, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.8029672443423692, 'num_epochs': 396}. Best is trial 6 with value: 0.6812757061077999.\n",
      "[I 2024-05-23 09:30:50,557] Trial 0 finished with value: 0.6873753160238266 and parameters: {'learning_rate': 0.00018693240812657676, 'l1_coef': 1.3847744667082167e-06, 'patience': 10, 'batch_size': 128, 'lr_factor': 0.5221406960042503, 'num_epochs': 268}. Best is trial 6 with value: 0.6812757061077999.\n",
      "[I 2024-05-23 09:31:10,572] Trial 3 finished with value: 0.6768181204795838 and parameters: {'learning_rate': 0.0005409399027692975, 'l1_coef': 6.1709829609438185e-09, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.16893323217496425, 'num_epochs': 289}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:31:24,495] Trial 2 finished with value: 0.7500820517539978 and parameters: {'learning_rate': 0.004649572372397662, 'l1_coef': 0.0021772393938454216, 'patience': 5, 'batch_size': 256, 'lr_factor': 0.7867564513943964, 'num_epochs': 212}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:32:32,207] Trial 11 finished with value: 0.7189856896033654 and parameters: {'learning_rate': 0.007854280054425702, 'l1_coef': 0.00026460526142075175, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.4446672329823411, 'num_epochs': 320}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:32:58,176] Trial 8 finished with value: 0.802174323797226 and parameters: {'learning_rate': 0.00034048622744302164, 'l1_coef': 0.003310963134962015, 'patience': 9, 'batch_size': 256, 'lr_factor': 0.5794154496895835, 'num_epochs': 453}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:33:07,833] Trial 5 finished with value: 0.7415653063700749 and parameters: {'learning_rate': 0.004425799250772705, 'l1_coef': 0.0016858702602482799, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.2186183517598811, 'num_epochs': 268}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:37:45,472] Trial 16 finished with value: 0.7026651297296796 and parameters: {'learning_rate': 0.0007338767612547678, 'l1_coef': 0.00030354427730002164, 'patience': 12, 'batch_size': 64, 'lr_factor': 0.5232893580005366, 'num_epochs': 375}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:38:07,561] Trial 9 finished with value: 0.7531774163246154 and parameters: {'learning_rate': 4.722908586450891e-06, 'l1_coef': 1.1418816270158677e-05, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.7171881164367337, 'num_epochs': 168}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:38:33,777] Trial 17 finished with value: 1.5035875022411347 and parameters: {'learning_rate': 1.0557143950552139e-05, 'l1_coef': 0.013945145609337718, 'patience': 15, 'batch_size': 128, 'lr_factor': 0.2305422720837431, 'num_epochs': 124}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:39:53,067] Trial 10 finished with value: 0.8835555672645569 and parameters: {'learning_rate': 1.8477382204622073e-06, 'l1_coef': 2.517358029517873e-08, 'patience': 17, 'batch_size': 256, 'lr_factor': 0.4621572918353388, 'num_epochs': 304}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:41:29,133] Trial 20 finished with value: 0.7328992137542137 and parameters: {'learning_rate': 0.09205670859306618, 'l1_coef': 6.105914967656527e-10, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.8802725300774799, 'num_epochs': 340}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:42:03,201] Trial 18 finished with value: 0.7482857167720794 and parameters: {'learning_rate': 0.00029083335100203457, 'l1_coef': 0.0006392065427306484, 'patience': 11, 'batch_size': 256, 'lr_factor': 0.17600483972131917, 'num_epochs': 479}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:42:29,762] Trial 12 finished with value: 0.7537996189934867 and parameters: {'learning_rate': 7.961378563341216e-06, 'l1_coef': 8.333881356222247e-07, 'patience': 5, 'batch_size': 64, 'lr_factor': 0.7318087866011219, 'num_epochs': 193}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:43:19,711] Trial 15 finished with value: 0.7689335525035859 and parameters: {'learning_rate': 1.2894547532286975e-05, 'l1_coef': 0.00014500103800443225, 'patience': 18, 'batch_size': 256, 'lr_factor': 0.544319615213947, 'num_epochs': 309}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:45:15,670] Trial 13 finished with value: 0.7455705083333528 and parameters: {'learning_rate': 5.525959682928511e-06, 'l1_coef': 1.19919275900499e-07, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.49396933945620025, 'num_epochs': 156}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:46:20,601] Trial 4 finished with value: 2.408093327283859 and parameters: {'learning_rate': 3.6330041905241947e-06, 'l1_coef': 0.04543241061378637, 'patience': 6, 'batch_size': 128, 'lr_factor': 0.4348999211584973, 'num_epochs': 412}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:46:39,772] Trial 14 finished with value: 0.7091912448406219 and parameters: {'learning_rate': 6.149104707063485e-05, 'l1_coef': 6.04293863258721e-07, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.5564123238538246, 'num_epochs': 437}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:48:13,706] Trial 19 finished with value: 0.7240600971075205 and parameters: {'learning_rate': 1.8605764497713892e-05, 'l1_coef': 8.711319034120133e-10, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.1965466455856224, 'num_epochs': 110}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:48:45,998] Trial 28 finished with value: 0.6914025691839365 and parameters: {'learning_rate': 0.020503712946656833, 'l1_coef': 3.9640610992737855e-09, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.3118070199790041, 'num_epochs': 362}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:49:20,829] Trial 7 finished with value: 0.7613074217523847 and parameters: {'learning_rate': 1.7248236957052475e-05, 'l1_coef': 0.0005046990496355163, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.5002576366416099, 'num_epochs': 352}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:50:04,394] Trial 29 finished with value: 0.6842709036973806 and parameters: {'learning_rate': 0.01609267991901119, 'l1_coef': 2.1199660164743985e-05, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.10971300683195873, 'num_epochs': 245}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:50:06,551] Trial 21 finished with value: 0.6826570180746224 and parameters: {'learning_rate': 5.1034719550242414e-05, 'l1_coef': 1.2891396520951312e-10, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.8692474514388664, 'num_epochs': 496}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:50:44,624] Trial 30 finished with value: 0.6811463981866837 and parameters: {'learning_rate': 0.0008873551342709799, 'l1_coef': 1.696123965203376e-05, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.6301361416338449, 'num_epochs': 263}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:50:59,045] Trial 23 finished with value: 0.6827339465801533 and parameters: {'learning_rate': 6.695978591536407e-05, 'l1_coef': 2.6815141120541095e-07, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.3224509592124778, 'num_epochs': 403}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:51:06,660] Trial 31 finished with value: 0.6794387757778168 and parameters: {'learning_rate': 0.0014150410572255486, 'l1_coef': 1.5024692640276379e-05, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.11638870728895531, 'num_epochs': 268}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:51:24,468] Trial 24 finished with value: 0.6842488729036772 and parameters: {'learning_rate': 5.655528290323813e-05, 'l1_coef': 1.74491121595033e-10, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.3174009826245247, 'num_epochs': 403}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:51:46,647] Trial 22 finished with value: 0.6827514969385586 and parameters: {'learning_rate': 5.891272821265854e-05, 'l1_coef': 1.4693088454203754e-07, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.11071633981433232, 'num_epochs': 477}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:51:53,942] Trial 25 finished with value: 0.6806719459020174 and parameters: {'learning_rate': 8.269780618636412e-05, 'l1_coef': 3.4360486403834625e-08, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.13303756600134317, 'num_epochs': 405}. Best is trial 3 with value: 0.6768181204795838.\n",
      "[I 2024-05-23 09:52:11,026] Trial 33 finished with value: 0.6744976795636691 and parameters: {'learning_rate': 0.0015597253393749076, 'l1_coef': 1.1108384297161599e-10, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.8994095425163515, 'num_epochs': 480}. Best is trial 33 with value: 0.6744976795636691.\n",
      "[I 2024-05-23 09:52:18,899] Trial 32 finished with value: 0.6813486961218027 and parameters: {'learning_rate': 0.0014002840484895434, 'l1_coef': 1.7292408084749793e-05, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.13402489328710215, 'num_epochs': 236}. Best is trial 33 with value: 0.6744976795636691.\n",
      "[I 2024-05-23 09:52:32,820] Trial 34 finished with value: 0.682879364490509 and parameters: {'learning_rate': 0.0012293714595852205, 'l1_coef': 2.7730992814902664e-05, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.6831557850086234, 'num_epochs': 240}. Best is trial 33 with value: 0.6744976795636691.\n",
      "[I 2024-05-23 09:52:49,125] Trial 35 finished with value: 0.6795062899589539 and parameters: {'learning_rate': 0.001152162450032837, 'l1_coef': 9.898879154682592e-06, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.6473894184780363, 'num_epochs': 265}. Best is trial 33 with value: 0.6744976795636691.\n",
      "[I 2024-05-23 09:52:49,265] Trial 36 finished with value: 0.6744176477193833 and parameters: {'learning_rate': 0.0015001864480257668, 'l1_coef': 4.260151787725831e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.6451430136611431, 'num_epochs': 228}. Best is trial 36 with value: 0.6744176477193833.\n",
      "[I 2024-05-23 09:53:03,040] Trial 27 finished with value: 0.6907777639535757 and parameters: {'learning_rate': 4.977806504676875e-05, 'l1_coef': 1.184484855831831e-10, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.3033276515815348, 'num_epochs': 254}. Best is trial 36 with value: 0.6744176477193833.\n",
      "[I 2024-05-23 09:53:11,549] Trial 37 finished with value: 0.6755998283624649 and parameters: {'learning_rate': 0.0013774288501678842, 'l1_coef': 5.7791218740047823e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.6295500444536255, 'num_epochs': 229}. Best is trial 36 with value: 0.6744176477193833.\n",
      "[I 2024-05-23 09:53:29,518] Trial 38 finished with value: 0.6765350311994552 and parameters: {'learning_rate': 0.0011516227162102466, 'l1_coef': 1.5250310855231366e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.2567103937736763, 'num_epochs': 267}. Best is trial 36 with value: 0.6744176477193833.\n",
      "[I 2024-05-23 09:53:30,135] Trial 40 finished with value: 0.6742670863866806 and parameters: {'learning_rate': 0.0019013770932253097, 'l1_coef': 1.1500507959212075e-08, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.15424960219137812, 'num_epochs': 241}. Best is trial 40 with value: 0.6742670863866806.\n",
      "[I 2024-05-23 09:53:40,971] Trial 41 finished with value: 0.6747801423072814 and parameters: {'learning_rate': 0.0022017791682168654, 'l1_coef': 1.2885881406935182e-08, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.2528348119626439, 'num_epochs': 269}. Best is trial 40 with value: 0.6742670863866806.\n",
      "[I 2024-05-23 09:53:42,123] Trial 39 finished with value: 0.6749100118875504 and parameters: {'learning_rate': 0.0011711832608912293, 'l1_coef': 2.697044454491809e-08, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.16192208008323192, 'num_epochs': 278}. Best is trial 40 with value: 0.6742670863866806.\n",
      "[I 2024-05-23 09:53:47,080] Trial 42 finished with value: 0.6726817697286606 and parameters: {'learning_rate': 0.0025520173110965406, 'l1_coef': 1.4363060201055876e-08, 'patience': 14, 'batch_size': 128, 'lr_factor': 0.2424982839825733, 'num_epochs': 276}. Best is trial 42 with value: 0.6726817697286606.\n",
      "[I 2024-05-23 09:53:55,263] Trial 26 finished with value: 0.6834507474532494 and parameters: {'learning_rate': 5.998600909439842e-05, 'l1_coef': 1.157611717954229e-09, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.31849172074577203, 'num_epochs': 405}. Best is trial 42 with value: 0.6726817697286606.\n",
      "[I 2024-05-23 09:53:56,759] Trial 44 finished with value: 0.6733805894851684 and parameters: {'learning_rate': 0.003241870248783623, 'l1_coef': 6.308389579037366e-09, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.3696794148475484, 'num_epochs': 282}. Best is trial 42 with value: 0.6726817697286606.\n",
      "[I 2024-05-23 09:53:56,911] Trial 43 finished with value: 0.673901554942131 and parameters: {'learning_rate': 0.0027684577861192042, 'l1_coef': 5.586319391355345e-09, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.37283982702276364, 'num_epochs': 286}. Best is trial 42 with value: 0.6726817697286606.\n",
      "[I 2024-05-23 09:54:00,857] Trial 45 finished with value: 0.6736828476190567 and parameters: {'learning_rate': 0.002752618026811649, 'l1_coef': 5.807565969851344e-09, 'patience': 14, 'batch_size': 128, 'lr_factor': 0.38205640985921596, 'num_epochs': 291}. Best is trial 42 with value: 0.6726817697286606.\n",
      "[I 2024-05-23 09:54:04,846] Trial 46 finished with value: 0.6710712105035782 and parameters: {'learning_rate': 0.0032661505291700322, 'l1_coef': 7.96191891885754e-09, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.8078850819388251, 'num_epochs': 218}. Best is trial 46 with value: 0.6710712105035782.\n",
      "[I 2024-05-23 09:54:05,493] Trial 49 finished with value: 0.6795381784439087 and parameters: {'learning_rate': 0.004405907072518198, 'l1_coef': 8.193160381423667e-09, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.37662979016368137, 'num_epochs': 209}. Best is trial 46 with value: 0.6710712105035782.\n",
      "[I 2024-05-23 09:54:05,711] Trial 48 finished with value: 0.6722722142934799 and parameters: {'learning_rate': 0.0031068570765730888, 'l1_coef': 2.7478222918573627e-09, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.8110736961609686, 'num_epochs': 212}. Best is trial 46 with value: 0.6710712105035782.\n",
      "[I 2024-05-23 09:54:05,746] Trial 47 finished with value: 0.6739266902208328 and parameters: {'learning_rate': 0.002496695342349868, 'l1_coef': 1.2258208064380636e-08, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.8106141145287807, 'num_epochs': 208}. Best is trial 46 with value: 0.6710712105035782.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 17 - Best hyperparameters: {'learning_rate': 0.0032661505291700322, 'l1_coef': 7.96191891885754e-09, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.8078850819388251, 'num_epochs': 218}\n",
      "Chr 17 - Best value: 0.6711\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr17/final_model_chr17.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr17/individual_r2_scores_chr17.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr17/individual_iqs_scores_chr17.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  277\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 09:54:12,563] A new study created in RDB with name: unphased_full_23andMe_chr18_study_logistic_regression\n",
      "[I 2024-05-23 09:55:16,679] Trial 8 finished with value: 0.7049856305122375 and parameters: {'learning_rate': 0.0034400693195760956, 'l1_coef': 2.395671659507723e-06, 'patience': 5, 'batch_size': 256, 'lr_factor': 0.29884066012745725, 'num_epochs': 164}. Best is trial 8 with value: 0.7049856305122375.\n",
      "[I 2024-05-23 09:55:21,420] Trial 9 finished with value: 0.7008734434843064 and parameters: {'learning_rate': 0.012841773534334038, 'l1_coef': 2.2181286380772192e-06, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.24594562671118833, 'num_epochs': 169}. Best is trial 9 with value: 0.7008734434843064.\n",
      "[I 2024-05-23 09:55:41,407] Trial 1 finished with value: 0.8334831297397614 and parameters: {'learning_rate': 0.027388054586999284, 'l1_coef': 4.413596227351853e-10, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.7112555504120148, 'num_epochs': 122}. Best is trial 9 with value: 0.7008734434843064.\n",
      "[I 2024-05-23 09:56:07,307] Trial 10 finished with value: 0.9034855663776398 and parameters: {'learning_rate': 0.05727761043126007, 'l1_coef': 4.831113402618604e-10, 'patience': 11, 'batch_size': 128, 'lr_factor': 0.2993297637096082, 'num_epochs': 347}. Best is trial 9 with value: 0.7008734434843064.\n",
      "[I 2024-05-23 09:56:27,802] Trial 4 finished with value: 0.7015563130378724 and parameters: {'learning_rate': 0.0016202484499375695, 'l1_coef': 2.3853076801459816e-09, 'patience': 18, 'batch_size': 256, 'lr_factor': 0.14121011767521266, 'num_epochs': 240}. Best is trial 9 with value: 0.7008734434843064.\n",
      "[I 2024-05-23 09:56:46,731] Trial 11 finished with value: 1.662221687180655 and parameters: {'learning_rate': 0.04735225488254799, 'l1_coef': 0.0583332112388736, 'patience': 8, 'batch_size': 64, 'lr_factor': 0.3439539355759279, 'num_epochs': 333}. Best is trial 9 with value: 0.7008734434843064.\n",
      "[I 2024-05-23 09:57:38,014] Trial 2 finished with value: 0.8651863813400269 and parameters: {'learning_rate': 7.311317673934937e-05, 'l1_coef': 1.5555336838494845e-10, 'patience': 13, 'batch_size': 256, 'lr_factor': 0.4167193420924816, 'num_epochs': 111}. Best is trial 9 with value: 0.7008734434843064.\n",
      "[I 2024-05-23 09:57:51,857] Trial 13 finished with value: 0.7381262284058792 and parameters: {'learning_rate': 0.011085986747333802, 'l1_coef': 1.2707270826336867e-06, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.24764532638886136, 'num_epochs': 464}. Best is trial 9 with value: 0.7008734434843064.\n",
      "[I 2024-05-23 09:58:40,317] Trial 12 finished with value: 0.6873034924268723 and parameters: {'learning_rate': 0.0015081461835625724, 'l1_coef': 2.140231075892299e-07, 'patience': 7, 'batch_size': 128, 'lr_factor': 0.5321573061874013, 'num_epochs': 460}. Best is trial 12 with value: 0.6873034924268723.\n",
      "[I 2024-05-23 09:59:22,164] Trial 3 finished with value: 0.6711326360702514 and parameters: {'learning_rate': 0.0007623430994630923, 'l1_coef': 7.144879943505314e-07, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.4129277610636408, 'num_epochs': 397}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 09:59:39,932] Trial 16 finished with value: 0.7714776277542115 and parameters: {'learning_rate': 0.0002880782961109529, 'l1_coef': 1.213036604411264e-07, 'patience': 8, 'batch_size': 256, 'lr_factor': 0.16001427425039136, 'num_epochs': 251}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:00:30,621] Trial 0 finished with value: 0.7463443398475647 and parameters: {'learning_rate': 8.295081404192807e-05, 'l1_coef': 6.277228364310035e-08, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.5992800601798826, 'num_epochs': 239}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:02:12,059] Trial 5 finished with value: 1.1318017840385437 and parameters: {'learning_rate': 5.3997260248460475e-06, 'l1_coef': 0.001275715100763558, 'patience': 9, 'batch_size': 256, 'lr_factor': 0.8593407598798435, 'num_epochs': 227}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:03:31,049] Trial 15 finished with value: 0.9906173288822174 and parameters: {'learning_rate': 2.9964466800781348e-05, 'l1_coef': 0.0031252340765962, 'patience': 8, 'batch_size': 256, 'lr_factor': 0.4285497120283508, 'num_epochs': 346}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:05:44,082] Trial 6 finished with value: 1.0263480186462401 and parameters: {'learning_rate': 1.1581577609038867e-06, 'l1_coef': 2.0657593409832636e-10, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.349978084419129, 'num_epochs': 331}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:07:23,457] Trial 23 finished with value: 0.7355592975249656 and parameters: {'learning_rate': 0.0012526739903261058, 'l1_coef': 8.998335737449642e-05, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.5427784349533212, 'num_epochs': 457}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:08:10,694] Trial 22 finished with value: 0.7405663031798142 and parameters: {'learning_rate': 0.0008094023502857993, 'l1_coef': 0.00011230205039408521, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.5568600639576262, 'num_epochs': 465}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:09:04,544] Trial 18 finished with value: 0.7768924419696515 and parameters: {'learning_rate': 3.9008441224354934e-05, 'l1_coef': 1.0786109047244988e-08, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.16048147564708728, 'num_epochs': 135}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:10:39,260] Trial 24 finished with value: 0.7122325814687288 and parameters: {'learning_rate': 0.0009329109703371792, 'l1_coef': 3.599776610680066e-05, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.5541576407937187, 'num_epochs': 457}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:12:04,554] Trial 26 finished with value: 0.7009394824504852 and parameters: {'learning_rate': 0.00032973066672073806, 'l1_coef': 3.4652455102963864e-08, 'patience': 5, 'batch_size': 128, 'lr_factor': 0.6298235459876556, 'num_epochs': 407}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:13:27,007] Trial 27 finished with value: 0.7399847865104675 and parameters: {'learning_rate': 0.00026841359493273286, 'l1_coef': 3.492694153779642e-05, 'patience': 20, 'batch_size': 128, 'lr_factor': 0.6689654915291002, 'num_epochs': 399}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:13:39,233] Trial 29 finished with value: 0.7007596224546433 and parameters: {'learning_rate': 0.0049473737104256165, 'l1_coef': 5.737836759455819e-07, 'patience': 20, 'batch_size': 128, 'lr_factor': 0.7022361917270291, 'num_epochs': 403}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:14:08,804] Trial 25 finished with value: 0.6716311344733606 and parameters: {'learning_rate': 0.0004993020691664435, 'l1_coef': 6.292757571658197e-08, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.6502804906626842, 'num_epochs': 415}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:14:29,681] Trial 28 finished with value: 0.7217193424701691 and parameters: {'learning_rate': 0.0002670914583453219, 'l1_coef': 1.6414405517940653e-07, 'patience': 5, 'batch_size': 128, 'lr_factor': 0.691530530755006, 'num_epochs': 400}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:14:34,529] Trial 30 finished with value: 0.7231526076793671 and parameters: {'learning_rate': 0.009754164589443405, 'l1_coef': 4.85318319279109e-07, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.45586580654074715, 'num_epochs': 404}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:14:45,148] Trial 7 finished with value: 0.8419511471475873 and parameters: {'learning_rate': 8.933239211130891e-06, 'l1_coef': 3.845880119826588e-08, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.85474461545519, 'num_epochs': 334}. Best is trial 3 with value: 0.6711326360702514.\n",
      "[I 2024-05-23 10:16:56,559] Trial 31 finished with value: 0.6601460635662079 and parameters: {'learning_rate': 0.0037153585430474774, 'l1_coef': 3.5351272685119223e-07, 'patience': 20, 'batch_size': 128, 'lr_factor': 0.7472516207159128, 'num_epochs': 394}. Best is trial 31 with value: 0.6601460635662079.\n",
      "[I 2024-05-23 10:17:50,623] Trial 35 finished with value: 0.6974673087780292 and parameters: {'learning_rate': 0.004011668069892887, 'l1_coef': 5.002031596111009e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.499184790118373, 'num_epochs': 494}. Best is trial 31 with value: 0.6601460635662079.\n",
      "[I 2024-05-23 10:18:21,874] Trial 32 finished with value: 0.6636504806005037 and parameters: {'learning_rate': 0.002695580610874677, 'l1_coef': 2.8524127492652603e-07, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.7910641713850819, 'num_epochs': 493}. Best is trial 31 with value: 0.6601460635662079.\n",
      "[I 2024-05-23 10:18:22,619] Trial 34 finished with value: 0.6601013788810143 and parameters: {'learning_rate': 0.0028409556715509043, 'l1_coef': 5.601348439562547e-09, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.7965033990912138, 'num_epochs': 494}. Best is trial 34 with value: 0.6601013788810143.\n",
      "[I 2024-05-23 10:18:34,054] Trial 33 finished with value: 0.656250043098743 and parameters: {'learning_rate': 0.003265608490544992, 'l1_coef': 8.369409692394013e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.7976113624125284, 'num_epochs': 427}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:19:45,676] Trial 36 finished with value: 0.6764693214343144 and parameters: {'learning_rate': 0.0047616346995508, 'l1_coef': 1.0820353653242384e-05, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.7905060531781656, 'num_epochs': 294}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:20:03,778] Trial 39 finished with value: 0.7845759221485682 and parameters: {'learning_rate': 0.022486538117491427, 'l1_coef': 1.2442733629242662e-05, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.7958334023891696, 'num_epochs': 495}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:20:11,772] Trial 17 finished with value: 1.1373853426713212 and parameters: {'learning_rate': 1.4347986562583167e-06, 'l1_coef': 0.0016598434077763897, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.4651091128411443, 'num_epochs': 232}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:21:41,877] Trial 40 finished with value: 0.6880435888583845 and parameters: {'learning_rate': 0.002433495909171578, 'l1_coef': 2.772550113091442e-09, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.7816346277694387, 'num_epochs': 483}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:21:43,276] Trial 38 finished with value: 0.6894507380632253 and parameters: {'learning_rate': 0.0026830659695677222, 'l1_coef': 1.0296760230156782e-05, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.7998483227734163, 'num_epochs': 283}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:22:23,882] Trial 41 finished with value: 0.8755029265697187 and parameters: {'learning_rate': 0.02403727803694899, 'l1_coef': 2.530392470138643e-09, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.778666372982658, 'num_epochs': 491}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:23:13,134] Trial 43 finished with value: 0.6778073237492488 and parameters: {'learning_rate': 0.0024622527897510444, 'l1_coef': 9.822359999983405e-10, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.7640253942721192, 'num_epochs': 431}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:23:21,235] Trial 42 finished with value: 0.6627601082508381 and parameters: {'learning_rate': 0.002396875488564608, 'l1_coef': 1.1837736565075247e-09, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.7642043426266154, 'num_epochs': 440}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:24:31,524] Trial 37 finished with value: 0.7328973137415373 and parameters: {'learning_rate': 0.00013497576289353642, 'l1_coef': 9.755216689859343e-06, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.7898551088342816, 'num_epochs': 286}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:24:38,520] Trial 45 finished with value: 0.8979721014316265 and parameters: {'learning_rate': 0.09751963110793403, 'l1_coef': 9.51479434615248e-10, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.8776492709412427, 'num_epochs': 429}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:25:00,714] Trial 47 finished with value: 0.6997759410313198 and parameters: {'learning_rate': 0.005605409839593528, 'l1_coef': 1.4507706250973983e-08, 'patience': 17, 'batch_size': 64, 'lr_factor': 0.8918987844902024, 'num_epochs': 375}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:26:25,487] Trial 49 finished with value: 0.706976524421147 and parameters: {'learning_rate': 0.008102235340877683, 'l1_coef': 1.5407690368735946e-10, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.8700526435561341, 'num_epochs': 373}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:27:35,804] Trial 14 finished with value: 0.8713375064042899 and parameters: {'learning_rate': 2.919578630492043e-06, 'l1_coef': 5.0307079467850596e-06, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.8661773526248758, 'num_epochs': 340}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:27:36,119] Trial 48 finished with value: 0.7368910891669136 and parameters: {'learning_rate': 0.00012719799762105085, 'l1_coef': 1.0906458679585994e-10, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.8663300039675601, 'num_epochs': 370}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:28:30,612] Trial 44 finished with value: 0.6987241084759052 and parameters: {'learning_rate': 0.00011498608171958238, 'l1_coef': 1.1949046694731418e-09, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.7324213839287316, 'num_epochs': 439}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:28:37,637] Trial 46 finished with value: 0.6975417779042171 and parameters: {'learning_rate': 0.00012231202824621, 'l1_coef': 1.347122646037277e-08, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.8829098132476909, 'num_epochs': 435}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:29:58,738] Trial 19 finished with value: 0.956756280018733 and parameters: {'learning_rate': 2.4126928844604846e-06, 'l1_coef': 0.001103304367349557, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.8863326250984127, 'num_epochs': 433}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:30:18,560] Trial 21 finished with value: 0.9724172803071829 and parameters: {'learning_rate': 1.6027880026083728e-06, 'l1_coef': 0.0006920979352878075, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.5553823110579377, 'num_epochs': 460}. Best is trial 33 with value: 0.656250043098743.\n",
      "[I 2024-05-23 10:30:22,727] Trial 20 finished with value: 0.9405182966819176 and parameters: {'learning_rate': 1.862064507103988e-06, 'l1_coef': 0.0004083179646334148, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.6350530089630927, 'num_epochs': 483}. Best is trial 33 with value: 0.656250043098743.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 18 - Best hyperparameters: {'learning_rate': 0.003265608490544992, 'l1_coef': 8.369409692394013e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.7976113624125284, 'num_epochs': 427}\n",
      "Chr 18 - Best value: 0.6563\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr18/final_model_chr18.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr18/individual_r2_scores_chr18.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr18/individual_iqs_scores_chr18.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  288\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 10:30:50,307] A new study created in RDB with name: unphased_full_23andMe_chr19_study_logistic_regression\n",
      "[I 2024-05-23 10:31:29,325] Trial 4 finished with value: 0.7989994525909424 and parameters: {'learning_rate': 0.02013670021681599, 'l1_coef': 3.172563198433545e-08, 'patience': 8, 'batch_size': 256, 'lr_factor': 0.7155551029031453, 'num_epochs': 338}. Best is trial 4 with value: 0.7989994525909424.\n",
      "[I 2024-05-23 10:31:47,856] Trial 2 finished with value: 0.9927492550441197 and parameters: {'learning_rate': 0.0453372432982793, 'l1_coef': 2.7933911540607385e-10, 'patience': 12, 'batch_size': 64, 'lr_factor': 0.22644295340642753, 'num_epochs': 324}. Best is trial 4 with value: 0.7989994525909424.\n",
      "[I 2024-05-23 10:32:17,419] Trial 3 finished with value: 0.9738792487553187 and parameters: {'learning_rate': 0.00358814636719523, 'l1_coef': 0.013658386387999533, 'patience': 7, 'batch_size': 64, 'lr_factor': 0.5087252260384596, 'num_epochs': 119}. Best is trial 4 with value: 0.7989994525909424.\n",
      "[I 2024-05-23 10:32:58,577] Trial 1 finished with value: 1.0106193917138238 and parameters: {'learning_rate': 0.002915170567666695, 'l1_coef': 0.04695495018679426, 'patience': 12, 'batch_size': 64, 'lr_factor': 0.49137757234963864, 'num_epochs': 429}. Best is trial 4 with value: 0.7989994525909424.\n",
      "[I 2024-05-23 10:33:47,038] Trial 13 finished with value: 0.8959649503231049 and parameters: {'learning_rate': 0.05501146361142601, 'l1_coef': 6.5634305379195314e-09, 'patience': 10, 'batch_size': 256, 'lr_factor': 0.5096605051112806, 'num_epochs': 457}. Best is trial 4 with value: 0.7989994525909424.\n",
      "[I 2024-05-23 10:34:34,154] Trial 6 finished with value: 0.8415306150913239 and parameters: {'learning_rate': 0.0005914319127596832, 'l1_coef': 0.0029451429634415266, 'patience': 7, 'batch_size': 128, 'lr_factor': 0.500692243813367, 'num_epochs': 282}. Best is trial 4 with value: 0.7989994525909424.\n",
      "[I 2024-05-23 10:34:54,770] Trial 10 finished with value: 0.977126013315641 and parameters: {'learning_rate': 0.015586648346970577, 'l1_coef': 0.010726548706568294, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.2740465006704095, 'num_epochs': 216}. Best is trial 4 with value: 0.7989994525909424.\n",
      "[I 2024-05-23 10:35:17,577] Trial 14 finished with value: 0.7218227565288544 and parameters: {'learning_rate': 0.0006230696557481742, 'l1_coef': 3.272360953943599e-05, 'patience': 12, 'batch_size': 256, 'lr_factor': 0.17983530670239845, 'num_epochs': 160}. Best is trial 14 with value: 0.7218227565288544.\n",
      "[I 2024-05-23 10:35:30,842] Trial 7 finished with value: 0.918846947806222 and parameters: {'learning_rate': 0.0019316110641246253, 'l1_coef': 0.007451898926207756, 'patience': 16, 'batch_size': 64, 'lr_factor': 0.4215495695895797, 'num_epochs': 481}. Best is trial 14 with value: 0.7218227565288544.\n",
      "[I 2024-05-23 10:37:16,284] Trial 15 finished with value: 0.6724659241162814 and parameters: {'learning_rate': 0.007529530646398472, 'l1_coef': 1.003681553186336e-05, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.5278132734239737, 'num_epochs': 230}. Best is trial 15 with value: 0.6724659241162814.\n",
      "[I 2024-05-23 10:37:51,366] Trial 5 finished with value: 0.9560187561171395 and parameters: {'learning_rate': 0.08783210469092263, 'l1_coef': 4.2081353271186737e-07, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.5989758538200435, 'num_epochs': 385}. Best is trial 15 with value: 0.6724659241162814.\n",
      "[I 2024-05-23 10:39:46,869] Trial 9 finished with value: 0.6635972353128287 and parameters: {'learning_rate': 0.0001127845715749341, 'l1_coef': 1.3757264708267926e-07, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.44814875635638196, 'num_epochs': 234}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 10:40:58,361] Trial 17 finished with value: 0.9675646653542153 and parameters: {'learning_rate': 0.002327423695720921, 'l1_coef': 0.029257631000229527, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.5450324504161911, 'num_epochs': 311}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 10:41:19,351] Trial 12 finished with value: 0.8143598973751068 and parameters: {'learning_rate': 2.6747228069344975e-05, 'l1_coef': 2.0892303885259735e-06, 'patience': 15, 'batch_size': 128, 'lr_factor': 0.3208381974195169, 'num_epochs': 211}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 10:41:19,953] Trial 8 finished with value: 0.6705180832317896 and parameters: {'learning_rate': 0.00010097339314907507, 'l1_coef': 1.224653841722445e-06, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.291513781234334, 'num_epochs': 429}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 10:44:20,816] Trial 18 finished with value: 0.9157742917537689 and parameters: {'learning_rate': 2.997159293961759e-06, 'l1_coef': 4.974405928634025e-06, 'patience': 8, 'batch_size': 128, 'lr_factor': 0.7963654488256086, 'num_epochs': 209}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 10:47:47,542] Trial 0 finished with value: 0.9994188024447513 and parameters: {'learning_rate': 3.2988311774587684e-05, 'l1_coef': 0.05593762315617397, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.5304288541060027, 'num_epochs': 194}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 10:48:02,348] Trial 11 finished with value: 0.985542542200822 and parameters: {'learning_rate': 3.621831546605253e-05, 'l1_coef': 0.024855526016958465, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.4597943489330968, 'num_epochs': 216}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 10:50:19,792] Trial 20 finished with value: 0.7571922036317679 and parameters: {'learning_rate': 2.1993480000842832e-05, 'l1_coef': 1.0210571961748526e-05, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.1007973672291349, 'num_epochs': 165}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 10:55:07,324] Trial 26 finished with value: 0.691037288078895 and parameters: {'learning_rate': 0.00011057059543300658, 'l1_coef': 0.0001507153772483821, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.11695377960753839, 'num_epochs': 387}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 10:56:06,052] Trial 16 finished with value: 0.8918475866317749 and parameters: {'learning_rate': 2.767352070100345e-06, 'l1_coef': 1.1209766789248704e-09, 'patience': 6, 'batch_size': 64, 'lr_factor': 0.4989922306205439, 'num_epochs': 373}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 10:57:00,006] Trial 19 finished with value: 0.8136654881330637 and parameters: {'learning_rate': 6.293821895646224e-06, 'l1_coef': 5.328474005847029e-06, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.8940826087912486, 'num_epochs': 229}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 10:57:54,556] Trial 27 finished with value: 0.6927007812720077 and parameters: {'learning_rate': 0.00013458209051149886, 'l1_coef': 0.00022952879041307354, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.35205896791594393, 'num_epochs': 407}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 10:58:51,572] Trial 21 finished with value: 0.7380679304783161 and parameters: {'learning_rate': 2.2441730238537957e-05, 'l1_coef': 2.7892446652352677e-05, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.8755765974837597, 'num_epochs': 223}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 10:59:21,445] Trial 25 finished with value: 0.7048588083340571 and parameters: {'learning_rate': 5.880869164861024e-05, 'l1_coef': 0.0002576855933956766, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.3564214630643977, 'num_epochs': 414}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 11:00:57,377] Trial 24 finished with value: 0.7001232651563791 and parameters: {'learning_rate': 3.529055610058112e-05, 'l1_coef': 6.844783011511637e-05, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.3724221315963575, 'num_epochs': 374}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 11:01:40,966] Trial 22 finished with value: 0.7425380202440116 and parameters: {'learning_rate': 1.9772045409369217e-05, 'l1_coef': 2.4505993578208386e-05, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.8336908739077562, 'num_epochs': 241}. Best is trial 9 with value: 0.6635972353128287.\n",
      "[I 2024-05-23 11:01:48,676] Trial 30 finished with value: 0.6627656689056984 and parameters: {'learning_rate': 0.00015279201052123, 'l1_coef': 2.492657122222256e-07, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.36344010910767, 'num_epochs': 270}. Best is trial 30 with value: 0.6627656689056984.\n",
      "[I 2024-05-23 11:02:24,332] Trial 23 finished with value: 0.7246074034617498 and parameters: {'learning_rate': 3.221827155480797e-05, 'l1_coef': 9.5401634285569e-05, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.876717577643906, 'num_epochs': 245}. Best is trial 30 with value: 0.6627656689056984.\n",
      "[I 2024-05-23 11:02:39,717] Trial 31 finished with value: 0.6655265597196726 and parameters: {'learning_rate': 0.00014351225419161913, 'l1_coef': 1.708534665876088e-07, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.38441881251917925, 'num_epochs': 266}. Best is trial 30 with value: 0.6627656689056984.\n",
      "[I 2024-05-23 11:03:04,318] Trial 34 finished with value: 0.6677231141499111 and parameters: {'learning_rate': 0.0002774670843692207, 'l1_coef': 7.707572540323924e-08, 'patience': 10, 'batch_size': 64, 'lr_factor': 0.6574711051693918, 'num_epochs': 279}. Best is trial 30 with value: 0.6627656689056984.\n",
      "[I 2024-05-23 11:03:19,369] Trial 28 finished with value: 0.7415460433278765 and parameters: {'learning_rate': 9.928274815432715e-05, 'l1_coef': 0.0005396217677561323, 'patience': 10, 'batch_size': 64, 'lr_factor': 0.3183199850861773, 'num_epochs': 269}. Best is trial 30 with value: 0.6627656689056984.\n",
      "[I 2024-05-23 11:03:57,718] Trial 33 finished with value: 0.655514276944674 and parameters: {'learning_rate': 0.00016362105272885684, 'l1_coef': 8.090358388345066e-08, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.6168972242692096, 'num_epochs': 242}. Best is trial 33 with value: 0.655514276944674.\n",
      "[I 2024-05-23 11:05:03,993] Trial 35 finished with value: 0.6682020851543972 and parameters: {'learning_rate': 0.0002691176429515444, 'l1_coef': 1.8811000693101447e-07, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.6349258473411463, 'num_epochs': 280}. Best is trial 33 with value: 0.655514276944674.\n",
      "[I 2024-05-23 11:06:32,993] Trial 38 finished with value: 0.6678428207124982 and parameters: {'learning_rate': 0.0002792994641994686, 'l1_coef': 1.2512974370411356e-07, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.6100952934871826, 'num_epochs': 277}. Best is trial 33 with value: 0.655514276944674.\n",
      "[I 2024-05-23 11:08:07,555] Trial 32 finished with value: 0.6614228184406573 and parameters: {'learning_rate': 0.00010954378853817793, 'l1_coef': 1.820776928169976e-07, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.6338226580809709, 'num_epochs': 260}. Best is trial 33 with value: 0.655514276944674.\n",
      "[I 2024-05-23 11:09:06,682] Trial 36 finished with value: 0.6731316259929112 and parameters: {'learning_rate': 0.00015797885872473306, 'l1_coef': 3.8142198365615495e-07, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.6495705025597303, 'num_epochs': 273}. Best is trial 33 with value: 0.655514276944674.\n",
      "[I 2024-05-23 11:09:21,394] Trial 39 finished with value: 0.6496172409791212 and parameters: {'learning_rate': 0.00024760118454231396, 'l1_coef': 1.2173517474453952e-07, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.6216921965579141, 'num_epochs': 279}. Best is trial 39 with value: 0.6496172409791212.\n",
      "[I 2024-05-23 11:09:36,288] Trial 40 finished with value: 0.6468390189684354 and parameters: {'learning_rate': 0.0003016660337632342, 'l1_coef': 9.34831888387587e-08, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.6267489439261082, 'num_epochs': 272}. Best is trial 40 with value: 0.6468390189684354.\n",
      "[I 2024-05-23 11:09:44,629] Trial 37 finished with value: 0.6640668869018554 and parameters: {'learning_rate': 0.00018662884443508348, 'l1_coef': 1.816369015466922e-07, 'patience': 11, 'batch_size': 64, 'lr_factor': 0.637251923109827, 'num_epochs': 293}. Best is trial 40 with value: 0.6468390189684354.\n",
      "[I 2024-05-23 11:09:53,647] Trial 43 finished with value: 0.6397577395805947 and parameters: {'learning_rate': 0.0009174036159621663, 'l1_coef': 2.2355088789809733e-08, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.4122826910205584, 'num_epochs': 183}. Best is trial 43 with value: 0.6397577395805947.\n",
      "[I 2024-05-23 11:09:55,784] Trial 41 finished with value: 0.6456944493147043 and parameters: {'learning_rate': 0.000319717191790612, 'l1_coef': 1.4830857175199785e-07, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.622364050591192, 'num_epochs': 278}. Best is trial 43 with value: 0.6397577395805947.\n",
      "[I 2024-05-23 11:10:10,229] Trial 42 finished with value: 0.6485452477748577 and parameters: {'learning_rate': 0.0002846887705221547, 'l1_coef': 1.8521268241398237e-07, 'patience': 13, 'batch_size': 32, 'lr_factor': 0.5882650234635862, 'num_epochs': 260}. Best is trial 43 with value: 0.6397577395805947.\n",
      "[I 2024-05-23 11:10:49,221] Trial 44 finished with value: 0.6389962728206928 and parameters: {'learning_rate': 0.0010644472676853208, 'l1_coef': 6.190624344033467e-09, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.42083359592272906, 'num_epochs': 175}. Best is trial 44 with value: 0.6389962728206928.\n",
      "[I 2024-05-23 11:11:02,327] Trial 29 finished with value: 0.8536784189088003 and parameters: {'learning_rate': 5.166617890771149e-06, 'l1_coef': 1.2432538415500646e-07, 'patience': 10, 'batch_size': 64, 'lr_factor': 0.36198627084050483, 'num_epochs': 270}. Best is trial 44 with value: 0.6389962728206928.\n",
      "[I 2024-05-23 11:11:14,547] Trial 47 finished with value: 0.6729225516319275 and parameters: {'learning_rate': 0.00068972786929275, 'l1_coef': 1.3288969843269112e-08, 'patience': 17, 'batch_size': 256, 'lr_factor': 0.7185152130559674, 'num_epochs': 325}. Best is trial 44 with value: 0.6389962728206928.\n",
      "[I 2024-05-23 11:11:20,302] Trial 49 finished with value: 0.6659191071987152 and parameters: {'learning_rate': 0.0008014010027361405, 'l1_coef': 1.4862660606440195e-08, 'patience': 17, 'batch_size': 256, 'lr_factor': 0.7193730519815454, 'num_epochs': 340}. Best is trial 44 with value: 0.6389962728206928.\n",
      "[I 2024-05-23 11:11:26,725] Trial 48 finished with value: 0.6541493177413941 and parameters: {'learning_rate': 0.000723541533200187, 'l1_coef': 2.0782345873164742e-08, 'patience': 18, 'batch_size': 128, 'lr_factor': 0.7339760346886854, 'num_epochs': 337}. Best is trial 44 with value: 0.6389962728206928.\n",
      "[I 2024-05-23 11:11:29,580] Trial 45 finished with value: 0.6387811761636 and parameters: {'learning_rate': 0.000823539476764051, 'l1_coef': 1.6874695481655914e-08, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.7424164998244227, 'num_epochs': 331}. Best is trial 45 with value: 0.6387811761636.\n",
      "[I 2024-05-23 11:11:39,141] Trial 46 finished with value: 0.621251457471114 and parameters: {'learning_rate': 0.0005699600577620382, 'l1_coef': 2.1247931949559007e-08, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.7547222609319668, 'num_epochs': 339}. Best is trial 46 with value: 0.621251457471114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 19 - Best hyperparameters: {'learning_rate': 0.0005699600577620382, 'l1_coef': 2.1247931949559007e-08, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.7547222609319668, 'num_epochs': 339}\n",
      "Chr 19 - Best value: 0.6213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 11:11:59,756] A new study created in RDB with name: unphased_full_23andMe_chr20_study_logistic_regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr19/final_model_chr19.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr19/individual_r2_scores_chr19.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr19/individual_iqs_scores_chr19.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  62\n",
      "PRS313 SNPs:  4\n",
      "Total SNPs used for Training:  58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-23 11:14:40,395] Trial 8 finished with value: 0.6391972184181214 and parameters: {'learning_rate': 0.011987920813509946, 'l1_coef': 2.3213538860849817e-06, 'patience': 15, 'batch_size': 256, 'lr_factor': 0.3687000334218582, 'num_epochs': 457}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:14:56,507] Trial 1 finished with value: 0.7809470415115356 and parameters: {'learning_rate': 0.061876952241310845, 'l1_coef': 0.0606669214515346, 'patience': 11, 'batch_size': 128, 'lr_factor': 0.18851297502125358, 'num_epochs': 214}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:16:41,849] Trial 9 finished with value: 0.705214011669159 and parameters: {'learning_rate': 7.521276198884805e-05, 'l1_coef': 4.907221442378259e-10, 'patience': 6, 'batch_size': 128, 'lr_factor': 0.4064474947532004, 'num_epochs': 183}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:16:58,044] Trial 10 finished with value: 0.6395760398644667 and parameters: {'learning_rate': 0.0052122067154185174, 'l1_coef': 1.6470524374968725e-10, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.11961012206702169, 'num_epochs': 424}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:18:21,827] Trial 5 finished with value: 0.7140461615153721 and parameters: {'learning_rate': 0.0016278806264859542, 'l1_coef': 0.003443970510281063, 'patience': 16, 'batch_size': 64, 'lr_factor': 0.11685765832696388, 'num_epochs': 311}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:20:29,173] Trial 12 finished with value: 0.7241441113608225 and parameters: {'learning_rate': 0.0026611275086110223, 'l1_coef': 0.06544234944168101, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.17264113038122514, 'num_epochs': 480}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:23:18,394] Trial 3 finished with value: 0.7827616636569683 and parameters: {'learning_rate': 2.7804807540376724e-06, 'l1_coef': 3.673968528248977e-06, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.7018066048261629, 'num_epochs': 111}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:25:06,957] Trial 2 finished with value: 0.7119924409048899 and parameters: {'learning_rate': 1.666129125860225e-05, 'l1_coef': 5.348951479453293e-06, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.5109110645576825, 'num_epochs': 193}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:25:22,145] Trial 4 finished with value: 0.9249543607234955 and parameters: {'learning_rate': 2.967389706128313e-06, 'l1_coef': 0.0018707814531660502, 'patience': 9, 'batch_size': 128, 'lr_factor': 0.21276043283961643, 'num_epochs': 271}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:26:23,394] Trial 7 finished with value: 0.7329569071531296 and parameters: {'learning_rate': 9.595273081144729e-06, 'l1_coef': 2.1602121672627012e-05, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.2775095520299262, 'num_epochs': 291}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:27:20,494] Trial 19 finished with value: 0.7177818536758422 and parameters: {'learning_rate': 0.0587040753604087, 'l1_coef': 1.4749697437162503e-08, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.8825996275269157, 'num_epochs': 386}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:28:17,876] Trial 6 finished with value: 0.7732898950576782 and parameters: {'learning_rate': 2.257022214876224e-05, 'l1_coef': 0.002640744365131749, 'patience': 15, 'batch_size': 256, 'lr_factor': 0.44364912143451507, 'num_epochs': 410}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:28:20,587] Trial 0 finished with value: 1.7207871556282044 and parameters: {'learning_rate': 1.3323610007171664e-06, 'l1_coef': 0.01446876686782429, 'patience': 6, 'batch_size': 256, 'lr_factor': 0.3830680339750151, 'num_epochs': 412}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:28:52,276] Trial 20 finished with value: 0.6408230038789602 and parameters: {'learning_rate': 0.005413648860666893, 'l1_coef': 2.2317985442895943e-08, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.39063520628809845, 'num_epochs': 497}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:30:04,364] Trial 21 finished with value: 0.6408311422054584 and parameters: {'learning_rate': 0.005155144897558483, 'l1_coef': 2.6097631897665094e-08, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.3329764274010727, 'num_epochs': 496}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:31:44,838] Trial 18 finished with value: 0.7327917729105268 and parameters: {'learning_rate': 0.0001593361826340187, 'l1_coef': 0.002234914439842281, 'patience': 6, 'batch_size': 64, 'lr_factor': 0.6399161881481501, 'num_epochs': 176}. Best is trial 8 with value: 0.6391972184181214.\n",
      "[I 2024-05-23 11:32:07,257] Trial 17 finished with value: 0.6374639373559219 and parameters: {'learning_rate': 0.0010150272625559563, 'l1_coef': 9.253973640009528e-10, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.35205341952899627, 'num_epochs': 434}. Best is trial 17 with value: 0.6374639373559219.\n",
      "[I 2024-05-23 11:32:14,423] Trial 22 finished with value: 0.6376957554083604 and parameters: {'learning_rate': 0.007382133245845197, 'l1_coef': 3.807720368540938e-08, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.5925712515221292, 'num_epochs': 490}. Best is trial 17 with value: 0.6374639373559219.\n",
      "[I 2024-05-23 11:32:18,018] Trial 13 finished with value: 0.7012852549552917 and parameters: {'learning_rate': 3.188825405732309e-05, 'l1_coef': 1.695012908097627e-09, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.5158664235877534, 'num_epochs': 324}. Best is trial 17 with value: 0.6374639373559219.\n",
      "[I 2024-05-23 11:32:21,980] Trial 23 finished with value: 0.6350759066068209 and parameters: {'learning_rate': 0.011282691704502485, 'l1_coef': 1.0640747617245795e-07, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.5788790731135443, 'num_epochs': 364}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:33:56,783] Trial 15 finished with value: 0.6631216003344609 and parameters: {'learning_rate': 7.98537310485338e-05, 'l1_coef': 7.209744544173693e-07, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.5128443812373327, 'num_epochs': 223}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:34:07,012] Trial 11 finished with value: 0.8152768697057452 and parameters: {'learning_rate': 1.6864444613444568e-06, 'l1_coef': 0.00020005663219603537, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.764088284803337, 'num_epochs': 293}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:34:10,584] Trial 25 finished with value: 0.6377305269241333 and parameters: {'learning_rate': 0.01794153432659484, 'l1_coef': 2.5864871237245633e-10, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.6262831448515676, 'num_epochs': 356}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:37:12,680] Trial 16 finished with value: 1.007015013694763 and parameters: {'learning_rate': 1.2993442793460985e-06, 'l1_coef': 1.6715672116357373e-08, 'patience': 7, 'batch_size': 256, 'lr_factor': 0.10626006243289102, 'num_epochs': 367}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:37:54,996] Trial 26 finished with value: 0.6609046816825866 and parameters: {'learning_rate': 0.0004948578524120227, 'l1_coef': 7.884831820299923e-05, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.5649473564572505, 'num_epochs': 351}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:38:07,387] Trial 24 finished with value: 0.6405289044746987 and parameters: {'learning_rate': 0.0004964363947162547, 'l1_coef': 1.5738781474356925e-10, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.5643110041300996, 'num_epochs': 357}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:40:13,365] Trial 29 finished with value: 0.6403802807514484 and parameters: {'learning_rate': 0.0005304367982902347, 'l1_coef': 1.8569284534751855e-07, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.7922066977524127, 'num_epochs': 349}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:40:18,560] Trial 27 finished with value: 0.6391638003862822 and parameters: {'learning_rate': 0.0006512264355325685, 'l1_coef': 2.9348926771974144e-09, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.564329175781867, 'num_epochs': 351}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:40:39,986] Trial 28 finished with value: 0.6390362739562988 and parameters: {'learning_rate': 0.0005851206569309111, 'l1_coef': 2.6002501661842797e-07, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.598570671826306, 'num_epochs': 371}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:41:53,926] Trial 30 finished with value: 0.637908251468952 and parameters: {'learning_rate': 0.0006772076049519638, 'l1_coef': 1.8194562063764106e-07, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.6336065219329287, 'num_epochs': 355}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:42:01,238] Trial 32 finished with value: 0.6384038356634287 and parameters: {'learning_rate': 0.0006510173691909875, 'l1_coef': 1.4312231928459512e-07, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.5865849425560247, 'num_epochs': 445}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:42:05,314] Trial 31 finished with value: 0.6378687666012691 and parameters: {'learning_rate': 0.0008687784526863155, 'l1_coef': 1.642442343426858e-07, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.6067717184069523, 'num_epochs': 358}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:42:49,363] Trial 37 finished with value: 0.637441570025224 and parameters: {'learning_rate': 0.01849907043678969, 'l1_coef': 1.485435152373482e-07, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.44941513196645005, 'num_epochs': 452}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:43:51,456] Trial 38 finished with value: 0.6582940459251404 and parameters: {'learning_rate': 0.027266278642314953, 'l1_coef': 3.102775791207586e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.6894664501795491, 'num_epochs': 444}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:43:55,803] Trial 39 finished with value: 0.6378387056864225 and parameters: {'learning_rate': 0.02334759015884215, 'l1_coef': 3.828265303189989e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.4624089450016701, 'num_epochs': 451}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:44:45,929] Trial 40 finished with value: 0.6581868996986976 and parameters: {'learning_rate': 0.02232514158736214, 'l1_coef': 2.011552065075253e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.6792317691135504, 'num_epochs': 403}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:44:49,496] Trial 41 finished with value: 0.6568368627474859 and parameters: {'learning_rate': 0.025270451668014646, 'l1_coef': 1.94555551532001e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.6782173677618506, 'num_epochs': 403}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:44:51,812] Trial 34 finished with value: 0.639149090876946 and parameters: {'learning_rate': 0.0007223979222509388, 'l1_coef': 2.2345229487180172e-07, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.609502028042441, 'num_epochs': 445}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:44:57,994] Trial 14 finished with value: 0.7050927593157842 and parameters: {'learning_rate': 9.52190198140103e-06, 'l1_coef': 1.882433013636567e-08, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.1543844966116799, 'num_epochs': 284}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:45:24,744] Trial 42 finished with value: 0.6369265088668237 and parameters: {'learning_rate': 0.026491473201785225, 'l1_coef': 3.366119632571231e-09, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.45375648233131516, 'num_epochs': 457}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:46:01,007] Trial 43 finished with value: 0.6861227228091313 and parameters: {'learning_rate': 0.09438223883586008, 'l1_coef': 9.294076320931466e-10, 'patience': 17, 'batch_size': 32, 'lr_factor': 0.4527270595773079, 'num_epochs': 405}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:46:18,810] Trial 35 finished with value: 0.635925083893996 and parameters: {'learning_rate': 0.0011552214201630702, 'l1_coef': 1.7859032151936875e-07, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.7767106547317453, 'num_epochs': 446}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:46:18,862] Trial 33 finished with value: 0.6384718317251938 and parameters: {'learning_rate': 0.0005756614534631208, 'l1_coef': 2.0861978001119422e-07, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.585772445174987, 'num_epochs': 443}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:46:20,804] Trial 36 finished with value: 0.6379303959699778 and parameters: {'learning_rate': 0.0015268486858405937, 'l1_coef': 1.2607625770398e-07, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.6406194243243281, 'num_epochs': 444}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:46:31,799] Trial 49 finished with value: 0.7158131390810013 and parameters: {'learning_rate': 0.06848368737851021, 'l1_coef': 7.357578506780978e-07, 'patience': 14, 'batch_size': 128, 'lr_factor': 0.27123794176304705, 'num_epochs': 423}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:46:34,155] Trial 48 finished with value: 0.7159137934446335 and parameters: {'learning_rate': 0.09198753677233258, 'l1_coef': 1.6300884114345657e-06, 'patience': 14, 'batch_size': 128, 'lr_factor': 0.26567362464148075, 'num_epochs': 472}. Best is trial 23 with value: 0.6350759066068209.\n",
      "[I 2024-05-23 11:46:50,769] Trial 44 finished with value: 0.6349273103934068 and parameters: {'learning_rate': 0.054578763547466075, 'l1_coef': 9.874512921112002e-07, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.3148327399546068, 'num_epochs': 406}. Best is trial 44 with value: 0.6349273103934068.\n",
      "[I 2024-05-23 11:46:52,949] Trial 45 finished with value: 0.6340064709003156 and parameters: {'learning_rate': 0.009741141887525059, 'l1_coef': 5.086408968461716e-08, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.2989080662232163, 'num_epochs': 470}. Best is trial 45 with value: 0.6340064709003156.\n",
      "[I 2024-05-23 11:46:56,305] Trial 47 finished with value: 0.7180865416159997 and parameters: {'learning_rate': 0.07656944791611663, 'l1_coef': 4.8127078550881936e-08, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.28722053197430125, 'num_epochs': 471}. Best is trial 45 with value: 0.6340064709003156.\n",
      "[I 2024-05-23 11:47:00,209] Trial 46 finished with value: 0.6366279812959524 and parameters: {'learning_rate': 0.002146588287221086, 'l1_coef': 1.0618372555132794e-06, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.2965603664108196, 'num_epochs': 435}. Best is trial 45 with value: 0.6340064709003156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 20 - Best hyperparameters: {'learning_rate': 0.009741141887525059, 'l1_coef': 5.086408968461716e-08, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.2989080662232163, 'num_epochs': 470}\n",
      "Chr 20 - Best value: 0.6340\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr20/final_model_chr20.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr20/individual_r2_scores_chr20.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr20/individual_iqs_scores_chr20.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  44\n",
      "PRS313 SNPs:  4\n",
      "Total SNPs used for Training:  40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 11:47:18,628] A new study created in RDB with name: unphased_full_23andMe_chr21_study_logistic_regression\n",
      "[I 2024-05-23 11:48:18,055] Trial 6 finished with value: 0.7160479247570037 and parameters: {'learning_rate': 0.045724692439618665, 'l1_coef': 7.881446682339455e-09, 'patience': 15, 'batch_size': 256, 'lr_factor': 0.30953500093983594, 'num_epochs': 132}. Best is trial 6 with value: 0.7160479247570037.\n",
      "[I 2024-05-23 11:49:27,296] Trial 5 finished with value: 0.7142757599170391 and parameters: {'learning_rate': 0.02669869306219022, 'l1_coef': 8.604820920110499e-08, 'patience': 16, 'batch_size': 32, 'lr_factor': 0.645036029775653, 'num_epochs': 262}. Best is trial 5 with value: 0.7142757599170391.\n",
      "[I 2024-05-23 11:52:00,179] Trial 3 finished with value: 0.7493791733469282 and parameters: {'learning_rate': 0.0026946779906731424, 'l1_coef': 0.00523662900845539, 'patience': 10, 'batch_size': 64, 'lr_factor': 0.5118875363761652, 'num_epochs': 400}. Best is trial 5 with value: 0.7142757599170391.\n",
      "[I 2024-05-23 11:54:53,421] Trial 8 finished with value: 1.1181333303451537 and parameters: {'learning_rate': 2.1442308908266395e-06, 'l1_coef': 0.0006249881425405949, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.17637999820972566, 'num_epochs': 232}. Best is trial 5 with value: 0.7142757599170391.\n",
      "[I 2024-05-23 11:54:54,253] Trial 7 finished with value: 0.7335094656263079 and parameters: {'learning_rate': 0.0019390043735174963, 'l1_coef': 0.0023941945939409113, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.8080239277747409, 'num_epochs': 187}. Best is trial 5 with value: 0.7142757599170391.\n",
      "[I 2024-05-23 11:55:34,286] Trial 4 finished with value: 1.926846295595169 and parameters: {'learning_rate': 3.4936224620962063e-06, 'l1_coef': 0.03150065377038004, 'patience': 10, 'batch_size': 128, 'lr_factor': 0.1265530461114338, 'num_epochs': 187}. Best is trial 5 with value: 0.7142757599170391.\n",
      "[I 2024-05-23 11:56:19,567] Trial 12 finished with value: 0.7070280698629526 and parameters: {'learning_rate': 0.0022526103230307735, 'l1_coef': 0.0010726702633989862, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.6347559098974843, 'num_epochs': 495}. Best is trial 12 with value: 0.7070280698629526.\n",
      "[I 2024-05-23 11:58:25,426] Trial 2 finished with value: 0.7898587048053741 and parameters: {'learning_rate': 3.776143452035646e-05, 'l1_coef': 8.183908867403571e-06, 'patience': 7, 'batch_size': 256, 'lr_factor': 0.8345213250715047, 'num_epochs': 309}. Best is trial 12 with value: 0.7070280698629526.\n",
      "[I 2024-05-23 11:58:31,342] Trial 1 finished with value: 0.7823827147483826 and parameters: {'learning_rate': 3.684998557898713e-05, 'l1_coef': 4.6920188129892866e-08, 'patience': 20, 'batch_size': 256, 'lr_factor': 0.5059009638034082, 'num_epochs': 312}. Best is trial 12 with value: 0.7070280698629526.\n",
      "[I 2024-05-23 11:59:16,632] Trial 16 finished with value: 0.7938255786895752 and parameters: {'learning_rate': 0.010202365928264902, 'l1_coef': 0.06211929744533675, 'patience': 15, 'batch_size': 128, 'lr_factor': 0.1828805154126032, 'num_epochs': 447}. Best is trial 12 with value: 0.7070280698629526.\n",
      "[I 2024-05-23 12:00:50,773] Trial 14 finished with value: 0.6728646457195282 and parameters: {'learning_rate': 0.0008964278423375625, 'l1_coef': 1.7835186182060325e-07, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.6508865831689716, 'num_epochs': 321}. Best is trial 14 with value: 0.6728646457195282.\n",
      "[I 2024-05-23 12:01:34,968] Trial 11 finished with value: 1.9495429720197404 and parameters: {'learning_rate': 4.671053194767427e-06, 'l1_coef': 0.06848717965736104, 'patience': 8, 'batch_size': 64, 'lr_factor': 0.6692695694629566, 'num_epochs': 198}. Best is trial 14 with value: 0.6728646457195282.\n",
      "[I 2024-05-23 12:02:17,500] Trial 10 finished with value: 1.0197863101959228 and parameters: {'learning_rate': 3.759559425292974e-05, 'l1_coef': 0.031034722776116568, 'patience': 18, 'batch_size': 256, 'lr_factor': 0.8692113922238955, 'num_epochs': 393}. Best is trial 14 with value: 0.6728646457195282.\n",
      "[I 2024-05-23 12:02:25,838] Trial 13 finished with value: 0.6835660427808762 and parameters: {'learning_rate': 0.00028694310837819266, 'l1_coef': 2.045344924766104e-07, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.30717178450818305, 'num_epochs': 408}. Best is trial 14 with value: 0.6728646457195282.\n",
      "[I 2024-05-23 12:04:22,135] Trial 9 finished with value: 0.6997042023218596 and parameters: {'learning_rate': 5.295087733259286e-05, 'l1_coef': 6.349930916049038e-06, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.7266307395260431, 'num_epochs': 365}. Best is trial 14 with value: 0.6728646457195282.\n",
      "[I 2024-05-23 12:04:46,803] Trial 17 finished with value: 1.0034667789936065 and parameters: {'learning_rate': 5.300796446266762e-06, 'l1_coef': 0.00019604938609463283, 'patience': 13, 'batch_size': 256, 'lr_factor': 0.21604667269565977, 'num_epochs': 183}. Best is trial 14 with value: 0.6728646457195282.\n",
      "[I 2024-05-23 12:06:21,131] Trial 20 finished with value: 0.67869091125635 and parameters: {'learning_rate': 0.0004999184375930417, 'l1_coef': 1.4296835071797622e-05, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.6730249376994804, 'num_epochs': 496}. Best is trial 14 with value: 0.6728646457195282.\n",
      "[I 2024-05-23 12:07:26,125] Trial 19 finished with value: 0.6843565234771141 and parameters: {'learning_rate': 0.00025472516767749436, 'l1_coef': 2.2037278669218583e-10, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.6722754563628507, 'num_epochs': 474}. Best is trial 14 with value: 0.6728646457195282.\n",
      "[I 2024-05-23 12:08:16,115] Trial 18 finished with value: 1.0761289775371552 and parameters: {'learning_rate': 3.3776905021303e-06, 'l1_coef': 0.0034578626490611875, 'patience': 5, 'batch_size': 128, 'lr_factor': 0.27382029717185574, 'num_epochs': 228}. Best is trial 14 with value: 0.6728646457195282.\n",
      "[I 2024-05-23 12:09:04,277] Trial 23 finished with value: 0.6885584533214569 and parameters: {'learning_rate': 0.0002843258667036349, 'l1_coef': 2.41790508825622e-06, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.3844179217247381, 'num_epochs': 360}. Best is trial 14 with value: 0.6728646457195282.\n",
      "[I 2024-05-23 12:09:45,718] Trial 15 finished with value: 0.9014481842517853 and parameters: {'learning_rate': 6.0776027043936295e-06, 'l1_coef': 6.078168924492225e-06, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.5692823738870626, 'num_epochs': 402}. Best is trial 14 with value: 0.6728646457195282.\n",
      "[I 2024-05-23 12:09:48,912] Trial 21 finished with value: 0.6806656076357915 and parameters: {'learning_rate': 0.00026555236704869434, 'l1_coef': 1.972249490165173e-10, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.6668352410054609, 'num_epochs': 492}. Best is trial 14 with value: 0.6728646457195282.\n",
      "[I 2024-05-23 12:09:59,287] Trial 22 finished with value: 0.6725232381087083 and parameters: {'learning_rate': 0.0004366503284675504, 'l1_coef': 1.381101405434729e-05, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.6619373368439745, 'num_epochs': 489}. Best is trial 22 with value: 0.6725232381087083.\n",
      "[I 2024-05-23 12:11:37,300] Trial 24 finished with value: 0.6858934134244918 and parameters: {'learning_rate': 0.0003287254008951749, 'l1_coef': 1.9224608383627834e-10, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.36018949389552657, 'num_epochs': 337}. Best is trial 22 with value: 0.6725232381087083.\n",
      "[I 2024-05-23 12:11:39,481] Trial 25 finished with value: 0.6820983439683914 and parameters: {'learning_rate': 0.0003636251541650872, 'l1_coef': 1.0864466838139288e-10, 'patience': 5, 'batch_size': 128, 'lr_factor': 0.36865415887597497, 'num_epochs': 369}. Best is trial 22 with value: 0.6725232381087083.\n",
      "[I 2024-05-23 12:12:38,020] Trial 26 finished with value: 0.6819333241536067 and parameters: {'learning_rate': 0.0002912501329913526, 'l1_coef': 1.0981907227292215e-10, 'patience': 5, 'batch_size': 32, 'lr_factor': 0.571798976092966, 'num_epochs': 500}. Best is trial 22 with value: 0.6725232381087083.\n",
      "[I 2024-05-23 12:13:02,416] Trial 29 finished with value: 0.6796326307150033 and parameters: {'learning_rate': 0.0009415565211675992, 'l1_coef': 5.541361407354793e-05, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.4244669361625504, 'num_epochs': 446}. Best is trial 22 with value: 0.6725232381087083.\n",
      "[I 2024-05-23 12:13:20,239] Trial 32 finished with value: 0.680483617232396 and parameters: {'learning_rate': 0.0009963604054710978, 'l1_coef': 4.0320334218899755e-05, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.7554853493957354, 'num_epochs': 451}. Best is trial 22 with value: 0.6725232381087083.\n",
      "[I 2024-05-23 12:14:04,595] Trial 31 finished with value: 0.6766418053553653 and parameters: {'learning_rate': 0.0008344831992691895, 'l1_coef': 9.04931934853032e-10, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.7717041499467324, 'num_epochs': 450}. Best is trial 22 with value: 0.6725232381087083.\n",
      "[I 2024-05-23 12:14:34,336] Trial 36 finished with value: 0.6724016767281753 and parameters: {'learning_rate': 0.006467573803287132, 'l1_coef': 9.279761842279748e-07, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.7671076418284213, 'num_epochs': 444}. Best is trial 36 with value: 0.6724016767281753.\n",
      "[I 2024-05-23 12:14:37,049] Trial 27 finished with value: 0.6802699565887451 and parameters: {'learning_rate': 0.00057376982531859, 'l1_coef': 6.844270508155054e-05, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.4285973758423046, 'num_epochs': 351}. Best is trial 36 with value: 0.6724016767281753.\n",
      "[I 2024-05-23 12:15:01,350] Trial 28 finished with value: 0.677960929274559 and parameters: {'learning_rate': 0.0006786622914378585, 'l1_coef': 4.675410985559932e-05, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.4183793168017952, 'num_epochs': 358}. Best is trial 36 with value: 0.6724016767281753.\n",
      "[I 2024-05-23 12:15:11,086] Trial 37 finished with value: 0.6716729677640475 and parameters: {'learning_rate': 0.007294586311408279, 'l1_coef': 5.573711536027145e-07, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.7685048811008448, 'num_epochs': 113}. Best is trial 37 with value: 0.6716729677640475.\n",
      "[I 2024-05-23 12:15:49,948] Trial 40 finished with value: 0.6737331307851351 and parameters: {'learning_rate': 0.009317429308325631, 'l1_coef': 6.252665275075595e-07, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.7681653174619769, 'num_epochs': 426}. Best is trial 37 with value: 0.6716729677640475.\n",
      "[I 2024-05-23 12:16:01,553] Trial 34 finished with value: 0.6803795236807603 and parameters: {'learning_rate': 0.0009974839890231912, 'l1_coef': 7.302640346567587e-05, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.768808744015516, 'num_epochs': 448}. Best is trial 37 with value: 0.6716729677640475.\n",
      "[I 2024-05-23 12:16:16,314] Trial 39 finished with value: 0.6707210847309657 and parameters: {'learning_rate': 0.007222838327053103, 'l1_coef': 2.3284737523855855e-07, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.557632371424554, 'num_epochs': 277}. Best is trial 39 with value: 0.6707210847309657.\n",
      "[I 2024-05-23 12:16:17,926] Trial 30 finished with value: 0.6735765844583511 and parameters: {'learning_rate': 0.0007051355537916761, 'l1_coef': 6.686630779178928e-07, 'patience': 12, 'batch_size': 128, 'lr_factor': 0.41738901004526263, 'num_epochs': 441}. Best is trial 39 with value: 0.6707210847309657.\n",
      "[I 2024-05-23 12:16:35,555] Trial 41 finished with value: 0.6716700260455791 and parameters: {'learning_rate': 0.008530789289522523, 'l1_coef': 8.561005157016659e-07, 'patience': 9, 'batch_size': 32, 'lr_factor': 0.7747823041555667, 'num_epochs': 426}. Best is trial 39 with value: 0.6707210847309657.\n",
      "[I 2024-05-23 12:17:04,222] Trial 33 finished with value: 0.6805891220386211 and parameters: {'learning_rate': 0.0008171155545065862, 'l1_coef': 8.723033787696895e-05, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.7684836522082126, 'num_epochs': 447}. Best is trial 39 with value: 0.6707210847309657.\n",
      "[I 2024-05-23 12:17:20,920] Trial 42 finished with value: 0.6711816650170547 and parameters: {'learning_rate': 0.007500412414258557, 'l1_coef': 5.106542399586311e-07, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.8815713134108117, 'num_epochs': 144}. Best is trial 39 with value: 0.6707210847309657.\n",
      "[I 2024-05-23 12:17:45,824] Trial 35 finished with value: 0.6734456777572632 and parameters: {'learning_rate': 0.000958551807052433, 'l1_coef': 7.94287418121126e-07, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.7687411846182315, 'num_epochs': 457}. Best is trial 39 with value: 0.6707210847309657.\n",
      "[I 2024-05-23 12:17:48,358] Trial 44 finished with value: 0.670775830745697 and parameters: {'learning_rate': 0.006104002097341308, 'l1_coef': 1.6481216133012145e-08, 'patience': 14, 'batch_size': 64, 'lr_factor': 0.8752648312270933, 'num_epochs': 289}. Best is trial 39 with value: 0.6707210847309657.\n",
      "[I 2024-05-23 12:17:50,827] Trial 45 finished with value: 0.6718123470033919 and parameters: {'learning_rate': 0.008763466085616425, 'l1_coef': 1.2314787472984157e-06, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.5158768085068934, 'num_epochs': 116}. Best is trial 39 with value: 0.6707210847309657.\n",
      "[I 2024-05-23 12:18:03,616] Trial 43 finished with value: 0.6704917871035062 and parameters: {'learning_rate': 0.007263548914775252, 'l1_coef': 9.202830817218824e-07, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.8950216594788208, 'num_epochs': 110}. Best is trial 43 with value: 0.6704917871035062.\n",
      "[I 2024-05-23 12:18:09,467] Trial 46 finished with value: 0.6714695385524205 and parameters: {'learning_rate': 0.005400822302738749, 'l1_coef': 1.70954437042191e-08, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.883737724287972, 'num_epochs': 286}. Best is trial 43 with value: 0.6704917871035062.\n",
      "[I 2024-05-23 12:18:11,867] Trial 47 finished with value: 0.6686211688177927 and parameters: {'learning_rate': 0.010264451052989764, 'l1_coef': 8.968690428428348e-09, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.8644584496713962, 'num_epochs': 134}. Best is trial 47 with value: 0.6686211688177927.\n",
      "[I 2024-05-23 12:18:17,858] Trial 48 finished with value: 0.7116735373224531 and parameters: {'learning_rate': 0.09168418644026922, 'l1_coef': 1.066056218482417e-08, 'patience': 18, 'batch_size': 64, 'lr_factor': 0.8944446613571346, 'num_epochs': 267}. Best is trial 47 with value: 0.6686211688177927.\n",
      "[I 2024-05-23 12:18:21,052] Trial 49 finished with value: 0.6683937617710659 and parameters: {'learning_rate': 0.06417463659123403, 'l1_coef': 1.4994401968392755e-08, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.8953661415766634, 'num_epochs': 117}. Best is trial 49 with value: 0.6683937617710659.\n",
      "[I 2024-05-23 12:18:21,889] Trial 0 finished with value: 0.7779250557606037 and parameters: {'learning_rate': 4.545415641559165e-06, 'l1_coef': 2.0034529148214843e-08, 'patience': 14, 'batch_size': 32, 'lr_factor': 0.6040221618973949, 'num_epochs': 356}. Best is trial 49 with value: 0.6683937617710659.\n",
      "[I 2024-05-23 12:19:15,838] Trial 38 finished with value: 0.6839376770533048 and parameters: {'learning_rate': 0.00010050863855284026, 'l1_coef': 1.864905192241299e-09, 'patience': 20, 'batch_size': 32, 'lr_factor': 0.7406782130937487, 'num_epochs': 420}. Best is trial 49 with value: 0.6683937617710659.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 21 - Best hyperparameters: {'learning_rate': 0.06417463659123403, 'l1_coef': 1.4994401968392755e-08, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.8953661415766634, 'num_epochs': 117}\n",
      "Chr 21 - Best value: 0.6684\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr21/final_model_chr21.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr21/individual_r2_scores_chr21.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr21/individual_iqs_scores_chr21.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  443\n",
      "PRS313 SNPs:  11\n",
      "Total SNPs used for Training:  432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n",
      "[I 2024-05-23 12:21:01,776] Trial 22 finished with value: 0.9262316722136278 and parameters: {'learning_rate': 0.05079781889732127, 'l1_coef': 0.006007062333265984, 'patience': 10, 'batch_size': 32, 'lr_factor': 0.1757661398292724, 'num_epochs': 306}. Best is trial 3 with value: 0.7342786401510238.\n",
      "[I 2024-05-23 12:21:10,050] Trial 23 finished with value: 0.696631726196834 and parameters: {'learning_rate': 0.0004549303724999769, 'l1_coef': 3.038022393227062e-06, 'patience': 9, 'batch_size': 64, 'lr_factor': 0.6520813926376375, 'num_epochs': 102}. Best is trial 23 with value: 0.696631726196834.\n",
      "[I 2024-05-23 12:21:29,468] Trial 21 finished with value: 0.7450952172279358 and parameters: {'learning_rate': 0.039819600609845504, 'l1_coef': 3.9580278352835204e-05, 'patience': 13, 'batch_size': 256, 'lr_factor': 0.17897184287161771, 'num_epochs': 379}. Best is trial 23 with value: 0.696631726196834.\n",
      "[I 2024-05-23 12:21:52,528] Trial 16 finished with value: 0.6878399312496185 and parameters: {'learning_rate': 0.0031870094425697605, 'l1_coef': 5.308727544481029e-05, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.11052212940056441, 'num_epochs': 317}. Best is trial 16 with value: 0.6878399312496185.\n",
      "[I 2024-05-23 12:22:08,723] Trial 25 finished with value: 0.7332644790410996 and parameters: {'learning_rate': 0.023052068807706928, 'l1_coef': 2.5037751990209327e-05, 'patience': 13, 'batch_size': 128, 'lr_factor': 0.40731439826647586, 'num_epochs': 116}. Best is trial 16 with value: 0.6878399312496185.\n",
      "[I 2024-05-23 12:23:01,766] Trial 15 finished with value: 0.8198195191530081 and parameters: {'learning_rate': 0.06125039322753305, 'l1_coef': 7.532031772714622e-07, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.5641008074857606, 'num_epochs': 109}. Best is trial 16 with value: 0.6878399312496185.\n",
      "[I 2024-05-23 12:24:28,489] Trial 29 finished with value: 0.6833258271217346 and parameters: {'learning_rate': 0.002170706387034528, 'l1_coef': 1.3385875499840686e-07, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.5766844582759846, 'num_epochs': 497}. Best is trial 29 with value: 0.6833258271217346.\n",
      "[I 2024-05-23 12:26:08,407] Trial 19 finished with value: 0.8639438062906265 and parameters: {'learning_rate': 2.2450760939046552e-06, 'l1_coef': 0.00012211854788330838, 'patience': 17, 'batch_size': 128, 'lr_factor': 0.3821526684723867, 'num_epochs': 153}. Best is trial 29 with value: 0.6833258271217346.\n",
      "[I 2024-05-23 12:26:30,267] Trial 30 finished with value: 0.6665582120418548 and parameters: {'learning_rate': 0.00108451114919118, 'l1_coef': 7.55598485720206e-07, 'patience': 17, 'batch_size': 256, 'lr_factor': 0.6241862123420044, 'num_epochs': 465}. Best is trial 30 with value: 0.6665582120418548.\n",
      "[I 2024-05-23 12:26:53,501] Trial 27 finished with value: 0.6964018753596715 and parameters: {'learning_rate': 0.0001195491935613873, 'l1_coef': 9.601943268432806e-08, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.8530886450661305, 'num_epochs': 349}. Best is trial 30 with value: 0.6665582120418548.\n",
      "[I 2024-05-23 12:27:35,529] Trial 31 finished with value: 0.6587279796600342 and parameters: {'learning_rate': 0.0022035316902073946, 'l1_coef': 1.049285168992847e-07, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.8768686676174978, 'num_epochs': 491}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:28:13,322] Trial 32 finished with value: 0.6946347475051879 and parameters: {'learning_rate': 0.002400081026299225, 'l1_coef': 9.041429698357427e-08, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.5290687331072956, 'num_epochs': 493}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:29:28,107] Trial 35 finished with value: 0.6920928955078125 and parameters: {'learning_rate': 0.003933996791923626, 'l1_coef': 2.048559545364149e-10, 'patience': 17, 'batch_size': 256, 'lr_factor': 0.8884209194571423, 'num_epochs': 494}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:29:47,703] Trial 28 finished with value: 0.7440932393074036 and parameters: {'learning_rate': 0.00012167495425373885, 'l1_coef': 0.00031249630344412535, 'patience': 19, 'batch_size': 128, 'lr_factor': 0.755628467283539, 'num_epochs': 277}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:29:49,336] Trial 17 finished with value: 0.7210863130433218 and parameters: {'learning_rate': 3.0938155574647e-05, 'l1_coef': 7.706726285313873e-06, 'patience': 20, 'batch_size': 64, 'lr_factor': 0.3353385513844305, 'num_epochs': 388}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:29:53,443] Trial 33 finished with value: 0.6602301359176636 and parameters: {'learning_rate': 0.001765248432389681, 'l1_coef': 9.205496600223845e-08, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.8980238234016517, 'num_epochs': 490}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:30:38,692] Trial 20 finished with value: 0.7323555001845727 and parameters: {'learning_rate': 1.9667674006876275e-05, 'l1_coef': 4.148525464680981e-05, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.8950904804637764, 'num_epochs': 279}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:30:57,739] Trial 34 finished with value: 0.6636885643005371 and parameters: {'learning_rate': 0.0010864481499735855, 'l1_coef': 1.1083473527325518e-07, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.5618338326417857, 'num_epochs': 497}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:31:57,488] Trial 42 finished with value: 0.7293830513954163 and parameters: {'learning_rate': 0.00864819311916155, 'l1_coef': 1.2871489176021973e-08, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.807661279828758, 'num_epochs': 430}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:32:07,050] Trial 24 finished with value: 0.7747393498053917 and parameters: {'learning_rate': 2.5617514436811118e-05, 'l1_coef': 0.0005370518461327926, 'patience': 18, 'batch_size': 32, 'lr_factor': 0.7350885918785702, 'num_epochs': 134}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:33:35,874] Trial 40 finished with value: 0.658806037902832 and parameters: {'learning_rate': 0.0007753543505407325, 'l1_coef': 2.2072200405367484e-08, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.8262353207497951, 'num_epochs': 443}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:33:38,015] Trial 39 finished with value: 0.67237189412117 and parameters: {'learning_rate': 0.0005083211392635711, 'l1_coef': 8.779576750986077e-09, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.6455484466792692, 'num_epochs': 446}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:34:29,004] Trial 41 finished with value: 0.6645863056182861 and parameters: {'learning_rate': 0.0007620319988825986, 'l1_coef': 3.837750565068663e-09, 'patience': 15, 'batch_size': 256, 'lr_factor': 0.6835583776564602, 'num_epochs': 437}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:34:46,453] Trial 46 finished with value: 0.7116260886192322 and parameters: {'learning_rate': 0.005868843530652475, 'l1_coef': 2.5848458315112603e-09, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.8248087985946714, 'num_epochs': 424}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:34:50,521] Trial 45 finished with value: 0.7249226152896882 and parameters: {'learning_rate': 0.012775492036885397, 'l1_coef': 3.4330289516164757e-09, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.8277896753375046, 'num_epochs': 442}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:35:15,701] Trial 43 finished with value: 0.6676049172878266 and parameters: {'learning_rate': 0.0004993651576876496, 'l1_coef': 7.621246084774634e-09, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.7083741898505712, 'num_epochs': 431}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:35:33,044] Trial 47 finished with value: 0.7108788788318634 and parameters: {'learning_rate': 0.008380040672479988, 'l1_coef': 1.0474524196002476e-10, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.8162736066516765, 'num_epochs': 402}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:35:46,744] Trial 48 finished with value: 0.71008460521698 and parameters: {'learning_rate': 0.009630904089009172, 'l1_coef': 2.774313219478347e-08, 'patience': 12, 'batch_size': 256, 'lr_factor': 0.46022257725455046, 'num_epochs': 399}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:35:49,589] Trial 44 finished with value: 0.669677609205246 and parameters: {'learning_rate': 0.0008230493907787874, 'l1_coef': 9.23147505376675e-09, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.6697086979218649, 'num_epochs': 432}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:36:20,006] Trial 37 finished with value: 0.7448782086372375 and parameters: {'learning_rate': 3.2604624422358216e-05, 'l1_coef': 8.562652472448677e-09, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.7070419650594445, 'num_epochs': 427}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:37:55,031] Trial 18 finished with value: 0.8225786775350571 and parameters: {'learning_rate': 1.1396932326510258e-05, 'l1_coef': 0.0013746716459465003, 'patience': 9, 'batch_size': 128, 'lr_factor': 0.5491111125368952, 'num_epochs': 409}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:38:06,143] Trial 51 finished with value: 0.6869122147560119 and parameters: {'learning_rate': 0.0014742055339191428, 'l1_coef': 3.4443070678251424e-08, 'patience': 12, 'batch_size': 256, 'lr_factor': 0.4473772223517847, 'num_epochs': 470}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:38:07,664] Trial 36 finished with value: 0.7564969003200531 and parameters: {'learning_rate': 2.7837545597976135e-05, 'l1_coef': 1.275760983653268e-10, 'patience': 18, 'batch_size': 256, 'lr_factor': 0.839674450463764, 'num_epochs': 433}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:38:16,823] Trial 49 finished with value: 0.714558732509613 and parameters: {'learning_rate': 0.0001696983238702778, 'l1_coef': 2.5146532804512164e-08, 'patience': 12, 'batch_size': 256, 'lr_factor': 0.4595329045046118, 'num_epochs': 402}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:38:32,018] Trial 50 finished with value: 0.6686708748340606 and parameters: {'learning_rate': 0.001436659320227936, 'l1_coef': 3.390362845486887e-08, 'patience': 18, 'batch_size': 256, 'lr_factor': 0.8930665066850599, 'num_epochs': 399}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:39:42,630] Trial 38 finished with value: 0.7630897343158722 and parameters: {'learning_rate': 2.446024931644379e-05, 'l1_coef': 4.932826737819443e-09, 'patience': 14, 'batch_size': 256, 'lr_factor': 0.6547293315676557, 'num_epochs': 435}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:39:51,558] Trial 53 finished with value: 0.6975086390972137 and parameters: {'learning_rate': 0.0002160425322411567, 'l1_coef': 4.085659534318369e-07, 'patience': 18, 'batch_size': 256, 'lr_factor': 0.7764709679654548, 'num_epochs': 469}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:39:51,835] Trial 52 finished with value: 0.6972448110580445 and parameters: {'learning_rate': 0.00022639018784795947, 'l1_coef': 4.2829817599763815e-07, 'patience': 18, 'batch_size': 256, 'lr_factor': 0.8924995241656868, 'num_epochs': 471}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:40:17,301] Trial 54 finished with value: 0.6945879995822907 and parameters: {'learning_rate': 0.00024278760129641837, 'l1_coef': 3.7137116774967617e-07, 'patience': 16, 'batch_size': 256, 'lr_factor': 0.7830723987233236, 'num_epochs': 469}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:41:05,205] Trial 57 finished with value: 0.6645278862544468 and parameters: {'learning_rate': 0.0014725437667055701, 'l1_coef': 2.0564740886427154e-07, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.7810288289296033, 'num_epochs': 466}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:41:48,471] Trial 55 finished with value: 0.6979841411113739 and parameters: {'learning_rate': 0.0002150655748125821, 'l1_coef': 5.086036857769249e-07, 'patience': 18, 'batch_size': 256, 'lr_factor': 0.7738904653725901, 'num_epochs': 465}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:41:59,751] Trial 56 finished with value: 0.6930436015129089 and parameters: {'learning_rate': 0.00025303234112065265, 'l1_coef': 5.149283558893691e-07, 'patience': 18, 'batch_size': 256, 'lr_factor': 0.8681439489675778, 'num_epochs': 471}. Best is trial 31 with value: 0.6587279796600342.\n",
      "[I 2024-05-23 12:43:28,179] Trial 62 finished with value: 0.6480656577990606 and parameters: {'learning_rate': 0.0008842867535788688, 'l1_coef': 3.953662605180574e-10, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.7809338408689392, 'num_epochs': 364}. Best is trial 62 with value: 0.6480656577990606.\n",
      "[I 2024-05-23 12:43:57,635] Trial 58 finished with value: 0.6743443625313896 and parameters: {'learning_rate': 0.0002451159519129237, 'l1_coef': 3.9549141857822816e-07, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.8951649044687812, 'num_epochs': 468}. Best is trial 62 with value: 0.6480656577990606.\n",
      "[I 2024-05-23 12:43:59,176] Trial 59 finished with value: 0.6744988168988908 and parameters: {'learning_rate': 0.0002540307019765502, 'l1_coef': 6.248888577436044e-07, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.7802236007254295, 'num_epochs': 466}. Best is trial 62 with value: 0.6480656577990606.\n",
      "[I 2024-05-23 12:44:23,939] Trial 60 finished with value: 0.6740205134664263 and parameters: {'learning_rate': 0.00024817608375125633, 'l1_coef': 4.094313296491722e-07, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.7686944785282045, 'num_epochs': 474}. Best is trial 62 with value: 0.6480656577990606.\n",
      "[I 2024-05-23 12:44:26,520] Trial 63 finished with value: 0.710831071649279 and parameters: {'learning_rate': 6.891690250477449e-05, 'l1_coef': 3.852437575829818e-10, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.599616719740218, 'num_epochs': 222}. Best is trial 62 with value: 0.6480656577990606.\n",
      "[I 2024-05-23 12:44:32,866] Trial 64 finished with value: 0.7138897078377859 and parameters: {'learning_rate': 7.044452796881058e-05, 'l1_coef': 3.715046729082639e-06, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.2889055195612064, 'num_epochs': 216}. Best is trial 62 with value: 0.6480656577990606.\n",
      "[I 2024-05-23 12:44:43,230] Trial 61 finished with value: 0.7023495316505433 and parameters: {'learning_rate': 7.078629225433263e-05, 'l1_coef': 6.851028421372248e-10, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.7783063088478142, 'num_epochs': 462}. Best is trial 62 with value: 0.6480656577990606.\n",
      "[I 2024-05-23 12:45:35,403] Trial 26 finished with value: 0.9393746495246887 and parameters: {'learning_rate': 2.8423077841880034e-06, 'l1_coef': 0.00761486713746949, 'patience': 6, 'batch_size': 32, 'lr_factor': 0.4838787668337443, 'num_epochs': 457}. Best is trial 62 with value: 0.6480656577990606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 22 - Best hyperparameters: {'learning_rate': 0.0008842867535788688, 'l1_coef': 3.953662605180574e-10, 'patience': 15, 'batch_size': 32, 'lr_factor': 0.7809338408689392, 'num_epochs': 364}\n",
      "Chr 22 - Best value: 0.6481\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr22/final_model_chr22.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr22/individual_r2_scores_chr22.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr22/individual_iqs_scores_chr22.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_98377/4219423060.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_squared = np.sum((contingency_table - expected_counts) ** 2 / expected_counts)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score, accuracy_score\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Create folders for saving files\n",
    "output_folder = \"../../Data/model_results_unphased_all_PRS/logistic_regression/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Create subfolders for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    os.makedirs(chr_model_folder, exist_ok=True)\n",
    "    os.makedirs(chr_csv_folder, exist_ok=True)\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.long)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the multinomial logistic regression model with L1 regularization\n",
    "    class MulticlassLogisticRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, num_classes=3, l1_coef=0.0):\n",
    "            super(MulticlassLogisticRegression, self).__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.linear = nn.ModuleList([nn.Linear(input_dim, output_dim) for _ in range(num_classes)])\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = torch.stack([linear(x) for linear in self.linear], dim=-1)\n",
    "            out = nn.functional.softmax(out, dim=-1)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * sum(torch.norm(linear.weight, p=1) for linear in self.linear)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set the hyperparameters for tuning\n",
    "    input_dim = X_train_val.shape[1]\n",
    "    output_dim = y_train_val.shape[1]\n",
    "    num_epochs = 500\n",
    "\n",
    "    # Define the objective function for Optuna with cross-validation and early stopping\n",
    "    def objective(trial):\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-1, log=True)\n",
    "        l1_coef = trial.suggest_float('l1_coef', 1e-10, 1e-1, log=True)\n",
    "        patience = trial.suggest_int('patience', 5, 20)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "        lr_factor = trial.suggest_float('lr_factor', 0.1, 0.9)\n",
    "        num_epochs = trial.suggest_int('num_epochs', 100, 500)\n",
    "\n",
    "        model = MulticlassLogisticRegression(input_dim, output_dim, l1_coef=l1_coef).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_factor, patience=patience, verbose=False)\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold_losses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_val)):\n",
    "            X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "            y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "            train_dataset = TensorDataset(X_train, y_train)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "            best_val_loss = float('inf')\n",
    "            counter = 0\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = 0.0\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs.transpose(1, 2), batch_y) + model.l1_loss()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                train_loss /= len(train_loader)\n",
    "\n",
    "                val_dataset = TensorDataset(X_val, y_val)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0.0\n",
    "                    for batch_X, batch_y in val_loader:\n",
    "                        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X)\n",
    "                        loss = criterion(outputs.transpose(1, 2), batch_y) + model.l1_loss()\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                    val_loss /= len(val_loader)\n",
    "                    scheduler.step(val_loss)\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= patience:\n",
    "                        break\n",
    "\n",
    "            fold_losses.append(best_val_loss)\n",
    "\n",
    "        return np.mean(fold_losses)\n",
    "    \n",
    "    # Create the \"optuna_studies\" folder if it doesn't exist\n",
    "    os.makedirs(\"optuna_studies\", exist_ok=True)\n",
    "\n",
    "    # Create an Optuna study and optimize the hyperparameters\n",
    "    study_name = f\"unphased_full_23andMe_chr{chromosome_number}_study_logistic_regression\"\n",
    "    storage_name = f\"sqlite:///optuna_studies/{study_name}.db\"\n",
    "\n",
    "    # Check if the study exists\n",
    "    current_dir = os.getcwd()\n",
    "    study_exists = os.path.exists(current_dir + f\"/optuna_studies/{study_name}.db\")\n",
    "\n",
    "    if study_exists:\n",
    "        # Load the existing study\n",
    "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "    else:\n",
    "        # Create a new study\n",
    "        study = optuna.create_study(direction='minimize', study_name=study_name, storage=storage_name)\n",
    "\n",
    "    study.optimize(objective, n_trials=50, n_jobs=-1)\n",
    "\n",
    "    # Print the best hyperparameters and best value\n",
    "    print(f\"Chr {chromosome_number} - Best hyperparameters: {study.best_params}\")\n",
    "    print(f\"Chr {chromosome_number} - Best value: {study.best_value:.4f}\")\n",
    "\n",
    "    # Train the final model with the best hyperparameters and early stopping\n",
    "    best_learning_rate = study.best_params['learning_rate']\n",
    "    best_l1_coef = study.best_params['l1_coef']\n",
    "    best_patience = study.best_params['patience']\n",
    "    best_batch_size = study.best_params['batch_size']\n",
    "    best_lr_factor = study.best_params['lr_factor']\n",
    "    best_num_epochs = study.best_params['num_epochs']\n",
    "\n",
    "    model = MulticlassLogisticRegression(input_dim, output_dim, l1_coef=best_l1_coef).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=best_lr_factor, patience=best_patience, verbose=False)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_val, y_train_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(best_num_epochs):\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs.transpose(1, 2), batch_y) + model.l1_loss()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            best_train_loss = train_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= best_patience:\n",
    "            break\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "    # Save the final model\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Final model saved at: {model_save_path}\")\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_outputs = test_outputs.argmax(dim=-1)\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "\n",
    "        test_accuracy = ((y_test == test_outputs).sum() / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test.cpu().numpy()[:, i].reshape(-1, 1), test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "    # Create a DataFrame to store the performance metrics for each chromosome\n",
    "    performance_df = pd.DataFrame({\n",
    "        'Chromosome': list(range(start, chromosome_number + 1)),\n",
    "        'R2 Score': r2_scores,\n",
    "        'IQS Score': iqs_scores,\n",
    "        'Accuracy Score': accuracy_scores\n",
    "    })\n",
    "\n",
    "    # Save the performance metrics to a CSV file\n",
    "    performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "    performance_df.to_csv(performance_csv_file, index=False)\n",
    "    print(f\"Performance metrics saved at: {performance_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score, accuracy_score\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Folders for saved models and CSV files\n",
    "output_folder = \"../../Data/model_results_unphased_all_PRS/logistic_regression/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "def calculate_iqs_unphased(y_true, y_pred):\n",
    "    # Dummy implementation of IQS calculation, replace with the actual function\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Paths for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.long)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the multinomial logistic regression model with L1 regularization\n",
    "    class MulticlassLogisticRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, num_classes=3, l1_coef=0.0):\n",
    "            super(MulticlassLogisticRegression, self).__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.linear = nn.ModuleList([nn.Linear(input_dim, output_dim) for _ in range(num_classes)])\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = torch.stack([linear(x) for linear in self.linear], dim=-1)\n",
    "            out = nn.functional.softmax(out, dim=-1)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * sum(torch.norm(linear.weight, p=1) for linear in self.linear)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the final model\n",
    "    model = MulticlassLogisticRegression(X_train_val.shape[1], y_train_val.shape[1])\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_outputs = test_outputs.argmax(dim=-1)\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_accuracy = ((y_test == test_outputs).sum() / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test.cpu().numpy()[:, i].reshape(-1, 1), test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "# Create a DataFrame to store the performance metrics for each chromosome\n",
    "performance_df = pd.DataFrame({\n",
    "    'Chromosome': list(range(start, 23)),\n",
    "    'R2 Score': r2_scores,\n",
    "    'IQS Score': iqs_scores,\n",
    "    'Accuracy Score': accuracy_scores\n",
    "})\n",
    "\n",
    "# Save the performance metrics to a CSV file\n",
    "performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "performance_df.to_csv(performance_csv_file, index=False)\n",
    "print(f\"Performance metrics saved at: {performance_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRS313 SNPs saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/prs313_snps.csv\n",
      "Total number of PRS313 SNPs: 313\n"
     ]
    }
   ],
   "source": [
    "# Loop through all the training datasets and document the PRS313 SNPs in each dataset. Save this to a CSV file.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_directory = '../../Data/Filtered_unphased_training_data_union_final/'\n",
    "output_folder = \"../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize a list to store the PRS313 SNPs in each dataset\n",
    "prs313_snps = []\n",
    "\n",
    "for chromosome_number in range(1, 23):\n",
    "    file_name = data_directory + \\\n",
    "        f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    prs313_snps.append(data.filter(regex='PRS313_').columns)\n",
    "\n",
    "# Create a DataFrame to store the PRS313 SNPs in each dataset\n",
    "prs313_df = pd.DataFrame({\n",
    "    'Chromosome': list(range(1, 23)),\n",
    "    'PRS313 SNPs': prs313_snps,\n",
    "    \"Number of PRS313 SNPs\": [len(snps) for snps in prs313_snps]\n",
    "})\n",
    "\n",
    "# Save the PRS313 SNPs to a CSV file\n",
    "prs313_csv_file = output_folder + 'prs313_snps.csv'\n",
    "prs313_df.to_csv(prs313_csv_file, index=False)\n",
    "print(f\"PRS313 SNPs saved at: {prs313_csv_file}\")\n",
    "\n",
    "# Print the total number of PRS313 SNPs in all datasets\n",
    "total_prs313_snps = sum(prs313_df[\"Number of PRS313 SNPs\"])\n",
    "print(f\"Total number of PRS313 SNPs: {total_prs313_snps}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
