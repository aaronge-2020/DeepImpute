{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model Unphased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_iqs_unphased(true_genotypes, imputed_genotypes):\n",
    "    \"\"\"\n",
    "    Calculate the Imputation Quality Score (IQS) for ununphased genotypes.\n",
    "\n",
    "    Args:\n",
    "        true_genotypes (numpy.ndarray): 2D array of true genotypes, where each genotype is represented by values 0, 1, or 2.\n",
    "        imputed_genotypes (numpy.ndarray): 2D array of imputed genotypes, where each genotype is represented by floating-point values between 0 and 2.\n",
    "        threshold (float): Threshold for converting imputed probabilities to discrete genotypes (default: 0.5).\n",
    "\n",
    "    Returns:\n",
    "        float: Imputation Quality Score (IQS).\n",
    "    \"\"\"\n",
    "    # Check if the shapes of true and imputed genotypes are the same\n",
    "    if true_genotypes.shape != imputed_genotypes.shape:\n",
    "        raise ValueError(\"Shape of true genotypes and imputed genotypes must be the same.\")\n",
    "\n",
    "    # Convert imputed probabilities to discrete genotypes based on the threshold\n",
    "    imputed_discrete = np.round(imputed_genotypes).astype(int)\n",
    "\n",
    "    # Create a contingency table\n",
    "    contingency_table = np.zeros((3, 3), dtype=int)\n",
    "\n",
    "    # Fill the contingency table\n",
    "    for true_geno, imputed_geno in zip(true_genotypes, imputed_discrete):\n",
    "        for true_allele, imputed_allele in zip(true_geno, imputed_geno):\n",
    "            contingency_table[int(true_allele), int(imputed_allele)] += 1\n",
    "\n",
    "    # Calculate the total number of alleles\n",
    "    total_alleles = np.sum(contingency_table)\n",
    "\n",
    "    # Calculate the observed agreement (Po)\n",
    "    po = np.sum(np.diag(contingency_table)) / total_alleles\n",
    "\n",
    "    # Calculate the expected agreement by chance (Pc)\n",
    "    true_counts = np.sum(contingency_table, axis=1)\n",
    "    imputed_counts = np.sum(contingency_table, axis=0)\n",
    "    pc = np.sum(true_counts * imputed_counts) / (total_alleles ** 2)\n",
    "\n",
    "    # Calculate the Imputation Quality Score (IQS)\n",
    "    iqs = (po - pc) / (1 - pc)\n",
    "\n",
    "    return iqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown PRS313 SNPs:  30\n",
      "Known PRS313 SNPs:  10\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  850\n",
      "Total SNPs used for Training:  850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-04-30 10:11:23,397] Trial 136 finished with value: 0.24072570720544229 and parameters: {'learning_rate': 0.06244280451709654, 'l1_coef': 1.2869733065346573e-05, 'patience': 16, 'batch_size': 32}. Best is trial 32 with value: 0.08649516483912101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 1 - Best hyperparameters: {'learning_rate': 0.01823591759267881, 'l1_coef': 1.0049346589997416e-05, 'patience': 9, 'batch_size': 32}\n",
      "Chr 1 - Best value: 0.0865\n",
      "Epoch [1/500], Train Loss: 0.6092\n",
      "Epoch [2/500], Train Loss: 0.3647\n",
      "Epoch [3/500], Train Loss: 0.3238\n",
      "Epoch [4/500], Train Loss: 0.2944\n",
      "Epoch [5/500], Train Loss: 0.2686\n",
      "Epoch [6/500], Train Loss: 0.2754\n",
      "Epoch [7/500], Train Loss: 0.2642\n",
      "Epoch [8/500], Train Loss: 0.2579\n",
      "Epoch [9/500], Train Loss: 0.2536\n",
      "Epoch [10/500], Train Loss: 0.2070\n",
      "Epoch [11/500], Train Loss: 0.1987\n",
      "Epoch [12/500], Train Loss: 0.1979\n",
      "Epoch [13/500], Train Loss: 0.1946\n",
      "Epoch [14/500], Train Loss: 0.1905\n",
      "Epoch [15/500], Train Loss: 0.1923\n",
      "Epoch [16/500], Train Loss: 0.1934\n",
      "Epoch [17/500], Train Loss: 0.1864\n",
      "Epoch [18/500], Train Loss: 0.1898\n",
      "Epoch [19/500], Train Loss: 0.1831\n",
      "Epoch [20/500], Train Loss: 0.1852\n",
      "Epoch [21/500], Train Loss: 0.1829\n",
      "Epoch [22/500], Train Loss: 0.1796\n",
      "Epoch [23/500], Train Loss: 0.1805\n",
      "Epoch [24/500], Train Loss: 0.1769\n",
      "Epoch [25/500], Train Loss: 0.1837\n",
      "Epoch [26/500], Train Loss: 0.1865\n",
      "Epoch [27/500], Train Loss: 0.1865\n",
      "Epoch [28/500], Train Loss: 0.1764\n",
      "Epoch [29/500], Train Loss: 0.1771\n",
      "Epoch [30/500], Train Loss: 0.1722\n",
      "Epoch [31/500], Train Loss: 0.1750\n",
      "Epoch [32/500], Train Loss: 0.1754\n",
      "Epoch [33/500], Train Loss: 0.1842\n",
      "Epoch [34/500], Train Loss: 0.2021\n",
      "Epoch [35/500], Train Loss: 0.2200\n",
      "Epoch [36/500], Train Loss: 0.2208\n",
      "Epoch [37/500], Train Loss: 0.1869\n",
      "Epoch [38/500], Train Loss: 0.1811\n",
      "Epoch [39/500], Train Loss: 0.1800\n",
      "Early stopping at epoch 39\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr1/final_model_chr1.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr1/individual_r2_scores_chr1.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr1/individual_iqs_scores_chr1.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  21\n",
      "Known PRS313 SNPs:  4\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  596\n",
      "Total SNPs used for Training:  596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-30 10:11:28,262] Trial 53 finished with value: 8.442827844619751 and parameters: {'learning_rate': 0.08866024484499739, 'l1_coef': 1.9153174210294036e-05, 'patience': 7, 'batch_size': 128}. Best is trial 50 with value: 0.11959010179226218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 2 - Best hyperparameters: {'learning_rate': 0.008236314117298912, 'l1_coef': 1.0089572204728918e-05, 'patience': 10, 'batch_size': 32}\n",
      "Chr 2 - Best value: 0.1196\n",
      "Epoch [1/500], Train Loss: 0.4278\n",
      "Epoch [2/500], Train Loss: 0.3145\n",
      "Epoch [3/500], Train Loss: 0.2757\n",
      "Epoch [4/500], Train Loss: 0.2468\n",
      "Epoch [5/500], Train Loss: 0.2339\n",
      "Epoch [6/500], Train Loss: 0.2202\n",
      "Epoch [7/500], Train Loss: 0.2112\n",
      "Epoch [8/500], Train Loss: 0.2029\n",
      "Epoch [9/500], Train Loss: 0.1988\n",
      "Epoch [10/500], Train Loss: 0.1932\n",
      "Epoch [11/500], Train Loss: 0.1907\n",
      "Epoch [12/500], Train Loss: 0.1849\n",
      "Epoch [13/500], Train Loss: 0.1821\n",
      "Epoch [14/500], Train Loss: 0.1792\n",
      "Epoch [15/500], Train Loss: 0.1770\n",
      "Epoch [16/500], Train Loss: 0.1747\n",
      "Epoch [17/500], Train Loss: 0.1721\n",
      "Epoch [18/500], Train Loss: 0.1711\n",
      "Epoch [19/500], Train Loss: 0.1684\n",
      "Epoch [20/500], Train Loss: 0.1653\n",
      "Epoch [21/500], Train Loss: 0.1664\n",
      "Epoch [22/500], Train Loss: 0.1672\n",
      "Epoch [23/500], Train Loss: 0.1641\n",
      "Epoch [24/500], Train Loss: 0.1623\n",
      "Epoch [25/500], Train Loss: 0.1602\n",
      "Epoch [26/500], Train Loss: 0.1620\n",
      "Epoch [27/500], Train Loss: 0.1601\n",
      "Epoch [28/500], Train Loss: 0.1617\n",
      "Epoch [29/500], Train Loss: 0.1602\n",
      "Epoch [30/500], Train Loss: 0.1578\n",
      "Epoch [31/500], Train Loss: 0.1577\n",
      "Epoch [32/500], Train Loss: 0.1595\n",
      "Epoch [33/500], Train Loss: 0.1544\n",
      "Epoch [34/500], Train Loss: 0.1556\n",
      "Epoch [35/500], Train Loss: 0.1548\n",
      "Epoch [36/500], Train Loss: 0.1528\n",
      "Epoch [37/500], Train Loss: 0.1541\n",
      "Epoch [38/500], Train Loss: 0.1531\n",
      "Epoch [39/500], Train Loss: 0.1531\n",
      "Epoch [40/500], Train Loss: 0.1513\n",
      "Epoch [41/500], Train Loss: 0.1527\n",
      "Epoch [42/500], Train Loss: 0.1522\n",
      "Epoch [43/500], Train Loss: 0.1518\n",
      "Epoch [44/500], Train Loss: 0.1519\n",
      "Epoch [45/500], Train Loss: 0.1511\n",
      "Epoch [46/500], Train Loss: 0.1510\n",
      "Epoch [47/500], Train Loss: 0.1500\n",
      "Epoch [48/500], Train Loss: 0.1502\n",
      "Epoch [49/500], Train Loss: 0.1528\n",
      "Epoch [50/500], Train Loss: 0.1487\n",
      "Epoch [51/500], Train Loss: 0.1482\n",
      "Epoch [52/500], Train Loss: 0.1497\n",
      "Epoch [53/500], Train Loss: 0.1489\n",
      "Epoch [54/500], Train Loss: 0.1490\n",
      "Epoch [55/500], Train Loss: 0.1490\n",
      "Epoch [56/500], Train Loss: 0.1490\n",
      "Epoch [57/500], Train Loss: 0.1462\n",
      "Epoch [58/500], Train Loss: 0.1472\n",
      "Epoch [59/500], Train Loss: 0.1493\n",
      "Epoch [60/500], Train Loss: 0.1460\n",
      "Epoch [61/500], Train Loss: 0.1467\n",
      "Epoch [62/500], Train Loss: 0.1457\n",
      "Epoch [63/500], Train Loss: 0.1457\n",
      "Epoch [64/500], Train Loss: 0.1463\n",
      "Epoch [65/500], Train Loss: 0.1476\n",
      "Epoch [66/500], Train Loss: 0.1473\n",
      "Epoch [67/500], Train Loss: 0.1465\n",
      "Epoch [68/500], Train Loss: 0.1483\n",
      "Epoch [69/500], Train Loss: 0.1442\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 209\u001b[0m\n\u001b[1;32m    206\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y) \u001b[38;5;241m+\u001b[39m model\u001b[38;5;241m.\u001b[39ml1_loss()\n\u001b[1;32m    208\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 209\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    212\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../Data/Filtered_unphased_training_data/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "false_positive_rates = []\n",
    "auc_rocs = []\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "\n",
    "# Create folders for saving files\n",
    "output_folder = \"../../Data/model_results_unphased/logistic_regression/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "curve_folder = output_folder + \"roc_curves/\"\n",
    "\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "os.makedirs(curve_folder, exist_ok=True)\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Create subfolders for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_curve_folder = curve_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    os.makedirs(chr_model_folder, exist_ok=True)\n",
    "    os.makedirs(chr_csv_folder, exist_ok=True)\n",
    "    os.makedirs(chr_curve_folder, exist_ok=True)\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*Unknown)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='Unknown').values, dtype=torch.float32)\n",
    "\n",
    "    print(\"Unknown PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Known PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_Known\" in col]].shape[1])\n",
    "    print(\"23AndMe SNPs with LD to Unknown PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_\" not in col]].shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the logistic regression model with lasso regularization\n",
    "    class LogisticRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, l1_coef=0.0):\n",
    "            super(LogisticRegression, self).__init__()\n",
    "            self.linear = nn.Linear(input_dim, output_dim)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.linear(x)\n",
    "            out = self.sigmoid(out)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * torch.norm(self.linear.weight, p=1)\n",
    "        \n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set the hyperparameters for tuning\n",
    "    input_dim = X_train_val.shape[1]\n",
    "    output_dim = y_train_val.shape[1]\n",
    "    num_epochs = 500\n",
    "    batch_size = 128\n",
    "\n",
    "    # Define the objective function for Optuna with cross-validation and early stopping\n",
    "    def objective(trial):\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "        l1_coef = trial.suggest_float('l1_coef', 1e-5, 1e-1, log=True)\n",
    "        patience = trial.suggest_int('patience', 5, 20)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "\n",
    "        model = LogisticRegression(input_dim, output_dim, l1_coef).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.BCELoss()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=False)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold_losses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_val, y_train_val.argmax(dim=1))):\n",
    "            X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "            y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "            train_dataset = TensorDataset(X_train, y_train)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "            best_val_loss = float('inf')\n",
    "            counter = 0\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = 0.0\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                train_loss /= len(train_loader)\n",
    "\n",
    "                val_dataset = TensorDataset(X_val, y_val)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0.0\n",
    "                    for batch_X, batch_y in val_loader:\n",
    "                        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X)\n",
    "                        loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                    val_loss /= len(val_loader)\n",
    "                    scheduler.step(val_loss)\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= patience:\n",
    "                        # print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                        break\n",
    "\n",
    "            fold_losses.append(best_val_loss)\n",
    "\n",
    "        return np.mean(fold_losses)\n",
    "\n",
    "    # Create the \"optuna_studies\" folder if it doesn't exist\n",
    "    os.makedirs(\"optuna_studies\", exist_ok=True)\n",
    "\n",
    "    # Create an Optuna study and optimize the hyperparameters\n",
    "    study_name = f\"chr{chromosome_number}_study\"\n",
    "    storage_name = f\"sqlite:///optuna_studies/{study_name}.db\"\n",
    "\n",
    "    # Check if the study exists\n",
    "\n",
    "    current_dir = os.getcwd()\n",
    "    study_exists = os.path.exists(current_dir + f\"/optuna_studies/{study_name}.db\")\n",
    "    \n",
    "    if study_exists:\n",
    "        # Load the existing study\n",
    "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "    else:\n",
    "        # Create a new study\n",
    "        study = optuna.create_study(direction='minimize', study_name=study_name, storage=storage_name)\n",
    "\n",
    "    study.optimize(objective, n_trials=25, n_jobs=-1)\n",
    "\n",
    "    # Print the best hyperparameters and best value\n",
    "    print(f\"Chr {chromosome_number} - Best hyperparameters: {study.best_params}\")\n",
    "    print(f\"Chr {chromosome_number} - Best value: {study.best_value:.4f}\")\n",
    "\n",
    "    # Train the final model with the best hyperparameters and early stopping\n",
    "    best_learning_rate = study.best_params['learning_rate']\n",
    "    best_l1_coef = study.best_params['l1_coef']\n",
    "    best_patience = study.best_params['patience']\n",
    "    best_batch_size = study.best_params['batch_size']\n",
    "\n",
    "    model = LogisticRegression(input_dim, output_dim, best_l1_coef).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=False)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_val, y_train_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            best_train_loss = train_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= best_patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "    # Save the final model\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Final model saved at: {model_save_path}\")\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_preds = (test_outputs > 0.5).float()\n",
    "        test_accuracy = float(((test_preds > 0.5) == y_test).float().mean())\n",
    "        test_precision = precision_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_recall = recall_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_f1 = f1_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_roc_auc = roc_auc_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), average='micro')\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "\n",
    "        # Calculate false positive rate\n",
    "        cm = confusion_matrix(y_test.cpu().numpy().ravel(), test_preds.cpu().numpy().ravel())\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        test_fpr = fp / (fp + tn)\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        accuracies.append(test_accuracy)\n",
    "        precisions.append(test_precision)\n",
    "        recalls.append(test_recall)\n",
    "        false_positive_rates.append(test_fpr)\n",
    "        auc_rocs.append(test_roc_auc)\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test.cpu().numpy()[:, i].reshape(-1, 1), test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='Unknown').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "        # Save individual AUC ROC curves for each SNP\n",
    "        for i, snp in enumerate(snp_names):\n",
    "            try: \n",
    "                fpr, tpr, _ = roc_curve(y_test.cpu().numpy()[:, i], test_outputs.cpu().numpy()[:, i])\n",
    "                plt.figure()\n",
    "                plt.plot(fpr, tpr, label=f'AUC ROC = {roc_auc_score(y_test.cpu().numpy()[:, i], test_outputs.cpu().numpy()[:, i]):.4f}')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title(f'AUC ROC Curve - {snp}')\n",
    "                plt.legend()\n",
    "                \n",
    "                curve_file = chr_curve_folder + f'auc_roc_curve_{snp}_chr{chromosome_number}.png'\n",
    "                plt.savefig(curve_file)\n",
    "                plt.close()\n",
    "            except ValueError:\n",
    "                # Save a placeholder image if there is insufficient data\n",
    "                plt.figure()\n",
    "                plt.axis('off')\n",
    "                plt.text(0.5, 0.5, \"Insufficient data for ROC curve\", ha='center', va='center')\n",
    "                curve_file = chr_curve_folder + f'auc_roc_curve_{snp}_chr{chromosome_number}.png'\n",
    "                plt.savefig(curve_file)\n",
    "                plt.close()\n",
    "\n",
    "                print(f\"Skipping SNP {snp} due to insufficient data\")\n",
    "\n",
    "\n",
    "        print(f\"Individual AUC ROC curves saved in: {curve_folder}\")\n",
    "\n",
    "        # Create a DataFrame to store the performance metrics for each chromosome\n",
    "        performance_df = pd.DataFrame({\n",
    "            'Chromosome': list(range(start, chromosome_number + 1)),\n",
    "            'Accuracy': accuracies,\n",
    "            'Precision': precisions,\n",
    "            'Recall': recalls,\n",
    "            'False Positive Rate': false_positive_rates,\n",
    "            'AUC ROC': auc_rocs,\n",
    "            'R2 Score': r2_scores,\n",
    "            'IQS Score': iqs_scores\n",
    "        })\n",
    "\n",
    "        # Save the performance metrics to a CSV file\n",
    "        performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "        performance_df.to_csv(performance_csv_file, index=False)\n",
    "        print(f\"Performance metrics saved at: {performance_csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL PRS Masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs:  880\n",
      "PRS313 SNPs:  30\n",
      "Total SNPs used for Training:  850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-04-30 10:27:53,209] Trial 139 finished with value: 0.18840676362697892 and parameters: {'learning_rate': 0.017766733705217527, 'l1_coef': 1.2665480475679596e-05, 'patience': 16, 'batch_size': 32}. Best is trial 32 with value: 0.08649516483912101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 1 - Best hyperparameters: {'learning_rate': 0.01823591759267881, 'l1_coef': 1.0049346589997416e-05, 'patience': 9, 'batch_size': 32}\n",
      "Chr 1 - Best value: 0.0865\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr1/final_model_chr1.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr1/individual_r2_scores_chr1.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr1/individual_iqs_scores_chr1.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  617\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-30 10:28:00,931] Trial 55 finished with value: 1.799717666552617 and parameters: {'learning_rate': 0.05814623543930508, 'l1_coef': 1.0077275037851262e-05, 'patience': 13, 'batch_size': 32}. Best is trial 50 with value: 0.11959010179226218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 2 - Best hyperparameters: {'learning_rate': 0.008236314117298912, 'l1_coef': 1.0089572204728918e-05, 'patience': 10, 'batch_size': 32}\n",
      "Chr 2 - Best value: 0.1196\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr2/final_model_chr2.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr2/individual_r2_scores_chr2.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr2/individual_iqs_scores_chr2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_81857/73971118.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  iqs = (po - pc) / (1 - pc)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping SNP chr2_217955896_GA_G_PRS313_Unknown_combined due to insufficient data\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  947\n",
      "PRS313 SNPs:  16\n",
      "Total SNPs used for Training:  931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-04-30 10:28:11,618] Trial 53 finished with value: 0.21338191330432893 and parameters: {'learning_rate': 0.004573407586569095, 'l1_coef': 0.00032839083267706057, 'patience': 16, 'batch_size': 128}. Best is trial 11 with value: 0.04525891537112849.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 3 - Best hyperparameters: {'learning_rate': 0.01168727761615579, 'l1_coef': 1.1084312581961695e-05, 'patience': 15, 'batch_size': 64}\n",
      "Chr 3 - Best value: 0.0453\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr3/final_model_chr3.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr3/individual_r2_scores_chr3.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr3/individual_iqs_scores_chr3.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  1034\n",
      "PRS313 SNPs:  11\n",
      "Total SNPs used for Training:  1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-04-30 10:28:18,338] Trial 53 finished with value: 0.13495085755219827 and parameters: {'learning_rate': 0.004034910377932012, 'l1_coef': 5.1561389578943313e-05, 'patience': 16, 'batch_size': 32}. Best is trial 6 with value: 0.05639927589467593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 4 - Best hyperparameters: {'learning_rate': 0.010022005750497007, 'l1_coef': 1.0999251330619296e-05, 'patience': 13, 'batch_size': 64}\n",
      "Chr 4 - Best value: 0.0564\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr4/final_model_chr4.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr4/individual_r2_scores_chr4.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr4/individual_iqs_scores_chr4.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  1334\n",
      "PRS313 SNPs:  34\n",
      "Total SNPs used for Training:  1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-04-30 10:28:26,050] Trial 53 finished with value: 0.5704796160970415 and parameters: {'learning_rate': 0.006893194414203874, 'l1_coef': 0.025389744718994568, 'patience': 17, 'batch_size': 64}. Best is trial 34 with value: 0.07268482106072562.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 5 - Best hyperparameters: {'learning_rate': 0.010757867162206202, 'l1_coef': 1.0440017068267564e-05, 'patience': 9, 'batch_size': 64}\n",
      "Chr 5 - Best value: 0.0727\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr5/final_model_chr5.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr5/individual_r2_scores_chr5.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr5/individual_iqs_scores_chr5.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  632\n",
      "PRS313 SNPs:  20\n",
      "Total SNPs used for Training:  612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-04-30 10:28:33,137] Trial 53 finished with value: 0.19546499252319335 and parameters: {'learning_rate': 0.0018822310876362624, 'l1_coef': 3.448011430605454e-05, 'patience': 9, 'batch_size': 256}. Best is trial 47 with value: 0.14764729972396579.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 6 - Best hyperparameters: {'learning_rate': 0.0005159914294373423, 'l1_coef': 1.0687801532020404e-05, 'patience': 8, 'batch_size': 64}\n",
      "Chr 6 - Best value: 0.1476\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr6/final_model_chr6.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr6/individual_r2_scores_chr6.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr6/individual_iqs_scores_chr6.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  487\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-04-30 10:28:41,107] Trial 52 finished with value: 0.214713709629499 and parameters: {'learning_rate': 0.007308500475530798, 'l1_coef': 1.9840108784289173e-05, 'patience': 13, 'batch_size': 32}. Best is trial 22 with value: 0.10665186093403742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 7 - Best hyperparameters: {'learning_rate': 0.00022929815822353796, 'l1_coef': 1.1733499979155006e-05, 'patience': 12, 'batch_size': 32}\n",
      "Chr 7 - Best value: 0.1067\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr7/final_model_chr7.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr7/individual_r2_scores_chr7.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr7/individual_iqs_scores_chr7.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  475\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-30 10:28:54,614] Trial 52 finished with value: 0.25141304410420934 and parameters: {'learning_rate': 0.003264186631207094, 'l1_coef': 2.2357327795485277e-05, 'patience': 10, 'batch_size': 32}. Best is trial 17 with value: 0.11601511778739784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 8 - Best hyperparameters: {'learning_rate': 0.0012197976599892346, 'l1_coef': 1.0397855148759009e-05, 'patience': 6, 'batch_size': 32}\n",
      "Chr 8 - Best value: 0.1160\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr8/final_model_chr8.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr8/individual_r2_scores_chr8.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr8/individual_iqs_scores_chr8.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  388\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-04-30 10:29:01,256] Trial 52 finished with value: 0.2895536681780448 and parameters: {'learning_rate': 0.015508319638127726, 'l1_coef': 6.626669475437266e-05, 'patience': 17, 'batch_size': 32}. Best is trial 21 with value: 0.11073745116591453.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 9 - Best hyperparameters: {'learning_rate': 0.05822594013574142, 'l1_coef': 1.5307383394547932e-05, 'patience': 14, 'batch_size': 256}\n",
      "Chr 9 - Best value: 0.1107\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr9/final_model_chr9.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr9/individual_r2_scores_chr9.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr9/individual_iqs_scores_chr9.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  546\n",
      "PRS313 SNPs:  18\n",
      "Total SNPs used for Training:  528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-04-30 10:29:07,941] Trial 52 finished with value: 0.3100840777158737 and parameters: {'learning_rate': 0.00010811662688741053, 'l1_coef': 1.6384795567067764e-05, 'patience': 15, 'batch_size': 256}. Best is trial 31 with value: 0.10043132305145264.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 10 - Best hyperparameters: {'learning_rate': 0.00022093387007935644, 'l1_coef': 1.0430280711765954e-05, 'patience': 5, 'batch_size': 32}\n",
      "Chr 10 - Best value: 0.1004\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr10/final_model_chr10.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr10/individual_r2_scores_chr10.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr10/individual_iqs_scores_chr10.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  871\n",
      "PRS313 SNPs:  19\n",
      "Total SNPs used for Training:  852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-30 10:29:20,527] Trial 52 finished with value: 0.36184742152690885 and parameters: {'learning_rate': 0.017868136226825957, 'l1_coef': 0.002297626932109794, 'patience': 7, 'batch_size': 256}. Best is trial 23 with value: 0.05782480022081963.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 11 - Best hyperparameters: {'learning_rate': 0.0002329404200995808, 'l1_coef': 1.2601501185021566e-05, 'patience': 9, 'batch_size': 32}\n",
      "Chr 11 - Best value: 0.0578\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr11/final_model_chr11.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr11/individual_r2_scores_chr11.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr11/individual_iqs_scores_chr11.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  630\n",
      "PRS313 SNPs:  17\n",
      "Total SNPs used for Training:  613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-04-30 10:29:37,824] Trial 52 finished with value: 0.22729269701700944 and parameters: {'learning_rate': 0.0022439553959050624, 'l1_coef': 3.332374944927245e-05, 'patience': 10, 'batch_size': 32}. Best is trial 29 with value: 0.05914152525365353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 12 - Best hyperparameters: {'learning_rate': 0.013368341073967381, 'l1_coef': 1.0168876770412278e-05, 'patience': 9, 'batch_size': 128}\n",
      "Chr 12 - Best value: 0.0591\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr12/final_model_chr12.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr12/individual_r2_scores_chr12.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr12/individual_iqs_scores_chr12.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  110\n",
      "PRS313 SNPs:  5\n",
      "Total SNPs used for Training:  105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-30 10:29:41,493] Trial 52 finished with value: 0.10674433303730828 and parameters: {'learning_rate': 0.07136407088690266, 'l1_coef': 1.9697354445686117e-05, 'patience': 12, 'batch_size': 64}. Best is trial 52 with value: 0.10674433303730828.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 13 - Best hyperparameters: {'learning_rate': 0.07136407088690266, 'l1_coef': 1.9697354445686117e-05, 'patience': 12, 'batch_size': 64}\n",
      "Chr 13 - Best value: 0.1067\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr13/final_model_chr13.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr13/individual_r2_scores_chr13.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr13/individual_iqs_scores_chr13.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  164\n",
      "PRS313 SNPs:  8\n",
      "Total SNPs used for Training:  156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-30 10:29:43,838] Trial 52 finished with value: 0.23166067131928036 and parameters: {'learning_rate': 0.06966203051213557, 'l1_coef': 1.0155377703214876e-05, 'patience': 19, 'batch_size': 64}. Best is trial 36 with value: 0.07342382765242031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 14 - Best hyperparameters: {'learning_rate': 0.04900486554871739, 'l1_coef': 1.160024455652371e-05, 'patience': 20, 'batch_size': 64}\n",
      "Chr 14 - Best value: 0.0734\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr14/final_model_chr14.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr14/individual_r2_scores_chr14.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr14/individual_iqs_scores_chr14.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  197\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-30 10:29:46,246] Trial 52 finished with value: 0.1678699722656837 and parameters: {'learning_rate': 0.004408387038129946, 'l1_coef': 2.2186380654901538e-05, 'patience': 6, 'batch_size': 32}. Best is trial 7 with value: 0.07289292319462849.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 15 - Best hyperparameters: {'learning_rate': 0.00031046985754389273, 'l1_coef': 1.7067190785696914e-05, 'patience': 5, 'batch_size': 32}\n",
      "Chr 15 - Best value: 0.0729\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr15/final_model_chr15.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr15/individual_r2_scores_chr15.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr15/individual_iqs_scores_chr15.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  356\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-04-30 10:29:53,421] Trial 52 finished with value: 0.13884924890903327 and parameters: {'learning_rate': 0.02053619076573046, 'l1_coef': 1.538505740973728e-05, 'patience': 11, 'batch_size': 32}. Best is trial 19 with value: 0.08846894302047217.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 16 - Best hyperparameters: {'learning_rate': 0.0003280120292913132, 'l1_coef': 1.0215158769106902e-05, 'patience': 14, 'batch_size': 32}\n",
      "Chr 16 - Best value: 0.0885\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr16/final_model_chr16.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr16/individual_r2_scores_chr16.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr16/individual_iqs_scores_chr16.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  178\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-04-30 10:30:04,625] Trial 52 finished with value: 0.18260469053472791 and parameters: {'learning_rate': 0.02888017786149784, 'l1_coef': 1.6497974654309698e-05, 'patience': 11, 'batch_size': 64}. Best is trial 25 with value: 0.03733763907636915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 17 - Best hyperparameters: {'learning_rate': 0.01875699494745296, 'l1_coef': 1.0107606908789018e-05, 'patience': 16, 'batch_size': 64}\n",
      "Chr 17 - Best value: 0.0373\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr17/final_model_chr17.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr17/individual_r2_scores_chr17.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr17/individual_iqs_scores_chr17.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  274\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-04-30 10:30:07,061] Trial 52 finished with value: 0.17247382402420045 and parameters: {'learning_rate': 0.06708007694589001, 'l1_coef': 2.3925522968264924e-05, 'patience': 18, 'batch_size': 128}. Best is trial 29 with value: 0.08387428413216884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 18 - Best hyperparameters: {'learning_rate': 0.06940442887866152, 'l1_coef': 2.1499468833674833e-05, 'patience': 17, 'batch_size': 32}\n",
      "Chr 18 - Best value: 0.0839\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr18/final_model_chr18.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr18/individual_r2_scores_chr18.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr18/individual_iqs_scores_chr18.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  280\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[I 2024-04-30 10:30:10,654] Trial 52 finished with value: 0.06354604506721863 and parameters: {'learning_rate': 0.07331290072707394, 'l1_coef': 5.2847778031440676e-05, 'patience': 10, 'batch_size': 32}. Best is trial 27 with value: 0.04425642937421799.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 19 - Best hyperparameters: {'learning_rate': 0.07098016523175216, 'l1_coef': 1.0298921090840162e-05, 'patience': 11, 'batch_size': 128}\n",
      "Chr 19 - Best value: 0.0443\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr19/final_model_chr19.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr19/individual_r2_scores_chr19.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr19/individual_iqs_scores_chr19.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  61\n",
      "PRS313 SNPs:  4\n",
      "Total SNPs used for Training:  57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-30 10:30:12,642] Trial 52 finished with value: 0.1714223898947239 and parameters: {'learning_rate': 0.025102827902595402, 'l1_coef': 1.828533363987135e-05, 'patience': 15, 'batch_size': 128}. Best is trial 23 with value: 0.11483677476644516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 20 - Best hyperparameters: {'learning_rate': 0.011727770284572503, 'l1_coef': 1.0588262176994207e-05, 'patience': 9, 'batch_size': 128}\n",
      "Chr 20 - Best value: 0.1148\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr20/final_model_chr20.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr20/individual_r2_scores_chr20.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr20/individual_iqs_scores_chr20.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  44\n",
      "PRS313 SNPs:  5\n",
      "Total SNPs used for Training:  39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-30 10:30:16,795] Trial 52 finished with value: 0.20912565932824062 and parameters: {'learning_rate': 0.015775715034127915, 'l1_coef': 4.7267050906877265e-05, 'patience': 19, 'batch_size': 32}. Best is trial 27 with value: 0.0400828163006476.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 21 - Best hyperparameters: {'learning_rate': 0.07634654140233994, 'l1_coef': 1.331717466479133e-05, 'patience': 19, 'batch_size': 64}\n",
      "Chr 21 - Best value: 0.0401\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr21/final_model_chr21.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr21/individual_r2_scores_chr21.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr21/individual_iqs_scores_chr21.csv\n",
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n",
      "Total SNPs:  397\n",
      "PRS313 SNPs:  11\n",
      "Total SNPs used for Training:  386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-30 10:30:18,921] Trial 52 finished with value: 0.20849275588989258 and parameters: {'learning_rate': 0.016704656913222003, 'l1_coef': 1.5002890636112717e-05, 'patience': 13, 'batch_size': 128}. Best is trial 40 with value: 0.06794291579952608.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 22 - Best hyperparameters: {'learning_rate': 0.02943043957881216, 'l1_coef': 1.0232605917875621e-05, 'patience': 12, 'batch_size': 32}\n",
      "Chr 22 - Best value: 0.0679\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr22/final_model_chr22.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr22/individual_r2_scores_chr22.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr22/individual_iqs_scores_chr22.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_81857/73971118.py:42: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  iqs = (po - pc) / (1 - pc)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results_unphased_all_PRS/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../Data/Filtered_unphased_training_data/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "false_positive_rates = []\n",
    "auc_rocs = []\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "\n",
    "# Create folders for saving files\n",
    "output_folder = \"../../Data/model_results_unphased_all_PRS/logistic_regression/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "curve_folder = output_folder + \"roc_curves/\"\n",
    "\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "os.makedirs(curve_folder, exist_ok=True)\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Create subfolders for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_curve_folder = curve_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    os.makedirs(chr_model_folder, exist_ok=True)\n",
    "    os.makedirs(chr_csv_folder, exist_ok=True)\n",
    "    os.makedirs(chr_curve_folder, exist_ok=True)\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    # print(\"Known PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_Known\" in col]].shape[1])\n",
    "    # print(\"23AndMe SNPs with LD to Unknown PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_\" not in col]].shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the logistic regression model with lasso regularization\n",
    "    class LogisticRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, l1_coef=0.0):\n",
    "            super(LogisticRegression, self).__init__()\n",
    "            self.linear = nn.Linear(input_dim, output_dim)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.linear(x)\n",
    "            out = self.sigmoid(out)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * torch.norm(self.linear.weight, p=1)\n",
    "        \n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set the hyperparameters for tuning\n",
    "    input_dim = X_train_val.shape[1]\n",
    "    output_dim = y_train_val.shape[1]\n",
    "    num_epochs = 500\n",
    "    batch_size = 128\n",
    "\n",
    "    # Define the objective function for Optuna with cross-validation and early stopping\n",
    "    def objective(trial):\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "        l1_coef = trial.suggest_float('l1_coef', 1e-5, 1e-1, log=True)\n",
    "        patience = trial.suggest_int('patience', 5, 20)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "\n",
    "        model = LogisticRegression(input_dim, output_dim, l1_coef).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.BCELoss()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=False)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold_losses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_val, y_train_val.argmax(dim=1))):\n",
    "            X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "            y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "            train_dataset = TensorDataset(X_train, y_train)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "            best_val_loss = float('inf')\n",
    "            counter = 0\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = 0.0\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                train_loss /= len(train_loader)\n",
    "\n",
    "                val_dataset = TensorDataset(X_val, y_val)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0.0\n",
    "                    for batch_X, batch_y in val_loader:\n",
    "                        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X)\n",
    "                        loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                    val_loss /= len(val_loader)\n",
    "                    scheduler.step(val_loss)\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= patience:\n",
    "                        # print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                        break\n",
    "\n",
    "            fold_losses.append(best_val_loss)\n",
    "\n",
    "        return np.mean(fold_losses)\n",
    "\n",
    "    # Create the \"optuna_studies\" folder if it doesn't exist\n",
    "    os.makedirs(\"optuna_studies\", exist_ok=True)\n",
    "\n",
    "    # Create an Optuna study and optimize the hyperparameters\n",
    "    study_name = f\"chr{chromosome_number}_study\"\n",
    "    storage_name = f\"sqlite:///optuna_studies/{study_name}.db\"\n",
    "\n",
    "    # Check if the study exists\n",
    "\n",
    "    current_dir = os.getcwd()\n",
    "    study_exists = os.path.exists(current_dir + f\"/optuna_studies/{study_name}.db\")\n",
    "    \n",
    "    if study_exists:\n",
    "        # Load the existing study\n",
    "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "    else:\n",
    "        # Create a new study\n",
    "        study = optuna.create_study(direction='minimize', study_name=study_name, storage=storage_name)\n",
    "\n",
    "    study.optimize(objective, n_trials=1, n_jobs=-1)\n",
    "\n",
    "    # Print the best hyperparameters and best value\n",
    "    print(f\"Chr {chromosome_number} - Best hyperparameters: {study.best_params}\")\n",
    "    print(f\"Chr {chromosome_number} - Best value: {study.best_value:.4f}\")\n",
    "\n",
    "    # Train the final model with the best hyperparameters and early stopping\n",
    "    best_learning_rate = study.best_params['learning_rate']\n",
    "    best_l1_coef = study.best_params['l1_coef']\n",
    "    best_patience = study.best_params['patience']\n",
    "    best_batch_size = study.best_params['batch_size']\n",
    "\n",
    "    model = LogisticRegression(input_dim, output_dim, best_l1_coef).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=False)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_val, y_train_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        # print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            best_train_loss = train_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= best_patience:\n",
    "            # print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "    # Save the final model\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Final model saved at: {model_save_path}\")\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_preds = (test_outputs > 0.5).float()\n",
    "        test_accuracy = float(((test_preds > 0.5) == y_test).float().mean())\n",
    "        test_precision = precision_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_recall = recall_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_f1 = f1_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_roc_auc = roc_auc_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), average='micro')\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "\n",
    "        # Calculate false positive rate\n",
    "        cm = confusion_matrix(y_test.cpu().numpy().ravel(), test_preds.cpu().numpy().ravel())\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        test_fpr = fp / (fp + tn)\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        accuracies.append(test_accuracy)\n",
    "        precisions.append(test_precision)\n",
    "        recalls.append(test_recall)\n",
    "        false_positive_rates.append(test_fpr)\n",
    "        auc_rocs.append(test_roc_auc)\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test.cpu().numpy()[:, i].reshape(-1, 1), test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='Unknown').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "        # Save individual AUC ROC curves for each SNP\n",
    "        for i, snp in enumerate(snp_names):\n",
    "            try: \n",
    "                fpr, tpr, _ = roc_curve(y_test.cpu().numpy()[:, i], test_outputs.cpu().numpy()[:, i])\n",
    "                plt.figure()\n",
    "                plt.plot(fpr, tpr, label=f'AUC ROC = {roc_auc_score(y_test.cpu().numpy()[:, i], test_outputs.cpu().numpy()[:, i]):.4f}')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title(f'AUC ROC Curve - {snp}')\n",
    "                plt.legend()\n",
    "                \n",
    "                curve_file = chr_curve_folder + f'auc_roc_curve_{snp}_chr{chromosome_number}.png'\n",
    "                plt.savefig(curve_file)\n",
    "                plt.close()\n",
    "            except ValueError:\n",
    "                # Save a placeholder image if there is insufficient data\n",
    "                plt.figure()\n",
    "                plt.axis('off')\n",
    "                plt.text(0.5, 0.5, \"Insufficient data for ROC curve\", ha='center', va='center')\n",
    "                curve_file = chr_curve_folder + f'auc_roc_curve_{snp}_chr{chromosome_number}.png'\n",
    "                plt.savefig(curve_file)\n",
    "                plt.close()\n",
    "\n",
    "                print(f\"Skipping SNP {snp} due to insufficient data\")\n",
    "\n",
    "\n",
    "        print(f\"Individual AUC ROC curves saved in: {curve_folder}\")\n",
    "\n",
    "        # Create a DataFrame to store the performance metrics for each chromosome\n",
    "        performance_df = pd.DataFrame({\n",
    "            'Chromosome': list(range(start, chromosome_number + 1)),\n",
    "            'Accuracy': accuracies,\n",
    "            'Precision': precisions,\n",
    "            'Recall': recalls,\n",
    "            'False Positive Rate': false_positive_rates,\n",
    "            'AUC ROC': auc_rocs,\n",
    "            'R2 Score': r2_scores,\n",
    "            'IQS Score': iqs_scores\n",
    "        })\n",
    "\n",
    "        # Save the performance metrics to a CSV file\n",
    "        performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "        performance_df.to_csv(performance_csv_file, index=False)\n",
    "        print(f\"Performance metrics saved at: {performance_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRS313 SNPs saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/prs313_snps.csv\n",
      "Total number of PRS313 SNPs: 314\n"
     ]
    }
   ],
   "source": [
    "# Loop through all the training datasets and document the PRS313 SNPs in each dataset. Save this to a CSV file.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_directory = '../../Data/Filtered_unphased_training_data/'\n",
    "output_folder = \"../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize a list to store the PRS313 SNPs in each dataset\n",
    "prs313_snps = []\n",
    "\n",
    "for chromosome_number in range(1, 23):\n",
    "    file_name = data_directory + \\\n",
    "        f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    prs313_snps.append(data.filter(regex='PRS313_').columns)\n",
    "\n",
    "# Create a DataFrame to store the PRS313 SNPs in each dataset\n",
    "prs313_df = pd.DataFrame({\n",
    "    'Chromosome': list(range(1, 23)),\n",
    "    'PRS313 SNPs': prs313_snps,\n",
    "    \"Number of PRS313 SNPs\": [len(snps) for snps in prs313_snps]\n",
    "})\n",
    "\n",
    "# Save the PRS313 SNPs to a CSV file\n",
    "prs313_csv_file = output_folder + 'prs313_snps.csv'\n",
    "prs313_df.to_csv(prs313_csv_file, index=False)\n",
    "print(f\"PRS313 SNPs saved at: {prs313_csv_file}\")\n",
    "\n",
    "# Print the total number of PRS313 SNPs in all datasets\n",
    "total_prs313_snps = sum(prs313_df[\"Number of PRS313 SNPs\"])\n",
    "print(f\"Total number of PRS313 SNPs: {total_prs313_snps}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chromosome\n",
       "1     30\n",
       "2     21\n",
       "3     16\n",
       "4     11\n",
       "5     34\n",
       "6     20\n",
       "7     14\n",
       "8     21\n",
       "9     14\n",
       "10    18\n",
       "11    19\n",
       "12    17\n",
       "13     5\n",
       "14     8\n",
       "15     7\n",
       "16    14\n",
       "17     9\n",
       "18     9\n",
       "19     7\n",
       "20     4\n",
       "21     4\n",
       "22    11\n",
       "Name: SNPa, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the PRS313 xlsx\n",
    "prs313_file = \"../../Data/PRS313.xlsx\"\n",
    "\n",
    "# Load the PRS313 data\n",
    "prs313_data = pd.read_excel(prs313_file)\n",
    "\n",
    "# Get the number of PRS313 SNPs per chromosome\n",
    "prs313_snps_per_chromosome = prs313_data.groupby(\"Chromosome\")[\"SNPa\"].count()\n",
    "prs313_snps_per_chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     30\n",
       "1     21\n",
       "2     16\n",
       "3     11\n",
       "4     34\n",
       "5     20\n",
       "6     14\n",
       "7     21\n",
       "8     14\n",
       "9     18\n",
       "10    19\n",
       "11    17\n",
       "12     5\n",
       "13     8\n",
       "14     7\n",
       "15    14\n",
       "16     9\n",
       "17     9\n",
       "18     7\n",
       "19     4\n",
       "20     5\n",
       "21    11\n",
       "Name: Number of PRS313 SNPs, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prs313_df[\"Number of PRS313 SNPs\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
