{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def read_vcf_header(file_path):\n",
    "    \"\"\"Reads the VCF file header (column names) and returns it.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('#CHROM'):\n",
    "                return line.strip().split('\\t')\n",
    "    return []\n",
    "\n",
    "def extract_snp_data(file_path, header):\n",
    "    \"\"\"Extracts SNP data from a VCF file.\"\"\"\n",
    "    snp_data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if not line.startswith('#'):\n",
    "                fields = line.strip().split('\\t')\n",
    "                chrom, pos, ref, alt = fields[0], fields[1], fields[3], fields[4]\n",
    "                snp_id = f\"chr{chrom}_{pos}_{ref}_{alt}\"\n",
    "                genotype_data = fields[9:]  # Genotype data starts from the 10th column\n",
    "                snp_data.append((snp_id, genotype_data))\n",
    "    return snp_data\n",
    "\n",
    "def process_vcf_files(directory):\n",
    "    \"\"\"Processes all VCF files in the specified directory.\"\"\"\n",
    "    vcf_files = glob.glob(os.path.join(directory, '*.vcf'))\n",
    "    all_snp_data = []\n",
    "    patient_ids = None\n",
    "    \n",
    "    for file_path in vcf_files:\n",
    "        if patient_ids is None:\n",
    "            patient_ids = read_vcf_header(file_path)[9:]  # Assuming the first 9 columns are standard VCF columns\n",
    "        snp_data = extract_snp_data(file_path, patient_ids)\n",
    "\n",
    "        if (len(snp_data) == 0):\n",
    "            # print(\"No matches found at \", file_path)\n",
    "            continue\n",
    "        else:\n",
    "            for SNP in snp_data:\n",
    "                position_in_vcf = SNP[0].split(\"_\")[1]\n",
    "                file_path_position = file_path.split(\"_pos\")[1][:-4]\n",
    "                if (position_in_vcf == file_path_position):\n",
    "                    all_snp_data.extend(snp_data)\n",
    "                    # print(\"Adding\")\n",
    "                else:\n",
    "                    # Ignoring copy number variations\n",
    "                    # print(\"Ignoring\")\n",
    "                    continue\n",
    "\n",
    "    # Convert the collected SNP data to a DataFrame\n",
    "    data_dict = {snp_id: genotypes for snp_id, genotypes in all_snp_data}\n",
    "    df = pd.DataFrame(data_dict, index=patient_ids)\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find intersection b/w 23AndMe and PRS313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated PRS313_df:\n",
      "                    Chromosome  Positionb Reference Allele Effect Allele  \\\n",
      "SNPa                                                                       \n",
      "1_100880328_A_T              1  100880328                A             T   \n",
      "1_10566215_A_G               1   10566215                A             G   \n",
      "1_110198129_CAAA_C           1  110198129             CAAA             C   \n",
      "1_114445880_G_A              1  114445880                G             A   \n",
      "1_118141492_A_C              1  118141492                A             C   \n",
      "...                        ...        ...              ...           ...   \n",
      "22_40904707_CT_C            22   40904707               CT             C   \n",
      "22_43433100_C_T             22   43433100                C             T   \n",
      "22_45319953_G_A             22   45319953                G             A   \n",
      "22_46283297_G_A             22   46283297                G             A   \n",
      "in_23andMe                   0          0            False         False   \n",
      "\n",
      "                        EAFc  Overall Breast Cancerd  ER-positivee  \\\n",
      "SNPa                                                                 \n",
      "1_100880328_A_T     0.409678                  0.0373        0.0355   \n",
      "1_10566215_A_G      0.329016                 -0.0586       -0.0407   \n",
      "1_110198129_CAAA_C  0.775478                  0.0458        0.0545   \n",
      "1_114445880_G_A     0.166363                  0.0621        0.0642   \n",
      "1_118141492_A_C     0.265682                  0.0452        0.0417   \n",
      "...                      ...                     ...           ...   \n",
      "22_40904707_CT_C    0.109871                  0.1148        0.1160   \n",
      "22_43433100_C_T     0.114445                 -0.0600       -0.0585   \n",
      "22_45319953_G_A     0.416619                 -0.0134       -0.0060   \n",
      "22_46283297_G_A     0.111687                  0.0736        0.0719   \n",
      "in_23andMe          0.000000                  0.0000        0.0000   \n",
      "\n",
      "                    ER-negativef  hybrid ER-positiveg  hybrid ER-negativeh  \\\n",
      "SNPa                                                                         \n",
      "1_100880328_A_T           0.0160               0.0373               0.0373   \n",
      "1_10566215_A_G           -0.1109              -0.0407              -0.1109   \n",
      "1_110198129_CAAA_C        0.0266               0.0458               0.0458   \n",
      "1_114445880_G_A           0.0579               0.0621               0.0621   \n",
      "1_118141492_A_C           0.0551               0.0452               0.0452   \n",
      "...                          ...                  ...                  ...   \n",
      "22_40904707_CT_C          0.1203               0.1148               0.1148   \n",
      "22_43433100_C_T          -0.0515              -0.0600              -0.0600   \n",
      "22_45319953_G_A          -0.0611              -0.0060              -0.0611   \n",
      "22_46283297_G_A           0.0993               0.0736               0.0736   \n",
      "in_23andMe                0.0000               0.0000               0.0000   \n",
      "\n",
      "                    ... 22_29135543_G_A 22_29203724_C_T 22_29551872_A_G  \\\n",
      "SNPa                ...                                                   \n",
      "1_100880328_A_T     ...             NaN             NaN             NaN   \n",
      "1_10566215_A_G      ...             NaN             NaN             NaN   \n",
      "1_110198129_CAAA_C  ...             NaN             NaN             NaN   \n",
      "1_114445880_G_A     ...             NaN             NaN             NaN   \n",
      "1_118141492_A_C     ...             NaN             NaN             NaN   \n",
      "...                 ...             ...             ...             ...   \n",
      "22_40904707_CT_C    ...             NaN             NaN             NaN   \n",
      "22_43433100_C_T     ...             NaN             NaN             NaN   \n",
      "22_45319953_G_A     ...             NaN             NaN             NaN   \n",
      "22_46283297_G_A     ...             NaN             NaN             NaN   \n",
      "in_23andMe          ...           False           False           False   \n",
      "\n",
      "                   22_38583315_AAAAG_AAAAGAAAG 22_39343916_T_A  \\\n",
      "SNPa                                                             \n",
      "1_100880328_A_T                            NaN             NaN   \n",
      "1_10566215_A_G                             NaN             NaN   \n",
      "1_110198129_CAAA_C                         NaN             NaN   \n",
      "1_114445880_G_A                            NaN             NaN   \n",
      "1_118141492_A_C                            NaN             NaN   \n",
      "...                                        ...             ...   \n",
      "22_40904707_CT_C                           NaN             NaN   \n",
      "22_43433100_C_T                            NaN             NaN   \n",
      "22_45319953_G_A                            NaN             NaN   \n",
      "22_46283297_G_A                            NaN             NaN   \n",
      "in_23andMe                               False            True   \n",
      "\n",
      "                   22_40904707_CT_C 22_43433100_C_T 22_45319953_G_A  \\\n",
      "SNPa                                                                  \n",
      "1_100880328_A_T                 NaN             NaN             NaN   \n",
      "1_10566215_A_G                  NaN             NaN             NaN   \n",
      "1_110198129_CAAA_C              NaN             NaN             NaN   \n",
      "1_114445880_G_A                 NaN             NaN             NaN   \n",
      "1_118141492_A_C                 NaN             NaN             NaN   \n",
      "...                             ...             ...             ...   \n",
      "22_40904707_CT_C                NaN             NaN             NaN   \n",
      "22_43433100_C_T                 NaN             NaN             NaN   \n",
      "22_45319953_G_A                 NaN             NaN             NaN   \n",
      "22_46283297_G_A                 NaN             NaN             NaN   \n",
      "in_23andMe                    False           False           False   \n",
      "\n",
      "                   22_46283297_G_A in_23andMe  \n",
      "SNPa                                           \n",
      "1_100880328_A_T                NaN        NaN  \n",
      "1_10566215_A_G                 NaN        NaN  \n",
      "1_110198129_CAAA_C             NaN        NaN  \n",
      "1_114445880_G_A                NaN        NaN  \n",
      "1_118141492_A_C                NaN        NaN  \n",
      "...                            ...        ...  \n",
      "22_40904707_CT_C               NaN        NaN  \n",
      "22_43433100_C_T                NaN        NaN  \n",
      "22_45319953_G_A                NaN        NaN  \n",
      "22_46283297_G_A                NaN        NaN  \n",
      "in_23andMe                   False      False  \n",
      "\n",
      "[314 rows x 324 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define file paths\n",
    "ttAndMeFullPanel = \"../../Data/23andMe_metadata_files/23andMeGenePanel.csv\"\n",
    "prs313_file = './concatenated_snps_processed.csv'\n",
    "\n",
    "# Read the CSV files into DataFrames\n",
    "ttAndMe = pd.read_csv(ttAndMeFullPanel)\n",
    "PRS313_df = pd.read_csv(prs313_file, index_col=0)\n",
    "\n",
    "# Extract chromosome and position information from PRS313_df columns\n",
    "PRS313_info = PRS313_df.columns.str.extract(r'chr(\\d+)_(\\d+)', expand=True)\n",
    "PRS313_info.columns = ['chromosome', 'position']\n",
    "\n",
    "# Create a new row in PRS313_df to store the boolean values\n",
    "PRS313_df.loc['in_23andMe'] = False\n",
    "\n",
    "# Merge ttAndMe with PRS313_info to identify matching rows\n",
    "ttAndMe['chromosome'] = ttAndMe['chromosome'].astype(str)\n",
    "ttAndMe['position'] = ttAndMe['position'].astype(str)\n",
    "\n",
    "merged_df = pd.merge(ttAndMe, PRS313_info, how='inner', left_on=['chromosome', 'position'], right_on=['chromosome', 'position'])\n",
    "\n",
    "# Set the 'in_23andMe' row to True for matching columns\n",
    "matching_columns = 'chr' + merged_df['chromosome'] + '_' + merged_df['position']\n",
    "PRS313_df.loc['in_23andMe', matching_columns] = True\n",
    "\n",
    "# Print the updated PRS313_df DataFrame\n",
    "print(\"Updated PRS313_df:\")\n",
    "print(PRS313_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(PRS313_df.loc['in_23andMe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2504, 53891)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m chromosome_N_snps \u001b[38;5;241m=\u001b[39m PRS313_df\u001b[38;5;241m.\u001b[39mloc[:, [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m PRS313_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)]]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# If the df_23AndMe DataFrame column has a matching column in the PRS313 DataFrame, add to its column name the string '_PRS313'\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m cols_renamed \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m df_23AndMe\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m chromosome_N_snps\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m chromosome_N_snps \u001b[38;5;241m=\u001b[39m PRS313_df\u001b[38;5;241m.\u001b[39mloc[:, [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m PRS313_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)]]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# If the df_23AndMe DataFrame column has a matching column in the PRS313 DataFrame, add to its column name the string '_PRS313'\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m cols_renamed \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m df_23AndMe\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m chromosome_N_snps\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1600\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1834\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.ThreadTracer.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "ttandMePositions = \"../../../Data/23andMe_metadata_files/23andMeGenePanel.csv\"\n",
    "\n",
    "output_dir   = \"../../../Data/Raw_training_data_23andMe_union/\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# Read the text file into a DataFrame\n",
    "ttAndMe = pd.read_csv(ttandMePositions, comment='#', header = 0)\n",
    "for i in range (1, 23):\n",
    "    chromosome_number = i\n",
    "        \n",
    "    # Replace 'your_directory_path' with the path to your directory containing the VCF files\n",
    "    directory_path = f'../../../Data/23AndMePositionsUnion/chr{chromosome_number}/'\n",
    "    df_23AndMe = process_vcf_files(directory_path)\n",
    "\n",
    "\n",
    "    # Filter the PRS313 data to only include SNPs on chromosome 1 by filtering column names that begin with chr1\n",
    "    chromosome_N_snps = PRS313_df.loc[:, [col for col in PRS313_df.columns if col.startswith(f'chr{chromosome_number}_')]]\n",
    "\n",
    "    # If the df_23AndMe DataFrame column has a matching column in the PRS313 DataFrame, add to its column name the string '_PRS313'\n",
    "    cols_renamed = []\n",
    "    for column in df_23AndMe.columns:\n",
    "        if column in chromosome_N_snps.columns:\n",
    "            df_23AndMe.rename(columns={column: f'{column}_PRS313_Known'}, inplace=True)\n",
    "            cols_renamed.append(column)\n",
    "            print(f\"Column {column} renamed to {column}_PRS313_Known\")\n",
    "            \n",
    "    print(len(cols_renamed))\n",
    "\n",
    "    # Add the columns from the PRS313 DataFrame that were not present in the 23andMe DataFrame. Use the 'in_23AndMe' row to add only the rows that weren't already there. Ensure that there is a '_PRS313_Unknown' suffix in the column name\n",
    "\n",
    "    added_columns = []\n",
    "    for column in chromosome_N_snps.columns:\n",
    "        if not chromosome_N_snps.loc['in_23andMe', column]:\n",
    "            df_23AndMe[column + '_PRS313_Unknown'] = chromosome_N_snps.loc[:, column]\n",
    "            added_columns.append(column)\n",
    "            print(f\"Column {column} added to df_23AndMe with suffix '_PRS313_Unknown'\")\n",
    "    print(len(added_columns))\n",
    "\n",
    "    df_23AndMe.to_parquet(f'{output_dir}/23AndMe_PRS313_merged_chr{chromosome_number}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[filtered_columns]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Replace the original parquet file with the filtered DataFrame\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mfiltered_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:2973\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2885\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2886\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[1;32m   2887\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2969\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[1;32m   2970\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2971\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 2973\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2981\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2982\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parquet.py:483\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m    481\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[0;32m--> 483\u001b[0m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io\u001b[38;5;241m.\u001b[39mBytesIO)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parquet.py:189\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[0;34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     from_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreserve_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[0;32m--> 189\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfrom_pandas_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mattrs:\n\u001b[1;32m    192\u001b[0m     df_metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPANDAS_ATTRS\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(df\u001b[38;5;241m.\u001b[39mattrs)}\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyarrow/table.pxi:3874\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyarrow/pandas_compat.py:570\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdataframe_to_arrays\u001b[39m(df, schema, preserve_index, nthreads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    563\u001b[0m                         safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    564\u001b[0m     (all_names,\n\u001b[1;32m    565\u001b[0m      column_names,\n\u001b[1;32m    566\u001b[0m      index_column_names,\n\u001b[1;32m    567\u001b[0m      index_descriptors,\n\u001b[1;32m    568\u001b[0m      index_columns,\n\u001b[1;32m    569\u001b[0m      columns_to_convert,\n\u001b[0;32m--> 570\u001b[0m      convert_fields) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_columns_to_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# NOTE(wesm): If nthreads=None, then we use a heuristic to decide whether\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;66;03m# using a thread pool is worth it. Currently the heuristic is whether the\u001b[39;00m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# nrows > 100 * ncols and ncols > 1.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nthreads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyarrow/pandas_compat.py:370\u001b[0m, in \u001b[0;36m_get_columns_to_convert\u001b[0;34m(df, schema, preserve_index, columns)\u001b[0m\n\u001b[1;32m    367\u001b[0m convert_fields \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m--> 370\u001b[0m     col \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    371\u001b[0m     name \u001b[38;5;241m=\u001b[39m _column_name_to_strings(name)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _pandas_api\u001b[38;5;241m.\u001b[39mis_sparse(col):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:3872\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3865\u001b[0m \u001b[38;5;66;03m# GH#45316 Return view if key is not duplicated\u001b[39;00m\n\u001b[1;32m   3866\u001b[0m \u001b[38;5;66;03m# Only use drop_duplicates with duplicates for performance\u001b[39;00m\n\u001b[1;32m   3867\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   3868\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[1;32m   3869\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   3870\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdrop_duplicates(keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3871\u001b[0m ):\n\u001b[0;32m-> 3872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_item_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3874\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_mi \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m   3875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4418\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4414\u001b[0m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[1;32m   4415\u001b[0m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[1;32m   4417\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(item)\n\u001b[0;32m-> 4418\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4420\u001b[0m     cache[item] \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m   4422\u001b[0m     \u001b[38;5;66;03m# for a chain\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:3806\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;66;03m# icol\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[i]\n\u001b[0;32m-> 3806\u001b[0m     col_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3807\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_box_col_values(col_mgr, i)\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m# this is a cached value, mark it so\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/internals/managers.py:1000\u001b[0m, in \u001b[0;36mBlockManager.iget\u001b[0;34m(self, i, track_ref)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# shortcut for select a single-dim from a 2-dim BM\u001b[39;00m\n\u001b[1;32m    999\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(values)))\n\u001b[0;32m-> 1000\u001b[0m nb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrack_ref\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m   1002\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SingleBlockManager(nb, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the parquet files\n",
    "directory = \"../Final_training_data/\"\n",
    "\n",
    "# Iterate over the files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\"23AndMe_PRS313_merged_chr\") and filename.endswith(\".parquet\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Extract the chromosome number from the filename\n",
    "        chromosome = filename.split(\"_\")[-1].split(\".\")[0]\n",
    "        \n",
    "        # Read the parquet file into a DataFrame\n",
    "        df = pd.read_parquet(file_path)\n",
    "        \n",
    "        # Filter the columns starting with \"chrN_\"\n",
    "        filtered_columns = [col for col in df.columns if col.startswith(f\"{chromosome}_\")]\n",
    "        filtered_df = df[filtered_columns]\n",
    "        \n",
    "        # Replace the original parquet file with the filtered DataFrame\n",
    "        filtered_df.to_parquet(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
