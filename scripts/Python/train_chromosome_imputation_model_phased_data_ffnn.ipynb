{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../Data/Filtered_split_training_data/'\n",
    "chromosome_number = 1\n",
    "\n",
    "hidden_size1 = 150\n",
    "hidden_size2 = 150\n",
    "\n",
    "for chromosome_number in range (1,23):\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_split.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "    print(\"Unknown PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_Unknown\" in col]].shape[1])\n",
    "    print(\"Known PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_Known\" in col]].shape[1])\n",
    "    print(\"23AndMe SNPs with LD to Unknown PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_\" not in col]].shape[1])\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*Unknown)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='Unknown').values, dtype=torch.float32)\n",
    "\n",
    "        \n",
    "        # Define the updated neural network architecture\n",
    "    class SimpleFFNN(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "            super(SimpleFFNN, self).__init__()\n",
    "            self.hidden1 = nn.Linear(input_size, hidden_size1)\n",
    "            self.hidden2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "            self.output = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.hidden1(x))\n",
    "            x = torch.relu(self.hidden2(x))\n",
    "            x = torch.sigmoid(self.output(x))\n",
    "            return x\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set the hyperparameters\n",
    "    input_dim = X.shape[1]\n",
    "    output_dim = y.shape[1]\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 400\n",
    "    batch_size = 128\n",
    "    num_folds = 5\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # K-fold cross-validation\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    fold_precisions = []\n",
    "    fold_recalls = []\n",
    "    fold_f1_scores = []\n",
    "    fold_roc_auc_scores = []\n",
    "    fold_r2_scores = []\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):\n",
    "        print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        val_dataset = TensorDataset(X_val, y_val)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "        \n",
    "        model = SimpleFFNN(input_dim,hidden_size1, hidden_size2, output_dim).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = 0.0\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                \n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            fold_train_losses.append(train_loss)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val.to(device))\n",
    "            val_loss = criterion(val_outputs, y_val.to(device))\n",
    "            fold_val_losses.append(val_loss.item())\n",
    "            \n",
    "            val_preds = (val_outputs > 0.5).float()\n",
    "            val_accuracy = float(((val_preds > 0.5) == y_val).float().mean())\n",
    "            val_precision = precision_score(y_val.cpu().numpy(), val_preds.cpu().numpy(), average='micro')\n",
    "            val_recall = recall_score(y_val.cpu().numpy(), val_preds.cpu().numpy(), average='micro')\n",
    "            val_f1 = f1_score(y_val.cpu().numpy(), val_preds.cpu().numpy(), average='micro')\n",
    "            val_roc_auc = roc_auc_score(y_val.cpu().numpy(), val_outputs.cpu().numpy(), average='micro')\n",
    "            val_r2 = sklearn_r2_score(y_val.cpu().numpy(), val_outputs.cpu().numpy())\n",
    "            val_iqs = (y_val.cpu().numpy(), val_preds.cpu().numpy())\n",
    "\n",
    "            fold_accuracies.append(val_accuracy)\n",
    "            fold_precisions.append(val_precision)\n",
    "            fold_recalls.append(val_recall)\n",
    "            fold_f1_scores.append(val_f1)\n",
    "            fold_roc_auc_scores.append(val_roc_auc)\n",
    "            fold_r2_scores.append(val_r2)\n",
    "\n",
    "            print(f\"Fold {fold + 1}/{num_folds}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc:.4f}, Val R2: {val_r2:.4f}\")\n",
    "\n",
    "\n",
    "    print(f\"Average Accuracy: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\")\n",
    "    print(f\"Average Precision: {np.mean(fold_precisions):.4f} +/- {np.std(fold_precisions):.4f}\")\n",
    "    print(f\"Average Recall: {np.mean(fold_recalls):.4f} +/- {np.std(fold_recalls):.4f}\")\n",
    "    print(f\"Average F1 Score: {np.mean(fold_f1_scores):.4f} +/- {np.std(fold_f1_scores):.4f}\")\n",
    "    print(f\"Average ROC AUC: {np.mean(fold_roc_auc_scores):.4f} +/- {np.std(fold_roc_auc_scores):.4f}\")\n",
    "    print(f\"Average R2 Score: {np.mean(fold_r2_scores):.4f} +/- {np.std(fold_r2_scores):.4f}\")\n",
    "    print(f\"Average IQS Score: {np.mean(fold_iqs_scores):.4f} +/- {np.std(fold_iqs_scores):.4f}\")\n",
    "\n",
    "    import csv\n",
    "\n",
    "    # Export results to CSV\n",
    "\n",
    "    output_folder = \"../../Data/model_results/logistic_regression/\"\n",
    "\n",
    "    csv_file = output_folder + f'cross_validation_results_chr{chromosome_number}.csv'\n",
    "    fieldnames = ['Fold', 'Train Loss', 'Val Loss', 'Val Accuracy', 'Val Precision', 'Val Recall', 'Val F1', 'Val ROC AUC', 'Val R2']\n",
    "\n",
    "    with open(csv_file, 'w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for fold in range(num_folds):\n",
    "            writer.writerow({\n",
    "                'Fold': fold + 1,\n",
    "                'Train Loss': fold_train_losses[fold],\n",
    "                'Val Loss': fold_val_losses[fold],\n",
    "                'Val Accuracy': fold_accuracies[fold],\n",
    "                'Val Precision': fold_precisions[fold],\n",
    "                'Val Recall': fold_recalls[fold],\n",
    "                'Val F1': fold_f1_scores[fold],\n",
    "                'Val ROC AUC': fold_roc_auc_scores[fold],\n",
    "                'Val R2': fold_r2_scores[fold]\n",
    "            })\n",
    "\n",
    "        writer.writerow({})  # Empty row for separation\n",
    "        writer.writerow({\n",
    "            'Fold': 'Average',\n",
    "            'Train Loss': np.mean(fold_train_losses),\n",
    "            'Val Loss': np.mean(fold_val_losses),\n",
    "            'Val Accuracy': np.mean(fold_accuracies),\n",
    "            'Val Precision': np.mean(fold_precisions),\n",
    "            'Val Recall': np.mean(fold_recalls),\n",
    "            'Val F1': np.mean(fold_f1_scores),\n",
    "            'Val ROC AUC': np.mean(fold_roc_auc_scores),\n",
    "            'Val R2': np.mean(fold_r2_scores)\n",
    "        })\n",
    "        writer.writerow({\n",
    "            'Fold': 'Std Dev',\n",
    "            'Train Loss': np.std(fold_train_losses),\n",
    "            'Val Loss': np.std(fold_val_losses),\n",
    "            'Val Accuracy': np.std(fold_accuracies),\n",
    "            'Val Precision': np.std(fold_precisions),\n",
    "            'Val Recall': np.std(fold_recalls),\n",
    "            'Val F1': np.std(fold_f1_scores),\n",
    "            'Val ROC AUC': np.std(fold_roc_auc_scores),\n",
    "            'Val R2': np.std(fold_r2_scores)\n",
    "        })\n",
    "\n",
    "    print(f\"Results exported to {csv_file}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
