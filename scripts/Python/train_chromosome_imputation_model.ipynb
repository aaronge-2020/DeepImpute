{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown PRS313 SNPs:  40\n",
      "Known PRS313 SNPs:  20\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  2204\n",
      "Fold 1/5\n",
      "Fold 1/5, Train Loss: 0.0000, Val Loss: 0.8972, Val Accuracy: 0.9076, Val Precision: 0.8658, Val Recall: 0.8268, Val F1: 0.8458, Val ROC AUC: 0.9522, Val R2: 0.5074\n",
      "Fold 2/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 88\u001b[0m\n\u001b[1;32m     86\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_X, batch_y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 88\u001b[0m     batch_X, batch_y \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_X\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, batch_y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     90\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(batch_X)\n\u001b[1;32m     91\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../Data/Filtered_split_training_data/'\n",
    "chromosome_number = 1\n",
    "\n",
    "hidden_size1 = 150\n",
    "hidden_size2 = 150\n",
    "\n",
    "for chromosome_number in range (1,23):\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_split.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "    print(\"Unknown PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_Unknown\" in col]].shape[1])\n",
    "    print(\"Known PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_Known\" in col]].shape[1])\n",
    "    print(\"23AndMe SNPs with LD to Unknown PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_\" not in col]].shape[1])\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*Unknown)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='Unknown').values, dtype=torch.float32)\n",
    "\n",
    "        \n",
    "        # Define the updated neural network architecture\n",
    "    class SimpleFFNN(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "            super(SimpleFFNN, self).__init__()\n",
    "            self.hidden1 = nn.Linear(input_size, hidden_size1)\n",
    "            self.hidden2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "            self.output = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.hidden1(x))\n",
    "            x = torch.relu(self.hidden2(x))\n",
    "            x = torch.sigmoid(self.output(x))\n",
    "            return x\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set the hyperparameters\n",
    "    input_dim = X.shape[1]\n",
    "    output_dim = y.shape[1]\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 400\n",
    "    batch_size = 128\n",
    "    num_folds = 5\n",
    "\n",
    "    # Define the loss function\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # K-fold cross-validation\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    fold_precisions = []\n",
    "    fold_recalls = []\n",
    "    fold_f1_scores = []\n",
    "    fold_roc_auc_scores = []\n",
    "    fold_r2_scores = []\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):\n",
    "        print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        val_dataset = TensorDataset(X_val, y_val)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "        \n",
    "        model = SimpleFFNN(input_dim,hidden_size1, hidden_size2, output_dim).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = 0.0\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                \n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            fold_train_losses.append(train_loss)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val.to(device))\n",
    "            val_loss = criterion(val_outputs, y_val.to(device))\n",
    "            fold_val_losses.append(val_loss.item())\n",
    "            \n",
    "            val_preds = (val_outputs > 0.5).float()\n",
    "            val_accuracy = float(((val_preds > 0.5) == y_val).float().mean())\n",
    "            val_precision = precision_score(y_val.cpu().numpy(), val_preds.cpu().numpy(), average='micro')\n",
    "            val_recall = recall_score(y_val.cpu().numpy(), val_preds.cpu().numpy(), average='micro')\n",
    "            val_f1 = f1_score(y_val.cpu().numpy(), val_preds.cpu().numpy(), average='micro')\n",
    "            val_roc_auc = roc_auc_score(y_val.cpu().numpy(), val_outputs.cpu().numpy(), average='micro')\n",
    "            val_r2 = sklearn_r2_score(y_val.cpu().numpy(), val_outputs.cpu().numpy())\n",
    "\n",
    "            fold_accuracies.append(val_accuracy)\n",
    "            fold_precisions.append(val_precision)\n",
    "            fold_recalls.append(val_recall)\n",
    "            fold_f1_scores.append(val_f1)\n",
    "            fold_roc_auc_scores.append(val_roc_auc)\n",
    "            fold_r2_scores.append(val_r2)\n",
    "\n",
    "            print(f\"Fold {fold + 1}/{num_folds}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, Val F1: {val_f1:.4f}, Val ROC AUC: {val_roc_auc:.4f}, Val R2: {val_r2:.4f}\")\n",
    "\n",
    "\n",
    "    print(f\"Average Accuracy: {np.mean(fold_accuracies):.4f} +/- {np.std(fold_accuracies):.4f}\")\n",
    "    print(f\"Average Precision: {np.mean(fold_precisions):.4f} +/- {np.std(fold_precisions):.4f}\")\n",
    "    print(f\"Average Recall: {np.mean(fold_recalls):.4f} +/- {np.std(fold_recalls):.4f}\")\n",
    "    print(f\"Average F1 Score: {np.mean(fold_f1_scores):.4f} +/- {np.std(fold_f1_scores):.4f}\")\n",
    "    print(f\"Average ROC AUC: {np.mean(fold_roc_auc_scores):.4f} +/- {np.std(fold_roc_auc_scores):.4f}\")\n",
    "    print(f\"Average R2 Score: {np.mean(fold_r2_scores):.4f} +/- {np.std(fold_r2_scores):.4f}\")\n",
    "\n",
    "    import csv\n",
    "\n",
    "    # Export results to CSV\n",
    "\n",
    "    output_folder = \"../../Data/model_results/logistic_regression/\"\n",
    "\n",
    "    csv_file = output_folder + f'cross_validation_results_chr{chromosome_number}.csv'\n",
    "    fieldnames = ['Fold', 'Train Loss', 'Val Loss', 'Val Accuracy', 'Val Precision', 'Val Recall', 'Val F1', 'Val ROC AUC', 'Val R2']\n",
    "\n",
    "    with open(csv_file, 'w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for fold in range(num_folds):\n",
    "            writer.writerow({\n",
    "                'Fold': fold + 1,\n",
    "                'Train Loss': fold_train_losses[fold],\n",
    "                'Val Loss': fold_val_losses[fold],\n",
    "                'Val Accuracy': fold_accuracies[fold],\n",
    "                'Val Precision': fold_precisions[fold],\n",
    "                'Val Recall': fold_recalls[fold],\n",
    "                'Val F1': fold_f1_scores[fold],\n",
    "                'Val ROC AUC': fold_roc_auc_scores[fold],\n",
    "                'Val R2': fold_r2_scores[fold]\n",
    "            })\n",
    "\n",
    "        writer.writerow({})  # Empty row for separation\n",
    "        writer.writerow({\n",
    "            'Fold': 'Average',\n",
    "            'Train Loss': np.mean(fold_train_losses),\n",
    "            'Val Loss': np.mean(fold_val_losses),\n",
    "            'Val Accuracy': np.mean(fold_accuracies),\n",
    "            'Val Precision': np.mean(fold_precisions),\n",
    "            'Val Recall': np.mean(fold_recalls),\n",
    "            'Val F1': np.mean(fold_f1_scores),\n",
    "            'Val ROC AUC': np.mean(fold_roc_auc_scores),\n",
    "            'Val R2': np.mean(fold_r2_scores)\n",
    "        })\n",
    "        writer.writerow({\n",
    "            'Fold': 'Std Dev',\n",
    "            'Train Loss': np.std(fold_train_losses),\n",
    "            'Val Loss': np.std(fold_val_losses),\n",
    "            'Val Accuracy': np.std(fold_accuracies),\n",
    "            'Val Precision': np.std(fold_precisions),\n",
    "            'Val Recall': np.std(fold_recalls),\n",
    "            'Val F1': np.std(fold_f1_scores),\n",
    "            'Val ROC AUC': np.std(fold_roc_auc_scores),\n",
    "            'Val R2': np.std(fold_r2_scores)\n",
    "        })\n",
    "\n",
    "    print(f\"Results exported to {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown PRS313 SNPs:  8\n",
      "Known PRS313 SNPs:  2\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  210\n",
      "Loaded checkpoint from checkpoint_chr13.pth. Starting from epoch 44\n",
      "Epoch 44: Val Loss did not improve from 0.1294\n",
      "Epoch 45: Val Loss did not improve from 0.1294\n",
      "Epoch 46: Val Loss did not improve from 0.1294\n",
      "Epoch 47: Val Loss did not improve from 0.1294\n",
      "Epoch 48: Val Loss did not improve from 0.1294\n",
      "Epoch 49: Val Loss did not improve from 0.1294\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 50: Val Loss did not improve from 0.1294\n",
      "Epoch 51: Val Loss did not improve from 0.1294\n",
      "Epoch 52: Val Loss did not improve from 0.1294\n",
      "Epoch 53: Val Loss did not improve from 0.1294\n",
      "Epoch 54: Val Loss did not improve from 0.1294\n",
      "Epoch 55: Val Loss did not improve from 0.1294\n",
      "Epoch 56: Val Loss did not improve from 0.1294\n",
      "Epoch 57: Val Loss did not improve from 0.1294\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch 58: Val Loss did not improve from 0.1294\n",
      "Epoch 59: Val Loss did not improve from 0.1294\n",
      "Epoch 60: Val Loss did not improve from 0.1294\n",
      "Epoch 61: Val Loss did not improve from 0.1294\n",
      "Epoch 62: Val Loss did not improve from 0.1294\n",
      "Epoch 63: Val Loss did not improve from 0.1294\n",
      "Epoch 00021: reducing learning rate of group 0 to 1.0000e-09.\n",
      "Epoch 64: Val Loss did not improve from 0.1294\n",
      "Epoch 65: Val Loss did not improve from 0.1294\n",
      "Epoch 66: Val Loss did not improve from 0.1294\n",
      "Epoch 67: Val Loss did not improve from 0.1294\n",
      "Epoch 68: Val Loss did not improve from 0.1294\n",
      "Epoch 69: Val Loss did not improve from 0.1294\n",
      "Epoch 70: Val Loss did not improve from 0.1294\n",
      "Epoch 71: Val Loss did not improve from 0.1294\n",
      "Epoch 72: Val Loss did not improve from 0.1294\n",
      "Epoch 73: Val Loss did not improve from 0.1294\n",
      "Epoch 74: Val Loss did not improve from 0.1294\n",
      "Epoch 75: Val Loss did not improve from 0.1294\n",
      "Epoch 76: Val Loss did not improve from 0.1294\n",
      "Epoch 77: Val Loss did not improve from 0.1294\n",
      "Epoch 78: Val Loss did not improve from 0.1294\n",
      "Epoch 79: Val Loss did not improve from 0.1294\n",
      "Epoch 80: Val Loss did not improve from 0.1294\n",
      "Epoch 81: Val Loss did not improve from 0.1294\n",
      "Epoch 82: Val Loss did not improve from 0.1294\n",
      "Epoch 83: Val Loss did not improve from 0.1294\n",
      "Epoch 84: Val Loss did not improve from 0.1294\n",
      "Epoch 85: Val Loss did not improve from 0.1294\n",
      "Epoch 86: Val Loss did not improve from 0.1294\n",
      "Epoch 87: Val Loss did not improve from 0.1294\n",
      "Epoch 88: Val Loss did not improve from 0.1294\n",
      "Epoch 89: Val Loss did not improve from 0.1294\n",
      "Epoch 90: Val Loss did not improve from 0.1294\n",
      "Epoch 91: Val Loss did not improve from 0.1294\n",
      "Epoch 92: Val Loss did not improve from 0.1294\n",
      "Epoch 93: Val Loss did not improve from 0.1294\n",
      "Epoch 94: Val Loss did not improve from 0.1294\n",
      "Epoch 95: Val Loss did not improve from 0.1294\n",
      "Epoch 96: Val Loss did not improve from 0.1294\n",
      "Epoch 97: Val Loss did not improve from 0.1294\n",
      "Epoch 98: Val Loss did not improve from 0.1294\n",
      "Epoch 99: Val Loss did not improve from 0.1294\n",
      "Epoch 100: Val Loss did not improve from 0.1294\n",
      "Epoch 101: Val Loss did not improve from 0.1294\n",
      "Epoch 102: Val Loss did not improve from 0.1294\n",
      "Epoch 103: Val Loss did not improve from 0.1294\n",
      "Epoch 104: Val Loss did not improve from 0.1294\n",
      "Epoch 105: Val Loss did not improve from 0.1294\n",
      "Epoch 106: Val Loss did not improve from 0.1294\n",
      "Epoch 107: Val Loss did not improve from 0.1294\n",
      "Epoch 108: Val Loss did not improve from 0.1294\n",
      "Epoch 109: Val Loss did not improve from 0.1294\n",
      "Epoch 110: Val Loss did not improve from 0.1294\n",
      "Epoch 111: Val Loss did not improve from 0.1294\n",
      "Epoch 112: Val Loss did not improve from 0.1294\n",
      "Epoch 113: Val Loss did not improve from 0.1294\n",
      "Epoch 114: Val Loss did not improve from 0.1294\n",
      "Epoch 115: Val Loss did not improve from 0.1294\n",
      "Epoch 116: Val Loss did not improve from 0.1294\n",
      "Epoch 117: Val Loss did not improve from 0.1294\n",
      "Epoch 118: Val Loss did not improve from 0.1294\n",
      "Epoch 119: Val Loss did not improve from 0.1294\n",
      "Epoch 120: Val Loss did not improve from 0.1294\n",
      "Epoch 121: Val Loss did not improve from 0.1294\n",
      "Epoch 122: Val Loss did not improve from 0.1294\n",
      "Epoch 123: Val Loss did not improve from 0.1294\n",
      "Epoch 124: Val Loss did not improve from 0.1294\n",
      "Epoch 125: Val Loss did not improve from 0.1294\n",
      "Epoch 126: Val Loss did not improve from 0.1294\n",
      "Epoch 127: Val Loss did not improve from 0.1294\n",
      "Epoch 128: Val Loss did not improve from 0.1294\n",
      "Epoch 129: Val Loss did not improve from 0.1294\n",
      "Epoch 130: Val Loss did not improve from 0.1294\n",
      "Epoch 131: Val Loss did not improve from 0.1294\n",
      "Epoch 132: Val Loss did not improve from 0.1294\n",
      "Epoch 133: Val Loss did not improve from 0.1294\n",
      "Epoch 134: Val Loss did not improve from 0.1294\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 125\u001b[0m\n\u001b[1;32m    123\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_chr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    124\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter()\n\u001b[0;32m--> 125\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Load the best model and evaluate on the validation set\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 46\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs, device, writer, checkpoint_path)\u001b[0m\n\u001b[1;32m     44\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(batch_X)\n\u001b[1;32m     45\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y)\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "# Define the updated neural network architecture\n",
    "class SimpleFFNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleFFNN, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.hidden2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.output = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "def train_and_evaluate_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs, device, writer, checkpoint_path):\n",
    "    best_val_loss = float('inf')\n",
    "    start_epoch = 0\n",
    "\n",
    "    # Load checkpoint if it exists\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_val_loss = checkpoint['best_val_loss']\n",
    "        print(f\"Loaded checkpoint from {checkpoint_path}. Starting from epoch {start_epoch + 1}\")\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            val_outputs = []\n",
    "            val_labels = []\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                val_loss += criterion(outputs, batch_y).item()\n",
    "                val_outputs.extend(outputs.cpu().numpy())\n",
    "                val_labels.extend(batch_y.cpu().numpy())\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "            scheduler.step(val_loss)  # Update the learning rate based on validation loss\n",
    "            val_outputs = np.array(val_outputs)\n",
    "            val_labels = np.array(val_labels)\n",
    "            val_accuracy = ((val_outputs > 0.5) == val_labels).mean()\n",
    "            # val_accuracy = accuracy_score((val_labels == 1), np.round(val_outputs))\n",
    "            # val_roc_auc = roc_auc_score(val_labels, val_outputs, average=\"macro\")\n",
    "            \n",
    "            writer.add_scalar('Val_Loss', val_loss, epoch)\n",
    "            writer.add_scalar('Val_Accuracy', val_accuracy, epoch)\n",
    "            # writer.add_scalar('Val_ROC_AUC', val_roc_auc, epoch)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'best_val_loss': best_val_loss\n",
    "                }, checkpoint_path)\n",
    "                print(\"Validation Accuracy is \", val_accuracy)\n",
    "                print(f\"Epoch {epoch+1}: Val Loss improved to {val_loss:.4f}, saved checkpoint\")\n",
    "            else:\n",
    "                print(f\"Epoch {epoch+1}: Val Loss did not improve from {best_val_loss:.4f}\")\n",
    "    \n",
    "    return best_val_loss\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../Data/Filtered_split_training_data/'\n",
    "chromosome_number = 13\n",
    "file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_split.parquet\"\n",
    "data = pd.read_parquet(file_name)\n",
    "\n",
    "print(\"Unknown PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_Unknown\" in col]].shape[1])\n",
    "print(\"Known PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_Known\" in col]].shape[1])\n",
    "print(\"23AndMe SNPs with LD to Unknown PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_\" not in col]].shape[1])\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "X = torch.tensor(data.filter(regex='^(?!.*Unknown)').values, dtype=torch.float32)\n",
    "y = torch.tensor(data.filter(regex='Unknown').values, dtype=torch.float32)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)\n",
    "\n",
    "# Set up the model, loss function, optimizer, and learning rate scheduler\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size1 = 100\n",
    "hidden_size2 = 100\n",
    "output_size = y_train.shape[1]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleFFNN(input_size, hidden_size1, hidden_size2, output_size).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.01, patience=5, verbose=True)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 400\n",
    "checkpoint_path = f'checkpoint_chr{chromosome_number}.pth'\n",
    "writer = SummaryWriter()\n",
    "best_val_loss = train_and_evaluate_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs, device, writer, checkpoint_path)\n",
    "writer.close()\n",
    "\n",
    "# Load the best model and evaluate on the validation set\n",
    "best_model = SimpleFFNN(input_size, hidden_size1, hidden_size2, output_size).to(device)\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "best_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for batch_X, batch_y in val_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = best_model(batch_X)\n",
    "        val_accuracy = ((outputs > 0.5) == batch_y.to(device)).float().mean()\n",
    "\n",
    "        val_accuracies.append(val_accuracy.cpu())\n",
    "\n",
    "    print(np.mean(val_accuracies))\n",
    "    # val_roc_auc = roc_auc_score(val_labels, val_outputs, average=\"macro\")\n",
    "    \n",
    "    print(f\"Best Model - Val Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:32:50,137] A new study created in memory with name: no-name-3bf43922-6c3e-45b8-8473-b86c21393c53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown PRS313 SNPs:  40\n",
      "Known PRS313 SNPs:  20\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  2204\n",
      "Early stopping at epoch 314\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:32:59,210] Trial 0 finished with value: 0.3783797353506088 and parameters: {'learning_rate': 0.0012230993553987712, 'lasso_coef': 0.00084032479638091, 'patience': 7}. Best is trial 0 with value: 0.3783797353506088.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 337\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:33:08,501] Trial 1 finished with value: 0.6453779369592667 and parameters: {'learning_rate': 0.0008500163745202439, 'lasso_coef': 0.014560640819924553, 'patience': 7}. Best is trial 0 with value: 0.3783797353506088.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 372\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:33:41,057] Trial 2 finished with value: 0.5300840511918068 and parameters: {'learning_rate': 0.00017967507993991836, 'lasso_coef': 0.005757941484843921, 'patience': 13}. Best is trial 0 with value: 0.3783797353506088.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 74\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 31\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:33:44,265] Trial 3 finished with value: 0.288528773188591 and parameters: {'learning_rate': 0.004811801477696267, 'lasso_coef': 0.00028839648982765024, 'patience': 8}. Best is trial 3 with value: 0.288528773188591.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 301\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:33:53,604] Trial 4 finished with value: 0.8530651837587356 and parameters: {'learning_rate': 0.0005962925683419763, 'lasso_coef': 0.05652955567249182, 'patience': 7}. Best is trial 3 with value: 0.288528773188591.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 28\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:34:08,062] Trial 5 finished with value: 0.15138572454452515 and parameters: {'learning_rate': 0.00025826569484393535, 'lasso_coef': 2.4212571923051545e-05, 'patience': 19}. Best is trial 5 with value: 0.15138572454452515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 230\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:34:14,441] Trial 6 finished with value: 0.2772123269736767 and parameters: {'learning_rate': 0.0020299842454766575, 'lasso_coef': 0.00031995805767330153, 'patience': 7}. Best is trial 5 with value: 0.15138572454452515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 228\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:34:33,620] Trial 7 finished with value: 0.5246105745434761 and parameters: {'learning_rate': 0.0003208083678535777, 'lasso_coef': 0.003749399376918273, 'patience': 10}. Best is trial 5 with value: 0.15138572454452515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:34:34,641] Trial 8 finished with value: 0.2780351184308529 and parameters: {'learning_rate': 0.030140900340615246, 'lasso_coef': 6.11461056959539e-05, 'patience': 5}. Best is trial 5 with value: 0.15138572454452515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 219\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 36\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:34:41,959] Trial 9 finished with value: 0.7265065431594848 and parameters: {'learning_rate': 0.0010359556939424357, 'lasso_coef': 0.019319171589928335, 'patience': 8}. Best is trial 5 with value: 0.15138572454452515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:34:55,744] Trial 10 finished with value: 0.17469144389033317 and parameters: {'learning_rate': 0.00010037902987110431, 'lasso_coef': 1.2216297854372993e-05, 'patience': 20}. Best is trial 5 with value: 0.15138572454452515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:35:09,674] Trial 11 finished with value: 0.1323610942810774 and parameters: {'learning_rate': 0.00022694090589234073, 'lasso_coef': 1.1185965483780849e-05, 'patience': 20}. Best is trial 11 with value: 0.1323610942810774.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 189\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:35:15,971] Trial 12 finished with value: 0.09792967177927495 and parameters: {'learning_rate': 0.005822442518770879, 'lasso_coef': 1.245112920869986e-05, 'patience': 20}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 85\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:35:19,668] Trial 13 finished with value: 0.1889827124774456 and parameters: {'learning_rate': 0.009415843072408071, 'lasso_coef': 6.749732293393164e-05, 'patience': 17}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 55\n",
      "Early stopping at epoch 31\n",
      "Early stopping at epoch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:35:24,883] Trial 14 finished with value: 14.277229976654052 and parameters: {'learning_rate': 0.07529232178329552, 'lasso_coef': 1.1728633755372099e-05, 'patience': 16}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 46\n",
      "Early stopping at epoch 86\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:35:28,477] Trial 15 finished with value: 0.1767492800951004 and parameters: {'learning_rate': 0.01067207199144315, 'lasso_coef': 5.3215213612574526e-05, 'patience': 15}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 162\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:35:34,051] Trial 16 finished with value: 0.22922801747918128 and parameters: {'learning_rate': 0.006098835162933512, 'lasso_coef': 0.00015090427158924772, 'patience': 18}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 62\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:35:36,976] Trial 17 finished with value: 0.15852947905659676 and parameters: {'learning_rate': 0.025055457312549587, 'lasso_coef': 2.738555253389191e-05, 'patience': 14}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 203\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:35:44,165] Trial 18 finished with value: 0.41085333228111265 and parameters: {'learning_rate': 0.002761171729740126, 'lasso_coef': 0.000938411635413146, 'patience': 20}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 28\n",
      "Early stopping at epoch 40\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:35:46,544] Trial 19 finished with value: 0.2754417881369591 and parameters: {'learning_rate': 0.023166689936966536, 'lasso_coef': 0.00013795362059224807, 'patience': 12}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 28\n",
      "Early stopping at epoch 47\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:35:52,055] Trial 20 finished with value: 17.93749017715454 and parameters: {'learning_rate': 0.09463688774589732, 'lasso_coef': 1.0052128921987064e-05, 'patience': 18}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 113\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:36:05,621] Trial 21 finished with value: 0.13722888231277466 and parameters: {'learning_rate': 0.0003717269860786281, 'lasso_coef': 2.4023228898377527e-05, 'patience': 19}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:36:19,132] Trial 22 finished with value: 0.13165346272289752 and parameters: {'learning_rate': 0.0005476050885183722, 'lasso_coef': 2.8351343797784366e-05, 'patience': 20}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:36:32,610] Trial 23 finished with value: 0.19493074491620063 and parameters: {'learning_rate': 0.00011359431547411494, 'lasso_coef': 2.453756346556397e-05, 'patience': 17}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 396\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:36:44,152] Trial 24 finished with value: 0.1417758245021105 and parameters: {'learning_rate': 0.0018796331530208754, 'lasso_coef': 4.2862889187872466e-05, 'patience': 20}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:36:59,046] Trial 25 finished with value: 0.2356528416275978 and parameters: {'learning_rate': 0.0004456249578759413, 'lasso_coef': 0.0001851577401378744, 'patience': 16}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:37:13,230] Trial 26 finished with value: 0.22940342873334885 and parameters: {'learning_rate': 0.0001682012453852482, 'lasso_coef': 9.273421086090848e-05, 'patience': 18}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:37:27,411] Trial 27 finished with value: 0.11029199585318565 and parameters: {'learning_rate': 0.0006375238624957426, 'lasso_coef': 1.6204636902237343e-05, 'patience': 19}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 28\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:37:42,131] Trial 28 finished with value: 0.32502795904874804 and parameters: {'learning_rate': 0.0006407595413525471, 'lasso_coef': 0.0005602965905739452, 'patience': 19}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 222\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:37:48,990] Trial 29 finished with value: 0.537722897529602 and parameters: {'learning_rate': 0.0015878758992347907, 'lasso_coef': 0.0025643844123918545, 'patience': 11}. Best is trial 12 with value: 0.09792967177927495.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Best hyperparameters: {'learning_rate': 0.005822442518770879, 'lasso_coef': 1.245112920869986e-05, 'patience': 20}\n",
      "Best value: 0.09792967177927495\n",
      "Epoch [1/500], Train Loss: 0.5972\n",
      "Epoch [2/500], Train Loss: 0.4016\n",
      "Epoch [3/500], Train Loss: 0.3267\n",
      "Epoch [4/500], Train Loss: 0.2814\n",
      "Epoch [5/500], Train Loss: 0.2537\n",
      "Epoch [6/500], Train Loss: 0.2306\n",
      "Epoch [7/500], Train Loss: 0.2133\n",
      "Epoch [8/500], Train Loss: 0.2007\n",
      "Epoch [9/500], Train Loss: 0.1879\n",
      "Epoch [10/500], Train Loss: 0.1784\n",
      "Epoch [11/500], Train Loss: 0.1704\n",
      "Epoch [12/500], Train Loss: 0.1625\n",
      "Epoch [13/500], Train Loss: 0.1579\n",
      "Epoch [14/500], Train Loss: 0.1521\n",
      "Epoch [15/500], Train Loss: 0.1470\n",
      "Epoch [16/500], Train Loss: 0.1425\n",
      "Epoch [17/500], Train Loss: 0.1389\n",
      "Epoch [18/500], Train Loss: 0.1348\n",
      "Epoch [19/500], Train Loss: 0.1316\n",
      "Epoch [20/500], Train Loss: 0.1282\n",
      "Epoch [21/500], Train Loss: 0.1259\n",
      "Epoch [22/500], Train Loss: 0.1229\n",
      "Epoch [23/500], Train Loss: 0.1205\n",
      "Epoch [24/500], Train Loss: 0.1189\n",
      "Epoch [25/500], Train Loss: 0.1167\n",
      "Epoch [26/500], Train Loss: 0.1149\n",
      "Epoch [27/500], Train Loss: 0.1131\n",
      "Epoch [28/500], Train Loss: 0.1114\n",
      "Epoch [29/500], Train Loss: 0.1091\n",
      "Epoch [30/500], Train Loss: 0.1082\n",
      "Epoch [31/500], Train Loss: 0.1070\n",
      "Epoch [32/500], Train Loss: 0.1050\n",
      "Epoch [33/500], Train Loss: 0.1047\n",
      "Epoch [34/500], Train Loss: 0.1039\n",
      "Epoch [35/500], Train Loss: 0.1022\n",
      "Epoch [36/500], Train Loss: 0.1013\n",
      "Epoch [37/500], Train Loss: 0.0998\n",
      "Epoch [38/500], Train Loss: 0.0993\n",
      "Epoch [39/500], Train Loss: 0.0983\n",
      "Epoch [40/500], Train Loss: 0.0974\n",
      "Epoch [41/500], Train Loss: 0.0961\n",
      "Epoch [42/500], Train Loss: 0.0956\n",
      "Epoch [43/500], Train Loss: 0.0946\n",
      "Epoch [44/500], Train Loss: 0.0939\n",
      "Epoch [45/500], Train Loss: 0.0931\n",
      "Epoch [46/500], Train Loss: 0.0925\n",
      "Epoch [47/500], Train Loss: 0.0921\n",
      "Epoch [48/500], Train Loss: 0.0911\n",
      "Epoch [49/500], Train Loss: 0.0910\n",
      "Epoch [50/500], Train Loss: 0.0903\n",
      "Epoch [51/500], Train Loss: 0.0896\n",
      "Epoch [52/500], Train Loss: 0.0889\n",
      "Epoch [53/500], Train Loss: 0.0885\n",
      "Epoch [54/500], Train Loss: 0.0877\n",
      "Epoch [55/500], Train Loss: 0.0874\n",
      "Epoch [56/500], Train Loss: 0.0868\n",
      "Epoch [57/500], Train Loss: 0.0863\n",
      "Epoch [58/500], Train Loss: 0.0860\n",
      "Epoch [59/500], Train Loss: 0.0854\n",
      "Epoch [60/500], Train Loss: 0.0849\n",
      "Epoch [61/500], Train Loss: 0.0849\n",
      "Epoch [62/500], Train Loss: 0.0842\n",
      "Epoch [63/500], Train Loss: 0.0843\n",
      "Epoch [64/500], Train Loss: 0.0836\n",
      "Epoch [65/500], Train Loss: 0.0831\n",
      "Epoch [66/500], Train Loss: 0.0827\n",
      "Epoch [67/500], Train Loss: 0.0822\n",
      "Epoch [68/500], Train Loss: 0.0820\n",
      "Epoch [69/500], Train Loss: 0.0817\n",
      "Epoch [70/500], Train Loss: 0.0822\n",
      "Epoch [71/500], Train Loss: 0.0815\n",
      "Epoch [72/500], Train Loss: 0.0806\n",
      "Epoch [73/500], Train Loss: 0.0804\n",
      "Epoch [74/500], Train Loss: 0.0804\n",
      "Epoch [75/500], Train Loss: 0.0804\n",
      "Epoch [76/500], Train Loss: 0.0794\n",
      "Epoch [77/500], Train Loss: 0.0794\n",
      "Epoch [78/500], Train Loss: 0.0789\n",
      "Epoch [79/500], Train Loss: 0.0787\n",
      "Epoch [80/500], Train Loss: 0.0783\n",
      "Epoch [81/500], Train Loss: 0.0782\n",
      "Epoch [82/500], Train Loss: 0.0782\n",
      "Epoch [83/500], Train Loss: 0.0775\n",
      "Epoch [84/500], Train Loss: 0.0774\n",
      "Epoch [85/500], Train Loss: 0.0773\n",
      "Epoch [86/500], Train Loss: 0.0774\n",
      "Epoch [87/500], Train Loss: 0.0768\n",
      "Epoch [88/500], Train Loss: 0.0764\n",
      "Epoch [89/500], Train Loss: 0.0769\n",
      "Epoch [90/500], Train Loss: 0.0763\n",
      "Epoch [91/500], Train Loss: 0.0761\n",
      "Epoch [92/500], Train Loss: 0.0761\n",
      "Epoch [93/500], Train Loss: 0.0754\n",
      "Epoch [94/500], Train Loss: 0.0756\n",
      "Epoch [95/500], Train Loss: 0.0760\n",
      "Epoch [96/500], Train Loss: 0.0752\n",
      "Epoch [97/500], Train Loss: 0.0746\n",
      "Epoch [98/500], Train Loss: 0.0746\n",
      "Epoch [99/500], Train Loss: 0.0746\n",
      "Epoch [100/500], Train Loss: 0.0746\n",
      "Epoch [101/500], Train Loss: 0.0740\n",
      "Epoch [102/500], Train Loss: 0.0738\n",
      "Epoch [103/500], Train Loss: 0.0737\n",
      "Epoch [104/500], Train Loss: 0.0740\n",
      "Epoch [105/500], Train Loss: 0.0735\n",
      "Epoch [106/500], Train Loss: 0.0736\n",
      "Epoch [107/500], Train Loss: 0.0735\n",
      "Epoch [108/500], Train Loss: 0.0732\n",
      "Epoch [109/500], Train Loss: 0.0732\n",
      "Epoch [110/500], Train Loss: 0.0734\n",
      "Epoch [111/500], Train Loss: 0.0727\n",
      "Epoch [112/500], Train Loss: 0.0724\n",
      "Epoch [113/500], Train Loss: 0.0726\n",
      "Epoch [114/500], Train Loss: 0.0727\n",
      "Epoch [115/500], Train Loss: 0.0725\n",
      "Epoch [116/500], Train Loss: 0.0722\n",
      "Epoch [117/500], Train Loss: 0.0719\n",
      "Epoch [118/500], Train Loss: 0.0723\n",
      "Epoch [119/500], Train Loss: 0.0720\n",
      "Epoch [120/500], Train Loss: 0.0718\n",
      "Epoch [121/500], Train Loss: 0.0716\n",
      "Epoch [122/500], Train Loss: 0.0715\n",
      "Epoch [123/500], Train Loss: 0.0714\n",
      "Epoch [124/500], Train Loss: 0.0714\n",
      "Epoch [125/500], Train Loss: 0.0713\n",
      "Epoch [126/500], Train Loss: 0.0709\n",
      "Epoch [127/500], Train Loss: 0.0708\n",
      "Epoch [128/500], Train Loss: 0.0706\n",
      "Epoch [129/500], Train Loss: 0.0706\n",
      "Epoch [130/500], Train Loss: 0.0706\n",
      "Epoch [131/500], Train Loss: 0.0707\n",
      "Epoch [132/500], Train Loss: 0.0709\n",
      "Epoch [133/500], Train Loss: 0.0700\n",
      "Epoch [134/500], Train Loss: 0.0702\n",
      "Epoch [135/500], Train Loss: 0.0702\n",
      "Epoch [136/500], Train Loss: 0.0700\n",
      "Epoch [137/500], Train Loss: 0.0699\n",
      "Epoch [138/500], Train Loss: 0.0697\n",
      "Epoch [139/500], Train Loss: 0.0694\n",
      "Epoch [140/500], Train Loss: 0.0696\n",
      "Epoch [141/500], Train Loss: 0.0694\n",
      "Epoch [142/500], Train Loss: 0.0691\n",
      "Epoch [143/500], Train Loss: 0.0691\n",
      "Epoch [144/500], Train Loss: 0.0694\n",
      "Epoch [145/500], Train Loss: 0.0695\n",
      "Epoch [146/500], Train Loss: 0.0690\n",
      "Epoch [147/500], Train Loss: 0.0693\n",
      "Epoch [148/500], Train Loss: 0.0694\n",
      "Epoch [149/500], Train Loss: 0.0692\n",
      "Epoch [150/500], Train Loss: 0.0690\n",
      "Epoch [151/500], Train Loss: 0.0689\n",
      "Epoch [152/500], Train Loss: 0.0684\n",
      "Epoch [153/500], Train Loss: 0.0685\n",
      "Epoch [154/500], Train Loss: 0.0687\n",
      "Epoch [155/500], Train Loss: 0.0686\n",
      "Epoch [156/500], Train Loss: 0.0686\n",
      "Epoch [157/500], Train Loss: 0.0688\n",
      "Epoch [158/500], Train Loss: 0.0687\n",
      "Epoch [159/500], Train Loss: 0.0690\n",
      "Epoch [160/500], Train Loss: 0.0682\n",
      "Epoch [161/500], Train Loss: 0.0679\n",
      "Epoch [162/500], Train Loss: 0.0682\n",
      "Epoch [163/500], Train Loss: 0.0683\n",
      "Epoch [164/500], Train Loss: 0.0679\n",
      "Epoch [165/500], Train Loss: 0.0682\n",
      "Epoch [166/500], Train Loss: 0.0683\n",
      "Epoch [167/500], Train Loss: 0.0681\n",
      "Epoch [168/500], Train Loss: 0.0680\n",
      "Epoch [169/500], Train Loss: 0.0676\n",
      "Epoch [170/500], Train Loss: 0.0680\n",
      "Epoch [171/500], Train Loss: 0.0677\n",
      "Epoch [172/500], Train Loss: 0.0674\n",
      "Epoch [173/500], Train Loss: 0.0675\n",
      "Epoch [174/500], Train Loss: 0.0677\n",
      "Epoch [175/500], Train Loss: 0.0678\n",
      "Epoch [176/500], Train Loss: 0.0676\n",
      "Epoch [177/500], Train Loss: 0.0674\n",
      "Epoch [178/500], Train Loss: 0.0678\n",
      "Epoch [179/500], Train Loss: 0.0674\n",
      "Epoch [180/500], Train Loss: 0.0676\n",
      "Epoch [181/500], Train Loss: 0.0680\n",
      "Epoch [182/500], Train Loss: 0.0684\n",
      "Epoch [183/500], Train Loss: 0.0677\n",
      "Epoch [184/500], Train Loss: 0.0682\n",
      "Epoch [185/500], Train Loss: 0.0677\n",
      "Epoch [186/500], Train Loss: 0.0670\n",
      "Epoch [187/500], Train Loss: 0.0666\n",
      "Epoch [188/500], Train Loss: 0.0665\n",
      "Epoch [189/500], Train Loss: 0.0672\n",
      "Epoch [190/500], Train Loss: 0.0674\n",
      "Epoch [191/500], Train Loss: 0.0669\n",
      "Epoch [192/500], Train Loss: 0.0672\n",
      "Epoch [193/500], Train Loss: 0.0672\n",
      "Epoch [194/500], Train Loss: 0.0673\n",
      "Epoch [195/500], Train Loss: 0.0675\n",
      "Epoch [196/500], Train Loss: 0.0669\n",
      "Epoch [197/500], Train Loss: 0.0667\n",
      "Epoch [198/500], Train Loss: 0.0672\n",
      "Epoch [199/500], Train Loss: 0.0666\n",
      "Epoch [200/500], Train Loss: 0.0666\n",
      "Epoch [201/500], Train Loss: 0.0663\n",
      "Epoch [202/500], Train Loss: 0.0666\n",
      "Epoch [203/500], Train Loss: 0.0665\n",
      "Epoch [204/500], Train Loss: 0.0664\n",
      "Epoch [205/500], Train Loss: 0.0669\n",
      "Epoch [206/500], Train Loss: 0.0668\n",
      "Epoch [207/500], Train Loss: 0.0664\n",
      "Epoch [208/500], Train Loss: 0.0664\n",
      "Epoch [209/500], Train Loss: 0.0663\n",
      "Epoch [210/500], Train Loss: 0.0659\n",
      "Epoch [211/500], Train Loss: 0.0662\n",
      "Epoch [212/500], Train Loss: 0.0664\n",
      "Epoch [213/500], Train Loss: 0.0662\n",
      "Epoch [214/500], Train Loss: 0.0661\n",
      "Epoch [215/500], Train Loss: 0.0662\n",
      "Epoch [216/500], Train Loss: 0.0666\n",
      "Epoch [217/500], Train Loss: 0.0664\n",
      "Epoch [218/500], Train Loss: 0.0669\n",
      "Epoch [219/500], Train Loss: 0.0660\n",
      "Epoch [220/500], Train Loss: 0.0659\n",
      "Epoch [221/500], Train Loss: 0.0660\n",
      "Epoch [222/500], Train Loss: 0.0661\n",
      "Epoch [223/500], Train Loss: 0.0661\n",
      "Epoch [224/500], Train Loss: 0.0664\n",
      "Epoch [225/500], Train Loss: 0.0662\n",
      "Epoch [226/500], Train Loss: 0.0658\n",
      "Epoch [227/500], Train Loss: 0.0661\n",
      "Epoch [228/500], Train Loss: 0.0657\n",
      "Epoch [229/500], Train Loss: 0.0658\n",
      "Epoch [230/500], Train Loss: 0.0659\n",
      "Epoch [231/500], Train Loss: 0.0658\n",
      "Epoch [232/500], Train Loss: 0.0663\n",
      "Epoch [233/500], Train Loss: 0.0661\n",
      "Epoch [234/500], Train Loss: 0.0659\n",
      "Epoch [235/500], Train Loss: 0.0664\n",
      "Epoch [236/500], Train Loss: 0.0663\n",
      "Epoch [237/500], Train Loss: 0.0658\n",
      "Epoch [238/500], Train Loss: 0.0663\n",
      "Epoch [239/500], Train Loss: 0.0665\n",
      "Epoch [240/500], Train Loss: 0.0663\n",
      "Epoch [241/500], Train Loss: 0.0662\n",
      "Epoch [242/500], Train Loss: 0.0658\n",
      "Epoch [243/500], Train Loss: 0.0656\n",
      "Epoch [244/500], Train Loss: 0.0655\n",
      "Epoch [245/500], Train Loss: 0.0659\n",
      "Epoch [246/500], Train Loss: 0.0659\n",
      "Epoch [247/500], Train Loss: 0.0660\n",
      "Epoch [248/500], Train Loss: 0.0658\n",
      "Epoch [249/500], Train Loss: 0.0664\n",
      "Epoch [250/500], Train Loss: 0.0655\n",
      "Epoch [251/500], Train Loss: 0.0661\n",
      "Epoch [252/500], Train Loss: 0.0656\n",
      "Epoch [253/500], Train Loss: 0.0662\n",
      "Epoch [254/500], Train Loss: 0.0662\n",
      "Epoch [255/500], Train Loss: 0.0657\n",
      "Epoch [256/500], Train Loss: 0.0654\n",
      "Epoch [257/500], Train Loss: 0.0652\n",
      "Epoch [258/500], Train Loss: 0.0656\n",
      "Epoch [259/500], Train Loss: 0.0656\n",
      "Epoch [260/500], Train Loss: 0.0657\n",
      "Epoch [261/500], Train Loss: 0.0652\n",
      "Epoch [262/500], Train Loss: 0.0651\n",
      "Epoch [263/500], Train Loss: 0.0650\n",
      "Epoch [264/500], Train Loss: 0.0651\n",
      "Epoch [265/500], Train Loss: 0.0656\n",
      "Epoch [266/500], Train Loss: 0.0657\n",
      "Epoch [267/500], Train Loss: 0.0656\n",
      "Epoch [268/500], Train Loss: 0.0653\n",
      "Epoch [269/500], Train Loss: 0.0650\n",
      "Epoch [270/500], Train Loss: 0.0653\n",
      "Epoch [271/500], Train Loss: 0.0652\n",
      "Epoch [272/500], Train Loss: 0.0656\n",
      "Epoch [273/500], Train Loss: 0.0654\n",
      "Epoch [274/500], Train Loss: 0.0656\n",
      "Epoch [275/500], Train Loss: 0.0654\n",
      "Epoch [276/500], Train Loss: 0.0655\n",
      "Epoch [277/500], Train Loss: 0.0657\n",
      "Epoch [278/500], Train Loss: 0.0656\n",
      "Epoch [279/500], Train Loss: 0.0649\n",
      "Epoch [280/500], Train Loss: 0.0646\n",
      "Epoch [281/500], Train Loss: 0.0646\n",
      "Epoch [282/500], Train Loss: 0.0650\n",
      "Epoch [283/500], Train Loss: 0.0652\n",
      "Epoch [284/500], Train Loss: 0.0650\n",
      "Epoch [285/500], Train Loss: 0.0650\n",
      "Epoch [286/500], Train Loss: 0.0654\n",
      "Epoch [287/500], Train Loss: 0.0653\n",
      "Epoch [288/500], Train Loss: 0.0648\n",
      "Epoch [289/500], Train Loss: 0.0646\n",
      "Epoch [290/500], Train Loss: 0.0644\n",
      "Epoch [291/500], Train Loss: 0.0642\n",
      "Epoch [292/500], Train Loss: 0.0648\n",
      "Epoch [293/500], Train Loss: 0.0651\n",
      "Epoch [294/500], Train Loss: 0.0652\n",
      "Epoch [295/500], Train Loss: 0.0661\n",
      "Epoch [296/500], Train Loss: 0.0655\n",
      "Epoch [297/500], Train Loss: 0.0649\n",
      "Epoch [298/500], Train Loss: 0.0651\n",
      "Epoch [299/500], Train Loss: 0.0652\n",
      "Epoch [300/500], Train Loss: 0.0655\n",
      "Epoch [301/500], Train Loss: 0.0659\n",
      "Epoch [302/500], Train Loss: 0.0662\n",
      "Epoch [303/500], Train Loss: 0.0660\n",
      "Epoch [304/500], Train Loss: 0.0655\n",
      "Epoch [305/500], Train Loss: 0.0651\n",
      "Epoch [306/500], Train Loss: 0.0651\n",
      "Epoch [307/500], Train Loss: 0.0655\n",
      "Epoch [308/500], Train Loss: 0.0654\n",
      "Epoch [309/500], Train Loss: 0.0647\n",
      "Epoch [310/500], Train Loss: 0.0648\n",
      "Epoch [311/500], Train Loss: 0.0648\n",
      "Early stopping at epoch 311\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr1/final_model_chr1.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr1/individual_r2_scores_chr1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:37:58,907] A new study created in memory with name: no-name-d852e783-7784-4807-a47e-39f56540266f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  34\n",
      "Known PRS313 SNPs:  8\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  1542\n",
      "Early stopping at epoch 191\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:38:12,744] Trial 0 finished with value: 0.557692351937294 and parameters: {'learning_rate': 0.0005431821080465398, 'lasso_coef': 0.00672578913091179, 'patience': 19}. Best is trial 0 with value: 0.557692351937294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:38:23,464] Trial 1 finished with value: 0.12255742438137532 and parameters: {'learning_rate': 0.0006757333091883756, 'lasso_coef': 1.0514718839941681e-05, 'patience': 18}. Best is trial 1 with value: 0.12255742438137532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:38:42,612] Trial 2 finished with value: 0.31015593111515044 and parameters: {'learning_rate': 0.0003224591454966812, 'lasso_coef': 0.0005517485116462356, 'patience': 8}. Best is trial 1 with value: 0.12255742438137532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:38:53,826] Trial 3 finished with value: 0.20276923030614852 and parameters: {'learning_rate': 0.000888693006237092, 'lasso_coef': 0.00012900058023496093, 'patience': 14}. Best is trial 1 with value: 0.12255742438137532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 328\n",
      "Early stopping at epoch 81\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:39:02,685] Trial 4 finished with value: 0.473009929060936 and parameters: {'learning_rate': 0.0007022628250607429, 'lasso_coef': 0.0022234296389095232, 'patience': 6}. Best is trial 1 with value: 0.12255742438137532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 99\n",
      "Early stopping at epoch 50\n",
      "Early stopping at epoch 32\n",
      "Early stopping at epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:39:07,454] Trial 5 finished with value: 6.089724731445313 and parameters: {'learning_rate': 0.012267388660734142, 'lasso_coef': 0.0789666724085997, 'patience': 18}. Best is trial 1 with value: 0.12255742438137532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 32\n",
      "Early stopping at epoch 32\n",
      "Early stopping at epoch 28\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:39:10,627] Trial 6 finished with value: 39.95237483978271 and parameters: {'learning_rate': 0.07193615462900571, 'lasso_coef': 0.09675873189985741, 'patience': 13}. Best is trial 1 with value: 0.12255742438137532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 46\n",
      "Early stopping at epoch 117\n",
      "Early stopping at epoch 49\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:39:15,318] Trial 7 finished with value: 0.3969737932085991 and parameters: {'learning_rate': 0.005931272565264708, 'lasso_coef': 0.0009231594282576222, 'patience': 14}. Best is trial 1 with value: 0.12255742438137532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 128\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 40\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:39:19,844] Trial 8 finished with value: 0.7242571979761123 and parameters: {'learning_rate': 0.0043028350063011945, 'lasso_coef': 0.006658153173588802, 'patience': 13}. Best is trial 1 with value: 0.12255742438137532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 37\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:39:31,195] Trial 9 finished with value: 0.21007517948746682 and parameters: {'learning_rate': 0.0006690931970079485, 'lasso_coef': 0.00013608027983998578, 'patience': 15}. Best is trial 1 with value: 0.12255742438137532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:39:43,306] Trial 10 finished with value: 0.21444813385605813 and parameters: {'learning_rate': 0.00010144509469179964, 'lasso_coef': 1.5842448085991822e-05, 'patience': 20}. Best is trial 1 with value: 0.12255742438137532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 441\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:39:54,053] Trial 11 finished with value: 0.1123901892453432 and parameters: {'learning_rate': 0.001684734432618489, 'lasso_coef': 1.0236102018223853e-05, 'patience': 17}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 343\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:40:02,702] Trial 12 finished with value: 0.11449868977069855 and parameters: {'learning_rate': 0.0021499607291298605, 'lasso_coef': 1.0615585711764306e-05, 'patience': 17}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 246\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:40:08,821] Trial 13 finished with value: 0.16454023644328117 and parameters: {'learning_rate': 0.0021426959547714074, 'lasso_coef': 4.950608522569024e-05, 'patience': 10}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 60\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:40:11,345] Trial 14 finished with value: 0.17378832921385765 and parameters: {'learning_rate': 0.018163702353010097, 'lasso_coef': 3.9261086022400434e-05, 'patience': 16}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:40:22,963] Trial 15 finished with value: 0.2199833333492279 and parameters: {'learning_rate': 0.0013252456595059749, 'lasso_coef': 0.00019149628031524634, 'patience': 17}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 72\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:40:25,225] Trial 16 finished with value: 0.16166824996471404 and parameters: {'learning_rate': 0.010382611072558785, 'lasso_coef': 3.589728691792987e-05, 'patience': 10}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 234\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:40:31,538] Trial 17 finished with value: 0.11843556948006154 and parameters: {'learning_rate': 0.002642823700169877, 'lasso_coef': 1.040547877899099e-05, 'patience': 16}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:40:42,487] Trial 18 finished with value: 0.19362886846065522 and parameters: {'learning_rate': 0.00020385362680147706, 'lasso_coef': 3.059941601035886e-05, 'patience': 11}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 417\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:40:52,721] Trial 19 finished with value: 0.24543210119009018 and parameters: {'learning_rate': 0.001866122266868212, 'lasso_coef': 0.0002797143480069898, 'patience': 19}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 48\n",
      "Early stopping at epoch 32\n",
      "Early stopping at epoch 37\n",
      "Early stopping at epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:40:57,092] Trial 20 finished with value: 5.537977075576782 and parameters: {'learning_rate': 0.03786289408127202, 'lasso_coef': 0.021320299316485655, 'patience': 20}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 52\n",
      "Early stopping at epoch 252\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:41:03,489] Trial 21 finished with value: 0.11724339835345746 and parameters: {'learning_rate': 0.002868107893054779, 'lasso_coef': 1.0983820747279357e-05, 'patience': 16}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 133\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:41:07,765] Trial 22 finished with value: 0.1956746071577072 and parameters: {'learning_rate': 0.006960109755319037, 'lasso_coef': 8.724886930852572e-05, 'patience': 16}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 287\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:41:14,648] Trial 23 finished with value: 0.13146016262471677 and parameters: {'learning_rate': 0.0033537268751170227, 'lasso_coef': 2.1758794520359383e-05, 'patience': 17}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 449\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:41:25,151] Trial 24 finished with value: 0.16742324605584144 and parameters: {'learning_rate': 0.0013103319525099861, 'lasso_coef': 6.142926072209718e-05, 'patience': 15}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 256\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:41:31,595] Trial 25 finished with value: 0.12985907047986983 and parameters: {'learning_rate': 0.004443491036737264, 'lasso_coef': 1.9839700980855455e-05, 'patience': 18}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 163\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:41:35,830] Trial 26 finished with value: 0.14219216965138912 and parameters: {'learning_rate': 0.0012441967735490058, 'lasso_coef': 1.041193988922592e-05, 'patience': 12}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:41:47,231] Trial 27 finished with value: 0.20095755085349082 and parameters: {'learning_rate': 0.0003436227165974164, 'lasso_coef': 7.421669254737094e-05, 'patience': 15}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 324\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:41:55,460] Trial 28 finished with value: 0.26513088345527647 and parameters: {'learning_rate': 0.0021810773836240423, 'lasso_coef': 0.0003504110857378195, 'patience': 17}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 53\n",
      "Early stopping at epoch 37\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:41:58,805] Trial 29 finished with value: 0.9870397299528122 and parameters: {'learning_rate': 0.022896183207356344, 'lasso_coef': 0.003151834433680785, 'patience': 19}. Best is trial 11 with value: 0.1123901892453432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 30\n",
      "Best hyperparameters: {'learning_rate': 0.001684734432618489, 'lasso_coef': 1.0236102018223853e-05, 'patience': 17}\n",
      "Best value: 0.1123901892453432\n",
      "Epoch [1/500], Train Loss: 0.5456\n",
      "Epoch [2/500], Train Loss: 0.4739\n",
      "Epoch [3/500], Train Loss: 0.4366\n",
      "Epoch [4/500], Train Loss: 0.4087\n",
      "Epoch [5/500], Train Loss: 0.3854\n",
      "Epoch [6/500], Train Loss: 0.3662\n",
      "Epoch [7/500], Train Loss: 0.3490\n",
      "Epoch [8/500], Train Loss: 0.3339\n",
      "Epoch [9/500], Train Loss: 0.3211\n",
      "Epoch [10/500], Train Loss: 0.3082\n",
      "Epoch [11/500], Train Loss: 0.2976\n",
      "Epoch [12/500], Train Loss: 0.2880\n",
      "Epoch [13/500], Train Loss: 0.2796\n",
      "Epoch [14/500], Train Loss: 0.2701\n",
      "Epoch [15/500], Train Loss: 0.2631\n",
      "Epoch [16/500], Train Loss: 0.2568\n",
      "Epoch [17/500], Train Loss: 0.2500\n",
      "Epoch [18/500], Train Loss: 0.2435\n",
      "Epoch [19/500], Train Loss: 0.2376\n",
      "Epoch [20/500], Train Loss: 0.2324\n",
      "Epoch [21/500], Train Loss: 0.2279\n",
      "Epoch [22/500], Train Loss: 0.2230\n",
      "Epoch [23/500], Train Loss: 0.2181\n",
      "Epoch [24/500], Train Loss: 0.2140\n",
      "Epoch [25/500], Train Loss: 0.2109\n",
      "Epoch [26/500], Train Loss: 0.2071\n",
      "Epoch [27/500], Train Loss: 0.2034\n",
      "Epoch [28/500], Train Loss: 0.1999\n",
      "Epoch [29/500], Train Loss: 0.1969\n",
      "Epoch [30/500], Train Loss: 0.1937\n",
      "Epoch [31/500], Train Loss: 0.1908\n",
      "Epoch [32/500], Train Loss: 0.1884\n",
      "Epoch [33/500], Train Loss: 0.1859\n",
      "Epoch [34/500], Train Loss: 0.1832\n",
      "Epoch [35/500], Train Loss: 0.1806\n",
      "Epoch [36/500], Train Loss: 0.1782\n",
      "Epoch [37/500], Train Loss: 0.1758\n",
      "Epoch [38/500], Train Loss: 0.1734\n",
      "Epoch [39/500], Train Loss: 0.1716\n",
      "Epoch [40/500], Train Loss: 0.1694\n",
      "Epoch [41/500], Train Loss: 0.1674\n",
      "Epoch [42/500], Train Loss: 0.1659\n",
      "Epoch [43/500], Train Loss: 0.1642\n",
      "Epoch [44/500], Train Loss: 0.1621\n",
      "Epoch [45/500], Train Loss: 0.1602\n",
      "Epoch [46/500], Train Loss: 0.1588\n",
      "Epoch [47/500], Train Loss: 0.1575\n",
      "Epoch [48/500], Train Loss: 0.1557\n",
      "Epoch [49/500], Train Loss: 0.1541\n",
      "Epoch [50/500], Train Loss: 0.1531\n",
      "Epoch [51/500], Train Loss: 0.1517\n",
      "Epoch [52/500], Train Loss: 0.1505\n",
      "Epoch [53/500], Train Loss: 0.1497\n",
      "Epoch [54/500], Train Loss: 0.1476\n",
      "Epoch [55/500], Train Loss: 0.1462\n",
      "Epoch [56/500], Train Loss: 0.1450\n",
      "Epoch [57/500], Train Loss: 0.1437\n",
      "Epoch [58/500], Train Loss: 0.1429\n",
      "Epoch [59/500], Train Loss: 0.1416\n",
      "Epoch [60/500], Train Loss: 0.1406\n",
      "Epoch [61/500], Train Loss: 0.1395\n",
      "Epoch [62/500], Train Loss: 0.1382\n",
      "Epoch [63/500], Train Loss: 0.1370\n",
      "Epoch [64/500], Train Loss: 0.1363\n",
      "Epoch [65/500], Train Loss: 0.1355\n",
      "Epoch [66/500], Train Loss: 0.1344\n",
      "Epoch [67/500], Train Loss: 0.1338\n",
      "Epoch [68/500], Train Loss: 0.1327\n",
      "Epoch [69/500], Train Loss: 0.1317\n",
      "Epoch [70/500], Train Loss: 0.1307\n",
      "Epoch [71/500], Train Loss: 0.1301\n",
      "Epoch [72/500], Train Loss: 0.1295\n",
      "Epoch [73/500], Train Loss: 0.1288\n",
      "Epoch [74/500], Train Loss: 0.1279\n",
      "Epoch [75/500], Train Loss: 0.1270\n",
      "Epoch [76/500], Train Loss: 0.1260\n",
      "Epoch [77/500], Train Loss: 0.1254\n",
      "Epoch [78/500], Train Loss: 0.1247\n",
      "Epoch [79/500], Train Loss: 0.1241\n",
      "Epoch [80/500], Train Loss: 0.1234\n",
      "Epoch [81/500], Train Loss: 0.1224\n",
      "Epoch [82/500], Train Loss: 0.1219\n",
      "Epoch [83/500], Train Loss: 0.1211\n",
      "Epoch [84/500], Train Loss: 0.1206\n",
      "Epoch [85/500], Train Loss: 0.1200\n",
      "Epoch [86/500], Train Loss: 0.1192\n",
      "Epoch [87/500], Train Loss: 0.1189\n",
      "Epoch [88/500], Train Loss: 0.1182\n",
      "Epoch [89/500], Train Loss: 0.1178\n",
      "Epoch [90/500], Train Loss: 0.1173\n",
      "Epoch [91/500], Train Loss: 0.1166\n",
      "Epoch [92/500], Train Loss: 0.1159\n",
      "Epoch [93/500], Train Loss: 0.1152\n",
      "Epoch [94/500], Train Loss: 0.1151\n",
      "Epoch [95/500], Train Loss: 0.1142\n",
      "Epoch [96/500], Train Loss: 0.1139\n",
      "Epoch [97/500], Train Loss: 0.1136\n",
      "Epoch [98/500], Train Loss: 0.1127\n",
      "Epoch [99/500], Train Loss: 0.1122\n",
      "Epoch [100/500], Train Loss: 0.1118\n",
      "Epoch [101/500], Train Loss: 0.1114\n",
      "Epoch [102/500], Train Loss: 0.1109\n",
      "Epoch [103/500], Train Loss: 0.1105\n",
      "Epoch [104/500], Train Loss: 0.1099\n",
      "Epoch [105/500], Train Loss: 0.1094\n",
      "Epoch [106/500], Train Loss: 0.1092\n",
      "Epoch [107/500], Train Loss: 0.1087\n",
      "Epoch [108/500], Train Loss: 0.1079\n",
      "Epoch [109/500], Train Loss: 0.1076\n",
      "Epoch [110/500], Train Loss: 0.1069\n",
      "Epoch [111/500], Train Loss: 0.1067\n",
      "Epoch [112/500], Train Loss: 0.1064\n",
      "Epoch [113/500], Train Loss: 0.1059\n",
      "Epoch [114/500], Train Loss: 0.1056\n",
      "Epoch [115/500], Train Loss: 0.1050\n",
      "Epoch [116/500], Train Loss: 0.1047\n",
      "Epoch [117/500], Train Loss: 0.1044\n",
      "Epoch [118/500], Train Loss: 0.1041\n",
      "Epoch [119/500], Train Loss: 0.1037\n",
      "Epoch [120/500], Train Loss: 0.1031\n",
      "Epoch [121/500], Train Loss: 0.1029\n",
      "Epoch [122/500], Train Loss: 0.1025\n",
      "Epoch [123/500], Train Loss: 0.1021\n",
      "Epoch [124/500], Train Loss: 0.1018\n",
      "Epoch [125/500], Train Loss: 0.1013\n",
      "Epoch [126/500], Train Loss: 0.1012\n",
      "Epoch [127/500], Train Loss: 0.1007\n",
      "Epoch [128/500], Train Loss: 0.1004\n",
      "Epoch [129/500], Train Loss: 0.1001\n",
      "Epoch [130/500], Train Loss: 0.1000\n",
      "Epoch [131/500], Train Loss: 0.0995\n",
      "Epoch [132/500], Train Loss: 0.0993\n",
      "Epoch [133/500], Train Loss: 0.0991\n",
      "Epoch [134/500], Train Loss: 0.0988\n",
      "Epoch [135/500], Train Loss: 0.0984\n",
      "Epoch [136/500], Train Loss: 0.0982\n",
      "Epoch [137/500], Train Loss: 0.0981\n",
      "Epoch [138/500], Train Loss: 0.0974\n",
      "Epoch [139/500], Train Loss: 0.0973\n",
      "Epoch [140/500], Train Loss: 0.0968\n",
      "Epoch [141/500], Train Loss: 0.0968\n",
      "Epoch [142/500], Train Loss: 0.0964\n",
      "Epoch [143/500], Train Loss: 0.0960\n",
      "Epoch [144/500], Train Loss: 0.0960\n",
      "Epoch [145/500], Train Loss: 0.0955\n",
      "Epoch [146/500], Train Loss: 0.0951\n",
      "Epoch [147/500], Train Loss: 0.0950\n",
      "Epoch [148/500], Train Loss: 0.0947\n",
      "Epoch [149/500], Train Loss: 0.0945\n",
      "Epoch [150/500], Train Loss: 0.0942\n",
      "Epoch [151/500], Train Loss: 0.0940\n",
      "Epoch [152/500], Train Loss: 0.0940\n",
      "Epoch [153/500], Train Loss: 0.0936\n",
      "Epoch [154/500], Train Loss: 0.0934\n",
      "Epoch [155/500], Train Loss: 0.0930\n",
      "Epoch [156/500], Train Loss: 0.0927\n",
      "Epoch [157/500], Train Loss: 0.0925\n",
      "Epoch [158/500], Train Loss: 0.0922\n",
      "Epoch [159/500], Train Loss: 0.0922\n",
      "Epoch [160/500], Train Loss: 0.0918\n",
      "Epoch [161/500], Train Loss: 0.0915\n",
      "Epoch [162/500], Train Loss: 0.0915\n",
      "Epoch [163/500], Train Loss: 0.0912\n",
      "Epoch [164/500], Train Loss: 0.0911\n",
      "Epoch [165/500], Train Loss: 0.0908\n",
      "Epoch [166/500], Train Loss: 0.0909\n",
      "Epoch [167/500], Train Loss: 0.0905\n",
      "Epoch [168/500], Train Loss: 0.0900\n",
      "Epoch [169/500], Train Loss: 0.0899\n",
      "Epoch [170/500], Train Loss: 0.0898\n",
      "Epoch [171/500], Train Loss: 0.0895\n",
      "Epoch [172/500], Train Loss: 0.0893\n",
      "Epoch [173/500], Train Loss: 0.0891\n",
      "Epoch [174/500], Train Loss: 0.0890\n",
      "Epoch [175/500], Train Loss: 0.0886\n",
      "Epoch [176/500], Train Loss: 0.0884\n",
      "Epoch [177/500], Train Loss: 0.0882\n",
      "Epoch [178/500], Train Loss: 0.0881\n",
      "Epoch [179/500], Train Loss: 0.0880\n",
      "Epoch [180/500], Train Loss: 0.0877\n",
      "Epoch [181/500], Train Loss: 0.0875\n",
      "Epoch [182/500], Train Loss: 0.0873\n",
      "Epoch [183/500], Train Loss: 0.0872\n",
      "Epoch [184/500], Train Loss: 0.0871\n",
      "Epoch [185/500], Train Loss: 0.0869\n",
      "Epoch [186/500], Train Loss: 0.0868\n",
      "Epoch [187/500], Train Loss: 0.0864\n",
      "Epoch [188/500], Train Loss: 0.0862\n",
      "Epoch [189/500], Train Loss: 0.0863\n",
      "Epoch [190/500], Train Loss: 0.0860\n",
      "Epoch [191/500], Train Loss: 0.0860\n",
      "Epoch [192/500], Train Loss: 0.0857\n",
      "Epoch [193/500], Train Loss: 0.0856\n",
      "Epoch [194/500], Train Loss: 0.0851\n",
      "Epoch [195/500], Train Loss: 0.0851\n",
      "Epoch [196/500], Train Loss: 0.0852\n",
      "Epoch [197/500], Train Loss: 0.0849\n",
      "Epoch [198/500], Train Loss: 0.0847\n",
      "Epoch [199/500], Train Loss: 0.0846\n",
      "Epoch [200/500], Train Loss: 0.0843\n",
      "Epoch [201/500], Train Loss: 0.0843\n",
      "Epoch [202/500], Train Loss: 0.0840\n",
      "Epoch [203/500], Train Loss: 0.0839\n",
      "Epoch [204/500], Train Loss: 0.0836\n",
      "Epoch [205/500], Train Loss: 0.0836\n",
      "Epoch [206/500], Train Loss: 0.0837\n",
      "Epoch [207/500], Train Loss: 0.0835\n",
      "Epoch [208/500], Train Loss: 0.0833\n",
      "Epoch [209/500], Train Loss: 0.0831\n",
      "Epoch [210/500], Train Loss: 0.0830\n",
      "Epoch [211/500], Train Loss: 0.0827\n",
      "Epoch [212/500], Train Loss: 0.0826\n",
      "Epoch [213/500], Train Loss: 0.0825\n",
      "Epoch [214/500], Train Loss: 0.0825\n",
      "Epoch [215/500], Train Loss: 0.0820\n",
      "Epoch [216/500], Train Loss: 0.0820\n",
      "Epoch [217/500], Train Loss: 0.0819\n",
      "Epoch [218/500], Train Loss: 0.0818\n",
      "Epoch [219/500], Train Loss: 0.0816\n",
      "Epoch [220/500], Train Loss: 0.0816\n",
      "Epoch [221/500], Train Loss: 0.0815\n",
      "Epoch [222/500], Train Loss: 0.0814\n",
      "Epoch [223/500], Train Loss: 0.0811\n",
      "Epoch [224/500], Train Loss: 0.0811\n",
      "Epoch [225/500], Train Loss: 0.0807\n",
      "Epoch [226/500], Train Loss: 0.0806\n",
      "Epoch [227/500], Train Loss: 0.0806\n",
      "Epoch [228/500], Train Loss: 0.0806\n",
      "Epoch [229/500], Train Loss: 0.0805\n",
      "Epoch [230/500], Train Loss: 0.0804\n",
      "Epoch [231/500], Train Loss: 0.0802\n",
      "Epoch [232/500], Train Loss: 0.0802\n",
      "Epoch [233/500], Train Loss: 0.0800\n",
      "Epoch [234/500], Train Loss: 0.0799\n",
      "Epoch [235/500], Train Loss: 0.0798\n",
      "Epoch [236/500], Train Loss: 0.0795\n",
      "Epoch [237/500], Train Loss: 0.0793\n",
      "Epoch [238/500], Train Loss: 0.0793\n",
      "Epoch [239/500], Train Loss: 0.0792\n",
      "Epoch [240/500], Train Loss: 0.0793\n",
      "Epoch [241/500], Train Loss: 0.0790\n",
      "Epoch [242/500], Train Loss: 0.0786\n",
      "Epoch [243/500], Train Loss: 0.0788\n",
      "Epoch [244/500], Train Loss: 0.0786\n",
      "Epoch [245/500], Train Loss: 0.0784\n",
      "Epoch [246/500], Train Loss: 0.0784\n",
      "Epoch [247/500], Train Loss: 0.0782\n",
      "Epoch [248/500], Train Loss: 0.0785\n",
      "Epoch [249/500], Train Loss: 0.0782\n",
      "Epoch [250/500], Train Loss: 0.0781\n",
      "Epoch [251/500], Train Loss: 0.0779\n",
      "Epoch [252/500], Train Loss: 0.0777\n",
      "Epoch [253/500], Train Loss: 0.0777\n",
      "Epoch [254/500], Train Loss: 0.0777\n",
      "Epoch [255/500], Train Loss: 0.0774\n",
      "Epoch [256/500], Train Loss: 0.0774\n",
      "Epoch [257/500], Train Loss: 0.0773\n",
      "Epoch [258/500], Train Loss: 0.0773\n",
      "Epoch [259/500], Train Loss: 0.0773\n",
      "Epoch [260/500], Train Loss: 0.0772\n",
      "Epoch [261/500], Train Loss: 0.0769\n",
      "Epoch [262/500], Train Loss: 0.0769\n",
      "Epoch [263/500], Train Loss: 0.0767\n",
      "Epoch [264/500], Train Loss: 0.0767\n",
      "Epoch [265/500], Train Loss: 0.0766\n",
      "Epoch [266/500], Train Loss: 0.0766\n",
      "Epoch [267/500], Train Loss: 0.0766\n",
      "Epoch [268/500], Train Loss: 0.0762\n",
      "Epoch [269/500], Train Loss: 0.0761\n",
      "Epoch [270/500], Train Loss: 0.0759\n",
      "Epoch [271/500], Train Loss: 0.0759\n",
      "Epoch [272/500], Train Loss: 0.0760\n",
      "Epoch [273/500], Train Loss: 0.0760\n",
      "Epoch [274/500], Train Loss: 0.0756\n",
      "Epoch [275/500], Train Loss: 0.0755\n",
      "Epoch [276/500], Train Loss: 0.0755\n",
      "Epoch [277/500], Train Loss: 0.0755\n",
      "Epoch [278/500], Train Loss: 0.0755\n",
      "Epoch [279/500], Train Loss: 0.0751\n",
      "Epoch [280/500], Train Loss: 0.0750\n",
      "Epoch [281/500], Train Loss: 0.0752\n",
      "Epoch [282/500], Train Loss: 0.0750\n",
      "Epoch [283/500], Train Loss: 0.0749\n",
      "Epoch [284/500], Train Loss: 0.0748\n",
      "Epoch [285/500], Train Loss: 0.0747\n",
      "Epoch [286/500], Train Loss: 0.0747\n",
      "Epoch [287/500], Train Loss: 0.0747\n",
      "Epoch [288/500], Train Loss: 0.0747\n",
      "Epoch [289/500], Train Loss: 0.0745\n",
      "Epoch [290/500], Train Loss: 0.0743\n",
      "Epoch [291/500], Train Loss: 0.0742\n",
      "Epoch [292/500], Train Loss: 0.0741\n",
      "Epoch [293/500], Train Loss: 0.0741\n",
      "Epoch [294/500], Train Loss: 0.0739\n",
      "Epoch [295/500], Train Loss: 0.0739\n",
      "Epoch [296/500], Train Loss: 0.0738\n",
      "Epoch [297/500], Train Loss: 0.0738\n",
      "Epoch [298/500], Train Loss: 0.0738\n",
      "Epoch [299/500], Train Loss: 0.0735\n",
      "Epoch [300/500], Train Loss: 0.0737\n",
      "Epoch [301/500], Train Loss: 0.0736\n",
      "Epoch [302/500], Train Loss: 0.0735\n",
      "Epoch [303/500], Train Loss: 0.0735\n",
      "Epoch [304/500], Train Loss: 0.0734\n",
      "Epoch [305/500], Train Loss: 0.0731\n",
      "Epoch [306/500], Train Loss: 0.0733\n",
      "Epoch [307/500], Train Loss: 0.0732\n",
      "Epoch [308/500], Train Loss: 0.0733\n",
      "Epoch [309/500], Train Loss: 0.0731\n",
      "Epoch [310/500], Train Loss: 0.0729\n",
      "Epoch [311/500], Train Loss: 0.0727\n",
      "Epoch [312/500], Train Loss: 0.0726\n",
      "Epoch [313/500], Train Loss: 0.0728\n",
      "Epoch [314/500], Train Loss: 0.0726\n",
      "Epoch [315/500], Train Loss: 0.0725\n",
      "Epoch [316/500], Train Loss: 0.0724\n",
      "Epoch [317/500], Train Loss: 0.0722\n",
      "Epoch [318/500], Train Loss: 0.0723\n",
      "Epoch [319/500], Train Loss: 0.0722\n",
      "Epoch [320/500], Train Loss: 0.0722\n",
      "Epoch [321/500], Train Loss: 0.0720\n",
      "Epoch [322/500], Train Loss: 0.0719\n",
      "Epoch [323/500], Train Loss: 0.0718\n",
      "Epoch [324/500], Train Loss: 0.0718\n",
      "Epoch [325/500], Train Loss: 0.0717\n",
      "Epoch [326/500], Train Loss: 0.0717\n",
      "Epoch [327/500], Train Loss: 0.0717\n",
      "Epoch [328/500], Train Loss: 0.0718\n",
      "Epoch [329/500], Train Loss: 0.0715\n",
      "Epoch [330/500], Train Loss: 0.0715\n",
      "Epoch [331/500], Train Loss: 0.0714\n",
      "Epoch [332/500], Train Loss: 0.0714\n",
      "Epoch [333/500], Train Loss: 0.0711\n",
      "Epoch [334/500], Train Loss: 0.0712\n",
      "Epoch [335/500], Train Loss: 0.0712\n",
      "Epoch [336/500], Train Loss: 0.0710\n",
      "Epoch [337/500], Train Loss: 0.0710\n",
      "Epoch [338/500], Train Loss: 0.0710\n",
      "Epoch [339/500], Train Loss: 0.0707\n",
      "Epoch [340/500], Train Loss: 0.0708\n",
      "Epoch [341/500], Train Loss: 0.0707\n",
      "Epoch [342/500], Train Loss: 0.0708\n",
      "Epoch [343/500], Train Loss: 0.0708\n",
      "Epoch [344/500], Train Loss: 0.0708\n",
      "Epoch [345/500], Train Loss: 0.0706\n",
      "Epoch [346/500], Train Loss: 0.0705\n",
      "Epoch [347/500], Train Loss: 0.0706\n",
      "Epoch [348/500], Train Loss: 0.0705\n",
      "Epoch [349/500], Train Loss: 0.0703\n",
      "Epoch [350/500], Train Loss: 0.0702\n",
      "Epoch [351/500], Train Loss: 0.0701\n",
      "Epoch [352/500], Train Loss: 0.0702\n",
      "Epoch [353/500], Train Loss: 0.0702\n",
      "Epoch [354/500], Train Loss: 0.0701\n",
      "Epoch [355/500], Train Loss: 0.0700\n",
      "Epoch [356/500], Train Loss: 0.0700\n",
      "Epoch [357/500], Train Loss: 0.0699\n",
      "Epoch [358/500], Train Loss: 0.0698\n",
      "Epoch [359/500], Train Loss: 0.0699\n",
      "Epoch [360/500], Train Loss: 0.0698\n",
      "Epoch [361/500], Train Loss: 0.0698\n",
      "Epoch [362/500], Train Loss: 0.0697\n",
      "Epoch [363/500], Train Loss: 0.0696\n",
      "Epoch [364/500], Train Loss: 0.0698\n",
      "Epoch [365/500], Train Loss: 0.0694\n",
      "Epoch [366/500], Train Loss: 0.0695\n",
      "Epoch [367/500], Train Loss: 0.0696\n",
      "Epoch [368/500], Train Loss: 0.0695\n",
      "Epoch [369/500], Train Loss: 0.0694\n",
      "Epoch [370/500], Train Loss: 0.0693\n",
      "Epoch [371/500], Train Loss: 0.0693\n",
      "Epoch [372/500], Train Loss: 0.0692\n",
      "Epoch [373/500], Train Loss: 0.0692\n",
      "Epoch [374/500], Train Loss: 0.0692\n",
      "Epoch [375/500], Train Loss: 0.0691\n",
      "Epoch [376/500], Train Loss: 0.0689\n",
      "Epoch [377/500], Train Loss: 0.0688\n",
      "Epoch [378/500], Train Loss: 0.0687\n",
      "Epoch [379/500], Train Loss: 0.0688\n",
      "Epoch [380/500], Train Loss: 0.0688\n",
      "Epoch [381/500], Train Loss: 0.0687\n",
      "Epoch [382/500], Train Loss: 0.0686\n",
      "Epoch [383/500], Train Loss: 0.0687\n",
      "Epoch [384/500], Train Loss: 0.0688\n",
      "Epoch [385/500], Train Loss: 0.0685\n",
      "Epoch [386/500], Train Loss: 0.0685\n",
      "Epoch [387/500], Train Loss: 0.0685\n",
      "Epoch [388/500], Train Loss: 0.0686\n",
      "Epoch [389/500], Train Loss: 0.0684\n",
      "Epoch [390/500], Train Loss: 0.0683\n",
      "Epoch [391/500], Train Loss: 0.0682\n",
      "Epoch [392/500], Train Loss: 0.0681\n",
      "Epoch [393/500], Train Loss: 0.0682\n",
      "Epoch [394/500], Train Loss: 0.0683\n",
      "Epoch [395/500], Train Loss: 0.0681\n",
      "Epoch [396/500], Train Loss: 0.0683\n",
      "Epoch [397/500], Train Loss: 0.0681\n",
      "Epoch [398/500], Train Loss: 0.0680\n",
      "Epoch [399/500], Train Loss: 0.0679\n",
      "Epoch [400/500], Train Loss: 0.0677\n",
      "Epoch [401/500], Train Loss: 0.0679\n",
      "Epoch [402/500], Train Loss: 0.0678\n",
      "Epoch [403/500], Train Loss: 0.0678\n",
      "Epoch [404/500], Train Loss: 0.0677\n",
      "Epoch [405/500], Train Loss: 0.0676\n",
      "Epoch [406/500], Train Loss: 0.0679\n",
      "Epoch [407/500], Train Loss: 0.0676\n",
      "Epoch [408/500], Train Loss: 0.0677\n",
      "Epoch [409/500], Train Loss: 0.0675\n",
      "Epoch [410/500], Train Loss: 0.0674\n",
      "Epoch [411/500], Train Loss: 0.0674\n",
      "Epoch [412/500], Train Loss: 0.0674\n",
      "Epoch [413/500], Train Loss: 0.0676\n",
      "Epoch [414/500], Train Loss: 0.0673\n",
      "Epoch [415/500], Train Loss: 0.0672\n",
      "Epoch [416/500], Train Loss: 0.0673\n",
      "Epoch [417/500], Train Loss: 0.0672\n",
      "Epoch [418/500], Train Loss: 0.0672\n",
      "Epoch [419/500], Train Loss: 0.0672\n",
      "Epoch [420/500], Train Loss: 0.0671\n",
      "Epoch [421/500], Train Loss: 0.0672\n",
      "Epoch [422/500], Train Loss: 0.0669\n",
      "Epoch [423/500], Train Loss: 0.0671\n",
      "Epoch [424/500], Train Loss: 0.0669\n",
      "Epoch [425/500], Train Loss: 0.0669\n",
      "Epoch [426/500], Train Loss: 0.0669\n",
      "Epoch [427/500], Train Loss: 0.0668\n",
      "Epoch [428/500], Train Loss: 0.0668\n",
      "Epoch [429/500], Train Loss: 0.0669\n",
      "Epoch [430/500], Train Loss: 0.0668\n",
      "Epoch [431/500], Train Loss: 0.0668\n",
      "Epoch [432/500], Train Loss: 0.0668\n",
      "Epoch [433/500], Train Loss: 0.0667\n",
      "Epoch [434/500], Train Loss: 0.0665\n",
      "Epoch [435/500], Train Loss: 0.0666\n",
      "Epoch [436/500], Train Loss: 0.0665\n",
      "Epoch [437/500], Train Loss: 0.0665\n",
      "Epoch [438/500], Train Loss: 0.0664\n",
      "Epoch [439/500], Train Loss: 0.0665\n",
      "Epoch [440/500], Train Loss: 0.0663\n",
      "Epoch [441/500], Train Loss: 0.0663\n",
      "Epoch [442/500], Train Loss: 0.0662\n",
      "Epoch [443/500], Train Loss: 0.0662\n",
      "Epoch [444/500], Train Loss: 0.0662\n",
      "Epoch [445/500], Train Loss: 0.0661\n",
      "Epoch [446/500], Train Loss: 0.0662\n",
      "Epoch [447/500], Train Loss: 0.0664\n",
      "Epoch [448/500], Train Loss: 0.0661\n",
      "Epoch [449/500], Train Loss: 0.0661\n",
      "Epoch [450/500], Train Loss: 0.0661\n",
      "Epoch [451/500], Train Loss: 0.0662\n",
      "Epoch [452/500], Train Loss: 0.0660\n",
      "Epoch [453/500], Train Loss: 0.0661\n",
      "Epoch [454/500], Train Loss: 0.0660\n",
      "Epoch [455/500], Train Loss: 0.0661\n",
      "Epoch [456/500], Train Loss: 0.0660\n",
      "Epoch [457/500], Train Loss: 0.0659\n",
      "Epoch [458/500], Train Loss: 0.0658\n",
      "Epoch [459/500], Train Loss: 0.0658\n",
      "Epoch [460/500], Train Loss: 0.0657\n",
      "Epoch [461/500], Train Loss: 0.0657\n",
      "Epoch [462/500], Train Loss: 0.0656\n",
      "Epoch [463/500], Train Loss: 0.0656\n",
      "Epoch [464/500], Train Loss: 0.0657\n",
      "Epoch [465/500], Train Loss: 0.0654\n",
      "Epoch [466/500], Train Loss: 0.0656\n",
      "Epoch [467/500], Train Loss: 0.0656\n",
      "Epoch [468/500], Train Loss: 0.0655\n",
      "Epoch [469/500], Train Loss: 0.0653\n",
      "Epoch [470/500], Train Loss: 0.0655\n",
      "Epoch [471/500], Train Loss: 0.0653\n",
      "Epoch [472/500], Train Loss: 0.0653\n",
      "Epoch [473/500], Train Loss: 0.0654\n",
      "Epoch [474/500], Train Loss: 0.0654\n",
      "Epoch [475/500], Train Loss: 0.0652\n",
      "Epoch [476/500], Train Loss: 0.0651\n",
      "Epoch [477/500], Train Loss: 0.0653\n",
      "Epoch [478/500], Train Loss: 0.0654\n",
      "Epoch [479/500], Train Loss: 0.0652\n",
      "Epoch [480/500], Train Loss: 0.0651\n",
      "Epoch [481/500], Train Loss: 0.0652\n",
      "Epoch [482/500], Train Loss: 0.0652\n",
      "Epoch [483/500], Train Loss: 0.0651\n",
      "Epoch [484/500], Train Loss: 0.0651\n",
      "Epoch [485/500], Train Loss: 0.0650\n",
      "Epoch [486/500], Train Loss: 0.0651\n",
      "Epoch [487/500], Train Loss: 0.0650\n",
      "Epoch [488/500], Train Loss: 0.0651\n",
      "Epoch [489/500], Train Loss: 0.0649\n",
      "Epoch [490/500], Train Loss: 0.0650\n",
      "Epoch [491/500], Train Loss: 0.0649\n",
      "Epoch [492/500], Train Loss: 0.0649\n",
      "Epoch [493/500], Train Loss: 0.0650\n",
      "Epoch [494/500], Train Loss: 0.0651\n",
      "Epoch [495/500], Train Loss: 0.0650\n",
      "Epoch [496/500], Train Loss: 0.0647\n",
      "Epoch [497/500], Train Loss: 0.0648\n",
      "Epoch [498/500], Train Loss: 0.0648\n",
      "Epoch [499/500], Train Loss: 0.0647\n",
      "Epoch [500/500], Train Loss: 0.0647\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr2/final_model_chr2.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr2/individual_r2_scores_chr2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:42:12,353] A new study created in memory with name: no-name-70ceca2c-78a1-4fcf-b946-b85845db0006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  26\n",
      "Known PRS313 SNPs:  6\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  1142\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:42:13,531] Trial 0 finished with value: 0.19270225390791892 and parameters: {'learning_rate': 0.06030963301383196, 'lasso_coef': 0.00011387994381494338, 'patience': 8}. Best is trial 0 with value: 0.19270225390791892.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 134\n",
      "Early stopping at epoch 52\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:42:17,494] Trial 1 finished with value: 0.6826570183038712 and parameters: {'learning_rate': 0.003282104812142994, 'lasso_coef': 0.016178220656141867, 'patience': 10}. Best is trial 0 with value: 0.19270225390791892.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 31\n",
      "Early stopping at epoch 332\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:42:23,651] Trial 2 finished with value: 0.15034919902682303 and parameters: {'learning_rate': 0.002890101497788646, 'lasso_coef': 0.0001930425572912788, 'patience': 18}. Best is trial 2 with value: 0.15034919902682303.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 42\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:42:25,521] Trial 3 finished with value: 1.3802290558815002 and parameters: {'learning_rate': 0.018551410499065897, 'lasso_coef': 0.013221992220484709, 'patience': 10}. Best is trial 2 with value: 0.15034919902682303.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:42:26,631] Trial 4 finished with value: 0.15088391453027725 and parameters: {'learning_rate': 0.03808427751103524, 'lasso_coef': 7.930415765350298e-05, 'patience': 8}. Best is trial 2 with value: 0.15034919902682303.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 72\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:42:28,823] Trial 5 finished with value: 0.7022365033626556 and parameters: {'learning_rate': 0.008057113682409831, 'lasso_coef': 0.0071218121884528696, 'patience': 9}. Best is trial 2 with value: 0.15034919902682303.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 160\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:42:31,996] Trial 6 finished with value: 0.30626712292432784 and parameters: {'learning_rate': 0.0035624670250985224, 'lasso_coef': 0.0012341710571234794, 'patience': 6}. Best is trial 2 with value: 0.15034919902682303.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 366\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:42:53,337] Trial 7 finished with value: 0.4974310174584389 and parameters: {'learning_rate': 0.00026410332415801674, 'lasso_coef': 0.0070559100197661135, 'patience': 17}. Best is trial 2 with value: 0.15034919902682303.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 55\n",
      "Early stopping at epoch 111\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:42:55,611] Trial 8 finished with value: 0.1507932350039482 and parameters: {'learning_rate': 0.004093332342790271, 'lasso_coef': 0.00013111809529938614, 'patience': 8}. Best is trial 2 with value: 0.15034919902682303.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:43:11,876] Trial 9 finished with value: 0.18069417774677277 and parameters: {'learning_rate': 0.00029778547763710907, 'lasso_coef': 0.00024698596479757047, 'patience': 18}. Best is trial 2 with value: 0.15034919902682303.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:43:20,460] Trial 10 finished with value: 0.07759086042642593 and parameters: {'learning_rate': 0.0007885014452111756, 'lasso_coef': 1.0475525077690606e-05, 'patience': 15}. Best is trial 10 with value: 0.07759086042642593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:43:28,972] Trial 11 finished with value: 0.08598847147077322 and parameters: {'learning_rate': 0.0008089364705530761, 'lasso_coef': 1.8775237563876525e-05, 'patience': 15}. Best is trial 10 with value: 0.07759086042642593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:43:37,482] Trial 12 finished with value: 0.07720059007406235 and parameters: {'learning_rate': 0.0008280105333347683, 'lasso_coef': 1.0584623376850032e-05, 'patience': 14}. Best is trial 12 with value: 0.07720059007406235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:43:45,767] Trial 13 finished with value: 0.07689052317291498 and parameters: {'learning_rate': 0.0008827324850538804, 'lasso_coef': 1.117350057537137e-05, 'patience': 14}. Best is trial 13 with value: 0.07689052317291498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:43:54,070] Trial 14 finished with value: 0.1657840959727764 and parameters: {'learning_rate': 0.00012481118007943656, 'lasso_coef': 2.9865120235860086e-05, 'patience': 13}. Best is trial 13 with value: 0.07689052317291498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 384\n",
      "Early stopping at epoch 49\n",
      "Early stopping at epoch 50\n",
      "Early stopping at epoch 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:44:02,705] Trial 15 finished with value: 0.773789918422699 and parameters: {'learning_rate': 0.0009911370657204226, 'lasso_coef': 0.08759187634669877, 'patience': 20}. Best is trial 13 with value: 0.07689052317291498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 456\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:44:10,764] Trial 16 finished with value: 0.2473950318992138 and parameters: {'learning_rate': 0.0011737368483459366, 'lasso_coef': 0.0008098572131068673, 'patience': 12}. Best is trial 13 with value: 0.07689052317291498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:44:19,191] Trial 17 finished with value: 0.12179789170622826 and parameters: {'learning_rate': 0.00042355426865666997, 'lasso_coef': 4.866138285211006e-05, 'patience': 13}. Best is trial 13 with value: 0.07689052317291498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:44:56,553] Trial 18 finished with value: 0.2647437758743763 and parameters: {'learning_rate': 0.0001333486335343878, 'lasso_coef': 0.0006829322462972893, 'patience': 16}. Best is trial 13 with value: 0.07689052317291498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 238\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:45:01,029] Trial 19 finished with value: 0.08159523941576481 and parameters: {'learning_rate': 0.0017589422138809734, 'lasso_coef': 1.031092176368048e-05, 'patience': 12}. Best is trial 13 with value: 0.07689052317291498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 134\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:45:03,920] Trial 20 finished with value: 0.09770267829298973 and parameters: {'learning_rate': 0.009077673181950451, 'lasso_coef': 3.268197567902061e-05, 'patience': 14}. Best is trial 13 with value: 0.07689052317291498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:45:12,290] Trial 21 finished with value: 0.08524548597633838 and parameters: {'learning_rate': 0.0005233660949687263, 'lasso_coef': 1.0960389304983773e-05, 'patience': 15}. Best is trial 13 with value: 0.07689052317291498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:45:20,660] Trial 22 finished with value: 0.0905882801860571 and parameters: {'learning_rate': 0.000629954101911004, 'lasso_coef': 1.9233020892626917e-05, 'patience': 15}. Best is trial 13 with value: 0.07689052317291498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:45:28,882] Trial 23 finished with value: 0.13666287660598755 and parameters: {'learning_rate': 0.0002862658548987801, 'lasso_coef': 5.034910563260179e-05, 'patience': 11}. Best is trial 13 with value: 0.07689052317291498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 400\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:45:36,000] Trial 24 finished with value: 0.07626579571515321 and parameters: {'learning_rate': 0.001641630031893393, 'lasso_coef': 1.3123218238487032e-05, 'patience': 14}. Best is trial 24 with value: 0.07626579571515321.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 465\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:45:44,021] Trial 25 finished with value: 0.18535615578293801 and parameters: {'learning_rate': 0.0017998264836549126, 'lasso_coef': 0.00038205287437476825, 'patience': 14}. Best is trial 24 with value: 0.07626579571515321.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 489\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:45:52,858] Trial 26 finished with value: 0.08628118745982646 and parameters: {'learning_rate': 0.001551796027887425, 'lasso_coef': 2.6830230332971018e-05, 'patience': 17}. Best is trial 24 with value: 0.07626579571515321.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 84\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:45:55,063] Trial 27 finished with value: 0.12247355319559575 and parameters: {'learning_rate': 0.007780757675319874, 'lasso_coef': 6.566548849587091e-05, 'patience': 13}. Best is trial 24 with value: 0.07626579571515321.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 135\n",
      "Early stopping at epoch 46\n",
      "Early stopping at epoch 41\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:45:59,349] Trial 28 finished with value: 0.36493721008300783 and parameters: {'learning_rate': 0.0054817719613660595, 'lasso_coef': 0.0017149265150859928, 'patience': 20}. Best is trial 24 with value: 0.07626579571515321.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 40\n",
      "Early stopping at epoch 124\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:46:01,827] Trial 29 finished with value: 0.15371475666761397 and parameters: {'learning_rate': 0.002123170530693983, 'lasso_coef': 0.00011312443058672244, 'patience': 5}. Best is trial 24 with value: 0.07626579571515321.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Best hyperparameters: {'learning_rate': 0.001641630031893393, 'lasso_coef': 1.3123218238487032e-05, 'patience': 14}\n",
      "Best value: 0.07626579571515321\n",
      "Epoch [1/500], Train Loss: 0.5035\n",
      "Epoch [2/500], Train Loss: 0.4190\n",
      "Epoch [3/500], Train Loss: 0.3861\n",
      "Epoch [4/500], Train Loss: 0.3608\n",
      "Epoch [5/500], Train Loss: 0.3377\n",
      "Epoch [6/500], Train Loss: 0.3186\n",
      "Epoch [7/500], Train Loss: 0.3026\n",
      "Epoch [8/500], Train Loss: 0.2878\n",
      "Epoch [9/500], Train Loss: 0.2753\n",
      "Epoch [10/500], Train Loss: 0.2645\n",
      "Epoch [11/500], Train Loss: 0.2542\n",
      "Epoch [12/500], Train Loss: 0.2453\n",
      "Epoch [13/500], Train Loss: 0.2367\n",
      "Epoch [14/500], Train Loss: 0.2298\n",
      "Epoch [15/500], Train Loss: 0.2222\n",
      "Epoch [16/500], Train Loss: 0.2161\n",
      "Epoch [17/500], Train Loss: 0.2101\n",
      "Epoch [18/500], Train Loss: 0.2042\n",
      "Epoch [19/500], Train Loss: 0.1998\n",
      "Epoch [20/500], Train Loss: 0.1948\n",
      "Epoch [21/500], Train Loss: 0.1907\n",
      "Epoch [22/500], Train Loss: 0.1864\n",
      "Epoch [23/500], Train Loss: 0.1825\n",
      "Epoch [24/500], Train Loss: 0.1786\n",
      "Epoch [25/500], Train Loss: 0.1748\n",
      "Epoch [26/500], Train Loss: 0.1718\n",
      "Epoch [27/500], Train Loss: 0.1689\n",
      "Epoch [28/500], Train Loss: 0.1654\n",
      "Epoch [29/500], Train Loss: 0.1627\n",
      "Epoch [30/500], Train Loss: 0.1596\n",
      "Epoch [31/500], Train Loss: 0.1573\n",
      "Epoch [32/500], Train Loss: 0.1547\n",
      "Epoch [33/500], Train Loss: 0.1518\n",
      "Epoch [34/500], Train Loss: 0.1502\n",
      "Epoch [35/500], Train Loss: 0.1478\n",
      "Epoch [36/500], Train Loss: 0.1460\n",
      "Epoch [37/500], Train Loss: 0.1440\n",
      "Epoch [38/500], Train Loss: 0.1419\n",
      "Epoch [39/500], Train Loss: 0.1396\n",
      "Epoch [40/500], Train Loss: 0.1379\n",
      "Epoch [41/500], Train Loss: 0.1364\n",
      "Epoch [42/500], Train Loss: 0.1350\n",
      "Epoch [43/500], Train Loss: 0.1331\n",
      "Epoch [44/500], Train Loss: 0.1315\n",
      "Epoch [45/500], Train Loss: 0.1301\n",
      "Epoch [46/500], Train Loss: 0.1285\n",
      "Epoch [47/500], Train Loss: 0.1270\n",
      "Epoch [48/500], Train Loss: 0.1256\n",
      "Epoch [49/500], Train Loss: 0.1244\n",
      "Epoch [50/500], Train Loss: 0.1231\n",
      "Epoch [51/500], Train Loss: 0.1219\n",
      "Epoch [52/500], Train Loss: 0.1205\n",
      "Epoch [53/500], Train Loss: 0.1192\n",
      "Epoch [54/500], Train Loss: 0.1179\n",
      "Epoch [55/500], Train Loss: 0.1171\n",
      "Epoch [56/500], Train Loss: 0.1160\n",
      "Epoch [57/500], Train Loss: 0.1148\n",
      "Epoch [58/500], Train Loss: 0.1138\n",
      "Epoch [59/500], Train Loss: 0.1128\n",
      "Epoch [60/500], Train Loss: 0.1118\n",
      "Epoch [61/500], Train Loss: 0.1109\n",
      "Epoch [62/500], Train Loss: 0.1099\n",
      "Epoch [63/500], Train Loss: 0.1093\n",
      "Epoch [64/500], Train Loss: 0.1084\n",
      "Epoch [65/500], Train Loss: 0.1071\n",
      "Epoch [66/500], Train Loss: 0.1063\n",
      "Epoch [67/500], Train Loss: 0.1056\n",
      "Epoch [68/500], Train Loss: 0.1050\n",
      "Epoch [69/500], Train Loss: 0.1040\n",
      "Epoch [70/500], Train Loss: 0.1035\n",
      "Epoch [71/500], Train Loss: 0.1027\n",
      "Epoch [72/500], Train Loss: 0.1020\n",
      "Epoch [73/500], Train Loss: 0.1010\n",
      "Epoch [74/500], Train Loss: 0.1003\n",
      "Epoch [75/500], Train Loss: 0.0998\n",
      "Epoch [76/500], Train Loss: 0.0992\n",
      "Epoch [77/500], Train Loss: 0.0982\n",
      "Epoch [78/500], Train Loss: 0.0978\n",
      "Epoch [79/500], Train Loss: 0.0975\n",
      "Epoch [80/500], Train Loss: 0.0967\n",
      "Epoch [81/500], Train Loss: 0.0962\n",
      "Epoch [82/500], Train Loss: 0.0954\n",
      "Epoch [83/500], Train Loss: 0.0949\n",
      "Epoch [84/500], Train Loss: 0.0944\n",
      "Epoch [85/500], Train Loss: 0.0937\n",
      "Epoch [86/500], Train Loss: 0.0930\n",
      "Epoch [87/500], Train Loss: 0.0926\n",
      "Epoch [88/500], Train Loss: 0.0919\n",
      "Epoch [89/500], Train Loss: 0.0915\n",
      "Epoch [90/500], Train Loss: 0.0909\n",
      "Epoch [91/500], Train Loss: 0.0903\n",
      "Epoch [92/500], Train Loss: 0.0899\n",
      "Epoch [93/500], Train Loss: 0.0895\n",
      "Epoch [94/500], Train Loss: 0.0890\n",
      "Epoch [95/500], Train Loss: 0.0885\n",
      "Epoch [96/500], Train Loss: 0.0881\n",
      "Epoch [97/500], Train Loss: 0.0877\n",
      "Epoch [98/500], Train Loss: 0.0872\n",
      "Epoch [99/500], Train Loss: 0.0868\n",
      "Epoch [100/500], Train Loss: 0.0864\n",
      "Epoch [101/500], Train Loss: 0.0858\n",
      "Epoch [102/500], Train Loss: 0.0855\n",
      "Epoch [103/500], Train Loss: 0.0851\n",
      "Epoch [104/500], Train Loss: 0.0847\n",
      "Epoch [105/500], Train Loss: 0.0844\n",
      "Epoch [106/500], Train Loss: 0.0841\n",
      "Epoch [107/500], Train Loss: 0.0836\n",
      "Epoch [108/500], Train Loss: 0.0833\n",
      "Epoch [109/500], Train Loss: 0.0828\n",
      "Epoch [110/500], Train Loss: 0.0823\n",
      "Epoch [111/500], Train Loss: 0.0821\n",
      "Epoch [112/500], Train Loss: 0.0817\n",
      "Epoch [113/500], Train Loss: 0.0812\n",
      "Epoch [114/500], Train Loss: 0.0810\n",
      "Epoch [115/500], Train Loss: 0.0806\n",
      "Epoch [116/500], Train Loss: 0.0803\n",
      "Epoch [117/500], Train Loss: 0.0802\n",
      "Epoch [118/500], Train Loss: 0.0796\n",
      "Epoch [119/500], Train Loss: 0.0792\n",
      "Epoch [120/500], Train Loss: 0.0791\n",
      "Epoch [121/500], Train Loss: 0.0787\n",
      "Epoch [122/500], Train Loss: 0.0782\n",
      "Epoch [123/500], Train Loss: 0.0781\n",
      "Epoch [124/500], Train Loss: 0.0778\n",
      "Epoch [125/500], Train Loss: 0.0776\n",
      "Epoch [126/500], Train Loss: 0.0772\n",
      "Epoch [127/500], Train Loss: 0.0769\n",
      "Epoch [128/500], Train Loss: 0.0767\n",
      "Epoch [129/500], Train Loss: 0.0765\n",
      "Epoch [130/500], Train Loss: 0.0763\n",
      "Epoch [131/500], Train Loss: 0.0761\n",
      "Epoch [132/500], Train Loss: 0.0759\n",
      "Epoch [133/500], Train Loss: 0.0753\n",
      "Epoch [134/500], Train Loss: 0.0752\n",
      "Epoch [135/500], Train Loss: 0.0749\n",
      "Epoch [136/500], Train Loss: 0.0748\n",
      "Epoch [137/500], Train Loss: 0.0744\n",
      "Epoch [138/500], Train Loss: 0.0740\n",
      "Epoch [139/500], Train Loss: 0.0739\n",
      "Epoch [140/500], Train Loss: 0.0735\n",
      "Epoch [141/500], Train Loss: 0.0731\n",
      "Epoch [142/500], Train Loss: 0.0729\n",
      "Epoch [143/500], Train Loss: 0.0729\n",
      "Epoch [144/500], Train Loss: 0.0728\n",
      "Epoch [145/500], Train Loss: 0.0724\n",
      "Epoch [146/500], Train Loss: 0.0721\n",
      "Epoch [147/500], Train Loss: 0.0720\n",
      "Epoch [148/500], Train Loss: 0.0717\n",
      "Epoch [149/500], Train Loss: 0.0715\n",
      "Epoch [150/500], Train Loss: 0.0713\n",
      "Epoch [151/500], Train Loss: 0.0712\n",
      "Epoch [152/500], Train Loss: 0.0709\n",
      "Epoch [153/500], Train Loss: 0.0709\n",
      "Epoch [154/500], Train Loss: 0.0707\n",
      "Epoch [155/500], Train Loss: 0.0705\n",
      "Epoch [156/500], Train Loss: 0.0700\n",
      "Epoch [157/500], Train Loss: 0.0699\n",
      "Epoch [158/500], Train Loss: 0.0696\n",
      "Epoch [159/500], Train Loss: 0.0694\n",
      "Epoch [160/500], Train Loss: 0.0693\n",
      "Epoch [161/500], Train Loss: 0.0690\n",
      "Epoch [162/500], Train Loss: 0.0690\n",
      "Epoch [163/500], Train Loss: 0.0690\n",
      "Epoch [164/500], Train Loss: 0.0688\n",
      "Epoch [165/500], Train Loss: 0.0685\n",
      "Epoch [166/500], Train Loss: 0.0681\n",
      "Epoch [167/500], Train Loss: 0.0681\n",
      "Epoch [168/500], Train Loss: 0.0680\n",
      "Epoch [169/500], Train Loss: 0.0678\n",
      "Epoch [170/500], Train Loss: 0.0680\n",
      "Epoch [171/500], Train Loss: 0.0676\n",
      "Epoch [172/500], Train Loss: 0.0672\n",
      "Epoch [173/500], Train Loss: 0.0670\n",
      "Epoch [174/500], Train Loss: 0.0668\n",
      "Epoch [175/500], Train Loss: 0.0667\n",
      "Epoch [176/500], Train Loss: 0.0666\n",
      "Epoch [177/500], Train Loss: 0.0663\n",
      "Epoch [178/500], Train Loss: 0.0662\n",
      "Epoch [179/500], Train Loss: 0.0661\n",
      "Epoch [180/500], Train Loss: 0.0660\n",
      "Epoch [181/500], Train Loss: 0.0657\n",
      "Epoch [182/500], Train Loss: 0.0655\n",
      "Epoch [183/500], Train Loss: 0.0654\n",
      "Epoch [184/500], Train Loss: 0.0653\n",
      "Epoch [185/500], Train Loss: 0.0651\n",
      "Epoch [186/500], Train Loss: 0.0649\n",
      "Epoch [187/500], Train Loss: 0.0649\n",
      "Epoch [188/500], Train Loss: 0.0647\n",
      "Epoch [189/500], Train Loss: 0.0646\n",
      "Epoch [190/500], Train Loss: 0.0646\n",
      "Epoch [191/500], Train Loss: 0.0643\n",
      "Epoch [192/500], Train Loss: 0.0640\n",
      "Epoch [193/500], Train Loss: 0.0640\n",
      "Epoch [194/500], Train Loss: 0.0638\n",
      "Epoch [195/500], Train Loss: 0.0637\n",
      "Epoch [196/500], Train Loss: 0.0637\n",
      "Epoch [197/500], Train Loss: 0.0634\n",
      "Epoch [198/500], Train Loss: 0.0634\n",
      "Epoch [199/500], Train Loss: 0.0631\n",
      "Epoch [200/500], Train Loss: 0.0630\n",
      "Epoch [201/500], Train Loss: 0.0630\n",
      "Epoch [202/500], Train Loss: 0.0629\n",
      "Epoch [203/500], Train Loss: 0.0627\n",
      "Epoch [204/500], Train Loss: 0.0625\n",
      "Epoch [205/500], Train Loss: 0.0625\n",
      "Epoch [206/500], Train Loss: 0.0626\n",
      "Epoch [207/500], Train Loss: 0.0624\n",
      "Epoch [208/500], Train Loss: 0.0622\n",
      "Epoch [209/500], Train Loss: 0.0621\n",
      "Epoch [210/500], Train Loss: 0.0620\n",
      "Epoch [211/500], Train Loss: 0.0617\n",
      "Epoch [212/500], Train Loss: 0.0616\n",
      "Epoch [213/500], Train Loss: 0.0615\n",
      "Epoch [214/500], Train Loss: 0.0614\n",
      "Epoch [215/500], Train Loss: 0.0611\n",
      "Epoch [216/500], Train Loss: 0.0615\n",
      "Epoch [217/500], Train Loss: 0.0609\n",
      "Epoch [218/500], Train Loss: 0.0612\n",
      "Epoch [219/500], Train Loss: 0.0609\n",
      "Epoch [220/500], Train Loss: 0.0607\n",
      "Epoch [221/500], Train Loss: 0.0606\n",
      "Epoch [222/500], Train Loss: 0.0605\n",
      "Epoch [223/500], Train Loss: 0.0604\n",
      "Epoch [224/500], Train Loss: 0.0602\n",
      "Epoch [225/500], Train Loss: 0.0602\n",
      "Epoch [226/500], Train Loss: 0.0600\n",
      "Epoch [227/500], Train Loss: 0.0598\n",
      "Epoch [228/500], Train Loss: 0.0598\n",
      "Epoch [229/500], Train Loss: 0.0597\n",
      "Epoch [230/500], Train Loss: 0.0597\n",
      "Epoch [231/500], Train Loss: 0.0597\n",
      "Epoch [232/500], Train Loss: 0.0593\n",
      "Epoch [233/500], Train Loss: 0.0592\n",
      "Epoch [234/500], Train Loss: 0.0593\n",
      "Epoch [235/500], Train Loss: 0.0590\n",
      "Epoch [236/500], Train Loss: 0.0592\n",
      "Epoch [237/500], Train Loss: 0.0588\n",
      "Epoch [238/500], Train Loss: 0.0588\n",
      "Epoch [239/500], Train Loss: 0.0589\n",
      "Epoch [240/500], Train Loss: 0.0587\n",
      "Epoch [241/500], Train Loss: 0.0585\n",
      "Epoch [242/500], Train Loss: 0.0586\n",
      "Epoch [243/500], Train Loss: 0.0585\n",
      "Epoch [244/500], Train Loss: 0.0582\n",
      "Epoch [245/500], Train Loss: 0.0580\n",
      "Epoch [246/500], Train Loss: 0.0580\n",
      "Epoch [247/500], Train Loss: 0.0579\n",
      "Epoch [248/500], Train Loss: 0.0579\n",
      "Epoch [249/500], Train Loss: 0.0578\n",
      "Epoch [250/500], Train Loss: 0.0578\n",
      "Epoch [251/500], Train Loss: 0.0577\n",
      "Epoch [252/500], Train Loss: 0.0575\n",
      "Epoch [253/500], Train Loss: 0.0575\n",
      "Epoch [254/500], Train Loss: 0.0574\n",
      "Epoch [255/500], Train Loss: 0.0574\n",
      "Epoch [256/500], Train Loss: 0.0573\n",
      "Epoch [257/500], Train Loss: 0.0573\n",
      "Epoch [258/500], Train Loss: 0.0571\n",
      "Epoch [259/500], Train Loss: 0.0570\n",
      "Epoch [260/500], Train Loss: 0.0569\n",
      "Epoch [261/500], Train Loss: 0.0568\n",
      "Epoch [262/500], Train Loss: 0.0566\n",
      "Epoch [263/500], Train Loss: 0.0567\n",
      "Epoch [264/500], Train Loss: 0.0565\n",
      "Epoch [265/500], Train Loss: 0.0565\n",
      "Epoch [266/500], Train Loss: 0.0566\n",
      "Epoch [267/500], Train Loss: 0.0563\n",
      "Epoch [268/500], Train Loss: 0.0563\n",
      "Epoch [269/500], Train Loss: 0.0563\n",
      "Epoch [270/500], Train Loss: 0.0561\n",
      "Epoch [271/500], Train Loss: 0.0561\n",
      "Epoch [272/500], Train Loss: 0.0562\n",
      "Epoch [273/500], Train Loss: 0.0559\n",
      "Epoch [274/500], Train Loss: 0.0558\n",
      "Epoch [275/500], Train Loss: 0.0558\n",
      "Epoch [276/500], Train Loss: 0.0556\n",
      "Epoch [277/500], Train Loss: 0.0555\n",
      "Epoch [278/500], Train Loss: 0.0555\n",
      "Epoch [279/500], Train Loss: 0.0554\n",
      "Epoch [280/500], Train Loss: 0.0553\n",
      "Epoch [281/500], Train Loss: 0.0552\n",
      "Epoch [282/500], Train Loss: 0.0552\n",
      "Epoch [283/500], Train Loss: 0.0551\n",
      "Epoch [284/500], Train Loss: 0.0552\n",
      "Epoch [285/500], Train Loss: 0.0549\n",
      "Epoch [286/500], Train Loss: 0.0549\n",
      "Epoch [287/500], Train Loss: 0.0549\n",
      "Epoch [288/500], Train Loss: 0.0548\n",
      "Epoch [289/500], Train Loss: 0.0548\n",
      "Epoch [290/500], Train Loss: 0.0547\n",
      "Epoch [291/500], Train Loss: 0.0546\n",
      "Epoch [292/500], Train Loss: 0.0549\n",
      "Epoch [293/500], Train Loss: 0.0546\n",
      "Epoch [294/500], Train Loss: 0.0545\n",
      "Epoch [295/500], Train Loss: 0.0543\n",
      "Epoch [296/500], Train Loss: 0.0543\n",
      "Epoch [297/500], Train Loss: 0.0542\n",
      "Epoch [298/500], Train Loss: 0.0542\n",
      "Epoch [299/500], Train Loss: 0.0541\n",
      "Epoch [300/500], Train Loss: 0.0541\n",
      "Epoch [301/500], Train Loss: 0.0539\n",
      "Epoch [302/500], Train Loss: 0.0539\n",
      "Epoch [303/500], Train Loss: 0.0539\n",
      "Epoch [304/500], Train Loss: 0.0537\n",
      "Epoch [305/500], Train Loss: 0.0537\n",
      "Epoch [306/500], Train Loss: 0.0535\n",
      "Epoch [307/500], Train Loss: 0.0536\n",
      "Epoch [308/500], Train Loss: 0.0537\n",
      "Epoch [309/500], Train Loss: 0.0537\n",
      "Epoch [310/500], Train Loss: 0.0535\n",
      "Epoch [311/500], Train Loss: 0.0535\n",
      "Epoch [312/500], Train Loss: 0.0534\n",
      "Epoch [313/500], Train Loss: 0.0533\n",
      "Epoch [314/500], Train Loss: 0.0532\n",
      "Epoch [315/500], Train Loss: 0.0531\n",
      "Epoch [316/500], Train Loss: 0.0530\n",
      "Epoch [317/500], Train Loss: 0.0531\n",
      "Epoch [318/500], Train Loss: 0.0530\n",
      "Epoch [319/500], Train Loss: 0.0529\n",
      "Epoch [320/500], Train Loss: 0.0528\n",
      "Epoch [321/500], Train Loss: 0.0527\n",
      "Epoch [322/500], Train Loss: 0.0528\n",
      "Epoch [323/500], Train Loss: 0.0527\n",
      "Epoch [324/500], Train Loss: 0.0527\n",
      "Epoch [325/500], Train Loss: 0.0525\n",
      "Epoch [326/500], Train Loss: 0.0526\n",
      "Epoch [327/500], Train Loss: 0.0526\n",
      "Epoch [328/500], Train Loss: 0.0525\n",
      "Epoch [329/500], Train Loss: 0.0524\n",
      "Epoch [330/500], Train Loss: 0.0523\n",
      "Epoch [331/500], Train Loss: 0.0522\n",
      "Epoch [332/500], Train Loss: 0.0522\n",
      "Epoch [333/500], Train Loss: 0.0523\n",
      "Epoch [334/500], Train Loss: 0.0522\n",
      "Epoch [335/500], Train Loss: 0.0521\n",
      "Epoch [336/500], Train Loss: 0.0521\n",
      "Epoch [337/500], Train Loss: 0.0523\n",
      "Epoch [338/500], Train Loss: 0.0522\n",
      "Epoch [339/500], Train Loss: 0.0519\n",
      "Epoch [340/500], Train Loss: 0.0519\n",
      "Epoch [341/500], Train Loss: 0.0518\n",
      "Epoch [342/500], Train Loss: 0.0517\n",
      "Epoch [343/500], Train Loss: 0.0518\n",
      "Epoch [344/500], Train Loss: 0.0516\n",
      "Epoch [345/500], Train Loss: 0.0516\n",
      "Epoch [346/500], Train Loss: 0.0516\n",
      "Epoch [347/500], Train Loss: 0.0516\n",
      "Epoch [348/500], Train Loss: 0.0515\n",
      "Epoch [349/500], Train Loss: 0.0513\n",
      "Epoch [350/500], Train Loss: 0.0513\n",
      "Epoch [351/500], Train Loss: 0.0513\n",
      "Epoch [352/500], Train Loss: 0.0512\n",
      "Epoch [353/500], Train Loss: 0.0512\n",
      "Epoch [354/500], Train Loss: 0.0512\n",
      "Epoch [355/500], Train Loss: 0.0511\n",
      "Epoch [356/500], Train Loss: 0.0509\n",
      "Epoch [357/500], Train Loss: 0.0510\n",
      "Epoch [358/500], Train Loss: 0.0509\n",
      "Epoch [359/500], Train Loss: 0.0510\n",
      "Epoch [360/500], Train Loss: 0.0509\n",
      "Epoch [361/500], Train Loss: 0.0508\n",
      "Epoch [362/500], Train Loss: 0.0507\n",
      "Epoch [363/500], Train Loss: 0.0508\n",
      "Epoch [364/500], Train Loss: 0.0507\n",
      "Epoch [365/500], Train Loss: 0.0508\n",
      "Epoch [366/500], Train Loss: 0.0506\n",
      "Epoch [367/500], Train Loss: 0.0506\n",
      "Epoch [368/500], Train Loss: 0.0505\n",
      "Epoch [369/500], Train Loss: 0.0506\n",
      "Epoch [370/500], Train Loss: 0.0503\n",
      "Epoch [371/500], Train Loss: 0.0504\n",
      "Epoch [372/500], Train Loss: 0.0504\n",
      "Epoch [373/500], Train Loss: 0.0503\n",
      "Epoch [374/500], Train Loss: 0.0502\n",
      "Epoch [375/500], Train Loss: 0.0503\n",
      "Epoch [376/500], Train Loss: 0.0501\n",
      "Epoch [377/500], Train Loss: 0.0502\n",
      "Epoch [378/500], Train Loss: 0.0501\n",
      "Epoch [379/500], Train Loss: 0.0502\n",
      "Epoch [380/500], Train Loss: 0.0501\n",
      "Epoch [381/500], Train Loss: 0.0500\n",
      "Epoch [382/500], Train Loss: 0.0499\n",
      "Epoch [383/500], Train Loss: 0.0499\n",
      "Epoch [384/500], Train Loss: 0.0500\n",
      "Epoch [385/500], Train Loss: 0.0497\n",
      "Epoch [386/500], Train Loss: 0.0499\n",
      "Epoch [387/500], Train Loss: 0.0497\n",
      "Epoch [388/500], Train Loss: 0.0497\n",
      "Epoch [389/500], Train Loss: 0.0496\n",
      "Epoch [390/500], Train Loss: 0.0496\n",
      "Epoch [391/500], Train Loss: 0.0496\n",
      "Epoch [392/500], Train Loss: 0.0495\n",
      "Epoch [393/500], Train Loss: 0.0495\n",
      "Epoch [394/500], Train Loss: 0.0494\n",
      "Epoch [395/500], Train Loss: 0.0495\n",
      "Epoch [396/500], Train Loss: 0.0493\n",
      "Epoch [397/500], Train Loss: 0.0494\n",
      "Epoch [398/500], Train Loss: 0.0495\n",
      "Epoch [399/500], Train Loss: 0.0493\n",
      "Epoch [400/500], Train Loss: 0.0491\n",
      "Epoch [401/500], Train Loss: 0.0493\n",
      "Epoch [402/500], Train Loss: 0.0493\n",
      "Epoch [403/500], Train Loss: 0.0493\n",
      "Epoch [404/500], Train Loss: 0.0492\n",
      "Epoch [405/500], Train Loss: 0.0490\n",
      "Epoch [406/500], Train Loss: 0.0490\n",
      "Epoch [407/500], Train Loss: 0.0490\n",
      "Epoch [408/500], Train Loss: 0.0490\n",
      "Epoch [409/500], Train Loss: 0.0491\n",
      "Epoch [410/500], Train Loss: 0.0490\n",
      "Epoch [411/500], Train Loss: 0.0489\n",
      "Epoch [412/500], Train Loss: 0.0488\n",
      "Epoch [413/500], Train Loss: 0.0488\n",
      "Epoch [414/500], Train Loss: 0.0489\n",
      "Epoch [415/500], Train Loss: 0.0489\n",
      "Epoch [416/500], Train Loss: 0.0488\n",
      "Epoch [417/500], Train Loss: 0.0486\n",
      "Epoch [418/500], Train Loss: 0.0487\n",
      "Epoch [419/500], Train Loss: 0.0486\n",
      "Epoch [420/500], Train Loss: 0.0485\n",
      "Epoch [421/500], Train Loss: 0.0484\n",
      "Epoch [422/500], Train Loss: 0.0484\n",
      "Epoch [423/500], Train Loss: 0.0485\n",
      "Epoch [424/500], Train Loss: 0.0485\n",
      "Epoch [425/500], Train Loss: 0.0484\n",
      "Epoch [426/500], Train Loss: 0.0484\n",
      "Epoch [427/500], Train Loss: 0.0483\n",
      "Epoch [428/500], Train Loss: 0.0484\n",
      "Epoch [429/500], Train Loss: 0.0482\n",
      "Epoch [430/500], Train Loss: 0.0483\n",
      "Epoch [431/500], Train Loss: 0.0483\n",
      "Epoch [432/500], Train Loss: 0.0482\n",
      "Epoch [433/500], Train Loss: 0.0481\n",
      "Epoch [434/500], Train Loss: 0.0481\n",
      "Epoch [435/500], Train Loss: 0.0480\n",
      "Epoch [436/500], Train Loss: 0.0480\n",
      "Epoch [437/500], Train Loss: 0.0480\n",
      "Epoch [438/500], Train Loss: 0.0480\n",
      "Epoch [439/500], Train Loss: 0.0480\n",
      "Epoch [440/500], Train Loss: 0.0480\n",
      "Epoch [441/500], Train Loss: 0.0481\n",
      "Epoch [442/500], Train Loss: 0.0480\n",
      "Epoch [443/500], Train Loss: 0.0479\n",
      "Epoch [444/500], Train Loss: 0.0478\n",
      "Epoch [445/500], Train Loss: 0.0478\n",
      "Epoch [446/500], Train Loss: 0.0477\n",
      "Epoch [447/500], Train Loss: 0.0477\n",
      "Epoch [448/500], Train Loss: 0.0478\n",
      "Epoch [449/500], Train Loss: 0.0477\n",
      "Epoch [450/500], Train Loss: 0.0477\n",
      "Epoch [451/500], Train Loss: 0.0477\n",
      "Epoch [452/500], Train Loss: 0.0476\n",
      "Epoch [453/500], Train Loss: 0.0475\n",
      "Epoch [454/500], Train Loss: 0.0475\n",
      "Epoch [455/500], Train Loss: 0.0475\n",
      "Epoch [456/500], Train Loss: 0.0475\n",
      "Epoch [457/500], Train Loss: 0.0475\n",
      "Epoch [458/500], Train Loss: 0.0475\n",
      "Epoch [459/500], Train Loss: 0.0477\n",
      "Epoch [460/500], Train Loss: 0.0475\n",
      "Epoch [461/500], Train Loss: 0.0474\n",
      "Epoch [462/500], Train Loss: 0.0474\n",
      "Epoch [463/500], Train Loss: 0.0473\n",
      "Epoch [464/500], Train Loss: 0.0473\n",
      "Epoch [465/500], Train Loss: 0.0472\n",
      "Epoch [466/500], Train Loss: 0.0472\n",
      "Epoch [467/500], Train Loss: 0.0471\n",
      "Epoch [468/500], Train Loss: 0.0472\n",
      "Epoch [469/500], Train Loss: 0.0472\n",
      "Epoch [470/500], Train Loss: 0.0471\n",
      "Epoch [471/500], Train Loss: 0.0471\n",
      "Epoch [472/500], Train Loss: 0.0471\n",
      "Epoch [473/500], Train Loss: 0.0470\n",
      "Epoch [474/500], Train Loss: 0.0469\n",
      "Epoch [475/500], Train Loss: 0.0470\n",
      "Epoch [476/500], Train Loss: 0.0469\n",
      "Epoch [477/500], Train Loss: 0.0469\n",
      "Epoch [478/500], Train Loss: 0.0471\n",
      "Epoch [479/500], Train Loss: 0.0468\n",
      "Epoch [480/500], Train Loss: 0.0469\n",
      "Epoch [481/500], Train Loss: 0.0469\n",
      "Epoch [482/500], Train Loss: 0.0469\n",
      "Epoch [483/500], Train Loss: 0.0468\n",
      "Epoch [484/500], Train Loss: 0.0470\n",
      "Epoch [485/500], Train Loss: 0.0467\n",
      "Epoch [486/500], Train Loss: 0.0469\n",
      "Epoch [487/500], Train Loss: 0.0469\n",
      "Epoch [488/500], Train Loss: 0.0469\n",
      "Epoch [489/500], Train Loss: 0.0466\n",
      "Epoch [490/500], Train Loss: 0.0466\n",
      "Epoch [491/500], Train Loss: 0.0465\n",
      "Epoch [492/500], Train Loss: 0.0466\n",
      "Epoch [493/500], Train Loss: 0.0466\n",
      "Epoch [494/500], Train Loss: 0.0466\n",
      "Epoch [495/500], Train Loss: 0.0463\n",
      "Epoch [496/500], Train Loss: 0.0466\n",
      "Epoch [497/500], Train Loss: 0.0466\n",
      "Epoch [498/500], Train Loss: 0.0465\n",
      "Epoch [499/500], Train Loss: 0.0465\n",
      "Epoch [500/500], Train Loss: 0.0465\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr3/final_model_chr3.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr3/individual_r2_scores_chr3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:46:11,331] A new study created in memory with name: no-name-207f3f9e-4196-4ed7-bb3f-8c73213c2be1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  20\n",
      "Known PRS313 SNPs:  2\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  722\n",
      "Early stopping at epoch 500\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:46:17,953] Trial 0 finished with value: 0.34696770310401914 and parameters: {'learning_rate': 0.000645791498648196, 'lasso_coef': 0.00048149119986647213, 'patience': 5}. Best is trial 0 with value: 0.34696770310401914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 229\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:46:21,434] Trial 1 finished with value: 0.6346211731433868 and parameters: {'learning_rate': 0.0008062280383266992, 'lasso_coef': 0.025380938785423014, 'patience': 7}. Best is trial 0 with value: 0.34696770310401914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 32\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:46:22,352] Trial 2 finished with value: 0.7641647160053253 and parameters: {'learning_rate': 0.005968623264993697, 'lasso_coef': 0.015423956300543792, 'patience': 5}. Best is trial 0 with value: 0.34696770310401914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 203\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:46:25,158] Trial 3 finished with value: 0.3196843355894089 and parameters: {'learning_rate': 0.0027506218113348417, 'lasso_coef': 0.00030217389880998806, 'patience': 6}. Best is trial 3 with value: 0.3196843355894089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 79\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 36\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:46:27,446] Trial 4 finished with value: 0.6187139362096786 and parameters: {'learning_rate': 0.009982284566004068, 'lasso_coef': 0.004431232907782692, 'patience': 13}. Best is trial 3 with value: 0.3196843355894089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 57\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 32\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:46:29,727] Trial 5 finished with value: 1.398773866891861 and parameters: {'learning_rate': 0.012674170597448207, 'lasso_coef': 0.03713206207547835, 'patience': 17}. Best is trial 3 with value: 0.3196843355894089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 42\n",
      "Early stopping at epoch 93\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:46:31,455] Trial 6 finished with value: 0.2832187727093697 and parameters: {'learning_rate': 0.0057816692399982675, 'lasso_coef': 9.890485902059387e-05, 'patience': 10}. Best is trial 6 with value: 0.2832187727093697.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:46:56,227] Trial 7 finished with value: 0.4694535657763481 and parameters: {'learning_rate': 0.00014589924235725902, 'lasso_coef': 0.0021584172435557907, 'patience': 12}. Best is trial 6 with value: 0.2832187727093697.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 147\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:46:58,341] Trial 8 finished with value: 0.3091473028063774 and parameters: {'learning_rate': 0.0015287019315708308, 'lasso_coef': 0.00013108451346062854, 'patience': 5}. Best is trial 6 with value: 0.2832187727093697.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 201\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:07,968] Trial 9 finished with value: 0.6046722292900085 and parameters: {'learning_rate': 0.0003169506020219153, 'lasso_coef': 0.011894624577390472, 'patience': 18}. Best is trial 6 with value: 0.2832187727093697.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:08,760] Trial 10 finished with value: 0.2814736939966679 and parameters: {'learning_rate': 0.09093049225740722, 'lasso_coef': 1.1288802269187774e-05, 'patience': 10}. Best is trial 10 with value: 0.2814736939966679.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:09,681] Trial 11 finished with value: 0.2887690797448158 and parameters: {'learning_rate': 0.09180122891950392, 'lasso_coef': 1.3919312755498196e-05, 'patience': 11}. Best is trial 10 with value: 0.2814736939966679.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 36\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:10,659] Trial 12 finished with value: 0.29413081854581835 and parameters: {'learning_rate': 0.0987215048237171, 'lasso_coef': 1.0819549840311766e-05, 'patience': 9}. Best is trial 10 with value: 0.2814736939966679.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:11,921] Trial 13 finished with value: 0.29476564973592756 and parameters: {'learning_rate': 0.02844859011364763, 'lasso_coef': 7.978584268263578e-05, 'patience': 15}. Best is trial 10 with value: 0.2814736939966679.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:12,827] Trial 14 finished with value: 0.2809955820441246 and parameters: {'learning_rate': 0.031348953493978524, 'lasso_coef': 5.146306097928184e-05, 'patience': 9}. Best is trial 14 with value: 0.2809955820441246.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:13,494] Trial 15 finished with value: 0.27071841806173325 and parameters: {'learning_rate': 0.03311101907073573, 'lasso_coef': 3.752178251671885e-05, 'patience': 8}. Best is trial 15 with value: 0.27071841806173325.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:14,303] Trial 16 finished with value: 0.2740183547139168 and parameters: {'learning_rate': 0.03001575316356175, 'lasso_coef': 4.4468933644309056e-05, 'patience': 8}. Best is trial 15 with value: 0.27071841806173325.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:14,982] Trial 17 finished with value: 0.2707232885062695 and parameters: {'learning_rate': 0.03219089621221401, 'lasso_coef': 3.625089758898579e-05, 'patience': 8}. Best is trial 15 with value: 0.27071841806173325.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 73\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:17,134] Trial 18 finished with value: 0.4152757927775383 and parameters: {'learning_rate': 0.016593085588364614, 'lasso_coef': 0.0009397404773511326, 'patience': 20}. Best is trial 15 with value: 0.27071841806173325.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 34\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:18,308] Trial 19 finished with value: 0.2662919521331787 and parameters: {'learning_rate': 0.040851769856763365, 'lasso_coef': 2.934906350840252e-05, 'patience': 14}. Best is trial 19 with value: 0.2662919521331787.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:19,582] Trial 20 finished with value: 0.3626694604754448 and parameters: {'learning_rate': 0.050165422506040856, 'lasso_coef': 0.00024290610836057825, 'patience': 14}. Best is trial 19 with value: 0.2662919521331787.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 36\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:20,866] Trial 21 finished with value: 0.25394858345389365 and parameters: {'learning_rate': 0.019407775734863315, 'lasso_coef': 3.0518675178348176e-05, 'patience': 15}. Best is trial 21 with value: 0.25394858345389365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 47\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:22,320] Trial 22 finished with value: 0.25319216921925547 and parameters: {'learning_rate': 0.01623339641396585, 'lasso_coef': 3.287703937714714e-05, 'patience': 16}. Best is trial 22 with value: 0.25319216921925547.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 61\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:23,959] Trial 23 finished with value: 0.2457618311047554 and parameters: {'learning_rate': 0.005774050997491677, 'lasso_coef': 2.3152089679816587e-05, 'patience': 16}. Best is trial 23 with value: 0.2457618311047554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 71\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 39\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:26,294] Trial 24 finished with value: 1.1768019318580627 and parameters: {'learning_rate': 0.00458978725407076, 'lasso_coef': 0.07800237688799756, 'patience': 16}. Best is trial 23 with value: 0.2457618311047554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 101\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:28,579] Trial 25 finished with value: 0.24764278829097747 and parameters: {'learning_rate': 0.0024319619801770474, 'lasso_coef': 2.025889098405302e-05, 'patience': 19}. Best is trial 23 with value: 0.2457618311047554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 480\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:35,987] Trial 26 finished with value: 0.2806898787617683 and parameters: {'learning_rate': 0.002308862533956502, 'lasso_coef': 0.00014344460717659872, 'patience': 20}. Best is trial 23 with value: 0.2457618311047554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 48\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:37,660] Trial 27 finished with value: 0.23901184573769568 and parameters: {'learning_rate': 0.00796838664838617, 'lasso_coef': 1.947627228413363e-05, 'patience': 18}. Best is trial 27 with value: 0.23901184573769568.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 165\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:40,747] Trial 28 finished with value: 0.24791111052036285 and parameters: {'learning_rate': 0.0016212112487855852, 'lasso_coef': 2.2543768424923492e-05, 'patience': 18}. Best is trial 27 with value: 0.23901184573769568.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:48,092] Trial 29 finished with value: 0.3493510246276855 and parameters: {'learning_rate': 0.0007403079350560574, 'lasso_coef': 0.0005580791200881853, 'patience': 19}. Best is trial 27 with value: 0.23901184573769568.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 23\n",
      "Best hyperparameters: {'learning_rate': 0.00796838664838617, 'lasso_coef': 1.947627228413363e-05, 'patience': 18}\n",
      "Best value: 0.23901184573769568\n",
      "Epoch [1/500], Train Loss: 0.5761\n",
      "Epoch [2/500], Train Loss: 0.4491\n",
      "Epoch [3/500], Train Loss: 0.3951\n",
      "Epoch [4/500], Train Loss: 0.3643\n",
      "Epoch [5/500], Train Loss: 0.3431\n",
      "Epoch [6/500], Train Loss: 0.3272\n",
      "Epoch [7/500], Train Loss: 0.3162\n",
      "Epoch [8/500], Train Loss: 0.3080\n",
      "Epoch [9/500], Train Loss: 0.2995\n",
      "Epoch [10/500], Train Loss: 0.2915\n",
      "Epoch [11/500], Train Loss: 0.2870\n",
      "Epoch [12/500], Train Loss: 0.2817\n",
      "Epoch [13/500], Train Loss: 0.2771\n",
      "Epoch [14/500], Train Loss: 0.2730\n",
      "Epoch [15/500], Train Loss: 0.2694\n",
      "Epoch [16/500], Train Loss: 0.2657\n",
      "Epoch [17/500], Train Loss: 0.2633\n",
      "Epoch [18/500], Train Loss: 0.2609\n",
      "Epoch [19/500], Train Loss: 0.2582\n",
      "Epoch [20/500], Train Loss: 0.2566\n",
      "Epoch [21/500], Train Loss: 0.2545\n",
      "Epoch [22/500], Train Loss: 0.2531\n",
      "Epoch [23/500], Train Loss: 0.2511\n",
      "Epoch [24/500], Train Loss: 0.2485\n",
      "Epoch [25/500], Train Loss: 0.2462\n",
      "Epoch [26/500], Train Loss: 0.2439\n",
      "Epoch [27/500], Train Loss: 0.2431\n",
      "Epoch [28/500], Train Loss: 0.2429\n",
      "Epoch [29/500], Train Loss: 0.2417\n",
      "Epoch [30/500], Train Loss: 0.2406\n",
      "Epoch [31/500], Train Loss: 0.2386\n",
      "Epoch [32/500], Train Loss: 0.2392\n",
      "Epoch [33/500], Train Loss: 0.2378\n",
      "Epoch [34/500], Train Loss: 0.2359\n",
      "Epoch [35/500], Train Loss: 0.2351\n",
      "Epoch [36/500], Train Loss: 0.2348\n",
      "Epoch [37/500], Train Loss: 0.2334\n",
      "Epoch [38/500], Train Loss: 0.2322\n",
      "Epoch [39/500], Train Loss: 0.2316\n",
      "Epoch [40/500], Train Loss: 0.2318\n",
      "Epoch [41/500], Train Loss: 0.2294\n",
      "Epoch [42/500], Train Loss: 0.2281\n",
      "Epoch [43/500], Train Loss: 0.2294\n",
      "Epoch [44/500], Train Loss: 0.2288\n",
      "Epoch [45/500], Train Loss: 0.2275\n",
      "Epoch [46/500], Train Loss: 0.2267\n",
      "Epoch [47/500], Train Loss: 0.2259\n",
      "Epoch [48/500], Train Loss: 0.2249\n",
      "Epoch [49/500], Train Loss: 0.2252\n",
      "Epoch [50/500], Train Loss: 0.2242\n",
      "Epoch [51/500], Train Loss: 0.2230\n",
      "Epoch [52/500], Train Loss: 0.2231\n",
      "Epoch [53/500], Train Loss: 0.2225\n",
      "Epoch [54/500], Train Loss: 0.2240\n",
      "Epoch [55/500], Train Loss: 0.2234\n",
      "Epoch [56/500], Train Loss: 0.2229\n",
      "Epoch [57/500], Train Loss: 0.2242\n",
      "Epoch [58/500], Train Loss: 0.2223\n",
      "Epoch [59/500], Train Loss: 0.2209\n",
      "Epoch [60/500], Train Loss: 0.2209\n",
      "Epoch [61/500], Train Loss: 0.2218\n",
      "Epoch [62/500], Train Loss: 0.2215\n",
      "Epoch [63/500], Train Loss: 0.2212\n",
      "Epoch [64/500], Train Loss: 0.2201\n",
      "Epoch [65/500], Train Loss: 0.2199\n",
      "Epoch [66/500], Train Loss: 0.2194\n",
      "Epoch [67/500], Train Loss: 0.2181\n",
      "Epoch [68/500], Train Loss: 0.2175\n",
      "Epoch [69/500], Train Loss: 0.2169\n",
      "Epoch [70/500], Train Loss: 0.2170\n",
      "Epoch [71/500], Train Loss: 0.2182\n",
      "Epoch [72/500], Train Loss: 0.2161\n",
      "Epoch [73/500], Train Loss: 0.2156\n",
      "Epoch [74/500], Train Loss: 0.2155\n",
      "Epoch [75/500], Train Loss: 0.2164\n",
      "Epoch [76/500], Train Loss: 0.2180\n",
      "Epoch [77/500], Train Loss: 0.2168\n",
      "Epoch [78/500], Train Loss: 0.2151\n",
      "Epoch [79/500], Train Loss: 0.2155\n",
      "Epoch [80/500], Train Loss: 0.2147\n",
      "Epoch [81/500], Train Loss: 0.2139\n",
      "Epoch [82/500], Train Loss: 0.2142\n",
      "Epoch [83/500], Train Loss: 0.2138\n",
      "Epoch [84/500], Train Loss: 0.2139\n",
      "Epoch [85/500], Train Loss: 0.2137\n",
      "Epoch [86/500], Train Loss: 0.2151\n",
      "Epoch [87/500], Train Loss: 0.2154\n",
      "Epoch [88/500], Train Loss: 0.2134\n",
      "Epoch [89/500], Train Loss: 0.2133\n",
      "Epoch [90/500], Train Loss: 0.2136\n",
      "Epoch [91/500], Train Loss: 0.2125\n",
      "Epoch [92/500], Train Loss: 0.2132\n",
      "Epoch [93/500], Train Loss: 0.2123\n",
      "Epoch [94/500], Train Loss: 0.2126\n",
      "Epoch [95/500], Train Loss: 0.2128\n",
      "Epoch [96/500], Train Loss: 0.2123\n",
      "Epoch [97/500], Train Loss: 0.2121\n",
      "Epoch [98/500], Train Loss: 0.2116\n",
      "Epoch [99/500], Train Loss: 0.2112\n",
      "Epoch [100/500], Train Loss: 0.2116\n",
      "Epoch [101/500], Train Loss: 0.2112\n",
      "Epoch [102/500], Train Loss: 0.2117\n",
      "Epoch [103/500], Train Loss: 0.2105\n",
      "Epoch [104/500], Train Loss: 0.2106\n",
      "Epoch [105/500], Train Loss: 0.2108\n",
      "Epoch [106/500], Train Loss: 0.2112\n",
      "Epoch [107/500], Train Loss: 0.2114\n",
      "Epoch [108/500], Train Loss: 0.2109\n",
      "Epoch [109/500], Train Loss: 0.2101\n",
      "Epoch [110/500], Train Loss: 0.2102\n",
      "Epoch [111/500], Train Loss: 0.2098\n",
      "Epoch [112/500], Train Loss: 0.2087\n",
      "Epoch [113/500], Train Loss: 0.2095\n",
      "Epoch [114/500], Train Loss: 0.2103\n",
      "Epoch [115/500], Train Loss: 0.2098\n",
      "Epoch [116/500], Train Loss: 0.2092\n",
      "Epoch [117/500], Train Loss: 0.2104\n",
      "Epoch [118/500], Train Loss: 0.2107\n",
      "Epoch [119/500], Train Loss: 0.2096\n",
      "Epoch [120/500], Train Loss: 0.2091\n",
      "Epoch [121/500], Train Loss: 0.2098\n",
      "Epoch [122/500], Train Loss: 0.2093\n",
      "Epoch [123/500], Train Loss: 0.2085\n",
      "Epoch [124/500], Train Loss: 0.2089\n",
      "Epoch [125/500], Train Loss: 0.2085\n",
      "Epoch [126/500], Train Loss: 0.2081\n",
      "Epoch [127/500], Train Loss: 0.2080\n",
      "Epoch [128/500], Train Loss: 0.2075\n",
      "Epoch [129/500], Train Loss: 0.2075\n",
      "Epoch [130/500], Train Loss: 0.2089\n",
      "Epoch [131/500], Train Loss: 0.2091\n",
      "Epoch [132/500], Train Loss: 0.2094\n",
      "Epoch [133/500], Train Loss: 0.2104\n",
      "Epoch [134/500], Train Loss: 0.2081\n",
      "Epoch [135/500], Train Loss: 0.2080\n",
      "Epoch [136/500], Train Loss: 0.2067\n",
      "Epoch [137/500], Train Loss: 0.2085\n",
      "Epoch [138/500], Train Loss: 0.2089\n",
      "Epoch [139/500], Train Loss: 0.2077\n",
      "Epoch [140/500], Train Loss: 0.2078\n",
      "Epoch [141/500], Train Loss: 0.2073\n",
      "Epoch [142/500], Train Loss: 0.2062\n",
      "Epoch [143/500], Train Loss: 0.2073\n",
      "Epoch [144/500], Train Loss: 0.2066\n",
      "Epoch [145/500], Train Loss: 0.2059\n",
      "Epoch [146/500], Train Loss: 0.2069\n",
      "Epoch [147/500], Train Loss: 0.2075\n",
      "Epoch [148/500], Train Loss: 0.2065\n",
      "Epoch [149/500], Train Loss: 0.2062\n",
      "Epoch [150/500], Train Loss: 0.2063\n",
      "Epoch [151/500], Train Loss: 0.2071\n",
      "Epoch [152/500], Train Loss: 0.2088\n",
      "Epoch [153/500], Train Loss: 0.2072\n",
      "Epoch [154/500], Train Loss: 0.2069\n",
      "Epoch [155/500], Train Loss: 0.2064\n",
      "Epoch [156/500], Train Loss: 0.2053\n",
      "Epoch [157/500], Train Loss: 0.2060\n",
      "Epoch [158/500], Train Loss: 0.2071\n",
      "Epoch [159/500], Train Loss: 0.2070\n",
      "Epoch [160/500], Train Loss: 0.2050\n",
      "Epoch [161/500], Train Loss: 0.2053\n",
      "Epoch [162/500], Train Loss: 0.2061\n",
      "Epoch [163/500], Train Loss: 0.2063\n",
      "Epoch [164/500], Train Loss: 0.2070\n",
      "Epoch [165/500], Train Loss: 0.2070\n",
      "Epoch [166/500], Train Loss: 0.2058\n",
      "Epoch [167/500], Train Loss: 0.2047\n",
      "Epoch [168/500], Train Loss: 0.2059\n",
      "Epoch [169/500], Train Loss: 0.2058\n",
      "Epoch [170/500], Train Loss: 0.2054\n",
      "Epoch [171/500], Train Loss: 0.2060\n",
      "Epoch [172/500], Train Loss: 0.2061\n",
      "Epoch [173/500], Train Loss: 0.2049\n",
      "Epoch [174/500], Train Loss: 0.2049\n",
      "Epoch [175/500], Train Loss: 0.2053\n",
      "Epoch [176/500], Train Loss: 0.2061\n",
      "Epoch [177/500], Train Loss: 0.2047\n",
      "Epoch [178/500], Train Loss: 0.2049\n",
      "Epoch [179/500], Train Loss: 0.2054\n",
      "Epoch [180/500], Train Loss: 0.2056\n",
      "Epoch [181/500], Train Loss: 0.2067\n",
      "Epoch [182/500], Train Loss: 0.2051\n",
      "Epoch [183/500], Train Loss: 0.2051\n",
      "Epoch [184/500], Train Loss: 0.2061\n",
      "Epoch [185/500], Train Loss: 0.2067\n",
      "Epoch [186/500], Train Loss: 0.2057\n",
      "Epoch [187/500], Train Loss: 0.2066\n",
      "Epoch [188/500], Train Loss: 0.2050\n",
      "Epoch [189/500], Train Loss: 0.2045\n",
      "Epoch [190/500], Train Loss: 0.2051\n",
      "Epoch [191/500], Train Loss: 0.2055\n",
      "Epoch [192/500], Train Loss: 0.2048\n",
      "Epoch [193/500], Train Loss: 0.2040\n",
      "Epoch [194/500], Train Loss: 0.2042\n",
      "Epoch [195/500], Train Loss: 0.2054\n",
      "Epoch [196/500], Train Loss: 0.2044\n",
      "Epoch [197/500], Train Loss: 0.2038\n",
      "Epoch [198/500], Train Loss: 0.2042\n",
      "Epoch [199/500], Train Loss: 0.2054\n",
      "Epoch [200/500], Train Loss: 0.2051\n",
      "Epoch [201/500], Train Loss: 0.2044\n",
      "Epoch [202/500], Train Loss: 0.2049\n",
      "Epoch [203/500], Train Loss: 0.2050\n",
      "Epoch [204/500], Train Loss: 0.2052\n",
      "Epoch [205/500], Train Loss: 0.2055\n",
      "Epoch [206/500], Train Loss: 0.2042\n",
      "Epoch [207/500], Train Loss: 0.2041\n",
      "Epoch [208/500], Train Loss: 0.2062\n",
      "Epoch [209/500], Train Loss: 0.2045\n",
      "Epoch [210/500], Train Loss: 0.2047\n",
      "Epoch [211/500], Train Loss: 0.2038\n",
      "Epoch [212/500], Train Loss: 0.2040\n",
      "Epoch [213/500], Train Loss: 0.2033\n",
      "Epoch [214/500], Train Loss: 0.2065\n",
      "Epoch [215/500], Train Loss: 0.2043\n",
      "Epoch [216/500], Train Loss: 0.2061\n",
      "Epoch [217/500], Train Loss: 0.2047\n",
      "Epoch [218/500], Train Loss: 0.2048\n",
      "Epoch [219/500], Train Loss: 0.2054\n",
      "Epoch [220/500], Train Loss: 0.2049\n",
      "Epoch [221/500], Train Loss: 0.2050\n",
      "Epoch [222/500], Train Loss: 0.2029\n",
      "Epoch [223/500], Train Loss: 0.2029\n",
      "Epoch [224/500], Train Loss: 0.2044\n",
      "Epoch [225/500], Train Loss: 0.2040\n",
      "Epoch [226/500], Train Loss: 0.2029\n",
      "Epoch [227/500], Train Loss: 0.2039\n",
      "Epoch [228/500], Train Loss: 0.2036\n",
      "Epoch [229/500], Train Loss: 0.2059\n",
      "Epoch [230/500], Train Loss: 0.2045\n",
      "Epoch [231/500], Train Loss: 0.2031\n",
      "Epoch [232/500], Train Loss: 0.2049\n",
      "Epoch [233/500], Train Loss: 0.2051\n",
      "Epoch [234/500], Train Loss: 0.2050\n",
      "Epoch [235/500], Train Loss: 0.2036\n",
      "Epoch [236/500], Train Loss: 0.2031\n",
      "Epoch [237/500], Train Loss: 0.2032\n",
      "Epoch [238/500], Train Loss: 0.2032\n",
      "Epoch [239/500], Train Loss: 0.2036\n",
      "Epoch [240/500], Train Loss: 0.2039\n",
      "Epoch [241/500], Train Loss: 0.2042\n",
      "Epoch [242/500], Train Loss: 0.2033\n",
      "Epoch [243/500], Train Loss: 0.2052\n",
      "Epoch [244/500], Train Loss: 0.2052\n",
      "Early stopping at epoch 244\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr4/final_model_chr4.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr4/individual_r2_scores_chr4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:52,487] A new study created in memory with name: no-name-e1029ec0-8ad7-48c8-80c7-74db24c44138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  54\n",
      "Known PRS313 SNPs:  14\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  1850\n",
      "Early stopping at epoch 55\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:55,073] Trial 0 finished with value: 0.349575386941433 and parameters: {'learning_rate': 0.008139392439861, 'lasso_coef': 0.00033299685284183796, 'patience': 5}. Best is trial 0 with value: 0.349575386941433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 61\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:47:58,256] Trial 1 finished with value: 0.18888425901532174 and parameters: {'learning_rate': 0.021685291263793715, 'lasso_coef': 2.9550186778147754e-05, 'patience': 18}. Best is trial 1 with value: 0.18888425901532174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:48:23,196] Trial 2 finished with value: 0.28783571124076845 and parameters: {'learning_rate': 0.00036503410855019913, 'lasso_coef': 0.0002519994665943706, 'patience': 9}. Best is trial 1 with value: 0.18888425901532174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 433\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:48:34,980] Trial 3 finished with value: 0.2719793751835823 and parameters: {'learning_rate': 0.0011911592668240056, 'lasso_coef': 0.0002380279576513291, 'patience': 10}. Best is trial 1 with value: 0.18888425901532174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 40\n",
      "Early stopping at epoch 54\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:48:38,836] Trial 4 finished with value: 0.5936871290206909 and parameters: {'learning_rate': 0.08023581985924987, 'lasso_coef': 0.00011237127676849995, 'patience': 16}. Best is trial 1 with value: 0.18888425901532174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 58\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:48:41,655] Trial 5 finished with value: 1.5820432722568512 and parameters: {'learning_rate': 0.011964518490506776, 'lasso_coef': 0.007229348033222593, 'patience': 7}. Best is trial 1 with value: 0.18888425901532174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 81\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:48:45,915] Trial 6 finished with value: 0.3397912189364433 and parameters: {'learning_rate': 0.013261982184308877, 'lasso_coef': 0.00027558206611682156, 'patience': 16}. Best is trial 1 with value: 0.18888425901532174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 429\n",
      "Early stopping at epoch 37\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:49:10,553] Trial 7 finished with value: 0.5934477269649505 and parameters: {'learning_rate': 0.00027122140962686193, 'lasso_coef': 0.022320442239309384, 'patience': 15}. Best is trial 1 with value: 0.18888425901532174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:49:24,122] Trial 8 finished with value: 0.16021855995059014 and parameters: {'learning_rate': 0.0005240412842032972, 'lasso_coef': 2.4368708332355428e-05, 'patience': 13}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 366\n",
      "Early stopping at epoch 65\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:49:36,601] Trial 9 finished with value: 0.8952160775661469 and parameters: {'learning_rate': 0.0011431078217002911, 'lasso_coef': 0.029364873857285922, 'patience': 18}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:49:50,850] Trial 10 finished with value: 0.1957549884915352 and parameters: {'learning_rate': 0.00014155598288713127, 'lasso_coef': 1.3757961382363711e-05, 'patience': 12}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 28\n",
      "Early stopping at epoch 52\n",
      "Early stopping at epoch 56\n",
      "Early stopping at epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:49:55,875] Trial 11 finished with value: 10.074746251106262 and parameters: {'learning_rate': 0.08436870379917132, 'lasso_coef': 1.1841834626403814e-05, 'patience': 20}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 32\n",
      "Early stopping at epoch 206\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:50:02,132] Trial 12 finished with value: 0.17105194851756095 and parameters: {'learning_rate': 0.0031850217789428253, 'lasso_coef': 3.5683930095266786e-05, 'patience': 13}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 238\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:50:09,145] Trial 13 finished with value: 0.537647294998169 and parameters: {'learning_rate': 0.0016430792682761235, 'lasso_coef': 0.002111149793148833, 'patience': 13}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 156\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:50:14,049] Trial 14 finished with value: 0.19079906195402146 and parameters: {'learning_rate': 0.0036339357599554345, 'lasso_coef': 5.049265149587448e-05, 'patience': 11}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 238\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:50:33,102] Trial 15 finished with value: 0.4599410712718964 and parameters: {'learning_rate': 0.00044241946308389, 'lasso_coef': 0.0014075256713362717, 'patience': 14}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 147\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:50:37,647] Trial 16 finished with value: 0.1945797860622406 and parameters: {'learning_rate': 0.0035356692649328395, 'lasso_coef': 5.301068885506742e-05, 'patience': 8}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:50:51,082] Trial 17 finished with value: 0.2501632884144783 and parameters: {'learning_rate': 0.00010053107814232065, 'lasso_coef': 3.013073450165784e-05, 'patience': 12}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:51:04,766] Trial 18 finished with value: 0.5518419414758682 and parameters: {'learning_rate': 0.0006471911779653182, 'lasso_coef': 0.0038777739612696595, 'patience': 14}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 300\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:51:13,643] Trial 19 finished with value: 0.36538136154413225 and parameters: {'learning_rate': 0.0025807327662981773, 'lasso_coef': 0.0005644886745262767, 'patience': 10}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 313\n",
      "Early stopping at epoch 101\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:51:37,362] Trial 20 finished with value: 0.7155036389827728 and parameters: {'learning_rate': 0.00022276077161965238, 'lasso_coef': 0.07804641715164061, 'patience': 17}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 41\n",
      "Early stopping at epoch 51\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:51:40,631] Trial 21 finished with value: 0.21385599821805953 and parameters: {'learning_rate': 0.03438037204428076, 'lasso_coef': 2.94975882259189e-05, 'patience': 20}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 39\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 39\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:51:44,126] Trial 22 finished with value: 0.3050275906920433 and parameters: {'learning_rate': 0.031197173175418584, 'lasso_coef': 0.0001125772996047053, 'patience': 18}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 158\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:51:49,394] Trial 23 finished with value: 0.22572352662682532 and parameters: {'learning_rate': 0.006494800666880344, 'lasso_coef': 9.053129681181897e-05, 'patience': 14}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 50\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:51:52,097] Trial 24 finished with value: 0.17873598933219909 and parameters: {'learning_rate': 0.02833604106909152, 'lasso_coef': 2.085290842913112e-05, 'patience': 13}. Best is trial 8 with value: 0.16021855995059014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 493\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:52:05,402] Trial 25 finished with value: 0.12476577535271645 and parameters: {'learning_rate': 0.0009605897257633915, 'lasso_coef': 1.0833018510839542e-05, 'patience': 13}. Best is trial 25 with value: 0.12476577535271645.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:52:18,682] Trial 26 finished with value: 0.12625186517834663 and parameters: {'learning_rate': 0.0007343472367189336, 'lasso_coef': 1.0109859203676933e-05, 'patience': 12}. Best is trial 25 with value: 0.12476577535271645.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:52:32,267] Trial 27 finished with value: 0.12653031013906002 and parameters: {'learning_rate': 0.0007422806824463017, 'lasso_coef': 1.0182748304718905e-05, 'patience': 11}. Best is trial 25 with value: 0.12476577535271645.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:52:45,269] Trial 28 finished with value: 0.1250130396336317 and parameters: {'learning_rate': 0.0008312784431377715, 'lasso_coef': 1.0259049644089237e-05, 'patience': 11}. Best is trial 25 with value: 0.12476577535271645.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 320\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:52:53,604] Trial 29 finished with value: 0.2088383689522743 and parameters: {'learning_rate': 0.0008697082828571324, 'lasso_coef': 6.722262661205927e-05, 'patience': 5}. Best is trial 25 with value: 0.12476577535271645.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Best hyperparameters: {'learning_rate': 0.0009605897257633915, 'lasso_coef': 1.0833018510839542e-05, 'patience': 13}\n",
      "Best value: 0.12476577535271645\n",
      "Epoch [1/500], Train Loss: 0.5534\n",
      "Epoch [2/500], Train Loss: 0.4884\n",
      "Epoch [3/500], Train Loss: 0.4602\n",
      "Epoch [4/500], Train Loss: 0.4402\n",
      "Epoch [5/500], Train Loss: 0.4225\n",
      "Epoch [6/500], Train Loss: 0.4069\n",
      "Epoch [7/500], Train Loss: 0.3928\n",
      "Epoch [8/500], Train Loss: 0.3806\n",
      "Epoch [9/500], Train Loss: 0.3686\n",
      "Epoch [10/500], Train Loss: 0.3579\n",
      "Epoch [11/500], Train Loss: 0.3477\n",
      "Epoch [12/500], Train Loss: 0.3391\n",
      "Epoch [13/500], Train Loss: 0.3305\n",
      "Epoch [14/500], Train Loss: 0.3229\n",
      "Epoch [15/500], Train Loss: 0.3155\n",
      "Epoch [16/500], Train Loss: 0.3087\n",
      "Epoch [17/500], Train Loss: 0.3021\n",
      "Epoch [18/500], Train Loss: 0.2964\n",
      "Epoch [19/500], Train Loss: 0.2907\n",
      "Epoch [20/500], Train Loss: 0.2852\n",
      "Epoch [21/500], Train Loss: 0.2806\n",
      "Epoch [22/500], Train Loss: 0.2756\n",
      "Epoch [23/500], Train Loss: 0.2712\n",
      "Epoch [24/500], Train Loss: 0.2667\n",
      "Epoch [25/500], Train Loss: 0.2628\n",
      "Epoch [26/500], Train Loss: 0.2589\n",
      "Epoch [27/500], Train Loss: 0.2550\n",
      "Epoch [28/500], Train Loss: 0.2516\n",
      "Epoch [29/500], Train Loss: 0.2478\n",
      "Epoch [30/500], Train Loss: 0.2447\n",
      "Epoch [31/500], Train Loss: 0.2414\n",
      "Epoch [32/500], Train Loss: 0.2386\n",
      "Epoch [33/500], Train Loss: 0.2358\n",
      "Epoch [34/500], Train Loss: 0.2328\n",
      "Epoch [35/500], Train Loss: 0.2298\n",
      "Epoch [36/500], Train Loss: 0.2278\n",
      "Epoch [37/500], Train Loss: 0.2253\n",
      "Epoch [38/500], Train Loss: 0.2227\n",
      "Epoch [39/500], Train Loss: 0.2204\n",
      "Epoch [40/500], Train Loss: 0.2180\n",
      "Epoch [41/500], Train Loss: 0.2160\n",
      "Epoch [42/500], Train Loss: 0.2138\n",
      "Epoch [43/500], Train Loss: 0.2117\n",
      "Epoch [44/500], Train Loss: 0.2099\n",
      "Epoch [45/500], Train Loss: 0.2077\n",
      "Epoch [46/500], Train Loss: 0.2060\n",
      "Epoch [47/500], Train Loss: 0.2041\n",
      "Epoch [48/500], Train Loss: 0.2024\n",
      "Epoch [49/500], Train Loss: 0.2009\n",
      "Epoch [50/500], Train Loss: 0.1991\n",
      "Epoch [51/500], Train Loss: 0.1975\n",
      "Epoch [52/500], Train Loss: 0.1959\n",
      "Epoch [53/500], Train Loss: 0.1946\n",
      "Epoch [54/500], Train Loss: 0.1932\n",
      "Epoch [55/500], Train Loss: 0.1914\n",
      "Epoch [56/500], Train Loss: 0.1903\n",
      "Epoch [57/500], Train Loss: 0.1885\n",
      "Epoch [58/500], Train Loss: 0.1874\n",
      "Epoch [59/500], Train Loss: 0.1859\n",
      "Epoch [60/500], Train Loss: 0.1848\n",
      "Epoch [61/500], Train Loss: 0.1840\n",
      "Epoch [62/500], Train Loss: 0.1825\n",
      "Epoch [63/500], Train Loss: 0.1814\n",
      "Epoch [64/500], Train Loss: 0.1801\n",
      "Epoch [65/500], Train Loss: 0.1790\n",
      "Epoch [66/500], Train Loss: 0.1776\n",
      "Epoch [67/500], Train Loss: 0.1769\n",
      "Epoch [68/500], Train Loss: 0.1758\n",
      "Epoch [69/500], Train Loss: 0.1747\n",
      "Epoch [70/500], Train Loss: 0.1735\n",
      "Epoch [71/500], Train Loss: 0.1727\n",
      "Epoch [72/500], Train Loss: 0.1718\n",
      "Epoch [73/500], Train Loss: 0.1705\n",
      "Epoch [74/500], Train Loss: 0.1699\n",
      "Epoch [75/500], Train Loss: 0.1689\n",
      "Epoch [76/500], Train Loss: 0.1680\n",
      "Epoch [77/500], Train Loss: 0.1672\n",
      "Epoch [78/500], Train Loss: 0.1661\n",
      "Epoch [79/500], Train Loss: 0.1654\n",
      "Epoch [80/500], Train Loss: 0.1645\n",
      "Epoch [81/500], Train Loss: 0.1638\n",
      "Epoch [82/500], Train Loss: 0.1629\n",
      "Epoch [83/500], Train Loss: 0.1623\n",
      "Epoch [84/500], Train Loss: 0.1614\n",
      "Epoch [85/500], Train Loss: 0.1606\n",
      "Epoch [86/500], Train Loss: 0.1598\n",
      "Epoch [87/500], Train Loss: 0.1592\n",
      "Epoch [88/500], Train Loss: 0.1585\n",
      "Epoch [89/500], Train Loss: 0.1577\n",
      "Epoch [90/500], Train Loss: 0.1572\n",
      "Epoch [91/500], Train Loss: 0.1564\n",
      "Epoch [92/500], Train Loss: 0.1556\n",
      "Epoch [93/500], Train Loss: 0.1549\n",
      "Epoch [94/500], Train Loss: 0.1545\n",
      "Epoch [95/500], Train Loss: 0.1538\n",
      "Epoch [96/500], Train Loss: 0.1532\n",
      "Epoch [97/500], Train Loss: 0.1525\n",
      "Epoch [98/500], Train Loss: 0.1518\n",
      "Epoch [99/500], Train Loss: 0.1511\n",
      "Epoch [100/500], Train Loss: 0.1507\n",
      "Epoch [101/500], Train Loss: 0.1500\n",
      "Epoch [102/500], Train Loss: 0.1494\n",
      "Epoch [103/500], Train Loss: 0.1490\n",
      "Epoch [104/500], Train Loss: 0.1485\n",
      "Epoch [105/500], Train Loss: 0.1480\n",
      "Epoch [106/500], Train Loss: 0.1473\n",
      "Epoch [107/500], Train Loss: 0.1469\n",
      "Epoch [108/500], Train Loss: 0.1462\n",
      "Epoch [109/500], Train Loss: 0.1455\n",
      "Epoch [110/500], Train Loss: 0.1452\n",
      "Epoch [111/500], Train Loss: 0.1449\n",
      "Epoch [112/500], Train Loss: 0.1443\n",
      "Epoch [113/500], Train Loss: 0.1438\n",
      "Epoch [114/500], Train Loss: 0.1433\n",
      "Epoch [115/500], Train Loss: 0.1427\n",
      "Epoch [116/500], Train Loss: 0.1421\n",
      "Epoch [117/500], Train Loss: 0.1418\n",
      "Epoch [118/500], Train Loss: 0.1416\n",
      "Epoch [119/500], Train Loss: 0.1410\n",
      "Epoch [120/500], Train Loss: 0.1403\n",
      "Epoch [121/500], Train Loss: 0.1400\n",
      "Epoch [122/500], Train Loss: 0.1394\n",
      "Epoch [123/500], Train Loss: 0.1390\n",
      "Epoch [124/500], Train Loss: 0.1387\n",
      "Epoch [125/500], Train Loss: 0.1383\n",
      "Epoch [126/500], Train Loss: 0.1379\n",
      "Epoch [127/500], Train Loss: 0.1373\n",
      "Epoch [128/500], Train Loss: 0.1370\n",
      "Epoch [129/500], Train Loss: 0.1367\n",
      "Epoch [130/500], Train Loss: 0.1363\n",
      "Epoch [131/500], Train Loss: 0.1358\n",
      "Epoch [132/500], Train Loss: 0.1354\n",
      "Epoch [133/500], Train Loss: 0.1349\n",
      "Epoch [134/500], Train Loss: 0.1346\n",
      "Epoch [135/500], Train Loss: 0.1342\n",
      "Epoch [136/500], Train Loss: 0.1339\n",
      "Epoch [137/500], Train Loss: 0.1337\n",
      "Epoch [138/500], Train Loss: 0.1334\n",
      "Epoch [139/500], Train Loss: 0.1329\n",
      "Epoch [140/500], Train Loss: 0.1326\n",
      "Epoch [141/500], Train Loss: 0.1320\n",
      "Epoch [142/500], Train Loss: 0.1317\n",
      "Epoch [143/500], Train Loss: 0.1315\n",
      "Epoch [144/500], Train Loss: 0.1312\n",
      "Epoch [145/500], Train Loss: 0.1307\n",
      "Epoch [146/500], Train Loss: 0.1305\n",
      "Epoch [147/500], Train Loss: 0.1302\n",
      "Epoch [148/500], Train Loss: 0.1297\n",
      "Epoch [149/500], Train Loss: 0.1295\n",
      "Epoch [150/500], Train Loss: 0.1293\n",
      "Epoch [151/500], Train Loss: 0.1287\n",
      "Epoch [152/500], Train Loss: 0.1283\n",
      "Epoch [153/500], Train Loss: 0.1282\n",
      "Epoch [154/500], Train Loss: 0.1278\n",
      "Epoch [155/500], Train Loss: 0.1276\n",
      "Epoch [156/500], Train Loss: 0.1273\n",
      "Epoch [157/500], Train Loss: 0.1270\n",
      "Epoch [158/500], Train Loss: 0.1266\n",
      "Epoch [159/500], Train Loss: 0.1266\n",
      "Epoch [160/500], Train Loss: 0.1261\n",
      "Epoch [161/500], Train Loss: 0.1257\n",
      "Epoch [162/500], Train Loss: 0.1254\n",
      "Epoch [163/500], Train Loss: 0.1253\n",
      "Epoch [164/500], Train Loss: 0.1248\n",
      "Epoch [165/500], Train Loss: 0.1249\n",
      "Epoch [166/500], Train Loss: 0.1245\n",
      "Epoch [167/500], Train Loss: 0.1241\n",
      "Epoch [168/500], Train Loss: 0.1238\n",
      "Epoch [169/500], Train Loss: 0.1236\n",
      "Epoch [170/500], Train Loss: 0.1233\n",
      "Epoch [171/500], Train Loss: 0.1230\n",
      "Epoch [172/500], Train Loss: 0.1227\n",
      "Epoch [173/500], Train Loss: 0.1225\n",
      "Epoch [174/500], Train Loss: 0.1222\n",
      "Epoch [175/500], Train Loss: 0.1223\n",
      "Epoch [176/500], Train Loss: 0.1217\n",
      "Epoch [177/500], Train Loss: 0.1214\n",
      "Epoch [178/500], Train Loss: 0.1213\n",
      "Epoch [179/500], Train Loss: 0.1211\n",
      "Epoch [180/500], Train Loss: 0.1208\n",
      "Epoch [181/500], Train Loss: 0.1205\n",
      "Epoch [182/500], Train Loss: 0.1202\n",
      "Epoch [183/500], Train Loss: 0.1202\n",
      "Epoch [184/500], Train Loss: 0.1200\n",
      "Epoch [185/500], Train Loss: 0.1197\n",
      "Epoch [186/500], Train Loss: 0.1195\n",
      "Epoch [187/500], Train Loss: 0.1192\n",
      "Epoch [188/500], Train Loss: 0.1190\n",
      "Epoch [189/500], Train Loss: 0.1188\n",
      "Epoch [190/500], Train Loss: 0.1185\n",
      "Epoch [191/500], Train Loss: 0.1183\n",
      "Epoch [192/500], Train Loss: 0.1181\n",
      "Epoch [193/500], Train Loss: 0.1179\n",
      "Epoch [194/500], Train Loss: 0.1176\n",
      "Epoch [195/500], Train Loss: 0.1174\n",
      "Epoch [196/500], Train Loss: 0.1172\n",
      "Epoch [197/500], Train Loss: 0.1169\n",
      "Epoch [198/500], Train Loss: 0.1168\n",
      "Epoch [199/500], Train Loss: 0.1167\n",
      "Epoch [200/500], Train Loss: 0.1164\n",
      "Epoch [201/500], Train Loss: 0.1163\n",
      "Epoch [202/500], Train Loss: 0.1160\n",
      "Epoch [203/500], Train Loss: 0.1157\n",
      "Epoch [204/500], Train Loss: 0.1155\n",
      "Epoch [205/500], Train Loss: 0.1154\n",
      "Epoch [206/500], Train Loss: 0.1153\n",
      "Epoch [207/500], Train Loss: 0.1149\n",
      "Epoch [208/500], Train Loss: 0.1149\n",
      "Epoch [209/500], Train Loss: 0.1146\n",
      "Epoch [210/500], Train Loss: 0.1143\n",
      "Epoch [211/500], Train Loss: 0.1142\n",
      "Epoch [212/500], Train Loss: 0.1141\n",
      "Epoch [213/500], Train Loss: 0.1138\n",
      "Epoch [214/500], Train Loss: 0.1138\n",
      "Epoch [215/500], Train Loss: 0.1136\n",
      "Epoch [216/500], Train Loss: 0.1133\n",
      "Epoch [217/500], Train Loss: 0.1132\n",
      "Epoch [218/500], Train Loss: 0.1130\n",
      "Epoch [219/500], Train Loss: 0.1129\n",
      "Epoch [220/500], Train Loss: 0.1126\n",
      "Epoch [221/500], Train Loss: 0.1124\n",
      "Epoch [222/500], Train Loss: 0.1124\n",
      "Epoch [223/500], Train Loss: 0.1121\n",
      "Epoch [224/500], Train Loss: 0.1118\n",
      "Epoch [225/500], Train Loss: 0.1118\n",
      "Epoch [226/500], Train Loss: 0.1114\n",
      "Epoch [227/500], Train Loss: 0.1113\n",
      "Epoch [228/500], Train Loss: 0.1112\n",
      "Epoch [229/500], Train Loss: 0.1109\n",
      "Epoch [230/500], Train Loss: 0.1109\n",
      "Epoch [231/500], Train Loss: 0.1109\n",
      "Epoch [232/500], Train Loss: 0.1108\n",
      "Epoch [233/500], Train Loss: 0.1105\n",
      "Epoch [234/500], Train Loss: 0.1103\n",
      "Epoch [235/500], Train Loss: 0.1100\n",
      "Epoch [236/500], Train Loss: 0.1099\n",
      "Epoch [237/500], Train Loss: 0.1098\n",
      "Epoch [238/500], Train Loss: 0.1098\n",
      "Epoch [239/500], Train Loss: 0.1097\n",
      "Epoch [240/500], Train Loss: 0.1093\n",
      "Epoch [241/500], Train Loss: 0.1091\n",
      "Epoch [242/500], Train Loss: 0.1089\n",
      "Epoch [243/500], Train Loss: 0.1089\n",
      "Epoch [244/500], Train Loss: 0.1086\n",
      "Epoch [245/500], Train Loss: 0.1084\n",
      "Epoch [246/500], Train Loss: 0.1085\n",
      "Epoch [247/500], Train Loss: 0.1082\n",
      "Epoch [248/500], Train Loss: 0.1081\n",
      "Epoch [249/500], Train Loss: 0.1079\n",
      "Epoch [250/500], Train Loss: 0.1079\n",
      "Epoch [251/500], Train Loss: 0.1077\n",
      "Epoch [252/500], Train Loss: 0.1075\n",
      "Epoch [253/500], Train Loss: 0.1075\n",
      "Epoch [254/500], Train Loss: 0.1074\n",
      "Epoch [255/500], Train Loss: 0.1071\n",
      "Epoch [256/500], Train Loss: 0.1070\n",
      "Epoch [257/500], Train Loss: 0.1069\n",
      "Epoch [258/500], Train Loss: 0.1068\n",
      "Epoch [259/500], Train Loss: 0.1067\n",
      "Epoch [260/500], Train Loss: 0.1065\n",
      "Epoch [261/500], Train Loss: 0.1063\n",
      "Epoch [262/500], Train Loss: 0.1061\n",
      "Epoch [263/500], Train Loss: 0.1061\n",
      "Epoch [264/500], Train Loss: 0.1060\n",
      "Epoch [265/500], Train Loss: 0.1057\n",
      "Epoch [266/500], Train Loss: 0.1057\n",
      "Epoch [267/500], Train Loss: 0.1055\n",
      "Epoch [268/500], Train Loss: 0.1054\n",
      "Epoch [269/500], Train Loss: 0.1054\n",
      "Epoch [270/500], Train Loss: 0.1053\n",
      "Epoch [271/500], Train Loss: 0.1051\n",
      "Epoch [272/500], Train Loss: 0.1050\n",
      "Epoch [273/500], Train Loss: 0.1049\n",
      "Epoch [274/500], Train Loss: 0.1046\n",
      "Epoch [275/500], Train Loss: 0.1046\n",
      "Epoch [276/500], Train Loss: 0.1043\n",
      "Epoch [277/500], Train Loss: 0.1043\n",
      "Epoch [278/500], Train Loss: 0.1040\n",
      "Epoch [279/500], Train Loss: 0.1041\n",
      "Epoch [280/500], Train Loss: 0.1039\n",
      "Epoch [281/500], Train Loss: 0.1038\n",
      "Epoch [282/500], Train Loss: 0.1036\n",
      "Epoch [283/500], Train Loss: 0.1035\n",
      "Epoch [284/500], Train Loss: 0.1035\n",
      "Epoch [285/500], Train Loss: 0.1034\n",
      "Epoch [286/500], Train Loss: 0.1032\n",
      "Epoch [287/500], Train Loss: 0.1032\n",
      "Epoch [288/500], Train Loss: 0.1031\n",
      "Epoch [289/500], Train Loss: 0.1030\n",
      "Epoch [290/500], Train Loss: 0.1028\n",
      "Epoch [291/500], Train Loss: 0.1028\n",
      "Epoch [292/500], Train Loss: 0.1027\n",
      "Epoch [293/500], Train Loss: 0.1026\n",
      "Epoch [294/500], Train Loss: 0.1023\n",
      "Epoch [295/500], Train Loss: 0.1023\n",
      "Epoch [296/500], Train Loss: 0.1024\n",
      "Epoch [297/500], Train Loss: 0.1021\n",
      "Epoch [298/500], Train Loss: 0.1020\n",
      "Epoch [299/500], Train Loss: 0.1020\n",
      "Epoch [300/500], Train Loss: 0.1018\n",
      "Epoch [301/500], Train Loss: 0.1015\n",
      "Epoch [302/500], Train Loss: 0.1015\n",
      "Epoch [303/500], Train Loss: 0.1015\n",
      "Epoch [304/500], Train Loss: 0.1016\n",
      "Epoch [305/500], Train Loss: 0.1013\n",
      "Epoch [306/500], Train Loss: 0.1012\n",
      "Epoch [307/500], Train Loss: 0.1010\n",
      "Epoch [308/500], Train Loss: 0.1010\n",
      "Epoch [309/500], Train Loss: 0.1008\n",
      "Epoch [310/500], Train Loss: 0.1009\n",
      "Epoch [311/500], Train Loss: 0.1007\n",
      "Epoch [312/500], Train Loss: 0.1007\n",
      "Epoch [313/500], Train Loss: 0.1004\n",
      "Epoch [314/500], Train Loss: 0.1006\n",
      "Epoch [315/500], Train Loss: 0.1002\n",
      "Epoch [316/500], Train Loss: 0.1002\n",
      "Epoch [317/500], Train Loss: 0.1000\n",
      "Epoch [318/500], Train Loss: 0.1001\n",
      "Epoch [319/500], Train Loss: 0.1000\n",
      "Epoch [320/500], Train Loss: 0.0999\n",
      "Epoch [321/500], Train Loss: 0.0998\n",
      "Epoch [322/500], Train Loss: 0.0997\n",
      "Epoch [323/500], Train Loss: 0.0996\n",
      "Epoch [324/500], Train Loss: 0.0994\n",
      "Epoch [325/500], Train Loss: 0.0994\n",
      "Epoch [326/500], Train Loss: 0.0993\n",
      "Epoch [327/500], Train Loss: 0.0991\n",
      "Epoch [328/500], Train Loss: 0.0991\n",
      "Epoch [329/500], Train Loss: 0.0990\n",
      "Epoch [330/500], Train Loss: 0.0989\n",
      "Epoch [331/500], Train Loss: 0.0989\n",
      "Epoch [332/500], Train Loss: 0.0987\n",
      "Epoch [333/500], Train Loss: 0.0988\n",
      "Epoch [334/500], Train Loss: 0.0986\n",
      "Epoch [335/500], Train Loss: 0.0985\n",
      "Epoch [336/500], Train Loss: 0.0983\n",
      "Epoch [337/500], Train Loss: 0.0983\n",
      "Epoch [338/500], Train Loss: 0.0982\n",
      "Epoch [339/500], Train Loss: 0.0983\n",
      "Epoch [340/500], Train Loss: 0.0982\n",
      "Epoch [341/500], Train Loss: 0.0981\n",
      "Epoch [342/500], Train Loss: 0.0980\n",
      "Epoch [343/500], Train Loss: 0.0978\n",
      "Epoch [344/500], Train Loss: 0.0977\n",
      "Epoch [345/500], Train Loss: 0.0977\n",
      "Epoch [346/500], Train Loss: 0.0975\n",
      "Epoch [347/500], Train Loss: 0.0974\n",
      "Epoch [348/500], Train Loss: 0.0974\n",
      "Epoch [349/500], Train Loss: 0.0973\n",
      "Epoch [350/500], Train Loss: 0.0972\n",
      "Epoch [351/500], Train Loss: 0.0972\n",
      "Epoch [352/500], Train Loss: 0.0971\n",
      "Epoch [353/500], Train Loss: 0.0971\n",
      "Epoch [354/500], Train Loss: 0.0971\n",
      "Epoch [355/500], Train Loss: 0.0968\n",
      "Epoch [356/500], Train Loss: 0.0967\n",
      "Epoch [357/500], Train Loss: 0.0967\n",
      "Epoch [358/500], Train Loss: 0.0968\n",
      "Epoch [359/500], Train Loss: 0.0966\n",
      "Epoch [360/500], Train Loss: 0.0966\n",
      "Epoch [361/500], Train Loss: 0.0964\n",
      "Epoch [362/500], Train Loss: 0.0965\n",
      "Epoch [363/500], Train Loss: 0.0964\n",
      "Epoch [364/500], Train Loss: 0.0962\n",
      "Epoch [365/500], Train Loss: 0.0962\n",
      "Epoch [366/500], Train Loss: 0.0960\n",
      "Epoch [367/500], Train Loss: 0.0960\n",
      "Epoch [368/500], Train Loss: 0.0959\n",
      "Epoch [369/500], Train Loss: 0.0958\n",
      "Epoch [370/500], Train Loss: 0.0956\n",
      "Epoch [371/500], Train Loss: 0.0958\n",
      "Epoch [372/500], Train Loss: 0.0959\n",
      "Epoch [373/500], Train Loss: 0.0957\n",
      "Epoch [374/500], Train Loss: 0.0956\n",
      "Epoch [375/500], Train Loss: 0.0956\n",
      "Epoch [376/500], Train Loss: 0.0954\n",
      "Epoch [377/500], Train Loss: 0.0953\n",
      "Epoch [378/500], Train Loss: 0.0952\n",
      "Epoch [379/500], Train Loss: 0.0951\n",
      "Epoch [380/500], Train Loss: 0.0951\n",
      "Epoch [381/500], Train Loss: 0.0950\n",
      "Epoch [382/500], Train Loss: 0.0952\n",
      "Epoch [383/500], Train Loss: 0.0949\n",
      "Epoch [384/500], Train Loss: 0.0949\n",
      "Epoch [385/500], Train Loss: 0.0949\n",
      "Epoch [386/500], Train Loss: 0.0948\n",
      "Epoch [387/500], Train Loss: 0.0947\n",
      "Epoch [388/500], Train Loss: 0.0947\n",
      "Epoch [389/500], Train Loss: 0.0946\n",
      "Epoch [390/500], Train Loss: 0.0945\n",
      "Epoch [391/500], Train Loss: 0.0944\n",
      "Epoch [392/500], Train Loss: 0.0943\n",
      "Epoch [393/500], Train Loss: 0.0943\n",
      "Epoch [394/500], Train Loss: 0.0942\n",
      "Epoch [395/500], Train Loss: 0.0941\n",
      "Epoch [396/500], Train Loss: 0.0941\n",
      "Epoch [397/500], Train Loss: 0.0940\n",
      "Epoch [398/500], Train Loss: 0.0939\n",
      "Epoch [399/500], Train Loss: 0.0939\n",
      "Epoch [400/500], Train Loss: 0.0940\n",
      "Epoch [401/500], Train Loss: 0.0939\n",
      "Epoch [402/500], Train Loss: 0.0938\n",
      "Epoch [403/500], Train Loss: 0.0938\n",
      "Epoch [404/500], Train Loss: 0.0937\n",
      "Epoch [405/500], Train Loss: 0.0937\n",
      "Epoch [406/500], Train Loss: 0.0935\n",
      "Epoch [407/500], Train Loss: 0.0936\n",
      "Epoch [408/500], Train Loss: 0.0936\n",
      "Epoch [409/500], Train Loss: 0.0934\n",
      "Epoch [410/500], Train Loss: 0.0934\n",
      "Epoch [411/500], Train Loss: 0.0932\n",
      "Epoch [412/500], Train Loss: 0.0934\n",
      "Epoch [413/500], Train Loss: 0.0932\n",
      "Epoch [414/500], Train Loss: 0.0931\n",
      "Epoch [415/500], Train Loss: 0.0930\n",
      "Epoch [416/500], Train Loss: 0.0930\n",
      "Epoch [417/500], Train Loss: 0.0930\n",
      "Epoch [418/500], Train Loss: 0.0929\n",
      "Epoch [419/500], Train Loss: 0.0929\n",
      "Epoch [420/500], Train Loss: 0.0929\n",
      "Epoch [421/500], Train Loss: 0.0928\n",
      "Epoch [422/500], Train Loss: 0.0928\n",
      "Epoch [423/500], Train Loss: 0.0927\n",
      "Epoch [424/500], Train Loss: 0.0927\n",
      "Epoch [425/500], Train Loss: 0.0926\n",
      "Epoch [426/500], Train Loss: 0.0926\n",
      "Epoch [427/500], Train Loss: 0.0926\n",
      "Epoch [428/500], Train Loss: 0.0925\n",
      "Epoch [429/500], Train Loss: 0.0924\n",
      "Epoch [430/500], Train Loss: 0.0924\n",
      "Epoch [431/500], Train Loss: 0.0923\n",
      "Epoch [432/500], Train Loss: 0.0923\n",
      "Epoch [433/500], Train Loss: 0.0921\n",
      "Epoch [434/500], Train Loss: 0.0921\n",
      "Epoch [435/500], Train Loss: 0.0922\n",
      "Epoch [436/500], Train Loss: 0.0920\n",
      "Epoch [437/500], Train Loss: 0.0920\n",
      "Epoch [438/500], Train Loss: 0.0919\n",
      "Epoch [439/500], Train Loss: 0.0919\n",
      "Epoch [440/500], Train Loss: 0.0919\n",
      "Epoch [441/500], Train Loss: 0.0919\n",
      "Epoch [442/500], Train Loss: 0.0917\n",
      "Epoch [443/500], Train Loss: 0.0917\n",
      "Epoch [444/500], Train Loss: 0.0917\n",
      "Epoch [445/500], Train Loss: 0.0917\n",
      "Epoch [446/500], Train Loss: 0.0915\n",
      "Epoch [447/500], Train Loss: 0.0914\n",
      "Epoch [448/500], Train Loss: 0.0915\n",
      "Epoch [449/500], Train Loss: 0.0914\n",
      "Epoch [450/500], Train Loss: 0.0915\n",
      "Epoch [451/500], Train Loss: 0.0913\n",
      "Epoch [452/500], Train Loss: 0.0913\n",
      "Epoch [453/500], Train Loss: 0.0912\n",
      "Epoch [454/500], Train Loss: 0.0912\n",
      "Epoch [455/500], Train Loss: 0.0912\n",
      "Epoch [456/500], Train Loss: 0.0913\n",
      "Epoch [457/500], Train Loss: 0.0910\n",
      "Epoch [458/500], Train Loss: 0.0910\n",
      "Epoch [459/500], Train Loss: 0.0910\n",
      "Epoch [460/500], Train Loss: 0.0911\n",
      "Epoch [461/500], Train Loss: 0.0909\n",
      "Epoch [462/500], Train Loss: 0.0909\n",
      "Epoch [463/500], Train Loss: 0.0909\n",
      "Epoch [464/500], Train Loss: 0.0909\n",
      "Epoch [465/500], Train Loss: 0.0907\n",
      "Epoch [466/500], Train Loss: 0.0906\n",
      "Epoch [467/500], Train Loss: 0.0906\n",
      "Epoch [468/500], Train Loss: 0.0907\n",
      "Epoch [469/500], Train Loss: 0.0905\n",
      "Epoch [470/500], Train Loss: 0.0906\n",
      "Epoch [471/500], Train Loss: 0.0906\n",
      "Epoch [472/500], Train Loss: 0.0905\n",
      "Epoch [473/500], Train Loss: 0.0904\n",
      "Epoch [474/500], Train Loss: 0.0904\n",
      "Epoch [475/500], Train Loss: 0.0905\n",
      "Epoch [476/500], Train Loss: 0.0903\n",
      "Epoch [477/500], Train Loss: 0.0902\n",
      "Epoch [478/500], Train Loss: 0.0903\n",
      "Epoch [479/500], Train Loss: 0.0902\n",
      "Epoch [480/500], Train Loss: 0.0901\n",
      "Epoch [481/500], Train Loss: 0.0900\n",
      "Epoch [482/500], Train Loss: 0.0901\n",
      "Epoch [483/500], Train Loss: 0.0901\n",
      "Epoch [484/500], Train Loss: 0.0900\n",
      "Epoch [485/500], Train Loss: 0.0900\n",
      "Epoch [486/500], Train Loss: 0.0899\n",
      "Epoch [487/500], Train Loss: 0.0900\n",
      "Epoch [488/500], Train Loss: 0.0899\n",
      "Epoch [489/500], Train Loss: 0.0898\n",
      "Epoch [490/500], Train Loss: 0.0898\n",
      "Epoch [491/500], Train Loss: 0.0896\n",
      "Epoch [492/500], Train Loss: 0.0897\n",
      "Epoch [493/500], Train Loss: 0.0896\n",
      "Epoch [494/500], Train Loss: 0.0896\n",
      "Epoch [495/500], Train Loss: 0.0895\n",
      "Epoch [496/500], Train Loss: 0.0894\n",
      "Epoch [497/500], Train Loss: 0.0896\n",
      "Epoch [498/500], Train Loss: 0.0895\n",
      "Epoch [499/500], Train Loss: 0.0893\n",
      "Epoch [500/500], Train Loss: 0.0894\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr5/final_model_chr5.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr5/individual_r2_scores_chr5.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:53:10,027] A new study created in memory with name: no-name-fd39c884-7f0d-4a6d-bdc7-c642f9aa33a7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  36\n",
      "Known PRS313 SNPs:  4\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  1300\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:53:11,614] Trial 0 finished with value: 0.3198725387454033 and parameters: {'learning_rate': 0.03433521973131225, 'lasso_coef': 0.00016942494332649097, 'patience': 9}. Best is trial 0 with value: 0.3198725387454033.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 93\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:53:14,002] Trial 1 finished with value: 0.20339595302939414 and parameters: {'learning_rate': 0.0030830150845402517, 'lasso_coef': 5.007665250879706e-05, 'patience': 5}. Best is trial 1 with value: 0.20339595302939414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:53:25,215] Trial 2 finished with value: 0.19858802929520608 and parameters: {'learning_rate': 0.00014598398778349226, 'lasso_coef': 1.3724221546462138e-05, 'patience': 17}. Best is trial 2 with value: 0.19858802929520608.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:54:11,064] Trial 3 finished with value: 0.5893458008766175 and parameters: {'learning_rate': 0.00010406506256765515, 'lasso_coef': 0.03794687017525477, 'patience': 18}. Best is trial 2 with value: 0.19858802929520608.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 289\n",
      "Early stopping at epoch 55\n",
      "Early stopping at epoch 35\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:54:13,941] Trial 4 finished with value: 2.559623098373413 and parameters: {'learning_rate': 0.007513781008010211, 'lasso_coef': 0.05161851714579476, 'patience': 10}. Best is trial 2 with value: 0.19858802929520608.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 186\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:54:19,539] Trial 5 finished with value: 0.6916284829378128 and parameters: {'learning_rate': 0.0034441452502167536, 'lasso_coef': 0.007296331896504144, 'patience': 14}. Best is trial 2 with value: 0.19858802929520608.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 48\n",
      "Early stopping at epoch 72\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:54:24,026] Trial 6 finished with value: 0.985145503282547 and parameters: {'learning_rate': 0.012392301846990087, 'lasso_coef': 0.006007701981753135, 'patience': 14}. Best is trial 2 with value: 0.19858802929520608.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 41\n",
      "Early stopping at epoch 166\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:54:29,152] Trial 7 finished with value: 0.15606106109917164 and parameters: {'learning_rate': 0.00293316978365522, 'lasso_coef': 2.1543596073732128e-05, 'patience': 20}. Best is trial 7 with value: 0.15606106109917164.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 84\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:54:32,981] Trial 8 finished with value: 0.4572357952594757 and parameters: {'learning_rate': 0.011128257971511195, 'lasso_coef': 0.0008997393108965962, 'patience': 15}. Best is trial 7 with value: 0.15606106109917164.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:54:55,212] Trial 9 finished with value: 0.298163665831089 and parameters: {'learning_rate': 0.00023575001459891757, 'lasso_coef': 0.00026730720483135077, 'patience': 16}. Best is trial 7 with value: 0.15606106109917164.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 412\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:55:05,502] Trial 10 finished with value: 0.13767381496727465 and parameters: {'learning_rate': 0.000711200497618949, 'lasso_coef': 1.0739840127545873e-05, 'patience': 20}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 469\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:55:16,789] Trial 11 finished with value: 0.1448282513767481 and parameters: {'learning_rate': 0.0007227560492053484, 'lasso_coef': 1.578181517935021e-05, 'patience': 20}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:55:28,434] Trial 12 finished with value: 0.2102053113281727 and parameters: {'learning_rate': 0.0005698025173554135, 'lasso_coef': 7.326095611027014e-05, 'patience': 20}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 377\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:55:37,472] Trial 13 finished with value: 0.13849703706800937 and parameters: {'learning_rate': 0.0007292275516185648, 'lasso_coef': 1.0384100345456886e-05, 'patience': 20}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:55:49,178] Trial 14 finished with value: 0.3406344085931778 and parameters: {'learning_rate': 0.000743588915699822, 'lasso_coef': 0.0005548817863362069, 'patience': 11}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 452\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:56:00,238] Trial 15 finished with value: 0.19114410132169724 and parameters: {'learning_rate': 0.0014286557724867677, 'lasso_coef': 5.832563637574013e-05, 'patience': 18}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:56:11,107] Trial 16 finished with value: 0.15403422378003598 and parameters: {'learning_rate': 0.00031447260374359754, 'lasso_coef': 1.1035579895111678e-05, 'patience': 5}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 271\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:56:18,757] Trial 17 finished with value: 0.543661504983902 and parameters: {'learning_rate': 0.0014446717746712263, 'lasso_coef': 0.0029651732697372835, 'patience': 18}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 34\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:56:21,784] Trial 18 finished with value: 0.364242984354496 and parameters: {'learning_rate': 0.05800368339734754, 'lasso_coef': 0.00015980109876133122, 'patience': 12}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:56:33,397] Trial 19 finished with value: 0.19521886929869653 and parameters: {'learning_rate': 0.0003389139165761184, 'lasso_coef': 4.053208501912486e-05, 'patience': 19}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 354\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:56:42,368] Trial 20 finished with value: 0.5019749119877815 and parameters: {'learning_rate': 0.0014035684412169406, 'lasso_coef': 0.0020839702064694874, 'patience': 16}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:56:54,570] Trial 21 finished with value: 0.15306674502789974 and parameters: {'learning_rate': 0.0006635507898360126, 'lasso_coef': 2.0498343416723565e-05, 'patience': 20}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 316\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:57:02,427] Trial 22 finished with value: 0.14049084410071372 and parameters: {'learning_rate': 0.0009860232756960892, 'lasso_coef': 1.1638696085104892e-05, 'patience': 19}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 388\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:57:12,016] Trial 23 finished with value: 0.16761246845126151 and parameters: {'learning_rate': 0.0012373828170452914, 'lasso_coef': 3.2383322787860275e-05, 'patience': 18}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:57:23,563] Trial 24 finished with value: 0.14318689703941345 and parameters: {'learning_rate': 0.00040388713264049604, 'lasso_coef': 1.0013936266827136e-05, 'patience': 8}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 202\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:57:29,631] Trial 25 finished with value: 0.22705677822232245 and parameters: {'learning_rate': 0.005224459310317587, 'lasso_coef': 9.828549697546561e-05, 'patience': 19}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 201\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:57:35,129] Trial 26 finished with value: 0.16976766064763069 and parameters: {'learning_rate': 0.002216769636484642, 'lasso_coef': 3.0340295723622914e-05, 'patience': 16}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:58:07,858] Trial 27 finished with value: 0.324116088449955 and parameters: {'learning_rate': 0.00021237111301265123, 'lasso_coef': 0.0003957830361037315, 'patience': 19}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:58:20,028] Trial 28 finished with value: 0.2294765867292881 and parameters: {'learning_rate': 0.0009485517158311436, 'lasso_coef': 0.00011717327866722195, 'patience': 17}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 54\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:58:22,408] Trial 29 finished with value: 0.3204812750220299 and parameters: {'learning_rate': 0.025727685292608788, 'lasso_coef': 0.00020927447018640214, 'patience': 14}. Best is trial 10 with value: 0.13767381496727465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Best hyperparameters: {'learning_rate': 0.000711200497618949, 'lasso_coef': 1.0739840127545873e-05, 'patience': 20}\n",
      "Best value: 0.13767381496727465\n",
      "Epoch [1/500], Train Loss: 0.5779\n",
      "Epoch [2/500], Train Loss: 0.5169\n",
      "Epoch [3/500], Train Loss: 0.4959\n",
      "Epoch [4/500], Train Loss: 0.4798\n",
      "Epoch [5/500], Train Loss: 0.4653\n",
      "Epoch [6/500], Train Loss: 0.4521\n",
      "Epoch [7/500], Train Loss: 0.4400\n",
      "Epoch [8/500], Train Loss: 0.4286\n",
      "Epoch [9/500], Train Loss: 0.4187\n",
      "Epoch [10/500], Train Loss: 0.4091\n",
      "Epoch [11/500], Train Loss: 0.3997\n",
      "Epoch [12/500], Train Loss: 0.3909\n",
      "Epoch [13/500], Train Loss: 0.3832\n",
      "Epoch [14/500], Train Loss: 0.3758\n",
      "Epoch [15/500], Train Loss: 0.3685\n",
      "Epoch [16/500], Train Loss: 0.3614\n",
      "Epoch [17/500], Train Loss: 0.3546\n",
      "Epoch [18/500], Train Loss: 0.3487\n",
      "Epoch [19/500], Train Loss: 0.3429\n",
      "Epoch [20/500], Train Loss: 0.3373\n",
      "Epoch [21/500], Train Loss: 0.3322\n",
      "Epoch [22/500], Train Loss: 0.3270\n",
      "Epoch [23/500], Train Loss: 0.3224\n",
      "Epoch [24/500], Train Loss: 0.3177\n",
      "Epoch [25/500], Train Loss: 0.3131\n",
      "Epoch [26/500], Train Loss: 0.3090\n",
      "Epoch [27/500], Train Loss: 0.3049\n",
      "Epoch [28/500], Train Loss: 0.3012\n",
      "Epoch [29/500], Train Loss: 0.2969\n",
      "Epoch [30/500], Train Loss: 0.2934\n",
      "Epoch [31/500], Train Loss: 0.2901\n",
      "Epoch [32/500], Train Loss: 0.2869\n",
      "Epoch [33/500], Train Loss: 0.2831\n",
      "Epoch [34/500], Train Loss: 0.2801\n",
      "Epoch [35/500], Train Loss: 0.2770\n",
      "Epoch [36/500], Train Loss: 0.2743\n",
      "Epoch [37/500], Train Loss: 0.2717\n",
      "Epoch [38/500], Train Loss: 0.2682\n",
      "Epoch [39/500], Train Loss: 0.2659\n",
      "Epoch [40/500], Train Loss: 0.2633\n",
      "Epoch [41/500], Train Loss: 0.2607\n",
      "Epoch [42/500], Train Loss: 0.2582\n",
      "Epoch [43/500], Train Loss: 0.2558\n",
      "Epoch [44/500], Train Loss: 0.2535\n",
      "Epoch [45/500], Train Loss: 0.2510\n",
      "Epoch [46/500], Train Loss: 0.2489\n",
      "Epoch [47/500], Train Loss: 0.2470\n",
      "Epoch [48/500], Train Loss: 0.2450\n",
      "Epoch [49/500], Train Loss: 0.2427\n",
      "Epoch [50/500], Train Loss: 0.2409\n",
      "Epoch [51/500], Train Loss: 0.2386\n",
      "Epoch [52/500], Train Loss: 0.2368\n",
      "Epoch [53/500], Train Loss: 0.2352\n",
      "Epoch [54/500], Train Loss: 0.2334\n",
      "Epoch [55/500], Train Loss: 0.2318\n",
      "Epoch [56/500], Train Loss: 0.2300\n",
      "Epoch [57/500], Train Loss: 0.2282\n",
      "Epoch [58/500], Train Loss: 0.2269\n",
      "Epoch [59/500], Train Loss: 0.2252\n",
      "Epoch [60/500], Train Loss: 0.2236\n",
      "Epoch [61/500], Train Loss: 0.2219\n",
      "Epoch [62/500], Train Loss: 0.2204\n",
      "Epoch [63/500], Train Loss: 0.2190\n",
      "Epoch [64/500], Train Loss: 0.2177\n",
      "Epoch [65/500], Train Loss: 0.2162\n",
      "Epoch [66/500], Train Loss: 0.2145\n",
      "Epoch [67/500], Train Loss: 0.2133\n",
      "Epoch [68/500], Train Loss: 0.2121\n",
      "Epoch [69/500], Train Loss: 0.2108\n",
      "Epoch [70/500], Train Loss: 0.2096\n",
      "Epoch [71/500], Train Loss: 0.2082\n",
      "Epoch [72/500], Train Loss: 0.2070\n",
      "Epoch [73/500], Train Loss: 0.2057\n",
      "Epoch [74/500], Train Loss: 0.2050\n",
      "Epoch [75/500], Train Loss: 0.2033\n",
      "Epoch [76/500], Train Loss: 0.2023\n",
      "Epoch [77/500], Train Loss: 0.2012\n",
      "Epoch [78/500], Train Loss: 0.1999\n",
      "Epoch [79/500], Train Loss: 0.1988\n",
      "Epoch [80/500], Train Loss: 0.1976\n",
      "Epoch [81/500], Train Loss: 0.1968\n",
      "Epoch [82/500], Train Loss: 0.1957\n",
      "Epoch [83/500], Train Loss: 0.1950\n",
      "Epoch [84/500], Train Loss: 0.1938\n",
      "Epoch [85/500], Train Loss: 0.1928\n",
      "Epoch [86/500], Train Loss: 0.1919\n",
      "Epoch [87/500], Train Loss: 0.1909\n",
      "Epoch [88/500], Train Loss: 0.1899\n",
      "Epoch [89/500], Train Loss: 0.1889\n",
      "Epoch [90/500], Train Loss: 0.1883\n",
      "Epoch [91/500], Train Loss: 0.1873\n",
      "Epoch [92/500], Train Loss: 0.1866\n",
      "Epoch [93/500], Train Loss: 0.1858\n",
      "Epoch [94/500], Train Loss: 0.1848\n",
      "Epoch [95/500], Train Loss: 0.1839\n",
      "Epoch [96/500], Train Loss: 0.1828\n",
      "Epoch [97/500], Train Loss: 0.1823\n",
      "Epoch [98/500], Train Loss: 0.1816\n",
      "Epoch [99/500], Train Loss: 0.1808\n",
      "Epoch [100/500], Train Loss: 0.1799\n",
      "Epoch [101/500], Train Loss: 0.1791\n",
      "Epoch [102/500], Train Loss: 0.1784\n",
      "Epoch [103/500], Train Loss: 0.1777\n",
      "Epoch [104/500], Train Loss: 0.1768\n",
      "Epoch [105/500], Train Loss: 0.1761\n",
      "Epoch [106/500], Train Loss: 0.1754\n",
      "Epoch [107/500], Train Loss: 0.1749\n",
      "Epoch [108/500], Train Loss: 0.1742\n",
      "Epoch [109/500], Train Loss: 0.1737\n",
      "Epoch [110/500], Train Loss: 0.1729\n",
      "Epoch [111/500], Train Loss: 0.1719\n",
      "Epoch [112/500], Train Loss: 0.1712\n",
      "Epoch [113/500], Train Loss: 0.1706\n",
      "Epoch [114/500], Train Loss: 0.1699\n",
      "Epoch [115/500], Train Loss: 0.1697\n",
      "Epoch [116/500], Train Loss: 0.1688\n",
      "Epoch [117/500], Train Loss: 0.1682\n",
      "Epoch [118/500], Train Loss: 0.1674\n",
      "Epoch [119/500], Train Loss: 0.1668\n",
      "Epoch [120/500], Train Loss: 0.1664\n",
      "Epoch [121/500], Train Loss: 0.1657\n",
      "Epoch [122/500], Train Loss: 0.1652\n",
      "Epoch [123/500], Train Loss: 0.1647\n",
      "Epoch [124/500], Train Loss: 0.1640\n",
      "Epoch [125/500], Train Loss: 0.1635\n",
      "Epoch [126/500], Train Loss: 0.1629\n",
      "Epoch [127/500], Train Loss: 0.1625\n",
      "Epoch [128/500], Train Loss: 0.1620\n",
      "Epoch [129/500], Train Loss: 0.1616\n",
      "Epoch [130/500], Train Loss: 0.1607\n",
      "Epoch [131/500], Train Loss: 0.1602\n",
      "Epoch [132/500], Train Loss: 0.1597\n",
      "Epoch [133/500], Train Loss: 0.1590\n",
      "Epoch [134/500], Train Loss: 0.1587\n",
      "Epoch [135/500], Train Loss: 0.1583\n",
      "Epoch [136/500], Train Loss: 0.1578\n",
      "Epoch [137/500], Train Loss: 0.1571\n",
      "Epoch [138/500], Train Loss: 0.1568\n",
      "Epoch [139/500], Train Loss: 0.1563\n",
      "Epoch [140/500], Train Loss: 0.1557\n",
      "Epoch [141/500], Train Loss: 0.1554\n",
      "Epoch [142/500], Train Loss: 0.1548\n",
      "Epoch [143/500], Train Loss: 0.1544\n",
      "Epoch [144/500], Train Loss: 0.1541\n",
      "Epoch [145/500], Train Loss: 0.1536\n",
      "Epoch [146/500], Train Loss: 0.1529\n",
      "Epoch [147/500], Train Loss: 0.1527\n",
      "Epoch [148/500], Train Loss: 0.1521\n",
      "Epoch [149/500], Train Loss: 0.1517\n",
      "Epoch [150/500], Train Loss: 0.1514\n",
      "Epoch [151/500], Train Loss: 0.1509\n",
      "Epoch [152/500], Train Loss: 0.1504\n",
      "Epoch [153/500], Train Loss: 0.1502\n",
      "Epoch [154/500], Train Loss: 0.1498\n",
      "Epoch [155/500], Train Loss: 0.1493\n",
      "Epoch [156/500], Train Loss: 0.1488\n",
      "Epoch [157/500], Train Loss: 0.1486\n",
      "Epoch [158/500], Train Loss: 0.1480\n",
      "Epoch [159/500], Train Loss: 0.1477\n",
      "Epoch [160/500], Train Loss: 0.1472\n",
      "Epoch [161/500], Train Loss: 0.1471\n",
      "Epoch [162/500], Train Loss: 0.1468\n",
      "Epoch [163/500], Train Loss: 0.1463\n",
      "Epoch [164/500], Train Loss: 0.1458\n",
      "Epoch [165/500], Train Loss: 0.1452\n",
      "Epoch [166/500], Train Loss: 0.1450\n",
      "Epoch [167/500], Train Loss: 0.1447\n",
      "Epoch [168/500], Train Loss: 0.1444\n",
      "Epoch [169/500], Train Loss: 0.1440\n",
      "Epoch [170/500], Train Loss: 0.1437\n",
      "Epoch [171/500], Train Loss: 0.1434\n",
      "Epoch [172/500], Train Loss: 0.1430\n",
      "Epoch [173/500], Train Loss: 0.1427\n",
      "Epoch [174/500], Train Loss: 0.1423\n",
      "Epoch [175/500], Train Loss: 0.1418\n",
      "Epoch [176/500], Train Loss: 0.1416\n",
      "Epoch [177/500], Train Loss: 0.1412\n",
      "Epoch [178/500], Train Loss: 0.1410\n",
      "Epoch [179/500], Train Loss: 0.1407\n",
      "Epoch [180/500], Train Loss: 0.1403\n",
      "Epoch [181/500], Train Loss: 0.1401\n",
      "Epoch [182/500], Train Loss: 0.1397\n",
      "Epoch [183/500], Train Loss: 0.1392\n",
      "Epoch [184/500], Train Loss: 0.1392\n",
      "Epoch [185/500], Train Loss: 0.1388\n",
      "Epoch [186/500], Train Loss: 0.1383\n",
      "Epoch [187/500], Train Loss: 0.1383\n",
      "Epoch [188/500], Train Loss: 0.1379\n",
      "Epoch [189/500], Train Loss: 0.1374\n",
      "Epoch [190/500], Train Loss: 0.1372\n",
      "Epoch [191/500], Train Loss: 0.1370\n",
      "Epoch [192/500], Train Loss: 0.1368\n",
      "Epoch [193/500], Train Loss: 0.1362\n",
      "Epoch [194/500], Train Loss: 0.1360\n",
      "Epoch [195/500], Train Loss: 0.1357\n",
      "Epoch [196/500], Train Loss: 0.1357\n",
      "Epoch [197/500], Train Loss: 0.1353\n",
      "Epoch [198/500], Train Loss: 0.1350\n",
      "Epoch [199/500], Train Loss: 0.1347\n",
      "Epoch [200/500], Train Loss: 0.1343\n",
      "Epoch [201/500], Train Loss: 0.1342\n",
      "Epoch [202/500], Train Loss: 0.1340\n",
      "Epoch [203/500], Train Loss: 0.1335\n",
      "Epoch [204/500], Train Loss: 0.1334\n",
      "Epoch [205/500], Train Loss: 0.1331\n",
      "Epoch [206/500], Train Loss: 0.1329\n",
      "Epoch [207/500], Train Loss: 0.1325\n",
      "Epoch [208/500], Train Loss: 0.1322\n",
      "Epoch [209/500], Train Loss: 0.1320\n",
      "Epoch [210/500], Train Loss: 0.1318\n",
      "Epoch [211/500], Train Loss: 0.1313\n",
      "Epoch [212/500], Train Loss: 0.1314\n",
      "Epoch [213/500], Train Loss: 0.1310\n",
      "Epoch [214/500], Train Loss: 0.1308\n",
      "Epoch [215/500], Train Loss: 0.1306\n",
      "Epoch [216/500], Train Loss: 0.1303\n",
      "Epoch [217/500], Train Loss: 0.1301\n",
      "Epoch [218/500], Train Loss: 0.1299\n",
      "Epoch [219/500], Train Loss: 0.1299\n",
      "Epoch [220/500], Train Loss: 0.1294\n",
      "Epoch [221/500], Train Loss: 0.1292\n",
      "Epoch [222/500], Train Loss: 0.1290\n",
      "Epoch [223/500], Train Loss: 0.1287\n",
      "Epoch [224/500], Train Loss: 0.1285\n",
      "Epoch [225/500], Train Loss: 0.1283\n",
      "Epoch [226/500], Train Loss: 0.1280\n",
      "Epoch [227/500], Train Loss: 0.1277\n",
      "Epoch [228/500], Train Loss: 0.1274\n",
      "Epoch [229/500], Train Loss: 0.1274\n",
      "Epoch [230/500], Train Loss: 0.1273\n",
      "Epoch [231/500], Train Loss: 0.1268\n",
      "Epoch [232/500], Train Loss: 0.1266\n",
      "Epoch [233/500], Train Loss: 0.1264\n",
      "Epoch [234/500], Train Loss: 0.1261\n",
      "Epoch [235/500], Train Loss: 0.1261\n",
      "Epoch [236/500], Train Loss: 0.1258\n",
      "Epoch [237/500], Train Loss: 0.1258\n",
      "Epoch [238/500], Train Loss: 0.1254\n",
      "Epoch [239/500], Train Loss: 0.1253\n",
      "Epoch [240/500], Train Loss: 0.1251\n",
      "Epoch [241/500], Train Loss: 0.1249\n",
      "Epoch [242/500], Train Loss: 0.1247\n",
      "Epoch [243/500], Train Loss: 0.1243\n",
      "Epoch [244/500], Train Loss: 0.1243\n",
      "Epoch [245/500], Train Loss: 0.1241\n",
      "Epoch [246/500], Train Loss: 0.1238\n",
      "Epoch [247/500], Train Loss: 0.1237\n",
      "Epoch [248/500], Train Loss: 0.1234\n",
      "Epoch [249/500], Train Loss: 0.1233\n",
      "Epoch [250/500], Train Loss: 0.1232\n",
      "Epoch [251/500], Train Loss: 0.1229\n",
      "Epoch [252/500], Train Loss: 0.1226\n",
      "Epoch [253/500], Train Loss: 0.1225\n",
      "Epoch [254/500], Train Loss: 0.1223\n",
      "Epoch [255/500], Train Loss: 0.1221\n",
      "Epoch [256/500], Train Loss: 0.1219\n",
      "Epoch [257/500], Train Loss: 0.1219\n",
      "Epoch [258/500], Train Loss: 0.1217\n",
      "Epoch [259/500], Train Loss: 0.1215\n",
      "Epoch [260/500], Train Loss: 0.1214\n",
      "Epoch [261/500], Train Loss: 0.1212\n",
      "Epoch [262/500], Train Loss: 0.1209\n",
      "Epoch [263/500], Train Loss: 0.1208\n",
      "Epoch [264/500], Train Loss: 0.1204\n",
      "Epoch [265/500], Train Loss: 0.1204\n",
      "Epoch [266/500], Train Loss: 0.1202\n",
      "Epoch [267/500], Train Loss: 0.1201\n",
      "Epoch [268/500], Train Loss: 0.1197\n",
      "Epoch [269/500], Train Loss: 0.1196\n",
      "Epoch [270/500], Train Loss: 0.1195\n",
      "Epoch [271/500], Train Loss: 0.1194\n",
      "Epoch [272/500], Train Loss: 0.1191\n",
      "Epoch [273/500], Train Loss: 0.1190\n",
      "Epoch [274/500], Train Loss: 0.1189\n",
      "Epoch [275/500], Train Loss: 0.1186\n",
      "Epoch [276/500], Train Loss: 0.1185\n",
      "Epoch [277/500], Train Loss: 0.1184\n",
      "Epoch [278/500], Train Loss: 0.1182\n",
      "Epoch [279/500], Train Loss: 0.1181\n",
      "Epoch [280/500], Train Loss: 0.1180\n",
      "Epoch [281/500], Train Loss: 0.1177\n",
      "Epoch [282/500], Train Loss: 0.1177\n",
      "Epoch [283/500], Train Loss: 0.1174\n",
      "Epoch [284/500], Train Loss: 0.1173\n",
      "Epoch [285/500], Train Loss: 0.1171\n",
      "Epoch [286/500], Train Loss: 0.1168\n",
      "Epoch [287/500], Train Loss: 0.1168\n",
      "Epoch [288/500], Train Loss: 0.1167\n",
      "Epoch [289/500], Train Loss: 0.1165\n",
      "Epoch [290/500], Train Loss: 0.1164\n",
      "Epoch [291/500], Train Loss: 0.1162\n",
      "Epoch [292/500], Train Loss: 0.1161\n",
      "Epoch [293/500], Train Loss: 0.1160\n",
      "Epoch [294/500], Train Loss: 0.1157\n",
      "Epoch [295/500], Train Loss: 0.1156\n",
      "Epoch [296/500], Train Loss: 0.1154\n",
      "Epoch [297/500], Train Loss: 0.1154\n",
      "Epoch [298/500], Train Loss: 0.1152\n",
      "Epoch [299/500], Train Loss: 0.1150\n",
      "Epoch [300/500], Train Loss: 0.1149\n",
      "Epoch [301/500], Train Loss: 0.1147\n",
      "Epoch [302/500], Train Loss: 0.1147\n",
      "Epoch [303/500], Train Loss: 0.1146\n",
      "Epoch [304/500], Train Loss: 0.1144\n",
      "Epoch [305/500], Train Loss: 0.1142\n",
      "Epoch [306/500], Train Loss: 0.1143\n",
      "Epoch [307/500], Train Loss: 0.1141\n",
      "Epoch [308/500], Train Loss: 0.1138\n",
      "Epoch [309/500], Train Loss: 0.1138\n",
      "Epoch [310/500], Train Loss: 0.1136\n",
      "Epoch [311/500], Train Loss: 0.1134\n",
      "Epoch [312/500], Train Loss: 0.1134\n",
      "Epoch [313/500], Train Loss: 0.1131\n",
      "Epoch [314/500], Train Loss: 0.1129\n",
      "Epoch [315/500], Train Loss: 0.1129\n",
      "Epoch [316/500], Train Loss: 0.1127\n",
      "Epoch [317/500], Train Loss: 0.1126\n",
      "Epoch [318/500], Train Loss: 0.1127\n",
      "Epoch [319/500], Train Loss: 0.1125\n",
      "Epoch [320/500], Train Loss: 0.1124\n",
      "Epoch [321/500], Train Loss: 0.1122\n",
      "Epoch [322/500], Train Loss: 0.1118\n",
      "Epoch [323/500], Train Loss: 0.1118\n",
      "Epoch [324/500], Train Loss: 0.1119\n",
      "Epoch [325/500], Train Loss: 0.1118\n",
      "Epoch [326/500], Train Loss: 0.1116\n",
      "Epoch [327/500], Train Loss: 0.1114\n",
      "Epoch [328/500], Train Loss: 0.1113\n",
      "Epoch [329/500], Train Loss: 0.1111\n",
      "Epoch [330/500], Train Loss: 0.1110\n",
      "Epoch [331/500], Train Loss: 0.1110\n",
      "Epoch [332/500], Train Loss: 0.1109\n",
      "Epoch [333/500], Train Loss: 0.1109\n",
      "Epoch [334/500], Train Loss: 0.1105\n",
      "Epoch [335/500], Train Loss: 0.1104\n",
      "Epoch [336/500], Train Loss: 0.1104\n",
      "Epoch [337/500], Train Loss: 0.1103\n",
      "Epoch [338/500], Train Loss: 0.1101\n",
      "Epoch [339/500], Train Loss: 0.1101\n",
      "Epoch [340/500], Train Loss: 0.1100\n",
      "Epoch [341/500], Train Loss: 0.1098\n",
      "Epoch [342/500], Train Loss: 0.1099\n",
      "Epoch [343/500], Train Loss: 0.1096\n",
      "Epoch [344/500], Train Loss: 0.1095\n",
      "Epoch [345/500], Train Loss: 0.1095\n",
      "Epoch [346/500], Train Loss: 0.1094\n",
      "Epoch [347/500], Train Loss: 0.1092\n",
      "Epoch [348/500], Train Loss: 0.1090\n",
      "Epoch [349/500], Train Loss: 0.1090\n",
      "Epoch [350/500], Train Loss: 0.1089\n",
      "Epoch [351/500], Train Loss: 0.1087\n",
      "Epoch [352/500], Train Loss: 0.1088\n",
      "Epoch [353/500], Train Loss: 0.1087\n",
      "Epoch [354/500], Train Loss: 0.1085\n",
      "Epoch [355/500], Train Loss: 0.1084\n",
      "Epoch [356/500], Train Loss: 0.1084\n",
      "Epoch [357/500], Train Loss: 0.1084\n",
      "Epoch [358/500], Train Loss: 0.1082\n",
      "Epoch [359/500], Train Loss: 0.1079\n",
      "Epoch [360/500], Train Loss: 0.1077\n",
      "Epoch [361/500], Train Loss: 0.1077\n",
      "Epoch [362/500], Train Loss: 0.1075\n",
      "Epoch [363/500], Train Loss: 0.1075\n",
      "Epoch [364/500], Train Loss: 0.1074\n",
      "Epoch [365/500], Train Loss: 0.1072\n",
      "Epoch [366/500], Train Loss: 0.1072\n",
      "Epoch [367/500], Train Loss: 0.1071\n",
      "Epoch [368/500], Train Loss: 0.1070\n",
      "Epoch [369/500], Train Loss: 0.1071\n",
      "Epoch [370/500], Train Loss: 0.1068\n",
      "Epoch [371/500], Train Loss: 0.1066\n",
      "Epoch [372/500], Train Loss: 0.1065\n",
      "Epoch [373/500], Train Loss: 0.1064\n",
      "Epoch [374/500], Train Loss: 0.1064\n",
      "Epoch [375/500], Train Loss: 0.1065\n",
      "Epoch [376/500], Train Loss: 0.1064\n",
      "Epoch [377/500], Train Loss: 0.1062\n",
      "Epoch [378/500], Train Loss: 0.1062\n",
      "Epoch [379/500], Train Loss: 0.1062\n",
      "Epoch [380/500], Train Loss: 0.1059\n",
      "Epoch [381/500], Train Loss: 0.1060\n",
      "Epoch [382/500], Train Loss: 0.1058\n",
      "Epoch [383/500], Train Loss: 0.1057\n",
      "Epoch [384/500], Train Loss: 0.1055\n",
      "Epoch [385/500], Train Loss: 0.1055\n",
      "Epoch [386/500], Train Loss: 0.1053\n",
      "Epoch [387/500], Train Loss: 0.1052\n",
      "Epoch [388/500], Train Loss: 0.1051\n",
      "Epoch [389/500], Train Loss: 0.1052\n",
      "Epoch [390/500], Train Loss: 0.1050\n",
      "Epoch [391/500], Train Loss: 0.1049\n",
      "Epoch [392/500], Train Loss: 0.1048\n",
      "Epoch [393/500], Train Loss: 0.1047\n",
      "Epoch [394/500], Train Loss: 0.1047\n",
      "Epoch [395/500], Train Loss: 0.1046\n",
      "Epoch [396/500], Train Loss: 0.1044\n",
      "Epoch [397/500], Train Loss: 0.1043\n",
      "Epoch [398/500], Train Loss: 0.1045\n",
      "Epoch [399/500], Train Loss: 0.1043\n",
      "Epoch [400/500], Train Loss: 0.1042\n",
      "Epoch [401/500], Train Loss: 0.1042\n",
      "Epoch [402/500], Train Loss: 0.1041\n",
      "Epoch [403/500], Train Loss: 0.1040\n",
      "Epoch [404/500], Train Loss: 0.1038\n",
      "Epoch [405/500], Train Loss: 0.1037\n",
      "Epoch [406/500], Train Loss: 0.1037\n",
      "Epoch [407/500], Train Loss: 0.1036\n",
      "Epoch [408/500], Train Loss: 0.1036\n",
      "Epoch [409/500], Train Loss: 0.1033\n",
      "Epoch [410/500], Train Loss: 0.1034\n",
      "Epoch [411/500], Train Loss: 0.1032\n",
      "Epoch [412/500], Train Loss: 0.1032\n",
      "Epoch [413/500], Train Loss: 0.1032\n",
      "Epoch [414/500], Train Loss: 0.1031\n",
      "Epoch [415/500], Train Loss: 0.1032\n",
      "Epoch [416/500], Train Loss: 0.1031\n",
      "Epoch [417/500], Train Loss: 0.1030\n",
      "Epoch [418/500], Train Loss: 0.1028\n",
      "Epoch [419/500], Train Loss: 0.1027\n",
      "Epoch [420/500], Train Loss: 0.1026\n",
      "Epoch [421/500], Train Loss: 0.1026\n",
      "Epoch [422/500], Train Loss: 0.1023\n",
      "Epoch [423/500], Train Loss: 0.1025\n",
      "Epoch [424/500], Train Loss: 0.1024\n",
      "Epoch [425/500], Train Loss: 0.1022\n",
      "Epoch [426/500], Train Loss: 0.1022\n",
      "Epoch [427/500], Train Loss: 0.1022\n",
      "Epoch [428/500], Train Loss: 0.1020\n",
      "Epoch [429/500], Train Loss: 0.1020\n",
      "Epoch [430/500], Train Loss: 0.1022\n",
      "Epoch [431/500], Train Loss: 0.1018\n",
      "Epoch [432/500], Train Loss: 0.1019\n",
      "Epoch [433/500], Train Loss: 0.1017\n",
      "Epoch [434/500], Train Loss: 0.1018\n",
      "Epoch [435/500], Train Loss: 0.1014\n",
      "Epoch [436/500], Train Loss: 0.1015\n",
      "Epoch [437/500], Train Loss: 0.1016\n",
      "Epoch [438/500], Train Loss: 0.1015\n",
      "Epoch [439/500], Train Loss: 0.1013\n",
      "Epoch [440/500], Train Loss: 0.1012\n",
      "Epoch [441/500], Train Loss: 0.1012\n",
      "Epoch [442/500], Train Loss: 0.1010\n",
      "Epoch [443/500], Train Loss: 0.1011\n",
      "Epoch [444/500], Train Loss: 0.1011\n",
      "Epoch [445/500], Train Loss: 0.1010\n",
      "Epoch [446/500], Train Loss: 0.1009\n",
      "Epoch [447/500], Train Loss: 0.1010\n",
      "Epoch [448/500], Train Loss: 0.1008\n",
      "Epoch [449/500], Train Loss: 0.1007\n",
      "Epoch [450/500], Train Loss: 0.1006\n",
      "Epoch [451/500], Train Loss: 0.1006\n",
      "Epoch [452/500], Train Loss: 0.1005\n",
      "Epoch [453/500], Train Loss: 0.1004\n",
      "Epoch [454/500], Train Loss: 0.1005\n",
      "Epoch [455/500], Train Loss: 0.1004\n",
      "Epoch [456/500], Train Loss: 0.1004\n",
      "Epoch [457/500], Train Loss: 0.1003\n",
      "Epoch [458/500], Train Loss: 0.1002\n",
      "Epoch [459/500], Train Loss: 0.1001\n",
      "Epoch [460/500], Train Loss: 0.0999\n",
      "Epoch [461/500], Train Loss: 0.0999\n",
      "Epoch [462/500], Train Loss: 0.0998\n",
      "Epoch [463/500], Train Loss: 0.0998\n",
      "Epoch [464/500], Train Loss: 0.0998\n",
      "Epoch [465/500], Train Loss: 0.0998\n",
      "Epoch [466/500], Train Loss: 0.0998\n",
      "Epoch [467/500], Train Loss: 0.0997\n",
      "Epoch [468/500], Train Loss: 0.0995\n",
      "Epoch [469/500], Train Loss: 0.0995\n",
      "Epoch [470/500], Train Loss: 0.0994\n",
      "Epoch [471/500], Train Loss: 0.0993\n",
      "Epoch [472/500], Train Loss: 0.0994\n",
      "Epoch [473/500], Train Loss: 0.0993\n",
      "Epoch [474/500], Train Loss: 0.0991\n",
      "Epoch [475/500], Train Loss: 0.0990\n",
      "Epoch [476/500], Train Loss: 0.0990\n",
      "Epoch [477/500], Train Loss: 0.0990\n",
      "Epoch [478/500], Train Loss: 0.0989\n",
      "Epoch [479/500], Train Loss: 0.0990\n",
      "Epoch [480/500], Train Loss: 0.0990\n",
      "Epoch [481/500], Train Loss: 0.0989\n",
      "Epoch [482/500], Train Loss: 0.0988\n",
      "Epoch [483/500], Train Loss: 0.0986\n",
      "Epoch [484/500], Train Loss: 0.0985\n",
      "Epoch [485/500], Train Loss: 0.0985\n",
      "Epoch [486/500], Train Loss: 0.0985\n",
      "Epoch [487/500], Train Loss: 0.0983\n",
      "Epoch [488/500], Train Loss: 0.0982\n",
      "Epoch [489/500], Train Loss: 0.0982\n",
      "Epoch [490/500], Train Loss: 0.0982\n",
      "Epoch [491/500], Train Loss: 0.0982\n",
      "Epoch [492/500], Train Loss: 0.0982\n",
      "Epoch [493/500], Train Loss: 0.0980\n",
      "Epoch [494/500], Train Loss: 0.0980\n",
      "Epoch [495/500], Train Loss: 0.0981\n",
      "Epoch [496/500], Train Loss: 0.0980\n",
      "Epoch [497/500], Train Loss: 0.0979\n",
      "Epoch [498/500], Train Loss: 0.0979\n",
      "Epoch [499/500], Train Loss: 0.0978\n",
      "Epoch [500/500], Train Loss: 0.0978\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr6/final_model_chr6.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr6/individual_r2_scores_chr6.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:58:36,035] A new study created in memory with name: no-name-f30d924d-24fa-40c8-a3df-83078904396e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  22\n",
      "Known PRS313 SNPs:  6\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  860\n",
      "Early stopping at epoch 81\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:58:38,486] Trial 0 finished with value: 0.7484712779521943 and parameters: {'learning_rate': 0.006940343498144362, 'lasso_coef': 0.015795568603736626, 'patience': 14}. Best is trial 0 with value: 0.7484712779521943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 335\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:58:44,039] Trial 1 finished with value: 0.18322074711322783 and parameters: {'learning_rate': 0.0011887500819002183, 'lasso_coef': 6.316816329658887e-05, 'patience': 11}. Best is trial 1 with value: 0.18322074711322783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 84\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 44\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:58:46,928] Trial 2 finished with value: 0.3753552258014679 and parameters: {'learning_rate': 0.015501452074375447, 'lasso_coef': 0.0010366898764840359, 'patience': 16}. Best is trial 1 with value: 0.18322074711322783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:59:08,746] Trial 3 finished with value: 0.3073686420917511 and parameters: {'learning_rate': 0.00016316819492382973, 'lasso_coef': 0.0005119936347112187, 'patience': 11}. Best is trial 1 with value: 0.18322074711322783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:59:09,381] Trial 4 finished with value: 1.2699077010154725 and parameters: {'learning_rate': 0.08145878984469657, 'lasso_coef': 0.0042643666421590815, 'patience': 6}. Best is trial 1 with value: 0.18322074711322783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 387\n",
      "Early stopping at epoch 170\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:59:24,672] Trial 5 finished with value: 0.5044814229011536 and parameters: {'learning_rate': 0.0002406324414191244, 'lasso_coef': 0.014608100221226862, 'patience': 12}. Best is trial 1 with value: 0.18322074711322783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:59:32,881] Trial 6 finished with value: 0.252700674533844 and parameters: {'learning_rate': 0.00042516548768676063, 'lasso_coef': 0.0002462577553506091, 'patience': 16}. Best is trial 1 with value: 0.18322074711322783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 15:59:41,744] Trial 7 finished with value: 0.17569410130381585 and parameters: {'learning_rate': 0.00033150137171788276, 'lasso_coef': 2.4421527829504875e-05, 'patience': 19}. Best is trial 7 with value: 0.17569410130381585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 404\n",
      "Early stopping at epoch 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:00:04,713] Trial 8 finished with value: 0.52646464407444 and parameters: {'learning_rate': 0.00012726465952925112, 'lasso_coef': 0.06536541612640644, 'patience': 16}. Best is trial 7 with value: 0.17569410130381585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:00:40,557] Trial 9 finished with value: 0.34538666158914566 and parameters: {'learning_rate': 0.0001373110066711046, 'lasso_coef': 0.0009368904054485188, 'patience': 14}. Best is trial 7 with value: 0.17569410130381585.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 259\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:00:45,642] Trial 10 finished with value: 0.14311533719301223 and parameters: {'learning_rate': 0.001166246206834397, 'lasso_coef': 1.1008639694529298e-05, 'patience': 20}. Best is trial 10 with value: 0.14311533719301223.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 242\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:00:50,492] Trial 11 finished with value: 0.14691816121339799 and parameters: {'learning_rate': 0.0013690762114225799, 'lasso_coef': 1.4739295259389431e-05, 'patience': 20}. Best is trial 10 with value: 0.14311533719301223.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 149\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:00:53,749] Trial 12 finished with value: 0.14405654668807982 and parameters: {'learning_rate': 0.0019476893070018047, 'lasso_coef': 1.0001673370965627e-05, 'patience': 20}. Best is trial 10 with value: 0.14311533719301223.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 229\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:00:58,078] Trial 13 finished with value: 0.190707977861166 and parameters: {'learning_rate': 0.0026427801458912036, 'lasso_coef': 8.04531385153245e-05, 'patience': 19}. Best is trial 10 with value: 0.14311533719301223.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 50\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:00:59,924] Trial 14 finished with value: 0.1396503996104002 and parameters: {'learning_rate': 0.007725310026829881, 'lasso_coef': 1.0722880691468908e-05, 'patience': 18}. Best is trial 14 with value: 0.1396503996104002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 59\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:01,281] Trial 15 finished with value: 0.1928195297718048 and parameters: {'learning_rate': 0.010900412808179554, 'lasso_coef': 6.413423308590115e-05, 'patience': 8}. Best is trial 14 with value: 0.1396503996104002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 35\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:02,864] Trial 16 finished with value: 0.17171492762863635 and parameters: {'learning_rate': 0.024011827202858996, 'lasso_coef': 3.314390123627659e-05, 'patience': 18}. Best is trial 14 with value: 0.1396503996104002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 183\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:06,530] Trial 17 finished with value: 0.23005348294973374 and parameters: {'learning_rate': 0.005064908910945936, 'lasso_coef': 0.0001847022563366729, 'patience': 17}. Best is trial 14 with value: 0.1396503996104002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:07,733] Trial 18 finished with value: 0.1396107766777277 and parameters: {'learning_rate': 0.040577946966748324, 'lasso_coef': 1.0505802575850352e-05, 'patience': 14}. Best is trial 18 with value: 0.1396107766777277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:08,637] Trial 19 finished with value: 0.2700449302792549 and parameters: {'learning_rate': 0.057886660974383074, 'lasso_coef': 0.00012443040672020656, 'patience': 9}. Best is trial 18 with value: 0.1396107766777277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 39\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:10,045] Trial 20 finished with value: 0.17730614691972732 and parameters: {'learning_rate': 0.02992555749737548, 'lasso_coef': 3.3275608294659824e-05, 'patience': 14}. Best is trial 18 with value: 0.1396107766777277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 482\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:18,108] Trial 21 finished with value: 0.14300816580653192 and parameters: {'learning_rate': 0.0006618550618116689, 'lasso_coef': 1.418579329674639e-05, 'patience': 18}. Best is trial 18 with value: 0.1396107766777277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:26,437] Trial 22 finished with value: 0.1534439254552126 and parameters: {'learning_rate': 0.0007431065349800915, 'lasso_coef': 2.5555598705450314e-05, 'patience': 17}. Best is trial 18 with value: 0.1396107766777277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 98\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:28,737] Trial 23 finished with value: 0.14951820336282254 and parameters: {'learning_rate': 0.0044687931776830865, 'lasso_coef': 1.845133081123288e-05, 'patience': 15}. Best is trial 18 with value: 0.1396107766777277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:30,383] Trial 24 finished with value: 0.20294291004538537 and parameters: {'learning_rate': 0.03605378919288853, 'lasso_coef': 5.0856404600138856e-05, 'patience': 18}. Best is trial 18 with value: 0.1396107766777277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 120\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 32\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:33,344] Trial 25 finished with value: 0.27171600311994554 and parameters: {'learning_rate': 0.011768132743564736, 'lasso_coef': 0.0003429297860643627, 'patience': 13}. Best is trial 18 with value: 0.1396107766777277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 384\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:39,704] Trial 26 finished with value: 0.1461135648190975 and parameters: {'learning_rate': 0.0006340533572576913, 'lasso_coef': 1.0629268518996964e-05, 'patience': 18}. Best is trial 18 with value: 0.1396107766777277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 28\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:41,080] Trial 27 finished with value: 0.26859956458210943 and parameters: {'learning_rate': 0.04890447498375537, 'lasso_coef': 0.0001268179267029454, 'patience': 15}. Best is trial 18 with value: 0.1396107766777277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 101\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:43,596] Trial 28 finished with value: 0.16971102319657802 and parameters: {'learning_rate': 0.007744874763695804, 'lasso_coef': 4.176001032613875e-05, 'patience': 17}. Best is trial 18 with value: 0.1396107766777277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 116\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:46,638] Trial 29 finished with value: 0.5091686069965362 and parameters: {'learning_rate': 0.0033216502593766003, 'lasso_coef': 0.004876492005103249, 'patience': 13}. Best is trial 18 with value: 0.1396107766777277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Best hyperparameters: {'learning_rate': 0.040577946966748324, 'lasso_coef': 1.0505802575850352e-05, 'patience': 14}\n",
      "Best value: 0.1396107766777277\n",
      "Epoch [1/500], Train Loss: 1.0788\n",
      "Epoch [2/500], Train Loss: 0.3968\n",
      "Epoch [3/500], Train Loss: 0.2494\n",
      "Epoch [4/500], Train Loss: 0.2004\n",
      "Epoch [5/500], Train Loss: 0.1809\n",
      "Epoch [6/500], Train Loss: 0.1691\n",
      "Epoch [7/500], Train Loss: 0.1596\n",
      "Epoch [8/500], Train Loss: 0.1526\n",
      "Epoch [9/500], Train Loss: 0.1502\n",
      "Epoch [10/500], Train Loss: 0.1408\n",
      "Epoch [11/500], Train Loss: 0.1389\n",
      "Epoch [12/500], Train Loss: 0.1396\n",
      "Epoch [13/500], Train Loss: 0.1337\n",
      "Epoch [14/500], Train Loss: 0.1284\n",
      "Epoch [15/500], Train Loss: 0.1285\n",
      "Epoch [16/500], Train Loss: 0.1271\n",
      "Epoch [17/500], Train Loss: 0.1228\n",
      "Epoch [18/500], Train Loss: 0.1223\n",
      "Epoch [19/500], Train Loss: 0.1193\n",
      "Epoch [20/500], Train Loss: 0.1164\n",
      "Epoch [21/500], Train Loss: 0.1159\n",
      "Epoch [22/500], Train Loss: 0.1153\n",
      "Epoch [23/500], Train Loss: 0.1152\n",
      "Epoch [24/500], Train Loss: 0.1209\n",
      "Epoch [25/500], Train Loss: 0.1170\n",
      "Epoch [26/500], Train Loss: 0.1140\n",
      "Epoch [27/500], Train Loss: 0.1173\n",
      "Epoch [28/500], Train Loss: 0.1167\n",
      "Epoch [29/500], Train Loss: 0.1098\n",
      "Epoch [30/500], Train Loss: 0.1083\n",
      "Epoch [31/500], Train Loss: 0.1078\n",
      "Epoch [32/500], Train Loss: 0.1069\n",
      "Epoch [33/500], Train Loss: 0.1090\n",
      "Epoch [34/500], Train Loss: 0.1105\n",
      "Epoch [35/500], Train Loss: 0.1081\n",
      "Epoch [36/500], Train Loss: 0.1082\n",
      "Epoch [37/500], Train Loss: 0.1081\n",
      "Epoch [38/500], Train Loss: 0.1046\n",
      "Epoch [39/500], Train Loss: 0.1056\n",
      "Epoch [40/500], Train Loss: 0.1089\n",
      "Epoch [41/500], Train Loss: 0.1086\n",
      "Epoch [42/500], Train Loss: 0.1047\n",
      "Epoch [43/500], Train Loss: 0.1022\n",
      "Epoch [44/500], Train Loss: 0.1040\n",
      "Epoch [45/500], Train Loss: 0.1031\n",
      "Epoch [46/500], Train Loss: 0.1032\n",
      "Epoch [47/500], Train Loss: 0.1015\n",
      "Epoch [48/500], Train Loss: 0.1009\n",
      "Epoch [49/500], Train Loss: 0.1032\n",
      "Epoch [50/500], Train Loss: 0.1041\n",
      "Epoch [51/500], Train Loss: 0.1097\n",
      "Epoch [52/500], Train Loss: 0.1025\n",
      "Epoch [53/500], Train Loss: 0.1007\n",
      "Epoch [54/500], Train Loss: 0.1002\n",
      "Epoch [55/500], Train Loss: 0.1022\n",
      "Epoch [56/500], Train Loss: 0.1026\n",
      "Epoch [57/500], Train Loss: 0.1065\n",
      "Epoch [58/500], Train Loss: 0.1046\n",
      "Epoch [59/500], Train Loss: 0.1013\n",
      "Epoch [60/500], Train Loss: 0.1019\n",
      "Epoch [61/500], Train Loss: 0.1030\n",
      "Epoch [62/500], Train Loss: 0.1023\n",
      "Epoch [63/500], Train Loss: 0.1015\n",
      "Epoch [64/500], Train Loss: 0.1009\n",
      "Epoch [65/500], Train Loss: 0.1017\n",
      "Epoch [66/500], Train Loss: 0.1025\n",
      "Epoch [67/500], Train Loss: 0.1010\n",
      "Epoch [68/500], Train Loss: 0.1044\n",
      "Early stopping at epoch 68\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr7/final_model_chr7.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr7/individual_r2_scores_chr7.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:48,881] A new study created in memory with name: no-name-5633e424-3e0b-4217-8a03-2687902aeff9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  28\n",
      "Known PRS313 SNPs:  14\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  1262\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:01:59,471] Trial 0 finished with value: 0.179796152561903 and parameters: {'learning_rate': 0.0009663889119324511, 'lasso_coef': 9.670281230531616e-05, 'patience': 18}. Best is trial 0 with value: 0.179796152561903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:02:09,526] Trial 1 finished with value: 0.1555660881102085 and parameters: {'learning_rate': 0.000745102078298868, 'lasso_coef': 5.103957485206282e-05, 'patience': 8}. Best is trial 1 with value: 0.1555660881102085.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 34\n",
      "Early stopping at epoch 32\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:02:11,817] Trial 2 finished with value: 0.9276938706636428 and parameters: {'learning_rate': 0.049471238906986965, 'lasso_coef': 1.298126243635743e-05, 'patience': 15}. Best is trial 1 with value: 0.1555660881102085.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:02:32,205] Trial 3 finished with value: 0.258164544403553 and parameters: {'learning_rate': 0.0003353175535355277, 'lasso_coef': 0.0003119651211217081, 'patience': 16}. Best is trial 1 with value: 0.1555660881102085.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:02:33,241] Trial 4 finished with value: 0.5812534421682358 and parameters: {'learning_rate': 0.08266041689230805, 'lasso_coef': 0.0006737034052846194, 'patience': 5}. Best is trial 1 with value: 0.1555660881102085.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:02:34,542] Trial 5 finished with value: 0.5490214407444001 and parameters: {'learning_rate': 0.055402237683498515, 'lasso_coef': 0.0008562677232507279, 'patience': 8}. Best is trial 1 with value: 0.1555660881102085.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 142\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:02:37,964] Trial 6 finished with value: 0.11246701292693614 and parameters: {'learning_rate': 0.004698130577979757, 'lasso_coef': 1.1390528761881886e-05, 'patience': 8}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 85\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:02:40,450] Trial 7 finished with value: 0.37297602891922 and parameters: {'learning_rate': 0.005504753388697206, 'lasso_coef': 0.000906572223537129, 'patience': 5}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 85\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:02:44,399] Trial 8 finished with value: 0.3290822982788086 and parameters: {'learning_rate': 0.014432435736470493, 'lasso_coef': 0.0005104186550340237, 'patience': 19}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 49\n",
      "Early stopping at epoch 442\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:02:54,092] Trial 9 finished with value: 0.2821791931986809 and parameters: {'learning_rate': 0.0011395895331035718, 'lasso_coef': 0.00047772940906838526, 'patience': 7}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 447\n",
      "Early stopping at epoch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:03:22,671] Trial 10 finished with value: 0.5586555153131485 and parameters: {'learning_rate': 0.00012836343259985908, 'lasso_coef': 0.024505600611662227, 'patience': 12}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 149\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:03:27,158] Trial 11 finished with value: 0.11472632437944412 and parameters: {'learning_rate': 0.0031351713515004125, 'lasso_coef': 1.0329633233643346e-05, 'patience': 10}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 106\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:03:30,645] Trial 12 finished with value: 0.11401485204696656 and parameters: {'learning_rate': 0.005857703248904297, 'lasso_coef': 1.1514008123915986e-05, 'patience': 11}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 54\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:03:32,879] Trial 13 finished with value: 0.9330976575613021 and parameters: {'learning_rate': 0.010613863536593207, 'lasso_coef': 0.008369026974953757, 'patience': 12}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 233\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:03:38,146] Trial 14 finished with value: 0.15410436540842057 and parameters: {'learning_rate': 0.0030071904458641757, 'lasso_coef': 5.242083843339299e-05, 'patience': 10}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 70\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:03:40,670] Trial 15 finished with value: 0.12764915339648725 and parameters: {'learning_rate': 0.01626062418087756, 'lasso_coef': 2.098350714219737e-05, 'patience': 14}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 100\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:03:43,939] Trial 16 finished with value: 0.5815538972616195 and parameters: {'learning_rate': 0.004697408398581062, 'lasso_coef': 0.003681707495775919, 'patience': 10}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 73\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:03:46,496] Trial 17 finished with value: 0.23408362343907357 and parameters: {'learning_rate': 0.021992783121817978, 'lasso_coef': 0.0001379622422691826, 'patience': 13}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 140\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 46\n",
      "Early stopping at epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:03:51,314] Trial 18 finished with value: 1.0153890073299408 and parameters: {'learning_rate': 0.001510414079982241, 'lasso_coef': 0.0812535674584528, 'patience': 11}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 72\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:03:53,352] Trial 19 finished with value: 0.14729092717170716 and parameters: {'learning_rate': 0.007193352774657277, 'lasso_coef': 3.2060913293443355e-05, 'patience': 7}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 35\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:03:54,919] Trial 20 finished with value: 0.2543137170374393 and parameters: {'learning_rate': 0.027413253019125706, 'lasso_coef': 0.00016220857528983116, 'patience': 9}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 244\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:04:00,766] Trial 21 finished with value: 0.11475209109485149 and parameters: {'learning_rate': 0.0028965097797136225, 'lasso_coef': 1.552505579004354e-05, 'patience': 10}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 206\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:04:05,620] Trial 22 finished with value: 0.11897814981639385 and parameters: {'learning_rate': 0.001939578660289914, 'lasso_coef': 1.1179547852631285e-05, 'patience': 7}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:04:16,031] Trial 23 finished with value: 0.16180043742060662 and parameters: {'learning_rate': 0.00042400486239253376, 'lasso_coef': 3.877323673018134e-05, 'patience': 11}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 71\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:04:18,193] Trial 24 finished with value: 0.11718232445418834 and parameters: {'learning_rate': 0.007811196725552397, 'lasso_coef': 1.12440604916928e-05, 'patience': 9}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 237\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:04:23,758] Trial 25 finished with value: 0.16637784391641616 and parameters: {'learning_rate': 0.0038831563426591324, 'lasso_coef': 6.921055965192045e-05, 'patience': 13}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 251\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:04:29,835] Trial 26 finished with value: 0.1323610156774521 and parameters: {'learning_rate': 0.002202800521785278, 'lasso_coef': 2.7321228068415832e-05, 'patience': 11}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 47\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:04:31,773] Trial 27 finished with value: 0.5538715720176697 and parameters: {'learning_rate': 0.00875763484204977, 'lasso_coef': 0.00230524971664359, 'patience': 6}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:04:42,553] Trial 28 finished with value: 0.2360424891114235 and parameters: {'learning_rate': 0.0005509030604833363, 'lasso_coef': 0.0002155776867730182, 'patience': 9}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 429\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:04:51,861] Trial 29 finished with value: 0.1733580656349659 and parameters: {'learning_rate': 0.0014413812213711224, 'lasso_coef': 8.699770748371016e-05, 'patience': 17}. Best is trial 6 with value: 0.11246701292693614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Best hyperparameters: {'learning_rate': 0.004698130577979757, 'lasso_coef': 1.1390528761881886e-05, 'patience': 8}\n",
      "Best value: 0.11246701292693614\n",
      "Epoch [1/500], Train Loss: 0.5601\n",
      "Epoch [2/500], Train Loss: 0.4412\n",
      "Epoch [3/500], Train Loss: 0.3803\n",
      "Epoch [4/500], Train Loss: 0.3398\n",
      "Epoch [5/500], Train Loss: 0.3097\n",
      "Epoch [6/500], Train Loss: 0.2873\n",
      "Epoch [7/500], Train Loss: 0.2681\n",
      "Epoch [8/500], Train Loss: 0.2504\n",
      "Epoch [9/500], Train Loss: 0.2374\n",
      "Epoch [10/500], Train Loss: 0.2257\n",
      "Epoch [11/500], Train Loss: 0.2168\n",
      "Epoch [12/500], Train Loss: 0.2073\n",
      "Epoch [13/500], Train Loss: 0.1986\n",
      "Epoch [14/500], Train Loss: 0.1921\n",
      "Epoch [15/500], Train Loss: 0.1864\n",
      "Epoch [16/500], Train Loss: 0.1803\n",
      "Epoch [17/500], Train Loss: 0.1746\n",
      "Epoch [18/500], Train Loss: 0.1702\n",
      "Epoch [19/500], Train Loss: 0.1655\n",
      "Epoch [20/500], Train Loss: 0.1611\n",
      "Epoch [21/500], Train Loss: 0.1584\n",
      "Epoch [22/500], Train Loss: 0.1545\n",
      "Epoch [23/500], Train Loss: 0.1511\n",
      "Epoch [24/500], Train Loss: 0.1483\n",
      "Epoch [25/500], Train Loss: 0.1457\n",
      "Epoch [26/500], Train Loss: 0.1426\n",
      "Epoch [27/500], Train Loss: 0.1401\n",
      "Epoch [28/500], Train Loss: 0.1374\n",
      "Epoch [29/500], Train Loss: 0.1352\n",
      "Epoch [30/500], Train Loss: 0.1333\n",
      "Epoch [31/500], Train Loss: 0.1313\n",
      "Epoch [32/500], Train Loss: 0.1289\n",
      "Epoch [33/500], Train Loss: 0.1275\n",
      "Epoch [34/500], Train Loss: 0.1256\n",
      "Epoch [35/500], Train Loss: 0.1242\n",
      "Epoch [36/500], Train Loss: 0.1230\n",
      "Epoch [37/500], Train Loss: 0.1208\n",
      "Epoch [38/500], Train Loss: 0.1202\n",
      "Epoch [39/500], Train Loss: 0.1184\n",
      "Epoch [40/500], Train Loss: 0.1171\n",
      "Epoch [41/500], Train Loss: 0.1162\n",
      "Epoch [42/500], Train Loss: 0.1150\n",
      "Epoch [43/500], Train Loss: 0.1136\n",
      "Epoch [44/500], Train Loss: 0.1123\n",
      "Epoch [45/500], Train Loss: 0.1111\n",
      "Epoch [46/500], Train Loss: 0.1105\n",
      "Epoch [47/500], Train Loss: 0.1094\n",
      "Epoch [48/500], Train Loss: 0.1085\n",
      "Epoch [49/500], Train Loss: 0.1070\n",
      "Epoch [50/500], Train Loss: 0.1062\n",
      "Epoch [51/500], Train Loss: 0.1055\n",
      "Epoch [52/500], Train Loss: 0.1050\n",
      "Epoch [53/500], Train Loss: 0.1038\n",
      "Epoch [54/500], Train Loss: 0.1033\n",
      "Epoch [55/500], Train Loss: 0.1023\n",
      "Epoch [56/500], Train Loss: 0.1013\n",
      "Epoch [57/500], Train Loss: 0.1008\n",
      "Epoch [58/500], Train Loss: 0.1001\n",
      "Epoch [59/500], Train Loss: 0.0997\n",
      "Epoch [60/500], Train Loss: 0.0986\n",
      "Epoch [61/500], Train Loss: 0.0983\n",
      "Epoch [62/500], Train Loss: 0.0976\n",
      "Epoch [63/500], Train Loss: 0.0970\n",
      "Epoch [64/500], Train Loss: 0.0963\n",
      "Epoch [65/500], Train Loss: 0.0953\n",
      "Epoch [66/500], Train Loss: 0.0950\n",
      "Epoch [67/500], Train Loss: 0.0949\n",
      "Epoch [68/500], Train Loss: 0.0942\n",
      "Epoch [69/500], Train Loss: 0.0935\n",
      "Epoch [70/500], Train Loss: 0.0931\n",
      "Epoch [71/500], Train Loss: 0.0921\n",
      "Epoch [72/500], Train Loss: 0.0922\n",
      "Epoch [73/500], Train Loss: 0.0916\n",
      "Epoch [74/500], Train Loss: 0.0912\n",
      "Epoch [75/500], Train Loss: 0.0909\n",
      "Epoch [76/500], Train Loss: 0.0903\n",
      "Epoch [77/500], Train Loss: 0.0895\n",
      "Epoch [78/500], Train Loss: 0.0895\n",
      "Epoch [79/500], Train Loss: 0.0894\n",
      "Epoch [80/500], Train Loss: 0.0898\n",
      "Epoch [81/500], Train Loss: 0.0890\n",
      "Epoch [82/500], Train Loss: 0.0882\n",
      "Epoch [83/500], Train Loss: 0.0872\n",
      "Epoch [84/500], Train Loss: 0.0871\n",
      "Epoch [85/500], Train Loss: 0.0870\n",
      "Epoch [86/500], Train Loss: 0.0863\n",
      "Epoch [87/500], Train Loss: 0.0856\n",
      "Epoch [88/500], Train Loss: 0.0854\n",
      "Epoch [89/500], Train Loss: 0.0855\n",
      "Epoch [90/500], Train Loss: 0.0853\n",
      "Epoch [91/500], Train Loss: 0.0849\n",
      "Epoch [92/500], Train Loss: 0.0847\n",
      "Epoch [93/500], Train Loss: 0.0838\n",
      "Epoch [94/500], Train Loss: 0.0835\n",
      "Epoch [95/500], Train Loss: 0.0836\n",
      "Epoch [96/500], Train Loss: 0.0837\n",
      "Epoch [97/500], Train Loss: 0.0829\n",
      "Epoch [98/500], Train Loss: 0.0828\n",
      "Epoch [99/500], Train Loss: 0.0825\n",
      "Epoch [100/500], Train Loss: 0.0824\n",
      "Epoch [101/500], Train Loss: 0.0819\n",
      "Epoch [102/500], Train Loss: 0.0817\n",
      "Epoch [103/500], Train Loss: 0.0812\n",
      "Epoch [104/500], Train Loss: 0.0814\n",
      "Epoch [105/500], Train Loss: 0.0811\n",
      "Epoch [106/500], Train Loss: 0.0813\n",
      "Epoch [107/500], Train Loss: 0.0811\n",
      "Epoch [108/500], Train Loss: 0.0800\n",
      "Epoch [109/500], Train Loss: 0.0799\n",
      "Epoch [110/500], Train Loss: 0.0797\n",
      "Epoch [111/500], Train Loss: 0.0795\n",
      "Epoch [112/500], Train Loss: 0.0797\n",
      "Epoch [113/500], Train Loss: 0.0787\n",
      "Epoch [114/500], Train Loss: 0.0789\n",
      "Epoch [115/500], Train Loss: 0.0790\n",
      "Epoch [116/500], Train Loss: 0.0784\n",
      "Epoch [117/500], Train Loss: 0.0781\n",
      "Epoch [118/500], Train Loss: 0.0780\n",
      "Epoch [119/500], Train Loss: 0.0777\n",
      "Epoch [120/500], Train Loss: 0.0775\n",
      "Epoch [121/500], Train Loss: 0.0774\n",
      "Epoch [122/500], Train Loss: 0.0775\n",
      "Epoch [123/500], Train Loss: 0.0770\n",
      "Epoch [124/500], Train Loss: 0.0776\n",
      "Epoch [125/500], Train Loss: 0.0769\n",
      "Epoch [126/500], Train Loss: 0.0767\n",
      "Epoch [127/500], Train Loss: 0.0763\n",
      "Epoch [128/500], Train Loss: 0.0761\n",
      "Epoch [129/500], Train Loss: 0.0763\n",
      "Epoch [130/500], Train Loss: 0.0760\n",
      "Epoch [131/500], Train Loss: 0.0755\n",
      "Epoch [132/500], Train Loss: 0.0754\n",
      "Epoch [133/500], Train Loss: 0.0753\n",
      "Epoch [134/500], Train Loss: 0.0750\n",
      "Epoch [135/500], Train Loss: 0.0748\n",
      "Epoch [136/500], Train Loss: 0.0749\n",
      "Epoch [137/500], Train Loss: 0.0746\n",
      "Epoch [138/500], Train Loss: 0.0744\n",
      "Epoch [139/500], Train Loss: 0.0743\n",
      "Epoch [140/500], Train Loss: 0.0742\n",
      "Epoch [141/500], Train Loss: 0.0739\n",
      "Epoch [142/500], Train Loss: 0.0737\n",
      "Epoch [143/500], Train Loss: 0.0737\n",
      "Epoch [144/500], Train Loss: 0.0736\n",
      "Epoch [145/500], Train Loss: 0.0737\n",
      "Epoch [146/500], Train Loss: 0.0735\n",
      "Epoch [147/500], Train Loss: 0.0734\n",
      "Epoch [148/500], Train Loss: 0.0735\n",
      "Epoch [149/500], Train Loss: 0.0729\n",
      "Epoch [150/500], Train Loss: 0.0729\n",
      "Epoch [151/500], Train Loss: 0.0727\n",
      "Epoch [152/500], Train Loss: 0.0727\n",
      "Epoch [153/500], Train Loss: 0.0724\n",
      "Epoch [154/500], Train Loss: 0.0721\n",
      "Epoch [155/500], Train Loss: 0.0721\n",
      "Epoch [156/500], Train Loss: 0.0719\n",
      "Epoch [157/500], Train Loss: 0.0720\n",
      "Epoch [158/500], Train Loss: 0.0723\n",
      "Epoch [159/500], Train Loss: 0.0715\n",
      "Epoch [160/500], Train Loss: 0.0713\n",
      "Epoch [161/500], Train Loss: 0.0713\n",
      "Epoch [162/500], Train Loss: 0.0715\n",
      "Epoch [163/500], Train Loss: 0.0711\n",
      "Epoch [164/500], Train Loss: 0.0710\n",
      "Epoch [165/500], Train Loss: 0.0713\n",
      "Epoch [166/500], Train Loss: 0.0711\n",
      "Epoch [167/500], Train Loss: 0.0708\n",
      "Epoch [168/500], Train Loss: 0.0708\n",
      "Epoch [169/500], Train Loss: 0.0706\n",
      "Epoch [170/500], Train Loss: 0.0702\n",
      "Epoch [171/500], Train Loss: 0.0704\n",
      "Epoch [172/500], Train Loss: 0.0701\n",
      "Epoch [173/500], Train Loss: 0.0703\n",
      "Epoch [174/500], Train Loss: 0.0706\n",
      "Epoch [175/500], Train Loss: 0.0703\n",
      "Epoch [176/500], Train Loss: 0.0703\n",
      "Epoch [177/500], Train Loss: 0.0698\n",
      "Epoch [178/500], Train Loss: 0.0699\n",
      "Epoch [179/500], Train Loss: 0.0695\n",
      "Epoch [180/500], Train Loss: 0.0692\n",
      "Epoch [181/500], Train Loss: 0.0696\n",
      "Epoch [182/500], Train Loss: 0.0697\n",
      "Epoch [183/500], Train Loss: 0.0694\n",
      "Epoch [184/500], Train Loss: 0.0688\n",
      "Epoch [185/500], Train Loss: 0.0693\n",
      "Epoch [186/500], Train Loss: 0.0690\n",
      "Epoch [187/500], Train Loss: 0.0691\n",
      "Epoch [188/500], Train Loss: 0.0694\n",
      "Epoch [189/500], Train Loss: 0.0686\n",
      "Epoch [190/500], Train Loss: 0.0686\n",
      "Epoch [191/500], Train Loss: 0.0686\n",
      "Epoch [192/500], Train Loss: 0.0691\n",
      "Epoch [193/500], Train Loss: 0.0686\n",
      "Epoch [194/500], Train Loss: 0.0687\n",
      "Epoch [195/500], Train Loss: 0.0684\n",
      "Epoch [196/500], Train Loss: 0.0689\n",
      "Epoch [197/500], Train Loss: 0.0682\n",
      "Epoch [198/500], Train Loss: 0.0679\n",
      "Epoch [199/500], Train Loss: 0.0678\n",
      "Epoch [200/500], Train Loss: 0.0679\n",
      "Epoch [201/500], Train Loss: 0.0681\n",
      "Epoch [202/500], Train Loss: 0.0679\n",
      "Epoch [203/500], Train Loss: 0.0674\n",
      "Epoch [204/500], Train Loss: 0.0677\n",
      "Epoch [205/500], Train Loss: 0.0674\n",
      "Epoch [206/500], Train Loss: 0.0676\n",
      "Epoch [207/500], Train Loss: 0.0674\n",
      "Epoch [208/500], Train Loss: 0.0676\n",
      "Epoch [209/500], Train Loss: 0.0673\n",
      "Epoch [210/500], Train Loss: 0.0674\n",
      "Epoch [211/500], Train Loss: 0.0672\n",
      "Epoch [212/500], Train Loss: 0.0672\n",
      "Epoch [213/500], Train Loss: 0.0668\n",
      "Epoch [214/500], Train Loss: 0.0670\n",
      "Epoch [215/500], Train Loss: 0.0671\n",
      "Epoch [216/500], Train Loss: 0.0671\n",
      "Epoch [217/500], Train Loss: 0.0668\n",
      "Epoch [218/500], Train Loss: 0.0670\n",
      "Epoch [219/500], Train Loss: 0.0668\n",
      "Epoch [220/500], Train Loss: 0.0667\n",
      "Epoch [221/500], Train Loss: 0.0668\n",
      "Epoch [222/500], Train Loss: 0.0664\n",
      "Epoch [223/500], Train Loss: 0.0663\n",
      "Epoch [224/500], Train Loss: 0.0663\n",
      "Epoch [225/500], Train Loss: 0.0660\n",
      "Epoch [226/500], Train Loss: 0.0659\n",
      "Epoch [227/500], Train Loss: 0.0662\n",
      "Epoch [228/500], Train Loss: 0.0660\n",
      "Epoch [229/500], Train Loss: 0.0661\n",
      "Epoch [230/500], Train Loss: 0.0659\n",
      "Epoch [231/500], Train Loss: 0.0659\n",
      "Epoch [232/500], Train Loss: 0.0660\n",
      "Epoch [233/500], Train Loss: 0.0661\n",
      "Epoch [234/500], Train Loss: 0.0662\n",
      "Early stopping at epoch 234\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr8/final_model_chr8.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr8/individual_r2_scores_chr8.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:04:58,307] A new study created in memory with name: no-name-b1c2e566-b623-4004-ad2a-75e169606b9f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  18\n",
      "Known PRS313 SNPs:  12\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  1036\n",
      "Early stopping at epoch 248\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:05:02,975] Trial 0 finished with value: 0.3491073280572891 and parameters: {'learning_rate': 0.0019424802729053061, 'lasso_coef': 0.0011668401926917841, 'patience': 8}. Best is trial 0 with value: 0.3491073280572891.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 45\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:05:04,888] Trial 1 finished with value: 2.807732307910919 and parameters: {'learning_rate': 0.03242271326005276, 'lasso_coef': 0.030317111693577137, 'patience': 14}. Best is trial 0 with value: 0.3491073280572891.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:05:12,973] Trial 2 finished with value: 0.1611998226493597 and parameters: {'learning_rate': 0.0002481594641661795, 'lasso_coef': 1.4251730522142439e-05, 'patience': 9}. Best is trial 2 with value: 0.1611998226493597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:05:21,360] Trial 3 finished with value: 0.1341105606406927 and parameters: {'learning_rate': 0.0008178065269056629, 'lasso_coef': 4.1803570598401806e-05, 'patience': 17}. Best is trial 3 with value: 0.1341105606406927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:05:29,329] Trial 4 finished with value: 0.29312702268362045 and parameters: {'learning_rate': 0.00010105621805293042, 'lasso_coef': 0.00010502776122948736, 'patience': 7}. Best is trial 3 with value: 0.1341105606406927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 55\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:05:31,671] Trial 5 finished with value: 1.1397986829280853 and parameters: {'learning_rate': 0.00872775198386109, 'lasso_coef': 0.028499052260943868, 'patience': 16}. Best is trial 3 with value: 0.1341105606406927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 45\n",
      "Early stopping at epoch 141\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:05:34,696] Trial 6 finished with value: 0.629343780875206 and parameters: {'learning_rate': 0.0018322331609331455, 'lasso_coef': 0.013336291296684089, 'patience': 10}. Best is trial 3 with value: 0.1341105606406927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 83\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:05:37,076] Trial 7 finished with value: 0.32709689140319825 and parameters: {'learning_rate': 0.01609047208038489, 'lasso_coef': 0.0007266784328201154, 'patience': 15}. Best is trial 3 with value: 0.1341105606406927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 147\n",
      "Early stopping at epoch 28\n",
      "Early stopping at epoch 31\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:05:40,938] Trial 8 finished with value: 0.57471943795681 and parameters: {'learning_rate': 0.003025962417978011, 'lasso_coef': 0.005673704324898164, 'patience': 20}. Best is trial 3 with value: 0.1341105606406927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 168\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:05:44,545] Trial 9 finished with value: 0.20037538111209868 and parameters: {'learning_rate': 0.007320707434360706, 'lasso_coef': 0.00020467806506307168, 'patience': 16}. Best is trial 3 with value: 0.1341105606406927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:05:53,337] Trial 10 finished with value: 0.11460240334272384 and parameters: {'learning_rate': 0.0005949819574161746, 'lasso_coef': 1.029389175748861e-05, 'patience': 20}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 417\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:06:00,919] Trial 11 finished with value: 0.11875369921326637 and parameters: {'learning_rate': 0.000655103779427567, 'lasso_coef': 1.0112393211681906e-05, 'patience': 20}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:06:09,739] Trial 12 finished with value: 0.12430621050298214 and parameters: {'learning_rate': 0.0005261451023562733, 'lasso_coef': 1.430697007615072e-05, 'patience': 20}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:06:18,426] Trial 13 finished with value: 0.11617181152105331 and parameters: {'learning_rate': 0.0005706554029227348, 'lasso_coef': 1.0464092709527635e-05, 'patience': 18}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:06:27,039] Trial 14 finished with value: 0.22335858270525932 and parameters: {'learning_rate': 0.00019894583574317284, 'lasso_coef': 7.321541841528585e-05, 'patience': 18}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:06:28,728] Trial 15 finished with value: 0.42140333354473114 and parameters: {'learning_rate': 0.09774907793470233, 'lasso_coef': 0.0005452685044705555, 'patience': 12}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 287\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:06:33,300] Trial 16 finished with value: 0.1395078867673874 and parameters: {'learning_rate': 0.001198288505060644, 'lasso_coef': 3.194215384022948e-05, 'patience': 5}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 473\n",
      "Early stopping at epoch 49\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:06:42,240] Trial 17 finished with value: 0.643813607096672 and parameters: {'learning_rate': 0.0003434570345878625, 'lasso_coef': 0.0995134113405228, 'patience': 18}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:06:57,507] Trial 18 finished with value: 0.28998380452394484 and parameters: {'learning_rate': 0.00010597256616469448, 'lasso_coef': 0.0002448432040942815, 'patience': 13}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:07:13,599] Trial 19 finished with value: 0.4369952157139778 and parameters: {'learning_rate': 0.00039451721664286363, 'lasso_coef': 0.0024336019835749408, 'patience': 18}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:07:21,900] Trial 20 finished with value: 0.11612601429224015 and parameters: {'learning_rate': 0.0011241728742198134, 'lasso_coef': 2.8384779471471907e-05, 'patience': 11}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:07:30,015] Trial 21 finished with value: 0.11599038168787956 and parameters: {'learning_rate': 0.0011734576446124994, 'lasso_coef': 2.897463875851425e-05, 'patience': 11}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 439\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:07:37,389] Trial 22 finished with value: 0.12131760604679584 and parameters: {'learning_rate': 0.0013350196063957665, 'lasso_coef': 3.464571200758247e-05, 'patience': 11}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 286\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:07:42,373] Trial 23 finished with value: 0.1629532277584076 and parameters: {'learning_rate': 0.0027668314817773194, 'lasso_coef': 0.0001110298697164137, 'patience': 12}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 186\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:07:45,716] Trial 24 finished with value: 0.1191167864948511 and parameters: {'learning_rate': 0.004948880583659354, 'lasso_coef': 3.22539047350118e-05, 'patience': 10}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:07:53,985] Trial 25 finished with value: 0.20920372232794762 and parameters: {'learning_rate': 0.0009966856974046245, 'lasso_coef': 0.00024407499503036496, 'patience': 13}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:08:01,637] Trial 26 finished with value: 0.18202952072024345 and parameters: {'learning_rate': 0.00021138274828799095, 'lasso_coef': 2.188048280718124e-05, 'patience': 7}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 273\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:08:06,300] Trial 27 finished with value: 0.13631006181240082 and parameters: {'learning_rate': 0.004154446490879121, 'lasso_coef': 6.272505984408537e-05, 'patience': 11}. Best is trial 10 with value: 0.11460240334272384.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:08:14,732] Trial 28 finished with value: 0.10114515013992786 and parameters: {'learning_rate': 0.0017178800720047587, 'lasso_coef': 1.9302937055198812e-05, 'patience': 14}. Best is trial 28 with value: 0.10114515013992786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 218\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:08:18,426] Trial 29 finished with value: 0.3999745428562164 and parameters: {'learning_rate': 0.0023933928452688773, 'lasso_coef': 0.0017334773703722142, 'patience': 8}. Best is trial 28 with value: 0.10114515013992786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Best hyperparameters: {'learning_rate': 0.0017178800720047587, 'lasso_coef': 1.9302937055198812e-05, 'patience': 14}\n",
      "Best value: 0.10114515013992786\n",
      "Epoch [1/500], Train Loss: 0.5809\n",
      "Epoch [2/500], Train Loss: 0.5127\n",
      "Epoch [3/500], Train Loss: 0.4765\n",
      "Epoch [4/500], Train Loss: 0.4507\n",
      "Epoch [5/500], Train Loss: 0.4277\n",
      "Epoch [6/500], Train Loss: 0.4082\n",
      "Epoch [7/500], Train Loss: 0.3913\n",
      "Epoch [8/500], Train Loss: 0.3757\n",
      "Epoch [9/500], Train Loss: 0.3622\n",
      "Epoch [10/500], Train Loss: 0.3497\n",
      "Epoch [11/500], Train Loss: 0.3397\n",
      "Epoch [12/500], Train Loss: 0.3295\n",
      "Epoch [13/500], Train Loss: 0.3196\n",
      "Epoch [14/500], Train Loss: 0.3113\n",
      "Epoch [15/500], Train Loss: 0.3031\n",
      "Epoch [16/500], Train Loss: 0.2960\n",
      "Epoch [17/500], Train Loss: 0.2894\n",
      "Epoch [18/500], Train Loss: 0.2829\n",
      "Epoch [19/500], Train Loss: 0.2770\n",
      "Epoch [20/500], Train Loss: 0.2712\n",
      "Epoch [21/500], Train Loss: 0.2662\n",
      "Epoch [22/500], Train Loss: 0.2614\n",
      "Epoch [23/500], Train Loss: 0.2567\n",
      "Epoch [24/500], Train Loss: 0.2524\n",
      "Epoch [25/500], Train Loss: 0.2473\n",
      "Epoch [26/500], Train Loss: 0.2432\n",
      "Epoch [27/500], Train Loss: 0.2397\n",
      "Epoch [28/500], Train Loss: 0.2358\n",
      "Epoch [29/500], Train Loss: 0.2327\n",
      "Epoch [30/500], Train Loss: 0.2298\n",
      "Epoch [31/500], Train Loss: 0.2257\n",
      "Epoch [32/500], Train Loss: 0.2225\n",
      "Epoch [33/500], Train Loss: 0.2202\n",
      "Epoch [34/500], Train Loss: 0.2177\n",
      "Epoch [35/500], Train Loss: 0.2145\n",
      "Epoch [36/500], Train Loss: 0.2112\n",
      "Epoch [37/500], Train Loss: 0.2087\n",
      "Epoch [38/500], Train Loss: 0.2069\n",
      "Epoch [39/500], Train Loss: 0.2049\n",
      "Epoch [40/500], Train Loss: 0.2019\n",
      "Epoch [41/500], Train Loss: 0.1996\n",
      "Epoch [42/500], Train Loss: 0.1977\n",
      "Epoch [43/500], Train Loss: 0.1950\n",
      "Epoch [44/500], Train Loss: 0.1933\n",
      "Epoch [45/500], Train Loss: 0.1916\n",
      "Epoch [46/500], Train Loss: 0.1894\n",
      "Epoch [47/500], Train Loss: 0.1875\n",
      "Epoch [48/500], Train Loss: 0.1860\n",
      "Epoch [49/500], Train Loss: 0.1841\n",
      "Epoch [50/500], Train Loss: 0.1832\n",
      "Epoch [51/500], Train Loss: 0.1809\n",
      "Epoch [52/500], Train Loss: 0.1789\n",
      "Epoch [53/500], Train Loss: 0.1779\n",
      "Epoch [54/500], Train Loss: 0.1762\n",
      "Epoch [55/500], Train Loss: 0.1750\n",
      "Epoch [56/500], Train Loss: 0.1741\n",
      "Epoch [57/500], Train Loss: 0.1725\n",
      "Epoch [58/500], Train Loss: 0.1714\n",
      "Epoch [59/500], Train Loss: 0.1694\n",
      "Epoch [60/500], Train Loss: 0.1681\n",
      "Epoch [61/500], Train Loss: 0.1667\n",
      "Epoch [62/500], Train Loss: 0.1657\n",
      "Epoch [63/500], Train Loss: 0.1643\n",
      "Epoch [64/500], Train Loss: 0.1632\n",
      "Epoch [65/500], Train Loss: 0.1619\n",
      "Epoch [66/500], Train Loss: 0.1607\n",
      "Epoch [67/500], Train Loss: 0.1601\n",
      "Epoch [68/500], Train Loss: 0.1589\n",
      "Epoch [69/500], Train Loss: 0.1577\n",
      "Epoch [70/500], Train Loss: 0.1567\n",
      "Epoch [71/500], Train Loss: 0.1558\n",
      "Epoch [72/500], Train Loss: 0.1547\n",
      "Epoch [73/500], Train Loss: 0.1537\n",
      "Epoch [74/500], Train Loss: 0.1529\n",
      "Epoch [75/500], Train Loss: 0.1517\n",
      "Epoch [76/500], Train Loss: 0.1508\n",
      "Epoch [77/500], Train Loss: 0.1506\n",
      "Epoch [78/500], Train Loss: 0.1496\n",
      "Epoch [79/500], Train Loss: 0.1481\n",
      "Epoch [80/500], Train Loss: 0.1476\n",
      "Epoch [81/500], Train Loss: 0.1467\n",
      "Epoch [82/500], Train Loss: 0.1459\n",
      "Epoch [83/500], Train Loss: 0.1453\n",
      "Epoch [84/500], Train Loss: 0.1443\n",
      "Epoch [85/500], Train Loss: 0.1439\n",
      "Epoch [86/500], Train Loss: 0.1427\n",
      "Epoch [87/500], Train Loss: 0.1422\n",
      "Epoch [88/500], Train Loss: 0.1419\n",
      "Epoch [89/500], Train Loss: 0.1406\n",
      "Epoch [90/500], Train Loss: 0.1400\n",
      "Epoch [91/500], Train Loss: 0.1390\n",
      "Epoch [92/500], Train Loss: 0.1386\n",
      "Epoch [93/500], Train Loss: 0.1379\n",
      "Epoch [94/500], Train Loss: 0.1374\n",
      "Epoch [95/500], Train Loss: 0.1366\n",
      "Epoch [96/500], Train Loss: 0.1356\n",
      "Epoch [97/500], Train Loss: 0.1350\n",
      "Epoch [98/500], Train Loss: 0.1348\n",
      "Epoch [99/500], Train Loss: 0.1339\n",
      "Epoch [100/500], Train Loss: 0.1337\n",
      "Epoch [101/500], Train Loss: 0.1328\n",
      "Epoch [102/500], Train Loss: 0.1322\n",
      "Epoch [103/500], Train Loss: 0.1319\n",
      "Epoch [104/500], Train Loss: 0.1312\n",
      "Epoch [105/500], Train Loss: 0.1304\n",
      "Epoch [106/500], Train Loss: 0.1296\n",
      "Epoch [107/500], Train Loss: 0.1289\n",
      "Epoch [108/500], Train Loss: 0.1285\n",
      "Epoch [109/500], Train Loss: 0.1282\n",
      "Epoch [110/500], Train Loss: 0.1274\n",
      "Epoch [111/500], Train Loss: 0.1271\n",
      "Epoch [112/500], Train Loss: 0.1266\n",
      "Epoch [113/500], Train Loss: 0.1262\n",
      "Epoch [114/500], Train Loss: 0.1258\n",
      "Epoch [115/500], Train Loss: 0.1254\n",
      "Epoch [116/500], Train Loss: 0.1246\n",
      "Epoch [117/500], Train Loss: 0.1245\n",
      "Epoch [118/500], Train Loss: 0.1237\n",
      "Epoch [119/500], Train Loss: 0.1232\n",
      "Epoch [120/500], Train Loss: 0.1226\n",
      "Epoch [121/500], Train Loss: 0.1226\n",
      "Epoch [122/500], Train Loss: 0.1222\n",
      "Epoch [123/500], Train Loss: 0.1215\n",
      "Epoch [124/500], Train Loss: 0.1209\n",
      "Epoch [125/500], Train Loss: 0.1208\n",
      "Epoch [126/500], Train Loss: 0.1200\n",
      "Epoch [127/500], Train Loss: 0.1200\n",
      "Epoch [128/500], Train Loss: 0.1194\n",
      "Epoch [129/500], Train Loss: 0.1191\n",
      "Epoch [130/500], Train Loss: 0.1187\n",
      "Epoch [131/500], Train Loss: 0.1184\n",
      "Epoch [132/500], Train Loss: 0.1180\n",
      "Epoch [133/500], Train Loss: 0.1172\n",
      "Epoch [134/500], Train Loss: 0.1171\n",
      "Epoch [135/500], Train Loss: 0.1166\n",
      "Epoch [136/500], Train Loss: 0.1159\n",
      "Epoch [137/500], Train Loss: 0.1158\n",
      "Epoch [138/500], Train Loss: 0.1153\n",
      "Epoch [139/500], Train Loss: 0.1151\n",
      "Epoch [140/500], Train Loss: 0.1150\n",
      "Epoch [141/500], Train Loss: 0.1144\n",
      "Epoch [142/500], Train Loss: 0.1144\n",
      "Epoch [143/500], Train Loss: 0.1142\n",
      "Epoch [144/500], Train Loss: 0.1135\n",
      "Epoch [145/500], Train Loss: 0.1128\n",
      "Epoch [146/500], Train Loss: 0.1126\n",
      "Epoch [147/500], Train Loss: 0.1123\n",
      "Epoch [148/500], Train Loss: 0.1120\n",
      "Epoch [149/500], Train Loss: 0.1121\n",
      "Epoch [150/500], Train Loss: 0.1116\n",
      "Epoch [151/500], Train Loss: 0.1110\n",
      "Epoch [152/500], Train Loss: 0.1105\n",
      "Epoch [153/500], Train Loss: 0.1102\n",
      "Epoch [154/500], Train Loss: 0.1099\n",
      "Epoch [155/500], Train Loss: 0.1097\n",
      "Epoch [156/500], Train Loss: 0.1092\n",
      "Epoch [157/500], Train Loss: 0.1089\n",
      "Epoch [158/500], Train Loss: 0.1088\n",
      "Epoch [159/500], Train Loss: 0.1086\n",
      "Epoch [160/500], Train Loss: 0.1083\n",
      "Epoch [161/500], Train Loss: 0.1078\n",
      "Epoch [162/500], Train Loss: 0.1075\n",
      "Epoch [163/500], Train Loss: 0.1073\n",
      "Epoch [164/500], Train Loss: 0.1071\n",
      "Epoch [165/500], Train Loss: 0.1072\n",
      "Epoch [166/500], Train Loss: 0.1066\n",
      "Epoch [167/500], Train Loss: 0.1066\n",
      "Epoch [168/500], Train Loss: 0.1058\n",
      "Epoch [169/500], Train Loss: 0.1057\n",
      "Epoch [170/500], Train Loss: 0.1055\n",
      "Epoch [171/500], Train Loss: 0.1051\n",
      "Epoch [172/500], Train Loss: 0.1049\n",
      "Epoch [173/500], Train Loss: 0.1046\n",
      "Epoch [174/500], Train Loss: 0.1043\n",
      "Epoch [175/500], Train Loss: 0.1044\n",
      "Epoch [176/500], Train Loss: 0.1042\n",
      "Epoch [177/500], Train Loss: 0.1037\n",
      "Epoch [178/500], Train Loss: 0.1033\n",
      "Epoch [179/500], Train Loss: 0.1034\n",
      "Epoch [180/500], Train Loss: 0.1031\n",
      "Epoch [181/500], Train Loss: 0.1026\n",
      "Epoch [182/500], Train Loss: 0.1022\n",
      "Epoch [183/500], Train Loss: 0.1022\n",
      "Epoch [184/500], Train Loss: 0.1016\n",
      "Epoch [185/500], Train Loss: 0.1016\n",
      "Epoch [186/500], Train Loss: 0.1011\n",
      "Epoch [187/500], Train Loss: 0.1013\n",
      "Epoch [188/500], Train Loss: 0.1010\n",
      "Epoch [189/500], Train Loss: 0.1007\n",
      "Epoch [190/500], Train Loss: 0.1010\n",
      "Epoch [191/500], Train Loss: 0.1005\n",
      "Epoch [192/500], Train Loss: 0.1001\n",
      "Epoch [193/500], Train Loss: 0.0997\n",
      "Epoch [194/500], Train Loss: 0.0998\n",
      "Epoch [195/500], Train Loss: 0.0994\n",
      "Epoch [196/500], Train Loss: 0.0989\n",
      "Epoch [197/500], Train Loss: 0.0989\n",
      "Epoch [198/500], Train Loss: 0.0991\n",
      "Epoch [199/500], Train Loss: 0.0990\n",
      "Epoch [200/500], Train Loss: 0.0988\n",
      "Epoch [201/500], Train Loss: 0.0982\n",
      "Epoch [202/500], Train Loss: 0.0982\n",
      "Epoch [203/500], Train Loss: 0.0978\n",
      "Epoch [204/500], Train Loss: 0.0976\n",
      "Epoch [205/500], Train Loss: 0.0974\n",
      "Epoch [206/500], Train Loss: 0.0973\n",
      "Epoch [207/500], Train Loss: 0.0967\n",
      "Epoch [208/500], Train Loss: 0.0966\n",
      "Epoch [209/500], Train Loss: 0.0965\n",
      "Epoch [210/500], Train Loss: 0.0963\n",
      "Epoch [211/500], Train Loss: 0.0959\n",
      "Epoch [212/500], Train Loss: 0.0960\n",
      "Epoch [213/500], Train Loss: 0.0957\n",
      "Epoch [214/500], Train Loss: 0.0953\n",
      "Epoch [215/500], Train Loss: 0.0955\n",
      "Epoch [216/500], Train Loss: 0.0953\n",
      "Epoch [217/500], Train Loss: 0.0955\n",
      "Epoch [218/500], Train Loss: 0.0951\n",
      "Epoch [219/500], Train Loss: 0.0951\n",
      "Epoch [220/500], Train Loss: 0.0951\n",
      "Epoch [221/500], Train Loss: 0.0945\n",
      "Epoch [222/500], Train Loss: 0.0945\n",
      "Epoch [223/500], Train Loss: 0.0939\n",
      "Epoch [224/500], Train Loss: 0.0936\n",
      "Epoch [225/500], Train Loss: 0.0936\n",
      "Epoch [226/500], Train Loss: 0.0937\n",
      "Epoch [227/500], Train Loss: 0.0931\n",
      "Epoch [228/500], Train Loss: 0.0931\n",
      "Epoch [229/500], Train Loss: 0.0930\n",
      "Epoch [230/500], Train Loss: 0.0925\n",
      "Epoch [231/500], Train Loss: 0.0928\n",
      "Epoch [232/500], Train Loss: 0.0928\n",
      "Epoch [233/500], Train Loss: 0.0928\n",
      "Epoch [234/500], Train Loss: 0.0923\n",
      "Epoch [235/500], Train Loss: 0.0920\n",
      "Epoch [236/500], Train Loss: 0.0922\n",
      "Epoch [237/500], Train Loss: 0.0917\n",
      "Epoch [238/500], Train Loss: 0.0916\n",
      "Epoch [239/500], Train Loss: 0.0916\n",
      "Epoch [240/500], Train Loss: 0.0915\n",
      "Epoch [241/500], Train Loss: 0.0912\n",
      "Epoch [242/500], Train Loss: 0.0908\n",
      "Epoch [243/500], Train Loss: 0.0905\n",
      "Epoch [244/500], Train Loss: 0.0905\n",
      "Epoch [245/500], Train Loss: 0.0907\n",
      "Epoch [246/500], Train Loss: 0.0903\n",
      "Epoch [247/500], Train Loss: 0.0901\n",
      "Epoch [248/500], Train Loss: 0.0900\n",
      "Epoch [249/500], Train Loss: 0.0897\n",
      "Epoch [250/500], Train Loss: 0.0899\n",
      "Epoch [251/500], Train Loss: 0.0897\n",
      "Epoch [252/500], Train Loss: 0.0896\n",
      "Epoch [253/500], Train Loss: 0.0893\n",
      "Epoch [254/500], Train Loss: 0.0892\n",
      "Epoch [255/500], Train Loss: 0.0890\n",
      "Epoch [256/500], Train Loss: 0.0890\n",
      "Epoch [257/500], Train Loss: 0.0887\n",
      "Epoch [258/500], Train Loss: 0.0885\n",
      "Epoch [259/500], Train Loss: 0.0885\n",
      "Epoch [260/500], Train Loss: 0.0881\n",
      "Epoch [261/500], Train Loss: 0.0881\n",
      "Epoch [262/500], Train Loss: 0.0882\n",
      "Epoch [263/500], Train Loss: 0.0879\n",
      "Epoch [264/500], Train Loss: 0.0877\n",
      "Epoch [265/500], Train Loss: 0.0879\n",
      "Epoch [266/500], Train Loss: 0.0875\n",
      "Epoch [267/500], Train Loss: 0.0873\n",
      "Epoch [268/500], Train Loss: 0.0873\n",
      "Epoch [269/500], Train Loss: 0.0870\n",
      "Epoch [270/500], Train Loss: 0.0866\n",
      "Epoch [271/500], Train Loss: 0.0867\n",
      "Epoch [272/500], Train Loss: 0.0869\n",
      "Epoch [273/500], Train Loss: 0.0867\n",
      "Epoch [274/500], Train Loss: 0.0865\n",
      "Epoch [275/500], Train Loss: 0.0869\n",
      "Epoch [276/500], Train Loss: 0.0865\n",
      "Epoch [277/500], Train Loss: 0.0860\n",
      "Epoch [278/500], Train Loss: 0.0863\n",
      "Epoch [279/500], Train Loss: 0.0860\n",
      "Epoch [280/500], Train Loss: 0.0859\n",
      "Epoch [281/500], Train Loss: 0.0858\n",
      "Epoch [282/500], Train Loss: 0.0858\n",
      "Epoch [283/500], Train Loss: 0.0855\n",
      "Epoch [284/500], Train Loss: 0.0853\n",
      "Epoch [285/500], Train Loss: 0.0854\n",
      "Epoch [286/500], Train Loss: 0.0851\n",
      "Epoch [287/500], Train Loss: 0.0849\n",
      "Epoch [288/500], Train Loss: 0.0851\n",
      "Epoch [289/500], Train Loss: 0.0847\n",
      "Epoch [290/500], Train Loss: 0.0846\n",
      "Epoch [291/500], Train Loss: 0.0846\n",
      "Epoch [292/500], Train Loss: 0.0843\n",
      "Epoch [293/500], Train Loss: 0.0845\n",
      "Epoch [294/500], Train Loss: 0.0842\n",
      "Epoch [295/500], Train Loss: 0.0840\n",
      "Epoch [296/500], Train Loss: 0.0841\n",
      "Epoch [297/500], Train Loss: 0.0842\n",
      "Epoch [298/500], Train Loss: 0.0838\n",
      "Epoch [299/500], Train Loss: 0.0836\n",
      "Epoch [300/500], Train Loss: 0.0836\n",
      "Epoch [301/500], Train Loss: 0.0834\n",
      "Epoch [302/500], Train Loss: 0.0833\n",
      "Epoch [303/500], Train Loss: 0.0833\n",
      "Epoch [304/500], Train Loss: 0.0832\n",
      "Epoch [305/500], Train Loss: 0.0833\n",
      "Epoch [306/500], Train Loss: 0.0829\n",
      "Epoch [307/500], Train Loss: 0.0827\n",
      "Epoch [308/500], Train Loss: 0.0830\n",
      "Epoch [309/500], Train Loss: 0.0830\n",
      "Epoch [310/500], Train Loss: 0.0824\n",
      "Epoch [311/500], Train Loss: 0.0824\n",
      "Epoch [312/500], Train Loss: 0.0823\n",
      "Epoch [313/500], Train Loss: 0.0825\n",
      "Epoch [314/500], Train Loss: 0.0824\n",
      "Epoch [315/500], Train Loss: 0.0819\n",
      "Epoch [316/500], Train Loss: 0.0819\n",
      "Epoch [317/500], Train Loss: 0.0818\n",
      "Epoch [318/500], Train Loss: 0.0818\n",
      "Epoch [319/500], Train Loss: 0.0820\n",
      "Epoch [320/500], Train Loss: 0.0817\n",
      "Epoch [321/500], Train Loss: 0.0814\n",
      "Epoch [322/500], Train Loss: 0.0813\n",
      "Epoch [323/500], Train Loss: 0.0813\n",
      "Epoch [324/500], Train Loss: 0.0810\n",
      "Epoch [325/500], Train Loss: 0.0811\n",
      "Epoch [326/500], Train Loss: 0.0811\n",
      "Epoch [327/500], Train Loss: 0.0813\n",
      "Epoch [328/500], Train Loss: 0.0808\n",
      "Epoch [329/500], Train Loss: 0.0808\n",
      "Epoch [330/500], Train Loss: 0.0808\n",
      "Epoch [331/500], Train Loss: 0.0808\n",
      "Epoch [332/500], Train Loss: 0.0802\n",
      "Epoch [333/500], Train Loss: 0.0805\n",
      "Epoch [334/500], Train Loss: 0.0804\n",
      "Epoch [335/500], Train Loss: 0.0800\n",
      "Epoch [336/500], Train Loss: 0.0802\n",
      "Epoch [337/500], Train Loss: 0.0801\n",
      "Epoch [338/500], Train Loss: 0.0799\n",
      "Epoch [339/500], Train Loss: 0.0798\n",
      "Epoch [340/500], Train Loss: 0.0798\n",
      "Epoch [341/500], Train Loss: 0.0798\n",
      "Epoch [342/500], Train Loss: 0.0796\n",
      "Epoch [343/500], Train Loss: 0.0794\n",
      "Epoch [344/500], Train Loss: 0.0794\n",
      "Epoch [345/500], Train Loss: 0.0794\n",
      "Epoch [346/500], Train Loss: 0.0792\n",
      "Epoch [347/500], Train Loss: 0.0793\n",
      "Epoch [348/500], Train Loss: 0.0791\n",
      "Epoch [349/500], Train Loss: 0.0790\n",
      "Epoch [350/500], Train Loss: 0.0792\n",
      "Epoch [351/500], Train Loss: 0.0791\n",
      "Epoch [352/500], Train Loss: 0.0788\n",
      "Epoch [353/500], Train Loss: 0.0787\n",
      "Epoch [354/500], Train Loss: 0.0787\n",
      "Epoch [355/500], Train Loss: 0.0787\n",
      "Epoch [356/500], Train Loss: 0.0784\n",
      "Epoch [357/500], Train Loss: 0.0785\n",
      "Epoch [358/500], Train Loss: 0.0783\n",
      "Epoch [359/500], Train Loss: 0.0783\n",
      "Epoch [360/500], Train Loss: 0.0782\n",
      "Epoch [361/500], Train Loss: 0.0782\n",
      "Epoch [362/500], Train Loss: 0.0779\n",
      "Epoch [363/500], Train Loss: 0.0780\n",
      "Epoch [364/500], Train Loss: 0.0778\n",
      "Epoch [365/500], Train Loss: 0.0779\n",
      "Epoch [366/500], Train Loss: 0.0775\n",
      "Epoch [367/500], Train Loss: 0.0777\n",
      "Epoch [368/500], Train Loss: 0.0778\n",
      "Epoch [369/500], Train Loss: 0.0773\n",
      "Epoch [370/500], Train Loss: 0.0774\n",
      "Epoch [371/500], Train Loss: 0.0773\n",
      "Epoch [372/500], Train Loss: 0.0772\n",
      "Epoch [373/500], Train Loss: 0.0775\n",
      "Epoch [374/500], Train Loss: 0.0772\n",
      "Epoch [375/500], Train Loss: 0.0768\n",
      "Epoch [376/500], Train Loss: 0.0768\n",
      "Epoch [377/500], Train Loss: 0.0770\n",
      "Epoch [378/500], Train Loss: 0.0769\n",
      "Epoch [379/500], Train Loss: 0.0770\n",
      "Epoch [380/500], Train Loss: 0.0765\n",
      "Epoch [381/500], Train Loss: 0.0767\n",
      "Epoch [382/500], Train Loss: 0.0766\n",
      "Epoch [383/500], Train Loss: 0.0766\n",
      "Epoch [384/500], Train Loss: 0.0766\n",
      "Epoch [385/500], Train Loss: 0.0763\n",
      "Epoch [386/500], Train Loss: 0.0764\n",
      "Epoch [387/500], Train Loss: 0.0766\n",
      "Epoch [388/500], Train Loss: 0.0768\n",
      "Epoch [389/500], Train Loss: 0.0761\n",
      "Epoch [390/500], Train Loss: 0.0760\n",
      "Epoch [391/500], Train Loss: 0.0761\n",
      "Epoch [392/500], Train Loss: 0.0760\n",
      "Epoch [393/500], Train Loss: 0.0759\n",
      "Epoch [394/500], Train Loss: 0.0760\n",
      "Epoch [395/500], Train Loss: 0.0759\n",
      "Epoch [396/500], Train Loss: 0.0758\n",
      "Epoch [397/500], Train Loss: 0.0755\n",
      "Epoch [398/500], Train Loss: 0.0756\n",
      "Epoch [399/500], Train Loss: 0.0757\n",
      "Epoch [400/500], Train Loss: 0.0757\n",
      "Epoch [401/500], Train Loss: 0.0755\n",
      "Epoch [402/500], Train Loss: 0.0754\n",
      "Epoch [403/500], Train Loss: 0.0752\n",
      "Epoch [404/500], Train Loss: 0.0751\n",
      "Epoch [405/500], Train Loss: 0.0752\n",
      "Epoch [406/500], Train Loss: 0.0750\n",
      "Epoch [407/500], Train Loss: 0.0749\n",
      "Epoch [408/500], Train Loss: 0.0750\n",
      "Epoch [409/500], Train Loss: 0.0748\n",
      "Epoch [410/500], Train Loss: 0.0746\n",
      "Epoch [411/500], Train Loss: 0.0746\n",
      "Epoch [412/500], Train Loss: 0.0748\n",
      "Epoch [413/500], Train Loss: 0.0748\n",
      "Epoch [414/500], Train Loss: 0.0749\n",
      "Epoch [415/500], Train Loss: 0.0747\n",
      "Epoch [416/500], Train Loss: 0.0747\n",
      "Epoch [417/500], Train Loss: 0.0745\n",
      "Epoch [418/500], Train Loss: 0.0743\n",
      "Epoch [419/500], Train Loss: 0.0745\n",
      "Epoch [420/500], Train Loss: 0.0744\n",
      "Epoch [421/500], Train Loss: 0.0744\n",
      "Epoch [422/500], Train Loss: 0.0741\n",
      "Epoch [423/500], Train Loss: 0.0745\n",
      "Epoch [424/500], Train Loss: 0.0739\n",
      "Epoch [425/500], Train Loss: 0.0741\n",
      "Epoch [426/500], Train Loss: 0.0739\n",
      "Epoch [427/500], Train Loss: 0.0745\n",
      "Epoch [428/500], Train Loss: 0.0745\n",
      "Epoch [429/500], Train Loss: 0.0741\n",
      "Epoch [430/500], Train Loss: 0.0739\n",
      "Epoch [431/500], Train Loss: 0.0738\n",
      "Epoch [432/500], Train Loss: 0.0739\n",
      "Epoch [433/500], Train Loss: 0.0738\n",
      "Epoch [434/500], Train Loss: 0.0736\n",
      "Epoch [435/500], Train Loss: 0.0735\n",
      "Epoch [436/500], Train Loss: 0.0737\n",
      "Epoch [437/500], Train Loss: 0.0737\n",
      "Epoch [438/500], Train Loss: 0.0735\n",
      "Epoch [439/500], Train Loss: 0.0734\n",
      "Epoch [440/500], Train Loss: 0.0733\n",
      "Epoch [441/500], Train Loss: 0.0732\n",
      "Epoch [442/500], Train Loss: 0.0732\n",
      "Epoch [443/500], Train Loss: 0.0731\n",
      "Epoch [444/500], Train Loss: 0.0731\n",
      "Epoch [445/500], Train Loss: 0.0731\n",
      "Epoch [446/500], Train Loss: 0.0730\n",
      "Epoch [447/500], Train Loss: 0.0731\n",
      "Epoch [448/500], Train Loss: 0.0729\n",
      "Epoch [449/500], Train Loss: 0.0729\n",
      "Epoch [450/500], Train Loss: 0.0728\n",
      "Epoch [451/500], Train Loss: 0.0727\n",
      "Epoch [452/500], Train Loss: 0.0727\n",
      "Epoch [453/500], Train Loss: 0.0724\n",
      "Epoch [454/500], Train Loss: 0.0729\n",
      "Epoch [455/500], Train Loss: 0.0728\n",
      "Epoch [456/500], Train Loss: 0.0727\n",
      "Epoch [457/500], Train Loss: 0.0724\n",
      "Epoch [458/500], Train Loss: 0.0728\n",
      "Epoch [459/500], Train Loss: 0.0728\n",
      "Epoch [460/500], Train Loss: 0.0725\n",
      "Epoch [461/500], Train Loss: 0.0723\n",
      "Epoch [462/500], Train Loss: 0.0724\n",
      "Epoch [463/500], Train Loss: 0.0722\n",
      "Epoch [464/500], Train Loss: 0.0720\n",
      "Epoch [465/500], Train Loss: 0.0723\n",
      "Epoch [466/500], Train Loss: 0.0720\n",
      "Epoch [467/500], Train Loss: 0.0719\n",
      "Epoch [468/500], Train Loss: 0.0720\n",
      "Epoch [469/500], Train Loss: 0.0719\n",
      "Epoch [470/500], Train Loss: 0.0717\n",
      "Epoch [471/500], Train Loss: 0.0720\n",
      "Epoch [472/500], Train Loss: 0.0721\n",
      "Epoch [473/500], Train Loss: 0.0718\n",
      "Epoch [474/500], Train Loss: 0.0718\n",
      "Epoch [475/500], Train Loss: 0.0717\n",
      "Epoch [476/500], Train Loss: 0.0721\n",
      "Epoch [477/500], Train Loss: 0.0715\n",
      "Epoch [478/500], Train Loss: 0.0716\n",
      "Epoch [479/500], Train Loss: 0.0715\n",
      "Epoch [480/500], Train Loss: 0.0716\n",
      "Epoch [481/500], Train Loss: 0.0716\n",
      "Epoch [482/500], Train Loss: 0.0714\n",
      "Epoch [483/500], Train Loss: 0.0713\n",
      "Epoch [484/500], Train Loss: 0.0712\n",
      "Epoch [485/500], Train Loss: 0.0712\n",
      "Epoch [486/500], Train Loss: 0.0710\n",
      "Epoch [487/500], Train Loss: 0.0712\n",
      "Epoch [488/500], Train Loss: 0.0711\n",
      "Epoch [489/500], Train Loss: 0.0711\n",
      "Epoch [490/500], Train Loss: 0.0710\n",
      "Epoch [491/500], Train Loss: 0.0712\n",
      "Epoch [492/500], Train Loss: 0.0713\n",
      "Epoch [493/500], Train Loss: 0.0710\n",
      "Epoch [494/500], Train Loss: 0.0709\n",
      "Epoch [495/500], Train Loss: 0.0708\n",
      "Epoch [496/500], Train Loss: 0.0707\n",
      "Epoch [497/500], Train Loss: 0.0708\n",
      "Epoch [498/500], Train Loss: 0.0709\n",
      "Epoch [499/500], Train Loss: 0.0708\n",
      "Epoch [500/500], Train Loss: 0.0709\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr9/final_model_chr9.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr9/individual_r2_scores_chr9.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:08:27,550] A new study created in memory with name: no-name-95b969be-46d7-4bbd-847b-0d3911eae32e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  28\n",
      "Known PRS313 SNPs:  10\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  1146\n",
      "Early stopping at epoch 78\n",
      "Early stopping at epoch 28\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:08:30,400] Trial 0 finished with value: 1.810671055316925 and parameters: {'learning_rate': 0.009282282734357458, 'lasso_coef': 0.037562216913836946, 'patience': 20}. Best is trial 0 with value: 1.810671055316925.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 390\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:08:37,841] Trial 1 finished with value: 0.5867463409900665 and parameters: {'learning_rate': 0.0008455851362740179, 'lasso_coef': 0.021024560799750385, 'patience': 12}. Best is trial 1 with value: 0.5867463409900665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:09:16,629] Trial 2 finished with value: 0.3287238508462906 and parameters: {'learning_rate': 0.0001360356583542064, 'lasso_coef': 0.0009445967142661605, 'patience': 20}. Best is trial 2 with value: 0.3287238508462906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 36\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:09:18,507] Trial 3 finished with value: 2.1903021797537803 and parameters: {'learning_rate': 0.09818802850456636, 'lasso_coef': 3.632665223610009e-05, 'patience': 8}. Best is trial 2 with value: 0.3287238508462906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 41\n",
      "Early stopping at epoch 170\n",
      "Early stopping at epoch 45\n",
      "Early stopping at epoch 43\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:09:23,449] Trial 4 finished with value: 1.330241358280182 and parameters: {'learning_rate': 0.002383712452075386, 'lasso_coef': 0.09732220648802858, 'patience': 19}. Best is trial 2 with value: 0.3287238508462906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 28\n",
      "Early stopping at epoch 291\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:09:37,346] Trial 5 finished with value: 0.2702466383576393 and parameters: {'learning_rate': 0.0008642883597756537, 'lasso_coef': 0.0007001788081906932, 'patience': 19}. Best is trial 5 with value: 0.2702466383576393.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 64\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:09:39,715] Trial 6 finished with value: 13.314086532592773 and parameters: {'learning_rate': 0.06572505076206642, 'lasso_coef': 0.053822631518930235, 'patience': 14}. Best is trial 5 with value: 0.2702466383576393.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:09:40,691] Trial 7 finished with value: 12.145578193664551 and parameters: {'learning_rate': 0.04712416507265991, 'lasso_coef': 0.06855389060608341, 'patience': 5}. Best is trial 5 with value: 0.2702466383576393.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 294\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:09:46,597] Trial 8 finished with value: 0.511877815425396 and parameters: {'learning_rate': 0.0014667182752833414, 'lasso_coef': 0.004596629518748544, 'patience': 16}. Best is trial 5 with value: 0.2702466383576393.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 409\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:01,999] Trial 9 finished with value: 0.4267410784959793 and parameters: {'learning_rate': 0.0003994833712439693, 'lasso_coef': 0.002621854484152561, 'patience': 16}. Best is trial 5 with value: 0.2702466383576393.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 131\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:04,794] Trial 10 finished with value: 0.19426105841994284 and parameters: {'learning_rate': 0.012375172555826805, 'lasso_coef': 0.00015996578597874222, 'patience': 10}. Best is trial 10 with value: 0.19426105841994284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 132\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:07,629] Trial 11 finished with value: 0.18063506931066514 and parameters: {'learning_rate': 0.009460327281867267, 'lasso_coef': 0.000128325270829546, 'patience': 10}. Best is trial 11 with value: 0.18063506931066514.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 103\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:09,960] Trial 12 finished with value: 0.1313995212316513 and parameters: {'learning_rate': 0.006667349272402868, 'lasso_coef': 4.049132197666559e-05, 'patience': 10}. Best is trial 12 with value: 0.1313995212316513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 78\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:11,770] Trial 13 finished with value: 0.09362113699316979 and parameters: {'learning_rate': 0.008778552977466547, 'lasso_coef': 1.0273084118665915e-05, 'patience': 8}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:12,643] Trial 14 finished with value: 0.10434486754238606 and parameters: {'learning_rate': 0.023687894131478676, 'lasso_coef': 1.2461367388987269e-05, 'patience': 6}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:13,498] Trial 15 finished with value: 0.10040567070245743 and parameters: {'learning_rate': 0.021693602149236872, 'lasso_coef': 1.0630015505861696e-05, 'patience': 6}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 31\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:14,501] Trial 16 finished with value: 0.09986820630729198 and parameters: {'learning_rate': 0.026096680962707113, 'lasso_coef': 1.1226086986206116e-05, 'patience': 7}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 219\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:18,799] Trial 17 finished with value: 0.1918015331029892 and parameters: {'learning_rate': 0.0038608325685057215, 'lasso_coef': 0.00019675118571339884, 'patience': 8}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 36\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:19,953] Trial 18 finished with value: 0.14411656372249126 and parameters: {'learning_rate': 0.028409294821822608, 'lasso_coef': 4.0295804054257094e-05, 'patience': 8}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 204\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:23,955] Trial 19 finished with value: 0.10492206439375877 and parameters: {'learning_rate': 0.004237295902050922, 'lasso_coef': 2.1734734924516228e-05, 'patience': 12}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 43\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:25,148] Trial 20 finished with value: 0.1676483042538166 and parameters: {'learning_rate': 0.016239092249564695, 'lasso_coef': 7.246394643498331e-05, 'patience': 7}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:25,905] Trial 21 finished with value: 0.10272953137755395 and parameters: {'learning_rate': 0.032319439705100234, 'lasso_coef': 1.0546834686955999e-05, 'patience': 5}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 35\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:26,984] Trial 22 finished with value: 0.1014927439391613 and parameters: {'learning_rate': 0.017355801723511418, 'lasso_coef': 1.2274023973157474e-05, 'patience': 7}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 181\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:30,679] Trial 23 finished with value: 0.21994760185480117 and parameters: {'learning_rate': 0.006295761314401806, 'lasso_coef': 0.00030895486928326826, 'patience': 9}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:31,627] Trial 24 finished with value: 0.13006674498319626 and parameters: {'learning_rate': 0.0441368750421549, 'lasso_coef': 2.434514079307969e-05, 'patience': 6}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 39\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:32,783] Trial 25 finished with value: 0.17803612872958183 and parameters: {'learning_rate': 0.021233323281911996, 'lasso_coef': 8.375453430713338e-05, 'patience': 6}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:34,375] Trial 26 finished with value: 0.42187646925449374 and parameters: {'learning_rate': 0.08590235070054848, 'lasso_coef': 0.0004213458807106435, 'patience': 11}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 130\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:36,914] Trial 27 finished with value: 0.11771267801523208 and parameters: {'learning_rate': 0.0025069122445979196, 'lasso_coef': 2.004034164547614e-05, 'patience': 7}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 32\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:38,127] Trial 28 finished with value: 0.18864167407155036 and parameters: {'learning_rate': 0.046519937909228225, 'lasso_coef': 6.915543834300711e-05, 'patience': 9}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 84\n",
      "Early stopping at epoch 31\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:41,418] Trial 29 finished with value: 0.4992852106690407 and parameters: {'learning_rate': 0.007765752143152636, 'lasso_coef': 0.002513153089289769, 'patience': 14}. Best is trial 13 with value: 0.09362113699316979.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 44\n",
      "Best hyperparameters: {'learning_rate': 0.008778552977466547, 'lasso_coef': 1.0273084118665915e-05, 'patience': 8}\n",
      "Best value: 0.09362113699316979\n",
      "Epoch [1/500], Train Loss: 0.5437\n",
      "Epoch [2/500], Train Loss: 0.3663\n",
      "Epoch [3/500], Train Loss: 0.2899\n",
      "Epoch [4/500], Train Loss: 0.2471\n",
      "Epoch [5/500], Train Loss: 0.2188\n",
      "Epoch [6/500], Train Loss: 0.1987\n",
      "Epoch [7/500], Train Loss: 0.1834\n",
      "Epoch [8/500], Train Loss: 0.1706\n",
      "Epoch [9/500], Train Loss: 0.1607\n",
      "Epoch [10/500], Train Loss: 0.1527\n",
      "Epoch [11/500], Train Loss: 0.1456\n",
      "Epoch [12/500], Train Loss: 0.1385\n",
      "Epoch [13/500], Train Loss: 0.1331\n",
      "Epoch [14/500], Train Loss: 0.1282\n",
      "Epoch [15/500], Train Loss: 0.1239\n",
      "Epoch [16/500], Train Loss: 0.1207\n",
      "Epoch [17/500], Train Loss: 0.1162\n",
      "Epoch [18/500], Train Loss: 0.1135\n",
      "Epoch [19/500], Train Loss: 0.1111\n",
      "Epoch [20/500], Train Loss: 0.1085\n",
      "Epoch [21/500], Train Loss: 0.1056\n",
      "Epoch [22/500], Train Loss: 0.1032\n",
      "Epoch [23/500], Train Loss: 0.1018\n",
      "Epoch [24/500], Train Loss: 0.0995\n",
      "Epoch [25/500], Train Loss: 0.0970\n",
      "Epoch [26/500], Train Loss: 0.0969\n",
      "Epoch [27/500], Train Loss: 0.0954\n",
      "Epoch [28/500], Train Loss: 0.0935\n",
      "Epoch [29/500], Train Loss: 0.0925\n",
      "Epoch [30/500], Train Loss: 0.0906\n",
      "Epoch [31/500], Train Loss: 0.0902\n",
      "Epoch [32/500], Train Loss: 0.0889\n",
      "Epoch [33/500], Train Loss: 0.0876\n",
      "Epoch [34/500], Train Loss: 0.0865\n",
      "Epoch [35/500], Train Loss: 0.0854\n",
      "Epoch [36/500], Train Loss: 0.0848\n",
      "Epoch [37/500], Train Loss: 0.0837\n",
      "Epoch [38/500], Train Loss: 0.0829\n",
      "Epoch [39/500], Train Loss: 0.0826\n",
      "Epoch [40/500], Train Loss: 0.0810\n",
      "Epoch [41/500], Train Loss: 0.0803\n",
      "Epoch [42/500], Train Loss: 0.0797\n",
      "Epoch [43/500], Train Loss: 0.0792\n",
      "Epoch [44/500], Train Loss: 0.0787\n",
      "Epoch [45/500], Train Loss: 0.0781\n",
      "Epoch [46/500], Train Loss: 0.0780\n",
      "Epoch [47/500], Train Loss: 0.0769\n",
      "Epoch [48/500], Train Loss: 0.0765\n",
      "Epoch [49/500], Train Loss: 0.0760\n",
      "Epoch [50/500], Train Loss: 0.0759\n",
      "Epoch [51/500], Train Loss: 0.0752\n",
      "Epoch [52/500], Train Loss: 0.0744\n",
      "Epoch [53/500], Train Loss: 0.0739\n",
      "Epoch [54/500], Train Loss: 0.0732\n",
      "Epoch [55/500], Train Loss: 0.0733\n",
      "Epoch [56/500], Train Loss: 0.0738\n",
      "Epoch [57/500], Train Loss: 0.0724\n",
      "Epoch [58/500], Train Loss: 0.0722\n",
      "Epoch [59/500], Train Loss: 0.0723\n",
      "Epoch [60/500], Train Loss: 0.0715\n",
      "Epoch [61/500], Train Loss: 0.0714\n",
      "Epoch [62/500], Train Loss: 0.0710\n",
      "Epoch [63/500], Train Loss: 0.0708\n",
      "Epoch [64/500], Train Loss: 0.0705\n",
      "Epoch [65/500], Train Loss: 0.0698\n",
      "Epoch [66/500], Train Loss: 0.0692\n",
      "Epoch [67/500], Train Loss: 0.0693\n",
      "Epoch [68/500], Train Loss: 0.0688\n",
      "Epoch [69/500], Train Loss: 0.0689\n",
      "Epoch [70/500], Train Loss: 0.0678\n",
      "Epoch [71/500], Train Loss: 0.0680\n",
      "Epoch [72/500], Train Loss: 0.0679\n",
      "Epoch [73/500], Train Loss: 0.0673\n",
      "Epoch [74/500], Train Loss: 0.0678\n",
      "Epoch [75/500], Train Loss: 0.0675\n",
      "Epoch [76/500], Train Loss: 0.0672\n",
      "Epoch [77/500], Train Loss: 0.0665\n",
      "Epoch [78/500], Train Loss: 0.0668\n",
      "Epoch [79/500], Train Loss: 0.0664\n",
      "Epoch [80/500], Train Loss: 0.0663\n",
      "Epoch [81/500], Train Loss: 0.0656\n",
      "Epoch [82/500], Train Loss: 0.0659\n",
      "Epoch [83/500], Train Loss: 0.0657\n",
      "Epoch [84/500], Train Loss: 0.0652\n",
      "Epoch [85/500], Train Loss: 0.0657\n",
      "Epoch [86/500], Train Loss: 0.0646\n",
      "Epoch [87/500], Train Loss: 0.0645\n",
      "Epoch [88/500], Train Loss: 0.0643\n",
      "Epoch [89/500], Train Loss: 0.0645\n",
      "Epoch [90/500], Train Loss: 0.0644\n",
      "Epoch [91/500], Train Loss: 0.0639\n",
      "Epoch [92/500], Train Loss: 0.0638\n",
      "Epoch [93/500], Train Loss: 0.0643\n",
      "Epoch [94/500], Train Loss: 0.0639\n",
      "Epoch [95/500], Train Loss: 0.0639\n",
      "Epoch [96/500], Train Loss: 0.0636\n",
      "Epoch [97/500], Train Loss: 0.0635\n",
      "Epoch [98/500], Train Loss: 0.0631\n",
      "Epoch [99/500], Train Loss: 0.0627\n",
      "Epoch [100/500], Train Loss: 0.0626\n",
      "Epoch [101/500], Train Loss: 0.0624\n",
      "Epoch [102/500], Train Loss: 0.0629\n",
      "Epoch [103/500], Train Loss: 0.0629\n",
      "Epoch [104/500], Train Loss: 0.0622\n",
      "Epoch [105/500], Train Loss: 0.0620\n",
      "Epoch [106/500], Train Loss: 0.0620\n",
      "Epoch [107/500], Train Loss: 0.0614\n",
      "Epoch [108/500], Train Loss: 0.0617\n",
      "Epoch [109/500], Train Loss: 0.0624\n",
      "Epoch [110/500], Train Loss: 0.0612\n",
      "Epoch [111/500], Train Loss: 0.0618\n",
      "Epoch [112/500], Train Loss: 0.0616\n",
      "Epoch [113/500], Train Loss: 0.0616\n",
      "Epoch [114/500], Train Loss: 0.0610\n",
      "Epoch [115/500], Train Loss: 0.0612\n",
      "Epoch [116/500], Train Loss: 0.0609\n",
      "Epoch [117/500], Train Loss: 0.0609\n",
      "Epoch [118/500], Train Loss: 0.0603\n",
      "Epoch [119/500], Train Loss: 0.0604\n",
      "Epoch [120/500], Train Loss: 0.0598\n",
      "Epoch [121/500], Train Loss: 0.0600\n",
      "Epoch [122/500], Train Loss: 0.0600\n",
      "Epoch [123/500], Train Loss: 0.0603\n",
      "Epoch [124/500], Train Loss: 0.0594\n",
      "Epoch [125/500], Train Loss: 0.0597\n",
      "Epoch [126/500], Train Loss: 0.0605\n",
      "Epoch [127/500], Train Loss: 0.0598\n",
      "Epoch [128/500], Train Loss: 0.0592\n",
      "Epoch [129/500], Train Loss: 0.0594\n",
      "Epoch [130/500], Train Loss: 0.0591\n",
      "Epoch [131/500], Train Loss: 0.0597\n",
      "Epoch [132/500], Train Loss: 0.0594\n",
      "Epoch [133/500], Train Loss: 0.0591\n",
      "Epoch [134/500], Train Loss: 0.0588\n",
      "Epoch [135/500], Train Loss: 0.0587\n",
      "Epoch [136/500], Train Loss: 0.0589\n",
      "Epoch [137/500], Train Loss: 0.0595\n",
      "Epoch [138/500], Train Loss: 0.0587\n",
      "Epoch [139/500], Train Loss: 0.0584\n",
      "Epoch [140/500], Train Loss: 0.0587\n",
      "Epoch [141/500], Train Loss: 0.0589\n",
      "Epoch [142/500], Train Loss: 0.0581\n",
      "Epoch [143/500], Train Loss: 0.0586\n",
      "Epoch [144/500], Train Loss: 0.0584\n",
      "Epoch [145/500], Train Loss: 0.0587\n",
      "Epoch [146/500], Train Loss: 0.0592\n",
      "Epoch [147/500], Train Loss: 0.0583\n",
      "Epoch [148/500], Train Loss: 0.0584\n",
      "Epoch [149/500], Train Loss: 0.0586\n",
      "Epoch [150/500], Train Loss: 0.0586\n",
      "Early stopping at epoch 150\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr10/final_model_chr10.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr10/individual_r2_scores_chr10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:45,900] A new study created in memory with name: no-name-5323c016-4e14-48f5-892b-84dfec746930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  34\n",
      "Known PRS313 SNPs:  4\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  1774\n",
      "Early stopping at epoch 86\n",
      "Early stopping at epoch 46\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:10:50,313] Trial 0 finished with value: 0.3024117648601532 and parameters: {'learning_rate': 0.009817337696485998, 'lasso_coef': 0.0005668997456142535, 'patience': 14}. Best is trial 0 with value: 0.3024117648601532.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:11:00,801] Trial 1 finished with value: 0.14129293113946914 and parameters: {'learning_rate': 0.00017431719710156774, 'lasso_coef': 2.176795795749788e-05, 'patience': 5}. Best is trial 1 with value: 0.14129293113946914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:11:01,975] Trial 2 finished with value: 0.3382491201162338 and parameters: {'learning_rate': 0.06009552755989671, 'lasso_coef': 0.00022143828181807863, 'patience': 5}. Best is trial 1 with value: 0.14129293113946914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:11:03,426] Trial 3 finished with value: 1.0756632521748544 and parameters: {'learning_rate': 0.03065851014799242, 'lasso_coef': 1.4085885877087146e-05, 'patience': 7}. Best is trial 1 with value: 0.14129293113946914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 214\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:11:09,886] Trial 4 finished with value: 0.6214485079050064 and parameters: {'learning_rate': 0.001882004723406475, 'lasso_coef': 0.0063572605281788045, 'patience': 18}. Best is trial 1 with value: 0.14129293113946914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 43\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:11:22,459] Trial 5 finished with value: 0.3696248695254326 and parameters: {'learning_rate': 0.0010912552419962214, 'lasso_coef': 0.0013024642647836123, 'patience': 18}. Best is trial 1 with value: 0.14129293113946914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 375\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 35\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:11:31,852] Trial 6 finished with value: 0.4864218905568123 and parameters: {'learning_rate': 0.0011166749804758054, 'lasso_coef': 0.0028497224094941936, 'patience': 15}. Best is trial 1 with value: 0.14129293113946914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:11:52,816] Trial 7 finished with value: 0.18808491453528403 and parameters: {'learning_rate': 0.00023019484071862482, 'lasso_coef': 0.00018651000281288456, 'patience': 5}. Best is trial 1 with value: 0.14129293113946914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:12:04,157] Trial 8 finished with value: 0.11200979612767696 and parameters: {'learning_rate': 0.001043688944733956, 'lasso_coef': 7.379707880552024e-05, 'patience': 9}. Best is trial 8 with value: 0.11200979612767696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:12:06,510] Trial 9 finished with value: 6.694907832145691 and parameters: {'learning_rate': 0.04956826041480116, 'lasso_coef': 0.017234951388027293, 'patience': 10}. Best is trial 8 with value: 0.11200979612767696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 86\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:12:10,192] Trial 10 finished with value: 3.5506439208984375 and parameters: {'learning_rate': 0.005953933565091187, 'lasso_coef': 0.07642116806000815, 'patience': 11}. Best is trial 8 with value: 0.11200979612767696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:12:21,471] Trial 11 finished with value: 0.16132140830159186 and parameters: {'learning_rate': 0.0001152353872590081, 'lasso_coef': 1.7414672092984683e-05, 'patience': 8}. Best is trial 8 with value: 0.11200979612767696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:12:32,650] Trial 12 finished with value: 0.14082049056887627 and parameters: {'learning_rate': 0.0004310951416533209, 'lasso_coef': 8.504723095505115e-05, 'patience': 8}. Best is trial 8 with value: 0.11200979612767696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:12:44,113] Trial 13 finished with value: 0.12951835244894028 and parameters: {'learning_rate': 0.0005018935285031992, 'lasso_coef': 7.496874122053995e-05, 'patience': 9}. Best is trial 8 with value: 0.11200979612767696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:12:55,984] Trial 14 finished with value: 0.12074476107954979 and parameters: {'learning_rate': 0.0005464699925044137, 'lasso_coef': 6.54364226062711e-05, 'patience': 11}. Best is trial 8 with value: 0.11200979612767696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 313\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:13:03,541] Trial 15 finished with value: 0.09972908087074757 and parameters: {'learning_rate': 0.0032060905665995303, 'lasso_coef': 5.7611754827161104e-05, 'patience': 12}. Best is trial 15 with value: 0.09972908087074757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 248\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:13:10,612] Trial 16 finished with value: 0.2508264988660812 and parameters: {'learning_rate': 0.00458317393871047, 'lasso_coef': 0.0004660951096746136, 'patience': 14}. Best is trial 15 with value: 0.09972908087074757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 28\n",
      "Early stopping at epoch 104\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:13:13,857] Trial 17 finished with value: 0.09797104820609093 and parameters: {'learning_rate': 0.011355557208552722, 'lasso_coef': 4.2376403853254666e-05, 'patience': 12}. Best is trial 17 with value: 0.09797104820609093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 92\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:13:17,507] Trial 18 finished with value: 0.09291653335094452 and parameters: {'learning_rate': 0.017160814711798214, 'lasso_coef': 3.3997062018712784e-05, 'patience': 16}. Best is trial 18 with value: 0.09291653335094452.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 167\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:13:22,810] Trial 19 finished with value: 0.08397202678024769 and parameters: {'learning_rate': 0.015285650511759211, 'lasso_coef': 2.572615124269807e-05, 'patience': 20}. Best is trial 19 with value: 0.08397202678024769.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 90\n",
      "Early stopping at epoch 43\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:13:27,920] Trial 20 finished with value: 0.21044480428099632 and parameters: {'learning_rate': 0.02093737897425198, 'lasso_coef': 0.00021096034750382785, 'patience': 20}. Best is trial 19 with value: 0.08397202678024769.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 31\n",
      "Early stopping at epoch 186\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:13:33,176] Trial 21 finished with value: 0.053608763962984085 and parameters: {'learning_rate': 0.013768959485176216, 'lasso_coef': 1.0022644521250132e-05, 'patience': 17}. Best is trial 21 with value: 0.053608763962984085.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 130\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:13:37,406] Trial 22 finished with value: 0.07977812439203262 and parameters: {'learning_rate': 0.018485900318982073, 'lasso_coef': 2.365407840893968e-05, 'patience': 17}. Best is trial 21 with value: 0.053608763962984085.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 66\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:13:41,580] Trial 23 finished with value: 15.757860851287841 and parameters: {'learning_rate': 0.09457754959407359, 'lasso_coef': 1.015607120236267e-05, 'patience': 20}. Best is trial 21 with value: 0.053608763962984085.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:13:44,269] Trial 24 finished with value: 0.5231581494212151 and parameters: {'learning_rate': 0.031223740496304046, 'lasso_coef': 2.584505191454739e-05, 'patience': 18}. Best is trial 21 with value: 0.053608763962984085.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 288\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:13:52,177] Trial 25 finished with value: 0.05178741198033095 and parameters: {'learning_rate': 0.008800051211263588, 'lasso_coef': 1.0603479506064519e-05, 'patience': 17}. Best is trial 25 with value: 0.05178741198033095.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 247\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:13:59,081] Trial 26 finished with value: 0.051062466204166414 and parameters: {'learning_rate': 0.00834008700883836, 'lasso_coef': 1.0869386762325727e-05, 'patience': 16}. Best is trial 26 with value: 0.051062466204166414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 230\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:14:05,508] Trial 27 finished with value: 0.052869345061481 and parameters: {'learning_rate': 0.008938348924359683, 'lasso_coef': 1.1164291715192768e-05, 'patience': 15}. Best is trial 26 with value: 0.051062466204166414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 199\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:14:11,687] Trial 28 finished with value: 0.17069526836276055 and parameters: {'learning_rate': 0.0074317550855863045, 'lasso_coef': 0.00018697099046130063, 'patience': 14}. Best is trial 26 with value: 0.051062466204166414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 305\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:14:20,357] Trial 29 finished with value: 0.2231620356440544 and parameters: {'learning_rate': 0.002990078035316699, 'lasso_coef': 0.0003859972354106677, 'patience': 15}. Best is trial 26 with value: 0.051062466204166414.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 22\n",
      "Best hyperparameters: {'learning_rate': 0.00834008700883836, 'lasso_coef': 1.0869386762325727e-05, 'patience': 16}\n",
      "Best value: 0.051062466204166414\n",
      "Epoch [1/500], Train Loss: 0.6531\n",
      "Epoch [2/500], Train Loss: 0.3857\n",
      "Epoch [3/500], Train Loss: 0.2890\n",
      "Epoch [4/500], Train Loss: 0.2394\n",
      "Epoch [5/500], Train Loss: 0.2097\n",
      "Epoch [6/500], Train Loss: 0.1860\n",
      "Epoch [7/500], Train Loss: 0.1695\n",
      "Epoch [8/500], Train Loss: 0.1569\n",
      "Epoch [9/500], Train Loss: 0.1447\n",
      "Epoch [10/500], Train Loss: 0.1353\n",
      "Epoch [11/500], Train Loss: 0.1284\n",
      "Epoch [12/500], Train Loss: 0.1211\n",
      "Epoch [13/500], Train Loss: 0.1153\n",
      "Epoch [14/500], Train Loss: 0.1106\n",
      "Epoch [15/500], Train Loss: 0.1055\n",
      "Epoch [16/500], Train Loss: 0.1018\n",
      "Epoch [17/500], Train Loss: 0.0980\n",
      "Epoch [18/500], Train Loss: 0.0945\n",
      "Epoch [19/500], Train Loss: 0.0918\n",
      "Epoch [20/500], Train Loss: 0.0894\n",
      "Epoch [21/500], Train Loss: 0.0868\n",
      "Epoch [22/500], Train Loss: 0.0848\n",
      "Epoch [23/500], Train Loss: 0.0829\n",
      "Epoch [24/500], Train Loss: 0.0811\n",
      "Epoch [25/500], Train Loss: 0.0788\n",
      "Epoch [26/500], Train Loss: 0.0775\n",
      "Epoch [27/500], Train Loss: 0.0764\n",
      "Epoch [28/500], Train Loss: 0.0745\n",
      "Epoch [29/500], Train Loss: 0.0735\n",
      "Epoch [30/500], Train Loss: 0.0720\n",
      "Epoch [31/500], Train Loss: 0.0709\n",
      "Epoch [32/500], Train Loss: 0.0697\n",
      "Epoch [33/500], Train Loss: 0.0689\n",
      "Epoch [34/500], Train Loss: 0.0676\n",
      "Epoch [35/500], Train Loss: 0.0667\n",
      "Epoch [36/500], Train Loss: 0.0661\n",
      "Epoch [37/500], Train Loss: 0.0652\n",
      "Epoch [38/500], Train Loss: 0.0638\n",
      "Epoch [39/500], Train Loss: 0.0633\n",
      "Epoch [40/500], Train Loss: 0.0626\n",
      "Epoch [41/500], Train Loss: 0.0622\n",
      "Epoch [42/500], Train Loss: 0.0614\n",
      "Epoch [43/500], Train Loss: 0.0603\n",
      "Epoch [44/500], Train Loss: 0.0598\n",
      "Epoch [45/500], Train Loss: 0.0592\n",
      "Epoch [46/500], Train Loss: 0.0589\n",
      "Epoch [47/500], Train Loss: 0.0581\n",
      "Epoch [48/500], Train Loss: 0.0577\n",
      "Epoch [49/500], Train Loss: 0.0570\n",
      "Epoch [50/500], Train Loss: 0.0569\n",
      "Epoch [51/500], Train Loss: 0.0558\n",
      "Epoch [52/500], Train Loss: 0.0556\n",
      "Epoch [53/500], Train Loss: 0.0552\n",
      "Epoch [54/500], Train Loss: 0.0548\n",
      "Epoch [55/500], Train Loss: 0.0541\n",
      "Epoch [56/500], Train Loss: 0.0538\n",
      "Epoch [57/500], Train Loss: 0.0536\n",
      "Epoch [58/500], Train Loss: 0.0528\n",
      "Epoch [59/500], Train Loss: 0.0525\n",
      "Epoch [60/500], Train Loss: 0.0526\n",
      "Epoch [61/500], Train Loss: 0.0519\n",
      "Epoch [62/500], Train Loss: 0.0516\n",
      "Epoch [63/500], Train Loss: 0.0514\n",
      "Epoch [64/500], Train Loss: 0.0513\n",
      "Epoch [65/500], Train Loss: 0.0508\n",
      "Epoch [66/500], Train Loss: 0.0504\n",
      "Epoch [67/500], Train Loss: 0.0501\n",
      "Epoch [68/500], Train Loss: 0.0496\n",
      "Epoch [69/500], Train Loss: 0.0494\n",
      "Epoch [70/500], Train Loss: 0.0491\n",
      "Epoch [71/500], Train Loss: 0.0489\n",
      "Epoch [72/500], Train Loss: 0.0491\n",
      "Epoch [73/500], Train Loss: 0.0490\n",
      "Epoch [74/500], Train Loss: 0.0484\n",
      "Epoch [75/500], Train Loss: 0.0479\n",
      "Epoch [76/500], Train Loss: 0.0476\n",
      "Epoch [77/500], Train Loss: 0.0475\n",
      "Epoch [78/500], Train Loss: 0.0470\n",
      "Epoch [79/500], Train Loss: 0.0471\n",
      "Epoch [80/500], Train Loss: 0.0468\n",
      "Epoch [81/500], Train Loss: 0.0463\n",
      "Epoch [82/500], Train Loss: 0.0463\n",
      "Epoch [83/500], Train Loss: 0.0464\n",
      "Epoch [84/500], Train Loss: 0.0462\n",
      "Epoch [85/500], Train Loss: 0.0459\n",
      "Epoch [86/500], Train Loss: 0.0458\n",
      "Epoch [87/500], Train Loss: 0.0454\n",
      "Epoch [88/500], Train Loss: 0.0455\n",
      "Epoch [89/500], Train Loss: 0.0451\n",
      "Epoch [90/500], Train Loss: 0.0451\n",
      "Epoch [91/500], Train Loss: 0.0447\n",
      "Epoch [92/500], Train Loss: 0.0446\n",
      "Epoch [93/500], Train Loss: 0.0446\n",
      "Epoch [94/500], Train Loss: 0.0443\n",
      "Epoch [95/500], Train Loss: 0.0439\n",
      "Epoch [96/500], Train Loss: 0.0441\n",
      "Epoch [97/500], Train Loss: 0.0441\n",
      "Epoch [98/500], Train Loss: 0.0436\n",
      "Epoch [99/500], Train Loss: 0.0436\n",
      "Epoch [100/500], Train Loss: 0.0433\n",
      "Epoch [101/500], Train Loss: 0.0433\n",
      "Epoch [102/500], Train Loss: 0.0433\n",
      "Epoch [103/500], Train Loss: 0.0430\n",
      "Epoch [104/500], Train Loss: 0.0427\n",
      "Epoch [105/500], Train Loss: 0.0427\n",
      "Epoch [106/500], Train Loss: 0.0428\n",
      "Epoch [107/500], Train Loss: 0.0426\n",
      "Epoch [108/500], Train Loss: 0.0422\n",
      "Epoch [109/500], Train Loss: 0.0419\n",
      "Epoch [110/500], Train Loss: 0.0419\n",
      "Epoch [111/500], Train Loss: 0.0419\n",
      "Epoch [112/500], Train Loss: 0.0421\n",
      "Epoch [113/500], Train Loss: 0.0418\n",
      "Epoch [114/500], Train Loss: 0.0414\n",
      "Epoch [115/500], Train Loss: 0.0413\n",
      "Epoch [116/500], Train Loss: 0.0413\n",
      "Epoch [117/500], Train Loss: 0.0412\n",
      "Epoch [118/500], Train Loss: 0.0410\n",
      "Epoch [119/500], Train Loss: 0.0409\n",
      "Epoch [120/500], Train Loss: 0.0412\n",
      "Epoch [121/500], Train Loss: 0.0412\n",
      "Epoch [122/500], Train Loss: 0.0412\n",
      "Epoch [123/500], Train Loss: 0.0410\n",
      "Epoch [124/500], Train Loss: 0.0409\n",
      "Epoch [125/500], Train Loss: 0.0412\n",
      "Epoch [126/500], Train Loss: 0.0408\n",
      "Epoch [127/500], Train Loss: 0.0404\n",
      "Epoch [128/500], Train Loss: 0.0405\n",
      "Epoch [129/500], Train Loss: 0.0402\n",
      "Epoch [130/500], Train Loss: 0.0400\n",
      "Epoch [131/500], Train Loss: 0.0398\n",
      "Epoch [132/500], Train Loss: 0.0402\n",
      "Epoch [133/500], Train Loss: 0.0396\n",
      "Epoch [134/500], Train Loss: 0.0397\n",
      "Epoch [135/500], Train Loss: 0.0395\n",
      "Epoch [136/500], Train Loss: 0.0395\n",
      "Epoch [137/500], Train Loss: 0.0398\n",
      "Epoch [138/500], Train Loss: 0.0395\n",
      "Epoch [139/500], Train Loss: 0.0391\n",
      "Epoch [140/500], Train Loss: 0.0394\n",
      "Epoch [141/500], Train Loss: 0.0392\n",
      "Epoch [142/500], Train Loss: 0.0390\n",
      "Epoch [143/500], Train Loss: 0.0389\n",
      "Epoch [144/500], Train Loss: 0.0386\n",
      "Epoch [145/500], Train Loss: 0.0386\n",
      "Epoch [146/500], Train Loss: 0.0386\n",
      "Epoch [147/500], Train Loss: 0.0388\n",
      "Epoch [148/500], Train Loss: 0.0385\n",
      "Epoch [149/500], Train Loss: 0.0384\n",
      "Epoch [150/500], Train Loss: 0.0384\n",
      "Epoch [151/500], Train Loss: 0.0387\n",
      "Epoch [152/500], Train Loss: 0.0388\n",
      "Epoch [153/500], Train Loss: 0.0385\n",
      "Epoch [154/500], Train Loss: 0.0381\n",
      "Epoch [155/500], Train Loss: 0.0381\n",
      "Epoch [156/500], Train Loss: 0.0382\n",
      "Epoch [157/500], Train Loss: 0.0381\n",
      "Epoch [158/500], Train Loss: 0.0379\n",
      "Epoch [159/500], Train Loss: 0.0379\n",
      "Epoch [160/500], Train Loss: 0.0382\n",
      "Epoch [161/500], Train Loss: 0.0382\n",
      "Epoch [162/500], Train Loss: 0.0380\n",
      "Epoch [163/500], Train Loss: 0.0381\n",
      "Epoch [164/500], Train Loss: 0.0379\n",
      "Epoch [165/500], Train Loss: 0.0377\n",
      "Epoch [166/500], Train Loss: 0.0376\n",
      "Epoch [167/500], Train Loss: 0.0377\n",
      "Epoch [168/500], Train Loss: 0.0379\n",
      "Epoch [169/500], Train Loss: 0.0377\n",
      "Epoch [170/500], Train Loss: 0.0375\n",
      "Epoch [171/500], Train Loss: 0.0374\n",
      "Epoch [172/500], Train Loss: 0.0375\n",
      "Epoch [173/500], Train Loss: 0.0376\n",
      "Epoch [174/500], Train Loss: 0.0373\n",
      "Epoch [175/500], Train Loss: 0.0375\n",
      "Epoch [176/500], Train Loss: 0.0375\n",
      "Epoch [177/500], Train Loss: 0.0371\n",
      "Epoch [178/500], Train Loss: 0.0370\n",
      "Epoch [179/500], Train Loss: 0.0371\n",
      "Epoch [180/500], Train Loss: 0.0377\n",
      "Epoch [181/500], Train Loss: 0.0373\n",
      "Epoch [182/500], Train Loss: 0.0370\n",
      "Epoch [183/500], Train Loss: 0.0370\n",
      "Epoch [184/500], Train Loss: 0.0369\n",
      "Epoch [185/500], Train Loss: 0.0372\n",
      "Epoch [186/500], Train Loss: 0.0371\n",
      "Epoch [187/500], Train Loss: 0.0375\n",
      "Epoch [188/500], Train Loss: 0.0374\n",
      "Epoch [189/500], Train Loss: 0.0373\n",
      "Epoch [190/500], Train Loss: 0.0370\n",
      "Epoch [191/500], Train Loss: 0.0370\n",
      "Epoch [192/500], Train Loss: 0.0366\n",
      "Epoch [193/500], Train Loss: 0.0366\n",
      "Epoch [194/500], Train Loss: 0.0368\n",
      "Epoch [195/500], Train Loss: 0.0368\n",
      "Epoch [196/500], Train Loss: 0.0367\n",
      "Epoch [197/500], Train Loss: 0.0366\n",
      "Epoch [198/500], Train Loss: 0.0368\n",
      "Epoch [199/500], Train Loss: 0.0370\n",
      "Epoch [200/500], Train Loss: 0.0369\n",
      "Epoch [201/500], Train Loss: 0.0370\n",
      "Epoch [202/500], Train Loss: 0.0368\n",
      "Epoch [203/500], Train Loss: 0.0364\n",
      "Epoch [204/500], Train Loss: 0.0365\n",
      "Epoch [205/500], Train Loss: 0.0366\n",
      "Epoch [206/500], Train Loss: 0.0363\n",
      "Epoch [207/500], Train Loss: 0.0360\n",
      "Epoch [208/500], Train Loss: 0.0362\n",
      "Epoch [209/500], Train Loss: 0.0362\n",
      "Epoch [210/500], Train Loss: 0.0360\n",
      "Epoch [211/500], Train Loss: 0.0364\n",
      "Epoch [212/500], Train Loss: 0.0365\n",
      "Epoch [213/500], Train Loss: 0.0365\n",
      "Epoch [214/500], Train Loss: 0.0360\n",
      "Epoch [215/500], Train Loss: 0.0363\n",
      "Epoch [216/500], Train Loss: 0.0365\n",
      "Epoch [217/500], Train Loss: 0.0365\n",
      "Epoch [218/500], Train Loss: 0.0360\n",
      "Epoch [219/500], Train Loss: 0.0361\n",
      "Epoch [220/500], Train Loss: 0.0362\n",
      "Epoch [221/500], Train Loss: 0.0363\n",
      "Epoch [222/500], Train Loss: 0.0364\n",
      "Epoch [223/500], Train Loss: 0.0361\n",
      "Epoch [224/500], Train Loss: 0.0358\n",
      "Epoch [225/500], Train Loss: 0.0359\n",
      "Epoch [226/500], Train Loss: 0.0361\n",
      "Epoch [227/500], Train Loss: 0.0362\n",
      "Epoch [228/500], Train Loss: 0.0360\n",
      "Epoch [229/500], Train Loss: 0.0356\n",
      "Epoch [230/500], Train Loss: 0.0358\n",
      "Epoch [231/500], Train Loss: 0.0355\n",
      "Epoch [232/500], Train Loss: 0.0354\n",
      "Epoch [233/500], Train Loss: 0.0353\n",
      "Epoch [234/500], Train Loss: 0.0355\n",
      "Epoch [235/500], Train Loss: 0.0358\n",
      "Epoch [236/500], Train Loss: 0.0361\n",
      "Epoch [237/500], Train Loss: 0.0363\n",
      "Epoch [238/500], Train Loss: 0.0359\n",
      "Epoch [239/500], Train Loss: 0.0356\n",
      "Epoch [240/500], Train Loss: 0.0358\n",
      "Epoch [241/500], Train Loss: 0.0358\n",
      "Epoch [242/500], Train Loss: 0.0354\n",
      "Epoch [243/500], Train Loss: 0.0352\n",
      "Epoch [244/500], Train Loss: 0.0353\n",
      "Epoch [245/500], Train Loss: 0.0358\n",
      "Epoch [246/500], Train Loss: 0.0360\n",
      "Epoch [247/500], Train Loss: 0.0356\n",
      "Epoch [248/500], Train Loss: 0.0357\n",
      "Epoch [249/500], Train Loss: 0.0360\n",
      "Epoch [250/500], Train Loss: 0.0360\n",
      "Epoch [251/500], Train Loss: 0.0359\n",
      "Epoch [252/500], Train Loss: 0.0358\n",
      "Epoch [253/500], Train Loss: 0.0356\n",
      "Epoch [254/500], Train Loss: 0.0356\n",
      "Epoch [255/500], Train Loss: 0.0355\n",
      "Epoch [256/500], Train Loss: 0.0360\n",
      "Epoch [257/500], Train Loss: 0.0362\n",
      "Epoch [258/500], Train Loss: 0.0352\n",
      "Epoch [259/500], Train Loss: 0.0354\n",
      "Epoch [260/500], Train Loss: 0.0357\n",
      "Epoch [261/500], Train Loss: 0.0357\n",
      "Epoch [262/500], Train Loss: 0.0363\n",
      "Epoch [263/500], Train Loss: 0.0365\n",
      "Epoch [264/500], Train Loss: 0.0360\n",
      "Epoch [265/500], Train Loss: 0.0357\n",
      "Epoch [266/500], Train Loss: 0.0355\n",
      "Epoch [267/500], Train Loss: 0.0354\n",
      "Epoch [268/500], Train Loss: 0.0361\n",
      "Epoch [269/500], Train Loss: 0.0360\n",
      "Epoch [270/500], Train Loss: 0.0361\n",
      "Epoch [271/500], Train Loss: 0.0359\n",
      "Epoch [272/500], Train Loss: 0.0358\n",
      "Epoch [273/500], Train Loss: 0.0354\n",
      "Epoch [274/500], Train Loss: 0.0350\n",
      "Epoch [275/500], Train Loss: 0.0348\n",
      "Epoch [276/500], Train Loss: 0.0349\n",
      "Epoch [277/500], Train Loss: 0.0350\n",
      "Epoch [278/500], Train Loss: 0.0352\n",
      "Epoch [279/500], Train Loss: 0.0352\n",
      "Epoch [280/500], Train Loss: 0.0356\n",
      "Epoch [281/500], Train Loss: 0.0356\n",
      "Epoch [282/500], Train Loss: 0.0357\n",
      "Epoch [283/500], Train Loss: 0.0352\n",
      "Epoch [284/500], Train Loss: 0.0349\n",
      "Epoch [285/500], Train Loss: 0.0351\n",
      "Epoch [286/500], Train Loss: 0.0354\n",
      "Epoch [287/500], Train Loss: 0.0354\n",
      "Epoch [288/500], Train Loss: 0.0351\n",
      "Epoch [289/500], Train Loss: 0.0358\n",
      "Epoch [290/500], Train Loss: 0.0355\n",
      "Epoch [291/500], Train Loss: 0.0356\n",
      "Early stopping at epoch 291\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr11/final_model_chr11.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr11/individual_r2_scores_chr11.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:14:29,501] A new study created in memory with name: no-name-6b179489-1449-4cbd-987a-9395c4b018f5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  22\n",
      "Known PRS313 SNPs:  12\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  986\n",
      "Early stopping at epoch 127\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:14:32,147] Trial 0 finished with value: 0.14915564619004726 and parameters: {'learning_rate': 0.007455189162186844, 'lasso_coef': 0.00011747897255341434, 'patience': 12}. Best is trial 0 with value: 0.14915564619004726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 49\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:14:33,683] Trial 1 finished with value: 0.2740127846598625 and parameters: {'learning_rate': 0.03357462255242979, 'lasso_coef': 0.0005070031531194921, 'patience': 10}. Best is trial 0 with value: 0.14915564619004726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:14:35,217] Trial 2 finished with value: 0.28552347272634504 and parameters: {'learning_rate': 0.05316950155993352, 'lasso_coef': 0.0004358656241149539, 'patience': 10}. Best is trial 0 with value: 0.14915564619004726.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 261\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:14:39,411] Trial 3 finished with value: 0.09666628055274487 and parameters: {'learning_rate': 0.002008350381400683, 'lasso_coef': 2.010568897533189e-05, 'patience': 8}. Best is trial 3 with value: 0.09666628055274487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 53\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:14:41,331] Trial 4 finished with value: 0.14358945414423943 and parameters: {'learning_rate': 0.02767936989838702, 'lasso_coef': 6.077718670665665e-05, 'patience': 19}. Best is trial 3 with value: 0.09666628055274487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 110\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:14:43,667] Trial 5 finished with value: 0.12158984914422036 and parameters: {'learning_rate': 0.006332503177744904, 'lasso_coef': 5.2567987838087575e-05, 'patience': 14}. Best is trial 3 with value: 0.09666628055274487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 60\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 36\n",
      "Early stopping at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:14:46,140] Trial 6 finished with value: 0.38524203598499296 and parameters: {'learning_rate': 0.024050794402500235, 'lasso_coef': 0.0012614949515015088, 'patience': 16}. Best is trial 3 with value: 0.09666628055274487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 31\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:14:47,532] Trial 7 finished with value: 0.6673222929239273 and parameters: {'learning_rate': 0.019157434983871905, 'lasso_coef': 0.0044726992863685635, 'patience': 6}. Best is trial 3 with value: 0.09666628055274487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 121\n",
      "Early stopping at epoch 31\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:14:57,287] Trial 8 finished with value: 0.4796717420220375 and parameters: {'learning_rate': 0.00039883745450256544, 'lasso_coef': 0.02928756763189848, 'patience': 14}. Best is trial 3 with value: 0.09666628055274487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 108\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:15:00,114] Trial 9 finished with value: 0.8914332330226898 and parameters: {'learning_rate': 0.003534131484049902, 'lasso_coef': 0.050279697029447075, 'patience': 11}. Best is trial 3 with value: 0.09666628055274487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:15:07,755] Trial 10 finished with value: 0.11601131372153758 and parameters: {'learning_rate': 0.00048167151701992327, 'lasso_coef': 2.856036737821478e-05, 'patience': 5}. Best is trial 3 with value: 0.09666628055274487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 276\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:15:12,001] Trial 11 finished with value: 0.11703734286129475 and parameters: {'learning_rate': 0.0005415399880895657, 'lasso_coef': 1.0070145187387197e-05, 'patience': 5}. Best is trial 3 with value: 0.09666628055274487.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 290\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:15:16,598] Trial 12 finished with value: 0.09514661841094493 and parameters: {'learning_rate': 0.0010844903148770186, 'lasso_coef': 1.0289552725588718e-05, 'patience': 7}. Best is trial 12 with value: 0.09514661841094493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 216\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:15:20,220] Trial 13 finished with value: 0.10397395826876163 and parameters: {'learning_rate': 0.0013907442863218536, 'lasso_coef': 1.5276095960156156e-05, 'patience': 8}. Best is trial 12 with value: 0.09514661841094493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:15:27,697] Trial 14 finished with value: 0.2337747722864151 and parameters: {'learning_rate': 0.00010206739026235673, 'lasso_coef': 0.00011254724735346156, 'patience': 7}. Best is trial 12 with value: 0.09514661841094493.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 313\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:15:32,628] Trial 15 finished with value: 0.0867562772706151 and parameters: {'learning_rate': 0.0015691913767453417, 'lasso_coef': 1.0492436110256668e-05, 'patience': 8}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 278\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:15:37,565] Trial 16 finished with value: 0.4538416162133217 and parameters: {'learning_rate': 0.0009911174362619015, 'lasso_coef': 0.006032798480671486, 'patience': 9}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:15:51,811] Trial 17 finished with value: 0.21357854902744294 and parameters: {'learning_rate': 0.00015563953999907966, 'lasso_coef': 0.00025283078921565626, 'patience': 7}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 316\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:15:57,371] Trial 18 finished with value: 0.10484888516366482 and parameters: {'learning_rate': 0.0032662084027689207, 'lasso_coef': 3.9288102304925925e-05, 'patience': 19}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:16:05,459] Trial 19 finished with value: 0.12053605504333972 and parameters: {'learning_rate': 0.0002389488088326878, 'lasso_coef': 1.0022338693183612e-05, 'patience': 13}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 132\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:16:08,514] Trial 20 finished with value: 0.3767444923520088 and parameters: {'learning_rate': 0.007826389800017453, 'lasso_coef': 0.0018260493660839125, 'patience': 17}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 385\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:16:14,481] Trial 21 finished with value: 0.10073729492723942 and parameters: {'learning_rate': 0.0012763096244037535, 'lasso_coef': 2.7168688652958614e-05, 'patience': 8}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 307\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:16:19,345] Trial 22 finished with value: 0.0939936215057969 and parameters: {'learning_rate': 0.0019838412403972664, 'lasso_coef': 2.0462300494399913e-05, 'patience': 9}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 354\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:16:24,998] Trial 23 finished with value: 0.14033308252692223 and parameters: {'learning_rate': 0.0017423936301130872, 'lasso_coef': 0.00010901141751494126, 'patience': 10}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:16:32,326] Trial 24 finished with value: 0.09634610284119845 and parameters: {'learning_rate': 0.0007304311700928629, 'lasso_coef': 1.861067246782446e-05, 'patience': 6}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 176\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:16:35,449] Trial 25 finished with value: 0.1261540178209543 and parameters: {'learning_rate': 0.003371678190139893, 'lasso_coef': 6.410115228123015e-05, 'patience': 9}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:16:43,455] Trial 26 finished with value: 0.20169916972517968 and parameters: {'learning_rate': 0.00028323982706222065, 'lasso_coef': 0.00021351526222487517, 'patience': 12}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 47\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:16:44,564] Trial 27 finished with value: 0.0919065024703741 and parameters: {'learning_rate': 0.012758856528830598, 'lasso_coef': 1.173672667874445e-05, 'patience': 7}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 90\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:16:46,467] Trial 28 finished with value: 0.109734520688653 and parameters: {'learning_rate': 0.014658803850741593, 'lasso_coef': 3.3773210207203264e-05, 'patience': 11}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 131\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:16:48,805] Trial 29 finished with value: 0.1402754709124565 and parameters: {'learning_rate': 0.009149610572835977, 'lasso_coef': 9.028986809911882e-05, 'patience': 9}. Best is trial 15 with value: 0.0867562772706151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Best hyperparameters: {'learning_rate': 0.0015691913767453417, 'lasso_coef': 1.0492436110256668e-05, 'patience': 8}\n",
      "Best value: 0.0867562772706151\n",
      "Epoch [1/500], Train Loss: 0.4849\n",
      "Epoch [2/500], Train Loss: 0.4097\n",
      "Epoch [3/500], Train Loss: 0.3742\n",
      "Epoch [4/500], Train Loss: 0.3515\n",
      "Epoch [5/500], Train Loss: 0.3319\n",
      "Epoch [6/500], Train Loss: 0.3156\n",
      "Epoch [7/500], Train Loss: 0.3013\n",
      "Epoch [8/500], Train Loss: 0.2885\n",
      "Epoch [9/500], Train Loss: 0.2779\n",
      "Epoch [10/500], Train Loss: 0.2682\n",
      "Epoch [11/500], Train Loss: 0.2590\n",
      "Epoch [12/500], Train Loss: 0.2512\n",
      "Epoch [13/500], Train Loss: 0.2440\n",
      "Epoch [14/500], Train Loss: 0.2365\n",
      "Epoch [15/500], Train Loss: 0.2302\n",
      "Epoch [16/500], Train Loss: 0.2245\n",
      "Epoch [17/500], Train Loss: 0.2192\n",
      "Epoch [18/500], Train Loss: 0.2137\n",
      "Epoch [19/500], Train Loss: 0.2090\n",
      "Epoch [20/500], Train Loss: 0.2047\n",
      "Epoch [21/500], Train Loss: 0.2002\n",
      "Epoch [22/500], Train Loss: 0.1963\n",
      "Epoch [23/500], Train Loss: 0.1924\n",
      "Epoch [24/500], Train Loss: 0.1896\n",
      "Epoch [25/500], Train Loss: 0.1858\n",
      "Epoch [26/500], Train Loss: 0.1826\n",
      "Epoch [27/500], Train Loss: 0.1792\n",
      "Epoch [28/500], Train Loss: 0.1761\n",
      "Epoch [29/500], Train Loss: 0.1737\n",
      "Epoch [30/500], Train Loss: 0.1706\n",
      "Epoch [31/500], Train Loss: 0.1685\n",
      "Epoch [32/500], Train Loss: 0.1661\n",
      "Epoch [33/500], Train Loss: 0.1630\n",
      "Epoch [34/500], Train Loss: 0.1608\n",
      "Epoch [35/500], Train Loss: 0.1586\n",
      "Epoch [36/500], Train Loss: 0.1569\n",
      "Epoch [37/500], Train Loss: 0.1550\n",
      "Epoch [38/500], Train Loss: 0.1529\n",
      "Epoch [39/500], Train Loss: 0.1505\n",
      "Epoch [40/500], Train Loss: 0.1493\n",
      "Epoch [41/500], Train Loss: 0.1472\n",
      "Epoch [42/500], Train Loss: 0.1454\n",
      "Epoch [43/500], Train Loss: 0.1437\n",
      "Epoch [44/500], Train Loss: 0.1420\n",
      "Epoch [45/500], Train Loss: 0.1404\n",
      "Epoch [46/500], Train Loss: 0.1390\n",
      "Epoch [47/500], Train Loss: 0.1373\n",
      "Epoch [48/500], Train Loss: 0.1361\n",
      "Epoch [49/500], Train Loss: 0.1347\n",
      "Epoch [50/500], Train Loss: 0.1333\n",
      "Epoch [51/500], Train Loss: 0.1323\n",
      "Epoch [52/500], Train Loss: 0.1308\n",
      "Epoch [53/500], Train Loss: 0.1297\n",
      "Epoch [54/500], Train Loss: 0.1285\n",
      "Epoch [55/500], Train Loss: 0.1275\n",
      "Epoch [56/500], Train Loss: 0.1259\n",
      "Epoch [57/500], Train Loss: 0.1249\n",
      "Epoch [58/500], Train Loss: 0.1237\n",
      "Epoch [59/500], Train Loss: 0.1228\n",
      "Epoch [60/500], Train Loss: 0.1214\n",
      "Epoch [61/500], Train Loss: 0.1209\n",
      "Epoch [62/500], Train Loss: 0.1196\n",
      "Epoch [63/500], Train Loss: 0.1187\n",
      "Epoch [64/500], Train Loss: 0.1180\n",
      "Epoch [65/500], Train Loss: 0.1169\n",
      "Epoch [66/500], Train Loss: 0.1156\n",
      "Epoch [67/500], Train Loss: 0.1151\n",
      "Epoch [68/500], Train Loss: 0.1137\n",
      "Epoch [69/500], Train Loss: 0.1132\n",
      "Epoch [70/500], Train Loss: 0.1124\n",
      "Epoch [71/500], Train Loss: 0.1117\n",
      "Epoch [72/500], Train Loss: 0.1111\n",
      "Epoch [73/500], Train Loss: 0.1097\n",
      "Epoch [74/500], Train Loss: 0.1092\n",
      "Epoch [75/500], Train Loss: 0.1084\n",
      "Epoch [76/500], Train Loss: 0.1077\n",
      "Epoch [77/500], Train Loss: 0.1069\n",
      "Epoch [78/500], Train Loss: 0.1064\n",
      "Epoch [79/500], Train Loss: 0.1058\n",
      "Epoch [80/500], Train Loss: 0.1049\n",
      "Epoch [81/500], Train Loss: 0.1044\n",
      "Epoch [82/500], Train Loss: 0.1034\n",
      "Epoch [83/500], Train Loss: 0.1030\n",
      "Epoch [84/500], Train Loss: 0.1022\n",
      "Epoch [85/500], Train Loss: 0.1016\n",
      "Epoch [86/500], Train Loss: 0.1011\n",
      "Epoch [87/500], Train Loss: 0.1006\n",
      "Epoch [88/500], Train Loss: 0.1000\n",
      "Epoch [89/500], Train Loss: 0.0993\n",
      "Epoch [90/500], Train Loss: 0.0987\n",
      "Epoch [91/500], Train Loss: 0.0982\n",
      "Epoch [92/500], Train Loss: 0.0980\n",
      "Epoch [93/500], Train Loss: 0.0973\n",
      "Epoch [94/500], Train Loss: 0.0971\n",
      "Epoch [95/500], Train Loss: 0.0960\n",
      "Epoch [96/500], Train Loss: 0.0955\n",
      "Epoch [97/500], Train Loss: 0.0950\n",
      "Epoch [98/500], Train Loss: 0.0946\n",
      "Epoch [99/500], Train Loss: 0.0940\n",
      "Epoch [100/500], Train Loss: 0.0938\n",
      "Epoch [101/500], Train Loss: 0.0934\n",
      "Epoch [102/500], Train Loss: 0.0929\n",
      "Epoch [103/500], Train Loss: 0.0925\n",
      "Epoch [104/500], Train Loss: 0.0917\n",
      "Epoch [105/500], Train Loss: 0.0913\n",
      "Epoch [106/500], Train Loss: 0.0908\n",
      "Epoch [107/500], Train Loss: 0.0906\n",
      "Epoch [108/500], Train Loss: 0.0901\n",
      "Epoch [109/500], Train Loss: 0.0895\n",
      "Epoch [110/500], Train Loss: 0.0894\n",
      "Epoch [111/500], Train Loss: 0.0888\n",
      "Epoch [112/500], Train Loss: 0.0883\n",
      "Epoch [113/500], Train Loss: 0.0880\n",
      "Epoch [114/500], Train Loss: 0.0878\n",
      "Epoch [115/500], Train Loss: 0.0873\n",
      "Epoch [116/500], Train Loss: 0.0871\n",
      "Epoch [117/500], Train Loss: 0.0863\n",
      "Epoch [118/500], Train Loss: 0.0863\n",
      "Epoch [119/500], Train Loss: 0.0857\n",
      "Epoch [120/500], Train Loss: 0.0856\n",
      "Epoch [121/500], Train Loss: 0.0850\n",
      "Epoch [122/500], Train Loss: 0.0846\n",
      "Epoch [123/500], Train Loss: 0.0842\n",
      "Epoch [124/500], Train Loss: 0.0841\n",
      "Epoch [125/500], Train Loss: 0.0836\n",
      "Epoch [126/500], Train Loss: 0.0832\n",
      "Epoch [127/500], Train Loss: 0.0831\n",
      "Epoch [128/500], Train Loss: 0.0826\n",
      "Epoch [129/500], Train Loss: 0.0823\n",
      "Epoch [130/500], Train Loss: 0.0820\n",
      "Epoch [131/500], Train Loss: 0.0820\n",
      "Epoch [132/500], Train Loss: 0.0815\n",
      "Epoch [133/500], Train Loss: 0.0811\n",
      "Epoch [134/500], Train Loss: 0.0809\n",
      "Epoch [135/500], Train Loss: 0.0806\n",
      "Epoch [136/500], Train Loss: 0.0803\n",
      "Epoch [137/500], Train Loss: 0.0801\n",
      "Epoch [138/500], Train Loss: 0.0797\n",
      "Epoch [139/500], Train Loss: 0.0796\n",
      "Epoch [140/500], Train Loss: 0.0793\n",
      "Epoch [141/500], Train Loss: 0.0791\n",
      "Epoch [142/500], Train Loss: 0.0788\n",
      "Epoch [143/500], Train Loss: 0.0783\n",
      "Epoch [144/500], Train Loss: 0.0780\n",
      "Epoch [145/500], Train Loss: 0.0780\n",
      "Epoch [146/500], Train Loss: 0.0777\n",
      "Epoch [147/500], Train Loss: 0.0776\n",
      "Epoch [148/500], Train Loss: 0.0770\n",
      "Epoch [149/500], Train Loss: 0.0767\n",
      "Epoch [150/500], Train Loss: 0.0765\n",
      "Epoch [151/500], Train Loss: 0.0763\n",
      "Epoch [152/500], Train Loss: 0.0760\n",
      "Epoch [153/500], Train Loss: 0.0760\n",
      "Epoch [154/500], Train Loss: 0.0757\n",
      "Epoch [155/500], Train Loss: 0.0755\n",
      "Epoch [156/500], Train Loss: 0.0752\n",
      "Epoch [157/500], Train Loss: 0.0750\n",
      "Epoch [158/500], Train Loss: 0.0747\n",
      "Epoch [159/500], Train Loss: 0.0745\n",
      "Epoch [160/500], Train Loss: 0.0745\n",
      "Epoch [161/500], Train Loss: 0.0743\n",
      "Epoch [162/500], Train Loss: 0.0741\n",
      "Epoch [163/500], Train Loss: 0.0742\n",
      "Epoch [164/500], Train Loss: 0.0733\n",
      "Epoch [165/500], Train Loss: 0.0732\n",
      "Epoch [166/500], Train Loss: 0.0730\n",
      "Epoch [167/500], Train Loss: 0.0726\n",
      "Epoch [168/500], Train Loss: 0.0726\n",
      "Epoch [169/500], Train Loss: 0.0721\n",
      "Epoch [170/500], Train Loss: 0.0722\n",
      "Epoch [171/500], Train Loss: 0.0719\n",
      "Epoch [172/500], Train Loss: 0.0718\n",
      "Epoch [173/500], Train Loss: 0.0716\n",
      "Epoch [174/500], Train Loss: 0.0714\n",
      "Epoch [175/500], Train Loss: 0.0712\n",
      "Epoch [176/500], Train Loss: 0.0710\n",
      "Epoch [177/500], Train Loss: 0.0711\n",
      "Epoch [178/500], Train Loss: 0.0705\n",
      "Epoch [179/500], Train Loss: 0.0707\n",
      "Epoch [180/500], Train Loss: 0.0704\n",
      "Epoch [181/500], Train Loss: 0.0700\n",
      "Epoch [182/500], Train Loss: 0.0701\n",
      "Epoch [183/500], Train Loss: 0.0699\n",
      "Epoch [184/500], Train Loss: 0.0697\n",
      "Epoch [185/500], Train Loss: 0.0696\n",
      "Epoch [186/500], Train Loss: 0.0692\n",
      "Epoch [187/500], Train Loss: 0.0692\n",
      "Epoch [188/500], Train Loss: 0.0691\n",
      "Epoch [189/500], Train Loss: 0.0688\n",
      "Epoch [190/500], Train Loss: 0.0687\n",
      "Epoch [191/500], Train Loss: 0.0684\n",
      "Epoch [192/500], Train Loss: 0.0682\n",
      "Epoch [193/500], Train Loss: 0.0680\n",
      "Epoch [194/500], Train Loss: 0.0680\n",
      "Epoch [195/500], Train Loss: 0.0676\n",
      "Epoch [196/500], Train Loss: 0.0677\n",
      "Epoch [197/500], Train Loss: 0.0676\n",
      "Epoch [198/500], Train Loss: 0.0672\n",
      "Epoch [199/500], Train Loss: 0.0673\n",
      "Epoch [200/500], Train Loss: 0.0670\n",
      "Epoch [201/500], Train Loss: 0.0669\n",
      "Epoch [202/500], Train Loss: 0.0666\n",
      "Epoch [203/500], Train Loss: 0.0665\n",
      "Epoch [204/500], Train Loss: 0.0665\n",
      "Epoch [205/500], Train Loss: 0.0662\n",
      "Epoch [206/500], Train Loss: 0.0661\n",
      "Epoch [207/500], Train Loss: 0.0660\n",
      "Epoch [208/500], Train Loss: 0.0657\n",
      "Epoch [209/500], Train Loss: 0.0657\n",
      "Epoch [210/500], Train Loss: 0.0655\n",
      "Epoch [211/500], Train Loss: 0.0652\n",
      "Epoch [212/500], Train Loss: 0.0653\n",
      "Epoch [213/500], Train Loss: 0.0651\n",
      "Epoch [214/500], Train Loss: 0.0650\n",
      "Epoch [215/500], Train Loss: 0.0650\n",
      "Epoch [216/500], Train Loss: 0.0651\n",
      "Epoch [217/500], Train Loss: 0.0647\n",
      "Epoch [218/500], Train Loss: 0.0646\n",
      "Epoch [219/500], Train Loss: 0.0643\n",
      "Epoch [220/500], Train Loss: 0.0641\n",
      "Epoch [221/500], Train Loss: 0.0640\n",
      "Epoch [222/500], Train Loss: 0.0638\n",
      "Epoch [223/500], Train Loss: 0.0637\n",
      "Epoch [224/500], Train Loss: 0.0635\n",
      "Epoch [225/500], Train Loss: 0.0635\n",
      "Epoch [226/500], Train Loss: 0.0634\n",
      "Epoch [227/500], Train Loss: 0.0632\n",
      "Epoch [228/500], Train Loss: 0.0631\n",
      "Epoch [229/500], Train Loss: 0.0631\n",
      "Epoch [230/500], Train Loss: 0.0629\n",
      "Epoch [231/500], Train Loss: 0.0628\n",
      "Epoch [232/500], Train Loss: 0.0627\n",
      "Epoch [233/500], Train Loss: 0.0625\n",
      "Epoch [234/500], Train Loss: 0.0623\n",
      "Epoch [235/500], Train Loss: 0.0621\n",
      "Epoch [236/500], Train Loss: 0.0621\n",
      "Epoch [237/500], Train Loss: 0.0620\n",
      "Epoch [238/500], Train Loss: 0.0620\n",
      "Epoch [239/500], Train Loss: 0.0620\n",
      "Epoch [240/500], Train Loss: 0.0617\n",
      "Epoch [241/500], Train Loss: 0.0616\n",
      "Epoch [242/500], Train Loss: 0.0614\n",
      "Epoch [243/500], Train Loss: 0.0615\n",
      "Epoch [244/500], Train Loss: 0.0613\n",
      "Epoch [245/500], Train Loss: 0.0612\n",
      "Epoch [246/500], Train Loss: 0.0610\n",
      "Epoch [247/500], Train Loss: 0.0609\n",
      "Epoch [248/500], Train Loss: 0.0608\n",
      "Epoch [249/500], Train Loss: 0.0607\n",
      "Epoch [250/500], Train Loss: 0.0606\n",
      "Epoch [251/500], Train Loss: 0.0604\n",
      "Epoch [252/500], Train Loss: 0.0603\n",
      "Epoch [253/500], Train Loss: 0.0603\n",
      "Epoch [254/500], Train Loss: 0.0603\n",
      "Epoch [255/500], Train Loss: 0.0602\n",
      "Epoch [256/500], Train Loss: 0.0601\n",
      "Epoch [257/500], Train Loss: 0.0599\n",
      "Epoch [258/500], Train Loss: 0.0598\n",
      "Epoch [259/500], Train Loss: 0.0598\n",
      "Epoch [260/500], Train Loss: 0.0597\n",
      "Epoch [261/500], Train Loss: 0.0597\n",
      "Epoch [262/500], Train Loss: 0.0595\n",
      "Epoch [263/500], Train Loss: 0.0595\n",
      "Epoch [264/500], Train Loss: 0.0593\n",
      "Epoch [265/500], Train Loss: 0.0592\n",
      "Epoch [266/500], Train Loss: 0.0592\n",
      "Epoch [267/500], Train Loss: 0.0590\n",
      "Epoch [268/500], Train Loss: 0.0590\n",
      "Epoch [269/500], Train Loss: 0.0589\n",
      "Epoch [270/500], Train Loss: 0.0587\n",
      "Epoch [271/500], Train Loss: 0.0586\n",
      "Epoch [272/500], Train Loss: 0.0586\n",
      "Epoch [273/500], Train Loss: 0.0585\n",
      "Epoch [274/500], Train Loss: 0.0585\n",
      "Epoch [275/500], Train Loss: 0.0583\n",
      "Epoch [276/500], Train Loss: 0.0582\n",
      "Epoch [277/500], Train Loss: 0.0581\n",
      "Epoch [278/500], Train Loss: 0.0580\n",
      "Epoch [279/500], Train Loss: 0.0579\n",
      "Epoch [280/500], Train Loss: 0.0578\n",
      "Epoch [281/500], Train Loss: 0.0578\n",
      "Epoch [282/500], Train Loss: 0.0576\n",
      "Epoch [283/500], Train Loss: 0.0575\n",
      "Epoch [284/500], Train Loss: 0.0574\n",
      "Epoch [285/500], Train Loss: 0.0573\n",
      "Epoch [286/500], Train Loss: 0.0574\n",
      "Epoch [287/500], Train Loss: 0.0574\n",
      "Epoch [288/500], Train Loss: 0.0574\n",
      "Epoch [289/500], Train Loss: 0.0571\n",
      "Epoch [290/500], Train Loss: 0.0569\n",
      "Epoch [291/500], Train Loss: 0.0569\n",
      "Epoch [292/500], Train Loss: 0.0568\n",
      "Epoch [293/500], Train Loss: 0.0569\n",
      "Epoch [294/500], Train Loss: 0.0566\n",
      "Epoch [295/500], Train Loss: 0.0566\n",
      "Epoch [296/500], Train Loss: 0.0566\n",
      "Epoch [297/500], Train Loss: 0.0565\n",
      "Epoch [298/500], Train Loss: 0.0565\n",
      "Epoch [299/500], Train Loss: 0.0562\n",
      "Epoch [300/500], Train Loss: 0.0562\n",
      "Epoch [301/500], Train Loss: 0.0563\n",
      "Epoch [302/500], Train Loss: 0.0561\n",
      "Epoch [303/500], Train Loss: 0.0560\n",
      "Epoch [304/500], Train Loss: 0.0558\n",
      "Epoch [305/500], Train Loss: 0.0561\n",
      "Epoch [306/500], Train Loss: 0.0557\n",
      "Epoch [307/500], Train Loss: 0.0557\n",
      "Epoch [308/500], Train Loss: 0.0555\n",
      "Epoch [309/500], Train Loss: 0.0556\n",
      "Epoch [310/500], Train Loss: 0.0555\n",
      "Epoch [311/500], Train Loss: 0.0554\n",
      "Epoch [312/500], Train Loss: 0.0553\n",
      "Epoch [313/500], Train Loss: 0.0551\n",
      "Epoch [314/500], Train Loss: 0.0553\n",
      "Epoch [315/500], Train Loss: 0.0553\n",
      "Epoch [316/500], Train Loss: 0.0552\n",
      "Epoch [317/500], Train Loss: 0.0549\n",
      "Epoch [318/500], Train Loss: 0.0549\n",
      "Epoch [319/500], Train Loss: 0.0549\n",
      "Epoch [320/500], Train Loss: 0.0548\n",
      "Epoch [321/500], Train Loss: 0.0547\n",
      "Epoch [322/500], Train Loss: 0.0548\n",
      "Epoch [323/500], Train Loss: 0.0546\n",
      "Epoch [324/500], Train Loss: 0.0545\n",
      "Epoch [325/500], Train Loss: 0.0545\n",
      "Epoch [326/500], Train Loss: 0.0543\n",
      "Epoch [327/500], Train Loss: 0.0543\n",
      "Epoch [328/500], Train Loss: 0.0542\n",
      "Epoch [329/500], Train Loss: 0.0542\n",
      "Epoch [330/500], Train Loss: 0.0543\n",
      "Epoch [331/500], Train Loss: 0.0541\n",
      "Epoch [332/500], Train Loss: 0.0540\n",
      "Epoch [333/500], Train Loss: 0.0538\n",
      "Epoch [334/500], Train Loss: 0.0538\n",
      "Epoch [335/500], Train Loss: 0.0537\n",
      "Epoch [336/500], Train Loss: 0.0538\n",
      "Epoch [337/500], Train Loss: 0.0538\n",
      "Epoch [338/500], Train Loss: 0.0534\n",
      "Epoch [339/500], Train Loss: 0.0536\n",
      "Epoch [340/500], Train Loss: 0.0536\n",
      "Epoch [341/500], Train Loss: 0.0534\n",
      "Epoch [342/500], Train Loss: 0.0533\n",
      "Epoch [343/500], Train Loss: 0.0533\n",
      "Epoch [344/500], Train Loss: 0.0532\n",
      "Epoch [345/500], Train Loss: 0.0532\n",
      "Epoch [346/500], Train Loss: 0.0530\n",
      "Epoch [347/500], Train Loss: 0.0532\n",
      "Epoch [348/500], Train Loss: 0.0531\n",
      "Epoch [349/500], Train Loss: 0.0530\n",
      "Epoch [350/500], Train Loss: 0.0530\n",
      "Epoch [351/500], Train Loss: 0.0529\n",
      "Epoch [352/500], Train Loss: 0.0528\n",
      "Epoch [353/500], Train Loss: 0.0528\n",
      "Epoch [354/500], Train Loss: 0.0529\n",
      "Epoch [355/500], Train Loss: 0.0526\n",
      "Epoch [356/500], Train Loss: 0.0526\n",
      "Epoch [357/500], Train Loss: 0.0524\n",
      "Epoch [358/500], Train Loss: 0.0525\n",
      "Epoch [359/500], Train Loss: 0.0524\n",
      "Epoch [360/500], Train Loss: 0.0526\n",
      "Epoch [361/500], Train Loss: 0.0521\n",
      "Epoch [362/500], Train Loss: 0.0524\n",
      "Epoch [363/500], Train Loss: 0.0522\n",
      "Epoch [364/500], Train Loss: 0.0522\n",
      "Epoch [365/500], Train Loss: 0.0522\n",
      "Epoch [366/500], Train Loss: 0.0522\n",
      "Epoch [367/500], Train Loss: 0.0520\n",
      "Epoch [368/500], Train Loss: 0.0517\n",
      "Epoch [369/500], Train Loss: 0.0519\n",
      "Epoch [370/500], Train Loss: 0.0517\n",
      "Epoch [371/500], Train Loss: 0.0516\n",
      "Epoch [372/500], Train Loss: 0.0518\n",
      "Epoch [373/500], Train Loss: 0.0516\n",
      "Epoch [374/500], Train Loss: 0.0515\n",
      "Epoch [375/500], Train Loss: 0.0516\n",
      "Epoch [376/500], Train Loss: 0.0515\n",
      "Epoch [377/500], Train Loss: 0.0516\n",
      "Epoch [378/500], Train Loss: 0.0515\n",
      "Epoch [379/500], Train Loss: 0.0513\n",
      "Epoch [380/500], Train Loss: 0.0513\n",
      "Epoch [381/500], Train Loss: 0.0512\n",
      "Epoch [382/500], Train Loss: 0.0513\n",
      "Epoch [383/500], Train Loss: 0.0511\n",
      "Epoch [384/500], Train Loss: 0.0512\n",
      "Epoch [385/500], Train Loss: 0.0511\n",
      "Epoch [386/500], Train Loss: 0.0511\n",
      "Epoch [387/500], Train Loss: 0.0510\n",
      "Epoch [388/500], Train Loss: 0.0511\n",
      "Epoch [389/500], Train Loss: 0.0508\n",
      "Epoch [390/500], Train Loss: 0.0507\n",
      "Epoch [391/500], Train Loss: 0.0508\n",
      "Epoch [392/500], Train Loss: 0.0507\n",
      "Epoch [393/500], Train Loss: 0.0507\n",
      "Epoch [394/500], Train Loss: 0.0508\n",
      "Epoch [395/500], Train Loss: 0.0505\n",
      "Epoch [396/500], Train Loss: 0.0506\n",
      "Epoch [397/500], Train Loss: 0.0508\n",
      "Epoch [398/500], Train Loss: 0.0505\n",
      "Epoch [399/500], Train Loss: 0.0503\n",
      "Epoch [400/500], Train Loss: 0.0504\n",
      "Epoch [401/500], Train Loss: 0.0506\n",
      "Epoch [402/500], Train Loss: 0.0503\n",
      "Epoch [403/500], Train Loss: 0.0503\n",
      "Epoch [404/500], Train Loss: 0.0501\n",
      "Epoch [405/500], Train Loss: 0.0502\n",
      "Epoch [406/500], Train Loss: 0.0501\n",
      "Epoch [407/500], Train Loss: 0.0500\n",
      "Epoch [408/500], Train Loss: 0.0500\n",
      "Epoch [409/500], Train Loss: 0.0499\n",
      "Epoch [410/500], Train Loss: 0.0500\n",
      "Epoch [411/500], Train Loss: 0.0501\n",
      "Epoch [412/500], Train Loss: 0.0499\n",
      "Epoch [413/500], Train Loss: 0.0498\n",
      "Epoch [414/500], Train Loss: 0.0500\n",
      "Epoch [415/500], Train Loss: 0.0499\n",
      "Epoch [416/500], Train Loss: 0.0497\n",
      "Epoch [417/500], Train Loss: 0.0496\n",
      "Epoch [418/500], Train Loss: 0.0498\n",
      "Epoch [419/500], Train Loss: 0.0496\n",
      "Epoch [420/500], Train Loss: 0.0495\n",
      "Epoch [421/500], Train Loss: 0.0496\n",
      "Epoch [422/500], Train Loss: 0.0495\n",
      "Epoch [423/500], Train Loss: 0.0494\n",
      "Epoch [424/500], Train Loss: 0.0493\n",
      "Epoch [425/500], Train Loss: 0.0492\n",
      "Epoch [426/500], Train Loss: 0.0494\n",
      "Epoch [427/500], Train Loss: 0.0493\n",
      "Epoch [428/500], Train Loss: 0.0492\n",
      "Epoch [429/500], Train Loss: 0.0491\n",
      "Epoch [430/500], Train Loss: 0.0492\n",
      "Epoch [431/500], Train Loss: 0.0491\n",
      "Epoch [432/500], Train Loss: 0.0490\n",
      "Epoch [433/500], Train Loss: 0.0489\n",
      "Epoch [434/500], Train Loss: 0.0490\n",
      "Epoch [435/500], Train Loss: 0.0490\n",
      "Epoch [436/500], Train Loss: 0.0489\n",
      "Epoch [437/500], Train Loss: 0.0490\n",
      "Epoch [438/500], Train Loss: 0.0488\n",
      "Epoch [439/500], Train Loss: 0.0487\n",
      "Epoch [440/500], Train Loss: 0.0487\n",
      "Epoch [441/500], Train Loss: 0.0488\n",
      "Epoch [442/500], Train Loss: 0.0488\n",
      "Epoch [443/500], Train Loss: 0.0488\n",
      "Epoch [444/500], Train Loss: 0.0487\n",
      "Epoch [445/500], Train Loss: 0.0486\n",
      "Epoch [446/500], Train Loss: 0.0486\n",
      "Epoch [447/500], Train Loss: 0.0485\n",
      "Epoch [448/500], Train Loss: 0.0488\n",
      "Epoch [449/500], Train Loss: 0.0486\n",
      "Epoch [450/500], Train Loss: 0.0485\n",
      "Epoch [451/500], Train Loss: 0.0484\n",
      "Epoch [452/500], Train Loss: 0.0485\n",
      "Epoch [453/500], Train Loss: 0.0483\n",
      "Epoch [454/500], Train Loss: 0.0484\n",
      "Epoch [455/500], Train Loss: 0.0485\n",
      "Epoch [456/500], Train Loss: 0.0483\n",
      "Epoch [457/500], Train Loss: 0.0482\n",
      "Epoch [458/500], Train Loss: 0.0482\n",
      "Epoch [459/500], Train Loss: 0.0481\n",
      "Epoch [460/500], Train Loss: 0.0481\n",
      "Epoch [461/500], Train Loss: 0.0481\n",
      "Epoch [462/500], Train Loss: 0.0480\n",
      "Epoch [463/500], Train Loss: 0.0481\n",
      "Epoch [464/500], Train Loss: 0.0481\n",
      "Epoch [465/500], Train Loss: 0.0480\n",
      "Epoch [466/500], Train Loss: 0.0479\n",
      "Epoch [467/500], Train Loss: 0.0480\n",
      "Epoch [468/500], Train Loss: 0.0479\n",
      "Epoch [469/500], Train Loss: 0.0480\n",
      "Epoch [470/500], Train Loss: 0.0477\n",
      "Epoch [471/500], Train Loss: 0.0479\n",
      "Epoch [472/500], Train Loss: 0.0479\n",
      "Epoch [473/500], Train Loss: 0.0477\n",
      "Epoch [474/500], Train Loss: 0.0478\n",
      "Epoch [475/500], Train Loss: 0.0478\n",
      "Epoch [476/500], Train Loss: 0.0478\n",
      "Epoch [477/500], Train Loss: 0.0477\n",
      "Epoch [478/500], Train Loss: 0.0475\n",
      "Epoch [479/500], Train Loss: 0.0475\n",
      "Epoch [480/500], Train Loss: 0.0476\n",
      "Epoch [481/500], Train Loss: 0.0476\n",
      "Epoch [482/500], Train Loss: 0.0477\n",
      "Epoch [483/500], Train Loss: 0.0477\n",
      "Epoch [484/500], Train Loss: 0.0475\n",
      "Epoch [485/500], Train Loss: 0.0475\n",
      "Epoch [486/500], Train Loss: 0.0475\n",
      "Epoch [487/500], Train Loss: 0.0474\n",
      "Epoch [488/500], Train Loss: 0.0473\n",
      "Epoch [489/500], Train Loss: 0.0473\n",
      "Epoch [490/500], Train Loss: 0.0472\n",
      "Epoch [491/500], Train Loss: 0.0472\n",
      "Epoch [492/500], Train Loss: 0.0471\n",
      "Epoch [493/500], Train Loss: 0.0471\n",
      "Epoch [494/500], Train Loss: 0.0471\n",
      "Epoch [495/500], Train Loss: 0.0470\n",
      "Epoch [496/500], Train Loss: 0.0471\n",
      "Epoch [497/500], Train Loss: 0.0471\n",
      "Epoch [498/500], Train Loss: 0.0474\n",
      "Epoch [499/500], Train Loss: 0.0473\n",
      "Epoch [500/500], Train Loss: 0.0470\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr12/final_model_chr12.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr12/individual_r2_scores_chr12.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:16:57,834] A new study created in memory with name: no-name-6fcb64a1-a41a-4ee7-947b-eda9a7f742c6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  8\n",
      "Known PRS313 SNPs:  2\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  210\n",
      "Early stopping at epoch 206\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:00,544] Trial 0 finished with value: 0.15657654777169228 and parameters: {'learning_rate': 0.012115241600946706, 'lasso_coef': 0.00020754923262329879, 'patience': 18}. Best is trial 0 with value: 0.15657654777169228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 323\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:04,024] Trial 1 finished with value: 0.274007710814476 and parameters: {'learning_rate': 0.0020477205613556593, 'lasso_coef': 0.0031298282424165186, 'patience': 9}. Best is trial 0 with value: 0.15657654777169228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 332\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:16,662] Trial 2 finished with value: 0.3003919765353203 and parameters: {'learning_rate': 0.0003336293075948003, 'lasso_coef': 0.003923783824908041, 'patience': 14}. Best is trial 0 with value: 0.15657654777169228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:22,133] Trial 3 finished with value: 0.16997467502951621 and parameters: {'learning_rate': 0.0008332849043977266, 'lasso_coef': 0.00025692070166752893, 'patience': 9}. Best is trial 0 with value: 0.15657654777169228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:27,328] Trial 4 finished with value: 0.20669272914528847 and parameters: {'learning_rate': 0.0011016232433022106, 'lasso_coef': 0.0008898064161111541, 'patience': 17}. Best is trial 0 with value: 0.15657654777169228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 62\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:28,345] Trial 5 finished with value: 0.13853071257472038 and parameters: {'learning_rate': 0.01859711157701896, 'lasso_coef': 8.34856068056902e-05, 'patience': 12}. Best is trial 5 with value: 0.13853071257472038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 76\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:29,519] Trial 6 finished with value: 0.11955973841249942 and parameters: {'learning_rate': 0.00949902741190947, 'lasso_coef': 2.1023327712999392e-05, 'patience': 13}. Best is trial 6 with value: 0.11955973841249942.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:39,487] Trial 7 finished with value: 0.18404768109321595 and parameters: {'learning_rate': 0.00012796941784470713, 'lasso_coef': 1.744577798385482e-05, 'patience': 16}. Best is trial 6 with value: 0.11955973841249942.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:44,381] Trial 8 finished with value: 0.1295113317668438 and parameters: {'learning_rate': 0.0006490416839528102, 'lasso_coef': 1.1518110906194283e-05, 'patience': 6}. Best is trial 6 with value: 0.11955973841249942.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 324\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:47,880] Trial 9 finished with value: 0.15344037301838398 and parameters: {'learning_rate': 0.004002016630976321, 'lasso_coef': 0.00020000349506042245, 'patience': 11}. Best is trial 6 with value: 0.11955973841249942.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:48,466] Trial 10 finished with value: 1.4192464768886566 and parameters: {'learning_rate': 0.08742554696449424, 'lasso_coef': 0.058522569524273385, 'patience': 5}. Best is trial 6 with value: 0.11955973841249942.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 101\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:49,777] Trial 11 finished with value: 0.11869364641606808 and parameters: {'learning_rate': 0.008021353521786909, 'lasso_coef': 2.080179580054242e-05, 'patience': 7}. Best is trial 11 with value: 0.11869364641606808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 98\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:51,139] Trial 12 finished with value: 0.1261200901120901 and parameters: {'learning_rate': 0.008010930768960704, 'lasso_coef': 3.796048968259085e-05, 'patience': 8}. Best is trial 11 with value: 0.11869364641606808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 47\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:52,304] Trial 13 finished with value: 0.1356722626835108 and parameters: {'learning_rate': 0.03734416336986967, 'lasso_coef': 6.137712643873815e-05, 'patience': 14}. Best is trial 11 with value: 0.11869364641606808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 165\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:54,722] Trial 14 finished with value: 0.11152401342988014 and parameters: {'learning_rate': 0.004865468679653537, 'lasso_coef': 1.029014194586688e-05, 'patience': 20}. Best is trial 14 with value: 0.11152401342988014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 182\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:17:57,166] Trial 15 finished with value: 0.11431457288563251 and parameters: {'learning_rate': 0.003521204796603657, 'lasso_coef': 1.023776196205596e-05, 'patience': 20}. Best is trial 14 with value: 0.11152401342988014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 217\n",
      "Early stopping at epoch 31\n",
      "Early stopping at epoch 41\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:00,187] Trial 16 finished with value: 0.44641167521476743 and parameters: {'learning_rate': 0.0039567113503920955, 'lasso_coef': 0.0646829430100164, 'patience': 20}. Best is trial 14 with value: 0.11152401342988014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 333\n",
      "Early stopping at epoch 46\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:04,291] Trial 17 finished with value: 0.38956816792488097 and parameters: {'learning_rate': 0.0019815124846041046, 'lasso_coef': 0.012493414051919597, 'patience': 20}. Best is trial 14 with value: 0.11152401342988014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 85\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:05,964] Trial 18 finished with value: 0.21628137528896332 and parameters: {'learning_rate': 0.02597894383100673, 'lasso_coef': 0.0010191246631861383, 'patience': 18}. Best is trial 14 with value: 0.11152401342988014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 204\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:08,433] Trial 19 finished with value: 0.137281646579504 and parameters: {'learning_rate': 0.004243178191533007, 'lasso_coef': 8.927620594358904e-05, 'patience': 16}. Best is trial 14 with value: 0.11152401342988014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:13,696] Trial 20 finished with value: 0.1631716288626194 and parameters: {'learning_rate': 0.00028982156093071713, 'lasso_coef': 1.0027934989871532e-05, 'patience': 20}. Best is trial 14 with value: 0.11152401342988014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 136\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:15,605] Trial 21 finished with value: 0.11800945699214935 and parameters: {'learning_rate': 0.006562606068572685, 'lasso_coef': 2.533935932444188e-05, 'patience': 18}. Best is trial 14 with value: 0.11152401342988014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 361\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:19,536] Trial 22 finished with value: 0.12181346267461776 and parameters: {'learning_rate': 0.001988840832686262, 'lasso_coef': 3.515889481205228e-05, 'patience': 18}. Best is trial 14 with value: 0.11152401342988014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 176\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:21,853] Trial 23 finished with value: 0.12332482002675534 and parameters: {'learning_rate': 0.005453486943868713, 'lasso_coef': 4.15440921336849e-05, 'patience': 19}. Best is trial 14 with value: 0.11152401342988014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 58\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:23,009] Trial 24 finished with value: 0.11177894100546837 and parameters: {'learning_rate': 0.016835217239984848, 'lasso_coef': 1.0339171215909149e-05, 'patience': 16}. Best is trial 14 with value: 0.11152401342988014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 37\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:24,016] Trial 25 finished with value: 0.15580901615321635 and parameters: {'learning_rate': 0.0537798348284803, 'lasso_coef': 0.00011619528901776455, 'patience': 16}. Best is trial 14 with value: 0.11152401342988014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 67\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:25,337] Trial 26 finished with value: 0.11148720011115074 and parameters: {'learning_rate': 0.01552480944470888, 'lasso_coef': 1.0822319588172079e-05, 'patience': 19}. Best is trial 26 with value: 0.11148720011115074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 162\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:27,485] Trial 27 finished with value: 0.18375303149223327 and parameters: {'learning_rate': 0.015974904305916197, 'lasso_coef': 0.00047384847986182017, 'patience': 15}. Best is trial 26 with value: 0.11148720011115074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 68\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:28,769] Trial 28 finished with value: 0.12863217294216156 and parameters: {'learning_rate': 0.027591160684299523, 'lasso_coef': 4.987826728347483e-05, 'patience': 17}. Best is trial 26 with value: 0.11148720011115074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 63\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:30,044] Trial 29 finished with value: 0.11671286709606647 and parameters: {'learning_rate': 0.015586435168383123, 'lasso_coef': 2.051505845985358e-05, 'patience': 19}. Best is trial 26 with value: 0.11148720011115074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Best hyperparameters: {'learning_rate': 0.01552480944470888, 'lasso_coef': 1.0822319588172079e-05, 'patience': 19}\n",
      "Best value: 0.11148720011115074\n",
      "Epoch [1/500], Train Loss: 0.4168\n",
      "Epoch [2/500], Train Loss: 0.3105\n",
      "Epoch [3/500], Train Loss: 0.2658\n",
      "Epoch [4/500], Train Loss: 0.2375\n",
      "Epoch [5/500], Train Loss: 0.2165\n",
      "Epoch [6/500], Train Loss: 0.2033\n",
      "Epoch [7/500], Train Loss: 0.1922\n",
      "Epoch [8/500], Train Loss: 0.1831\n",
      "Epoch [9/500], Train Loss: 0.1760\n",
      "Epoch [10/500], Train Loss: 0.1703\n",
      "Epoch [11/500], Train Loss: 0.1660\n",
      "Epoch [12/500], Train Loss: 0.1598\n",
      "Epoch [13/500], Train Loss: 0.1564\n",
      "Epoch [14/500], Train Loss: 0.1515\n",
      "Epoch [15/500], Train Loss: 0.1469\n",
      "Epoch [16/500], Train Loss: 0.1444\n",
      "Epoch [17/500], Train Loss: 0.1429\n",
      "Epoch [18/500], Train Loss: 0.1402\n",
      "Epoch [19/500], Train Loss: 0.1379\n",
      "Epoch [20/500], Train Loss: 0.1357\n",
      "Epoch [21/500], Train Loss: 0.1335\n",
      "Epoch [22/500], Train Loss: 0.1326\n",
      "Epoch [23/500], Train Loss: 0.1309\n",
      "Epoch [24/500], Train Loss: 0.1302\n",
      "Epoch [25/500], Train Loss: 0.1287\n",
      "Epoch [26/500], Train Loss: 0.1266\n",
      "Epoch [27/500], Train Loss: 0.1244\n",
      "Epoch [28/500], Train Loss: 0.1248\n",
      "Epoch [29/500], Train Loss: 0.1229\n",
      "Epoch [30/500], Train Loss: 0.1210\n",
      "Epoch [31/500], Train Loss: 0.1204\n",
      "Epoch [32/500], Train Loss: 0.1210\n",
      "Epoch [33/500], Train Loss: 0.1194\n",
      "Epoch [34/500], Train Loss: 0.1187\n",
      "Epoch [35/500], Train Loss: 0.1186\n",
      "Epoch [36/500], Train Loss: 0.1183\n",
      "Epoch [37/500], Train Loss: 0.1167\n",
      "Epoch [38/500], Train Loss: 0.1153\n",
      "Epoch [39/500], Train Loss: 0.1144\n",
      "Epoch [40/500], Train Loss: 0.1140\n",
      "Epoch [41/500], Train Loss: 0.1137\n",
      "Epoch [42/500], Train Loss: 0.1130\n",
      "Epoch [43/500], Train Loss: 0.1132\n",
      "Epoch [44/500], Train Loss: 0.1131\n",
      "Epoch [45/500], Train Loss: 0.1132\n",
      "Epoch [46/500], Train Loss: 0.1108\n",
      "Epoch [47/500], Train Loss: 0.1111\n",
      "Epoch [48/500], Train Loss: 0.1102\n",
      "Epoch [49/500], Train Loss: 0.1101\n",
      "Epoch [50/500], Train Loss: 0.1109\n",
      "Epoch [51/500], Train Loss: 0.1099\n",
      "Epoch [52/500], Train Loss: 0.1101\n",
      "Epoch [53/500], Train Loss: 0.1081\n",
      "Epoch [54/500], Train Loss: 0.1081\n",
      "Epoch [55/500], Train Loss: 0.1070\n",
      "Epoch [56/500], Train Loss: 0.1074\n",
      "Epoch [57/500], Train Loss: 0.1082\n",
      "Epoch [58/500], Train Loss: 0.1070\n",
      "Epoch [59/500], Train Loss: 0.1078\n",
      "Epoch [60/500], Train Loss: 0.1082\n",
      "Epoch [61/500], Train Loss: 0.1063\n",
      "Epoch [62/500], Train Loss: 0.1057\n",
      "Epoch [63/500], Train Loss: 0.1052\n",
      "Epoch [64/500], Train Loss: 0.1048\n",
      "Epoch [65/500], Train Loss: 0.1054\n",
      "Epoch [66/500], Train Loss: 0.1043\n",
      "Epoch [67/500], Train Loss: 0.1042\n",
      "Epoch [68/500], Train Loss: 0.1058\n",
      "Epoch [69/500], Train Loss: 0.1059\n",
      "Epoch [70/500], Train Loss: 0.1048\n",
      "Epoch [71/500], Train Loss: 0.1046\n",
      "Epoch [72/500], Train Loss: 0.1044\n",
      "Epoch [73/500], Train Loss: 0.1042\n",
      "Epoch [74/500], Train Loss: 0.1049\n",
      "Epoch [75/500], Train Loss: 0.1067\n",
      "Epoch [76/500], Train Loss: 0.1025\n",
      "Epoch [77/500], Train Loss: 0.1022\n",
      "Epoch [78/500], Train Loss: 0.1025\n",
      "Epoch [79/500], Train Loss: 0.1033\n",
      "Epoch [80/500], Train Loss: 0.1034\n",
      "Epoch [81/500], Train Loss: 0.1027\n",
      "Epoch [82/500], Train Loss: 0.1024\n",
      "Epoch [83/500], Train Loss: 0.1025\n",
      "Epoch [84/500], Train Loss: 0.1017\n",
      "Epoch [85/500], Train Loss: 0.1021\n",
      "Epoch [86/500], Train Loss: 0.1026\n",
      "Epoch [87/500], Train Loss: 0.1009\n",
      "Epoch [88/500], Train Loss: 0.1005\n",
      "Epoch [89/500], Train Loss: 0.1010\n",
      "Epoch [90/500], Train Loss: 0.1014\n",
      "Epoch [91/500], Train Loss: 0.1015\n",
      "Epoch [92/500], Train Loss: 0.1019\n",
      "Epoch [93/500], Train Loss: 0.1011\n",
      "Epoch [94/500], Train Loss: 0.1010\n",
      "Epoch [95/500], Train Loss: 0.1010\n",
      "Epoch [96/500], Train Loss: 0.1011\n",
      "Epoch [97/500], Train Loss: 0.1011\n",
      "Epoch [98/500], Train Loss: 0.0999\n",
      "Epoch [99/500], Train Loss: 0.1003\n",
      "Epoch [100/500], Train Loss: 0.0994\n",
      "Epoch [101/500], Train Loss: 0.0998\n",
      "Epoch [102/500], Train Loss: 0.0999\n",
      "Epoch [103/500], Train Loss: 0.1003\n",
      "Epoch [104/500], Train Loss: 0.0998\n",
      "Epoch [105/500], Train Loss: 0.0996\n",
      "Epoch [106/500], Train Loss: 0.0996\n",
      "Epoch [107/500], Train Loss: 0.1001\n",
      "Epoch [108/500], Train Loss: 0.0994\n",
      "Epoch [109/500], Train Loss: 0.0985\n",
      "Epoch [110/500], Train Loss: 0.0993\n",
      "Epoch [111/500], Train Loss: 0.0993\n",
      "Epoch [112/500], Train Loss: 0.0994\n",
      "Epoch [113/500], Train Loss: 0.0989\n",
      "Epoch [114/500], Train Loss: 0.0996\n",
      "Epoch [115/500], Train Loss: 0.0996\n",
      "Epoch [116/500], Train Loss: 0.0998\n",
      "Epoch [117/500], Train Loss: 0.0995\n",
      "Epoch [118/500], Train Loss: 0.0991\n",
      "Epoch [119/500], Train Loss: 0.0992\n",
      "Epoch [120/500], Train Loss: 0.0981\n",
      "Epoch [121/500], Train Loss: 0.0993\n",
      "Epoch [122/500], Train Loss: 0.0997\n",
      "Epoch [123/500], Train Loss: 0.0979\n",
      "Epoch [124/500], Train Loss: 0.0987\n",
      "Epoch [125/500], Train Loss: 0.0982\n",
      "Epoch [126/500], Train Loss: 0.0990\n",
      "Epoch [127/500], Train Loss: 0.0995\n",
      "Epoch [128/500], Train Loss: 0.1000\n",
      "Epoch [129/500], Train Loss: 0.0980\n",
      "Epoch [130/500], Train Loss: 0.0974\n",
      "Epoch [131/500], Train Loss: 0.0973\n",
      "Epoch [132/500], Train Loss: 0.0989\n",
      "Epoch [133/500], Train Loss: 0.1002\n",
      "Epoch [134/500], Train Loss: 0.0992\n",
      "Epoch [135/500], Train Loss: 0.0986\n",
      "Epoch [136/500], Train Loss: 0.0972\n",
      "Epoch [137/500], Train Loss: 0.0980\n",
      "Epoch [138/500], Train Loss: 0.0972\n",
      "Epoch [139/500], Train Loss: 0.0993\n",
      "Epoch [140/500], Train Loss: 0.0981\n",
      "Epoch [141/500], Train Loss: 0.0968\n",
      "Epoch [142/500], Train Loss: 0.0975\n",
      "Epoch [143/500], Train Loss: 0.0982\n",
      "Epoch [144/500], Train Loss: 0.0997\n",
      "Epoch [145/500], Train Loss: 0.0982\n",
      "Epoch [146/500], Train Loss: 0.0979\n",
      "Epoch [147/500], Train Loss: 0.0971\n",
      "Epoch [148/500], Train Loss: 0.0969\n",
      "Epoch [149/500], Train Loss: 0.0966\n",
      "Epoch [150/500], Train Loss: 0.0979\n",
      "Epoch [151/500], Train Loss: 0.0978\n",
      "Epoch [152/500], Train Loss: 0.0977\n",
      "Epoch [153/500], Train Loss: 0.0974\n",
      "Epoch [154/500], Train Loss: 0.0967\n",
      "Epoch [155/500], Train Loss: 0.0972\n",
      "Epoch [156/500], Train Loss: 0.0971\n",
      "Epoch [157/500], Train Loss: 0.0972\n",
      "Epoch [158/500], Train Loss: 0.0973\n",
      "Epoch [159/500], Train Loss: 0.0963\n",
      "Epoch [160/500], Train Loss: 0.0962\n",
      "Epoch [161/500], Train Loss: 0.0967\n",
      "Epoch [162/500], Train Loss: 0.0978\n",
      "Epoch [163/500], Train Loss: 0.0966\n",
      "Epoch [164/500], Train Loss: 0.0972\n",
      "Epoch [165/500], Train Loss: 0.0970\n",
      "Epoch [166/500], Train Loss: 0.0972\n",
      "Epoch [167/500], Train Loss: 0.0968\n",
      "Epoch [168/500], Train Loss: 0.0964\n",
      "Epoch [169/500], Train Loss: 0.0970\n",
      "Epoch [170/500], Train Loss: 0.0973\n",
      "Epoch [171/500], Train Loss: 0.0966\n",
      "Epoch [172/500], Train Loss: 0.0966\n",
      "Epoch [173/500], Train Loss: 0.0965\n",
      "Epoch [174/500], Train Loss: 0.0969\n",
      "Epoch [175/500], Train Loss: 0.0990\n",
      "Epoch [176/500], Train Loss: 0.0973\n",
      "Epoch [177/500], Train Loss: 0.0974\n",
      "Epoch [178/500], Train Loss: 0.0957\n",
      "Epoch [179/500], Train Loss: 0.0959\n",
      "Epoch [180/500], Train Loss: 0.0969\n",
      "Epoch [181/500], Train Loss: 0.0952\n",
      "Epoch [182/500], Train Loss: 0.0958\n",
      "Epoch [183/500], Train Loss: 0.0952\n",
      "Epoch [184/500], Train Loss: 0.0966\n",
      "Epoch [185/500], Train Loss: 0.0958\n",
      "Epoch [186/500], Train Loss: 0.0962\n",
      "Epoch [187/500], Train Loss: 0.0951\n",
      "Epoch [188/500], Train Loss: 0.0966\n",
      "Epoch [189/500], Train Loss: 0.0955\n",
      "Epoch [190/500], Train Loss: 0.0977\n",
      "Epoch [191/500], Train Loss: 0.0955\n",
      "Epoch [192/500], Train Loss: 0.0966\n",
      "Epoch [193/500], Train Loss: 0.0970\n",
      "Epoch [194/500], Train Loss: 0.0967\n",
      "Epoch [195/500], Train Loss: 0.0977\n",
      "Epoch [196/500], Train Loss: 0.0977\n",
      "Epoch [197/500], Train Loss: 0.0965\n",
      "Epoch [198/500], Train Loss: 0.0963\n",
      "Epoch [199/500], Train Loss: 0.0971\n",
      "Epoch [200/500], Train Loss: 0.0953\n",
      "Epoch [201/500], Train Loss: 0.0960\n",
      "Epoch [202/500], Train Loss: 0.0960\n",
      "Epoch [203/500], Train Loss: 0.0955\n",
      "Epoch [204/500], Train Loss: 0.0953\n",
      "Epoch [205/500], Train Loss: 0.0950\n",
      "Epoch [206/500], Train Loss: 0.0955\n",
      "Epoch [207/500], Train Loss: 0.0967\n",
      "Epoch [208/500], Train Loss: 0.0986\n",
      "Epoch [209/500], Train Loss: 0.0965\n",
      "Epoch [210/500], Train Loss: 0.0961\n",
      "Epoch [211/500], Train Loss: 0.0951\n",
      "Epoch [212/500], Train Loss: 0.0948\n",
      "Epoch [213/500], Train Loss: 0.0959\n",
      "Epoch [214/500], Train Loss: 0.0961\n",
      "Epoch [215/500], Train Loss: 0.0950\n",
      "Epoch [216/500], Train Loss: 0.0957\n",
      "Epoch [217/500], Train Loss: 0.0956\n",
      "Epoch [218/500], Train Loss: 0.0954\n",
      "Epoch [219/500], Train Loss: 0.0974\n",
      "Epoch [220/500], Train Loss: 0.0981\n",
      "Epoch [221/500], Train Loss: 0.0971\n",
      "Epoch [222/500], Train Loss: 0.0953\n",
      "Epoch [223/500], Train Loss: 0.0946\n",
      "Epoch [224/500], Train Loss: 0.0961\n",
      "Epoch [225/500], Train Loss: 0.0949\n",
      "Epoch [226/500], Train Loss: 0.0951\n",
      "Epoch [227/500], Train Loss: 0.0949\n",
      "Epoch [228/500], Train Loss: 0.0947\n",
      "Epoch [229/500], Train Loss: 0.0948\n",
      "Epoch [230/500], Train Loss: 0.0943\n",
      "Epoch [231/500], Train Loss: 0.0953\n",
      "Epoch [232/500], Train Loss: 0.0946\n",
      "Epoch [233/500], Train Loss: 0.0944\n",
      "Epoch [234/500], Train Loss: 0.0942\n",
      "Epoch [235/500], Train Loss: 0.0949\n",
      "Epoch [236/500], Train Loss: 0.0953\n",
      "Epoch [237/500], Train Loss: 0.0941\n",
      "Epoch [238/500], Train Loss: 0.0947\n",
      "Epoch [239/500], Train Loss: 0.0953\n",
      "Epoch [240/500], Train Loss: 0.0950\n",
      "Epoch [241/500], Train Loss: 0.0949\n",
      "Epoch [242/500], Train Loss: 0.0949\n",
      "Epoch [243/500], Train Loss: 0.0944\n",
      "Epoch [244/500], Train Loss: 0.0953\n",
      "Epoch [245/500], Train Loss: 0.0953\n",
      "Epoch [246/500], Train Loss: 0.0941\n",
      "Epoch [247/500], Train Loss: 0.0946\n",
      "Epoch [248/500], Train Loss: 0.0951\n",
      "Epoch [249/500], Train Loss: 0.0958\n",
      "Epoch [250/500], Train Loss: 0.0955\n",
      "Epoch [251/500], Train Loss: 0.0942\n",
      "Epoch [252/500], Train Loss: 0.0946\n",
      "Epoch [253/500], Train Loss: 0.0945\n",
      "Epoch [254/500], Train Loss: 0.0950\n",
      "Epoch [255/500], Train Loss: 0.0942\n",
      "Epoch [256/500], Train Loss: 0.0953\n",
      "Early stopping at epoch 256\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr13/final_model_chr13.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr13/individual_r2_scores_chr13.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:32,868] A new study created in memory with name: no-name-8da91e03-7dce-4fdc-b29d-4cfbddd4db74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  8\n",
      "Known PRS313 SNPs:  8\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  648\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:38,351] Trial 0 finished with value: 0.0957663856446743 and parameters: {'learning_rate': 0.00048691111239657645, 'lasso_coef': 2.940389716116394e-05, 'patience': 11}. Best is trial 0 with value: 0.0957663856446743.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:44,016] Trial 1 finished with value: 0.07867088075727224 and parameters: {'learning_rate': 0.0005605013695187792, 'lasso_coef': 1.0509017766786735e-05, 'patience': 13}. Best is trial 1 with value: 0.07867088075727224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:49,594] Trial 2 finished with value: 0.10743557140231133 and parameters: {'learning_rate': 0.0004928619475219902, 'lasso_coef': 5.5600401938095914e-05, 'patience': 13}. Best is trial 1 with value: 0.07867088075727224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:18:55,068] Trial 3 finished with value: 0.21688839942216873 and parameters: {'learning_rate': 0.00011084935003069523, 'lasso_coef': 5.160561047515049e-05, 'patience': 9}. Best is trial 1 with value: 0.07867088075727224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:00,897] Trial 4 finished with value: 0.5648111999034882 and parameters: {'learning_rate': 0.0003151102118946562, 'lasso_coef': 0.012767984844706946, 'patience': 7}. Best is trial 1 with value: 0.07867088075727224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:06,515] Trial 5 finished with value: 0.13468527756631374 and parameters: {'learning_rate': 0.00024533867754394635, 'lasso_coef': 3.418955364671422e-05, 'patience': 11}. Best is trial 1 with value: 0.07867088075727224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 152\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:08,881] Trial 6 finished with value: 0.08033343330025673 and parameters: {'learning_rate': 0.003478370267226868, 'lasso_coef': 2.5938043207888786e-05, 'patience': 19}. Best is trial 1 with value: 0.07867088075727224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:19,097] Trial 7 finished with value: 0.21281174197793007 and parameters: {'learning_rate': 0.00010001659923276002, 'lasso_coef': 0.0002425601815912548, 'patience': 6}. Best is trial 1 with value: 0.07867088075727224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 33\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:19,891] Trial 8 finished with value: 0.41119428128004076 and parameters: {'learning_rate': 0.0664913475895601, 'lasso_coef': 0.002570730833438726, 'patience': 6}. Best is trial 1 with value: 0.07867088075727224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 120\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:26,635] Trial 9 finished with value: 0.2576049841940403 and parameters: {'learning_rate': 0.0006950388661414461, 'lasso_coef': 0.0016957972090197615, 'patience': 10}. Best is trial 1 with value: 0.07867088075727224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 98\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:28,897] Trial 10 finished with value: 0.7848167359828949 and parameters: {'learning_rate': 0.003762528527505145, 'lasso_coef': 0.08321962402382993, 'patience': 16}. Best is trial 1 with value: 0.07867088075727224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 28\n",
      "Early stopping at epoch 134\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:31,091] Trial 11 finished with value: 0.07461627721786498 and parameters: {'learning_rate': 0.003654731468907849, 'lasso_coef': 1.5656638845438153e-05, 'patience': 20}. Best is trial 11 with value: 0.07461627721786498.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 42\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:32,386] Trial 12 finished with value: 0.06042153220623732 and parameters: {'learning_rate': 0.022161789836492876, 'lasso_coef': 1.1125484649844705e-05, 'patience': 20}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 88\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:34,236] Trial 13 finished with value: 0.1436120171099901 and parameters: {'learning_rate': 0.02734627621244727, 'lasso_coef': 0.00024131727488701713, 'patience': 20}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 139\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:36,402] Trial 14 finished with value: 0.13749800585210323 and parameters: {'learning_rate': 0.01377207156199612, 'lasso_coef': 0.000250839115929322, 'patience': 16}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 64\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:37,860] Trial 15 finished with value: 0.06819178145378828 and parameters: {'learning_rate': 0.009089585857511316, 'lasso_coef': 1.1983825707571197e-05, 'patience': 18}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 150\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:40,071] Trial 16 finished with value: 0.10684562772512436 and parameters: {'learning_rate': 0.01060410415081375, 'lasso_coef': 0.00011526732489653371, 'patience': 17}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 63\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:41,637] Trial 17 finished with value: 0.19638083428144454 and parameters: {'learning_rate': 0.061580040260901775, 'lasso_coef': 0.00047745407712703516, 'patience': 18}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 69\n",
      "Early stopping at epoch 46\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:43,542] Trial 18 finished with value: 0.42968573421239853 and parameters: {'learning_rate': 0.009670175089056312, 'lasso_coef': 0.004805480473096455, 'patience': 15}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 91\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:45,237] Trial 19 finished with value: 0.10582185722887516 and parameters: {'learning_rate': 0.027496057300000386, 'lasso_coef': 9.281758588250115e-05, 'patience': 18}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 157\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:47,615] Trial 20 finished with value: 0.6111963152885437 and parameters: {'learning_rate': 0.0015892077253272323, 'lasso_coef': 0.02063950572567644, 'patience': 14}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 92\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:49,387] Trial 21 finished with value: 0.07016424164175987 and parameters: {'learning_rate': 0.006305977769758069, 'lasso_coef': 1.4079096477755931e-05, 'patience': 20}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 92\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:51,180] Trial 22 finished with value: 0.06887839827686548 and parameters: {'learning_rate': 0.006015629450833509, 'lasso_coef': 1.1804325199039497e-05, 'patience': 20}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 42\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:52,379] Trial 23 finished with value: 0.06351117035374046 and parameters: {'learning_rate': 0.02051298900396418, 'lasso_coef': 1.2392748945335014e-05, 'patience': 18}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 69\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:53,864] Trial 24 finished with value: 0.10001191273331642 and parameters: {'learning_rate': 0.023901603183132045, 'lasso_coef': 8.138969426214189e-05, 'patience': 18}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 34\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:54,926] Trial 25 finished with value: 0.07047246042639017 and parameters: {'learning_rate': 0.04160719507731104, 'lasso_coef': 2.409678767584668e-05, 'patience': 17}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 32\n",
      "Early stopping at epoch 45\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:56,466] Trial 26 finished with value: 0.26410945504903793 and parameters: {'learning_rate': 0.0981884091806735, 'lasso_coef': 0.0008503038034783055, 'patience': 15}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 24\n",
      "Early stopping at epoch 125\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:19:58,633] Trial 27 finished with value: 0.11008571684360505 and parameters: {'learning_rate': 0.017023921237721697, 'lasso_coef': 0.0001244768715952469, 'patience': 19}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 225\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:01,629] Trial 28 finished with value: 0.07664527427405118 and parameters: {'learning_rate': 0.0015752472787160163, 'lasso_coef': 1.0045151767727908e-05, 'patience': 17}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 55\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:02,981] Trial 29 finished with value: 0.06977579984813928 and parameters: {'learning_rate': 0.019076370610397787, 'lasso_coef': 2.2689827780173758e-05, 'patience': 19}. Best is trial 12 with value: 0.06042153220623732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Best hyperparameters: {'learning_rate': 0.022161789836492876, 'lasso_coef': 1.1125484649844705e-05, 'patience': 20}\n",
      "Best value: 0.06042153220623732\n",
      "Epoch [1/500], Train Loss: 0.6759\n",
      "Epoch [2/500], Train Loss: 0.3411\n",
      "Epoch [3/500], Train Loss: 0.2377\n",
      "Epoch [4/500], Train Loss: 0.1936\n",
      "Epoch [5/500], Train Loss: 0.1674\n",
      "Epoch [6/500], Train Loss: 0.1494\n",
      "Epoch [7/500], Train Loss: 0.1345\n",
      "Epoch [8/500], Train Loss: 0.1228\n",
      "Epoch [9/500], Train Loss: 0.1139\n",
      "Epoch [10/500], Train Loss: 0.1063\n",
      "Epoch [11/500], Train Loss: 0.1015\n",
      "Epoch [12/500], Train Loss: 0.0965\n",
      "Epoch [13/500], Train Loss: 0.0909\n",
      "Epoch [14/500], Train Loss: 0.0876\n",
      "Epoch [15/500], Train Loss: 0.0827\n",
      "Epoch [16/500], Train Loss: 0.0799\n",
      "Epoch [17/500], Train Loss: 0.0767\n",
      "Epoch [18/500], Train Loss: 0.0745\n",
      "Epoch [19/500], Train Loss: 0.0713\n",
      "Epoch [20/500], Train Loss: 0.0687\n",
      "Epoch [21/500], Train Loss: 0.0666\n",
      "Epoch [22/500], Train Loss: 0.0646\n",
      "Epoch [23/500], Train Loss: 0.0627\n",
      "Epoch [24/500], Train Loss: 0.0619\n",
      "Epoch [25/500], Train Loss: 0.0588\n",
      "Epoch [26/500], Train Loss: 0.0588\n",
      "Epoch [27/500], Train Loss: 0.0574\n",
      "Epoch [28/500], Train Loss: 0.0571\n",
      "Epoch [29/500], Train Loss: 0.0552\n",
      "Epoch [30/500], Train Loss: 0.0535\n",
      "Epoch [31/500], Train Loss: 0.0521\n",
      "Epoch [32/500], Train Loss: 0.0504\n",
      "Epoch [33/500], Train Loss: 0.0493\n",
      "Epoch [34/500], Train Loss: 0.0500\n",
      "Epoch [35/500], Train Loss: 0.0485\n",
      "Epoch [36/500], Train Loss: 0.0474\n",
      "Epoch [37/500], Train Loss: 0.0467\n",
      "Epoch [38/500], Train Loss: 0.0451\n",
      "Epoch [39/500], Train Loss: 0.0446\n",
      "Epoch [40/500], Train Loss: 0.0440\n",
      "Epoch [41/500], Train Loss: 0.0438\n",
      "Epoch [42/500], Train Loss: 0.0433\n",
      "Epoch [43/500], Train Loss: 0.0422\n",
      "Epoch [44/500], Train Loss: 0.0419\n",
      "Epoch [45/500], Train Loss: 0.0410\n",
      "Epoch [46/500], Train Loss: 0.0410\n",
      "Epoch [47/500], Train Loss: 0.0405\n",
      "Epoch [48/500], Train Loss: 0.0394\n",
      "Epoch [49/500], Train Loss: 0.0389\n",
      "Epoch [50/500], Train Loss: 0.0387\n",
      "Epoch [51/500], Train Loss: 0.0379\n",
      "Epoch [52/500], Train Loss: 0.0382\n",
      "Epoch [53/500], Train Loss: 0.0376\n",
      "Epoch [54/500], Train Loss: 0.0375\n",
      "Epoch [55/500], Train Loss: 0.0362\n",
      "Epoch [56/500], Train Loss: 0.0358\n",
      "Epoch [57/500], Train Loss: 0.0363\n",
      "Epoch [58/500], Train Loss: 0.0356\n",
      "Epoch [59/500], Train Loss: 0.0351\n",
      "Epoch [60/500], Train Loss: 0.0350\n",
      "Epoch [61/500], Train Loss: 0.0350\n",
      "Epoch [62/500], Train Loss: 0.0345\n",
      "Epoch [63/500], Train Loss: 0.0339\n",
      "Epoch [64/500], Train Loss: 0.0337\n",
      "Epoch [65/500], Train Loss: 0.0342\n",
      "Epoch [66/500], Train Loss: 0.0343\n",
      "Epoch [67/500], Train Loss: 0.0335\n",
      "Epoch [68/500], Train Loss: 0.0328\n",
      "Epoch [69/500], Train Loss: 0.0328\n",
      "Epoch [70/500], Train Loss: 0.0323\n",
      "Epoch [71/500], Train Loss: 0.0320\n",
      "Epoch [72/500], Train Loss: 0.0318\n",
      "Epoch [73/500], Train Loss: 0.0312\n",
      "Epoch [74/500], Train Loss: 0.0314\n",
      "Epoch [75/500], Train Loss: 0.0315\n",
      "Epoch [76/500], Train Loss: 0.0308\n",
      "Epoch [77/500], Train Loss: 0.0305\n",
      "Epoch [78/500], Train Loss: 0.0309\n",
      "Epoch [79/500], Train Loss: 0.0305\n",
      "Epoch [80/500], Train Loss: 0.0307\n",
      "Epoch [81/500], Train Loss: 0.0304\n",
      "Epoch [82/500], Train Loss: 0.0300\n",
      "Epoch [83/500], Train Loss: 0.0296\n",
      "Epoch [84/500], Train Loss: 0.0295\n",
      "Epoch [85/500], Train Loss: 0.0296\n",
      "Epoch [86/500], Train Loss: 0.0294\n",
      "Epoch [87/500], Train Loss: 0.0292\n",
      "Epoch [88/500], Train Loss: 0.0289\n",
      "Epoch [89/500], Train Loss: 0.0295\n",
      "Epoch [90/500], Train Loss: 0.0291\n",
      "Epoch [91/500], Train Loss: 0.0289\n",
      "Epoch [92/500], Train Loss: 0.0287\n",
      "Epoch [93/500], Train Loss: 0.0288\n",
      "Epoch [94/500], Train Loss: 0.0288\n",
      "Epoch [95/500], Train Loss: 0.0284\n",
      "Epoch [96/500], Train Loss: 0.0279\n",
      "Epoch [97/500], Train Loss: 0.0284\n",
      "Epoch [98/500], Train Loss: 0.0285\n",
      "Epoch [99/500], Train Loss: 0.0279\n",
      "Epoch [100/500], Train Loss: 0.0278\n",
      "Epoch [101/500], Train Loss: 0.0277\n",
      "Epoch [102/500], Train Loss: 0.0275\n",
      "Epoch [103/500], Train Loss: 0.0272\n",
      "Epoch [104/500], Train Loss: 0.0273\n",
      "Epoch [105/500], Train Loss: 0.0271\n",
      "Epoch [106/500], Train Loss: 0.0270\n",
      "Epoch [107/500], Train Loss: 0.0269\n",
      "Epoch [108/500], Train Loss: 0.0266\n",
      "Epoch [109/500], Train Loss: 0.0265\n",
      "Epoch [110/500], Train Loss: 0.0272\n",
      "Epoch [111/500], Train Loss: 0.0268\n",
      "Epoch [112/500], Train Loss: 0.0268\n",
      "Epoch [113/500], Train Loss: 0.0269\n",
      "Epoch [114/500], Train Loss: 0.0270\n",
      "Epoch [115/500], Train Loss: 0.0267\n",
      "Epoch [116/500], Train Loss: 0.0274\n",
      "Epoch [117/500], Train Loss: 0.0263\n",
      "Epoch [118/500], Train Loss: 0.0266\n",
      "Epoch [119/500], Train Loss: 0.0262\n",
      "Epoch [120/500], Train Loss: 0.0262\n",
      "Epoch [121/500], Train Loss: 0.0257\n",
      "Epoch [122/500], Train Loss: 0.0258\n",
      "Epoch [123/500], Train Loss: 0.0255\n",
      "Epoch [124/500], Train Loss: 0.0257\n",
      "Epoch [125/500], Train Loss: 0.0256\n",
      "Epoch [126/500], Train Loss: 0.0257\n",
      "Epoch [127/500], Train Loss: 0.0255\n",
      "Epoch [128/500], Train Loss: 0.0254\n",
      "Epoch [129/500], Train Loss: 0.0258\n",
      "Epoch [130/500], Train Loss: 0.0258\n",
      "Epoch [131/500], Train Loss: 0.0253\n",
      "Epoch [132/500], Train Loss: 0.0255\n",
      "Epoch [133/500], Train Loss: 0.0253\n",
      "Epoch [134/500], Train Loss: 0.0251\n",
      "Epoch [135/500], Train Loss: 0.0250\n",
      "Epoch [136/500], Train Loss: 0.0250\n",
      "Epoch [137/500], Train Loss: 0.0252\n",
      "Epoch [138/500], Train Loss: 0.0249\n",
      "Epoch [139/500], Train Loss: 0.0249\n",
      "Epoch [140/500], Train Loss: 0.0251\n",
      "Epoch [141/500], Train Loss: 0.0248\n",
      "Epoch [142/500], Train Loss: 0.0249\n",
      "Epoch [143/500], Train Loss: 0.0247\n",
      "Epoch [144/500], Train Loss: 0.0254\n",
      "Epoch [145/500], Train Loss: 0.0248\n",
      "Epoch [146/500], Train Loss: 0.0244\n",
      "Epoch [147/500], Train Loss: 0.0244\n",
      "Epoch [148/500], Train Loss: 0.0244\n",
      "Epoch [149/500], Train Loss: 0.0249\n",
      "Epoch [150/500], Train Loss: 0.0248\n",
      "Epoch [151/500], Train Loss: 0.0243\n",
      "Epoch [152/500], Train Loss: 0.0249\n",
      "Epoch [153/500], Train Loss: 0.0248\n",
      "Epoch [154/500], Train Loss: 0.0246\n",
      "Epoch [155/500], Train Loss: 0.0248\n",
      "Epoch [156/500], Train Loss: 0.0243\n",
      "Epoch [157/500], Train Loss: 0.0241\n",
      "Epoch [158/500], Train Loss: 0.0240\n",
      "Epoch [159/500], Train Loss: 0.0242\n",
      "Epoch [160/500], Train Loss: 0.0243\n",
      "Epoch [161/500], Train Loss: 0.0239\n",
      "Epoch [162/500], Train Loss: 0.0239\n",
      "Epoch [163/500], Train Loss: 0.0238\n",
      "Epoch [164/500], Train Loss: 0.0240\n",
      "Epoch [165/500], Train Loss: 0.0239\n",
      "Epoch [166/500], Train Loss: 0.0239\n",
      "Epoch [167/500], Train Loss: 0.0239\n",
      "Epoch [168/500], Train Loss: 0.0237\n",
      "Epoch [169/500], Train Loss: 0.0238\n",
      "Epoch [170/500], Train Loss: 0.0238\n",
      "Epoch [171/500], Train Loss: 0.0240\n",
      "Epoch [172/500], Train Loss: 0.0238\n",
      "Epoch [173/500], Train Loss: 0.0239\n",
      "Epoch [174/500], Train Loss: 0.0236\n",
      "Epoch [175/500], Train Loss: 0.0234\n",
      "Epoch [176/500], Train Loss: 0.0234\n",
      "Epoch [177/500], Train Loss: 0.0234\n",
      "Epoch [178/500], Train Loss: 0.0235\n",
      "Epoch [179/500], Train Loss: 0.0237\n",
      "Epoch [180/500], Train Loss: 0.0235\n",
      "Epoch [181/500], Train Loss: 0.0237\n",
      "Epoch [182/500], Train Loss: 0.0234\n",
      "Epoch [183/500], Train Loss: 0.0232\n",
      "Epoch [184/500], Train Loss: 0.0230\n",
      "Epoch [185/500], Train Loss: 0.0231\n",
      "Epoch [186/500], Train Loss: 0.0232\n",
      "Epoch [187/500], Train Loss: 0.0234\n",
      "Epoch [188/500], Train Loss: 0.0235\n",
      "Epoch [189/500], Train Loss: 0.0235\n",
      "Epoch [190/500], Train Loss: 0.0234\n",
      "Epoch [191/500], Train Loss: 0.0233\n",
      "Epoch [192/500], Train Loss: 0.0242\n",
      "Epoch [193/500], Train Loss: 0.0237\n",
      "Epoch [194/500], Train Loss: 0.0236\n",
      "Epoch [195/500], Train Loss: 0.0230\n",
      "Epoch [196/500], Train Loss: 0.0228\n",
      "Epoch [197/500], Train Loss: 0.0229\n",
      "Epoch [198/500], Train Loss: 0.0232\n",
      "Epoch [199/500], Train Loss: 0.0236\n",
      "Epoch [200/500], Train Loss: 0.0236\n",
      "Epoch [201/500], Train Loss: 0.0238\n",
      "Epoch [202/500], Train Loss: 0.0235\n",
      "Epoch [203/500], Train Loss: 0.0230\n",
      "Epoch [204/500], Train Loss: 0.0231\n",
      "Epoch [205/500], Train Loss: 0.0233\n",
      "Epoch [206/500], Train Loss: 0.0232\n",
      "Epoch [207/500], Train Loss: 0.0231\n",
      "Epoch [208/500], Train Loss: 0.0227\n",
      "Epoch [209/500], Train Loss: 0.0227\n",
      "Epoch [210/500], Train Loss: 0.0228\n",
      "Epoch [211/500], Train Loss: 0.0228\n",
      "Epoch [212/500], Train Loss: 0.0224\n",
      "Epoch [213/500], Train Loss: 0.0228\n",
      "Epoch [214/500], Train Loss: 0.0227\n",
      "Epoch [215/500], Train Loss: 0.0228\n",
      "Epoch [216/500], Train Loss: 0.0229\n",
      "Epoch [217/500], Train Loss: 0.0231\n",
      "Epoch [218/500], Train Loss: 0.0227\n",
      "Epoch [219/500], Train Loss: 0.0226\n",
      "Epoch [220/500], Train Loss: 0.0224\n",
      "Epoch [221/500], Train Loss: 0.0229\n",
      "Epoch [222/500], Train Loss: 0.0231\n",
      "Epoch [223/500], Train Loss: 0.0226\n",
      "Epoch [224/500], Train Loss: 0.0227\n",
      "Epoch [225/500], Train Loss: 0.0230\n",
      "Epoch [226/500], Train Loss: 0.0235\n",
      "Epoch [227/500], Train Loss: 0.0225\n",
      "Epoch [228/500], Train Loss: 0.0228\n",
      "Epoch [229/500], Train Loss: 0.0230\n",
      "Epoch [230/500], Train Loss: 0.0226\n",
      "Epoch [231/500], Train Loss: 0.0225\n",
      "Epoch [232/500], Train Loss: 0.0223\n",
      "Epoch [233/500], Train Loss: 0.0224\n",
      "Epoch [234/500], Train Loss: 0.0229\n",
      "Epoch [235/500], Train Loss: 0.0230\n",
      "Epoch [236/500], Train Loss: 0.0232\n",
      "Epoch [237/500], Train Loss: 0.0234\n",
      "Epoch [238/500], Train Loss: 0.0227\n",
      "Epoch [239/500], Train Loss: 0.0220\n",
      "Epoch [240/500], Train Loss: 0.0221\n",
      "Epoch [241/500], Train Loss: 0.0219\n",
      "Epoch [242/500], Train Loss: 0.0222\n",
      "Epoch [243/500], Train Loss: 0.0223\n",
      "Epoch [244/500], Train Loss: 0.0226\n",
      "Epoch [245/500], Train Loss: 0.0224\n",
      "Epoch [246/500], Train Loss: 0.0220\n",
      "Epoch [247/500], Train Loss: 0.0221\n",
      "Epoch [248/500], Train Loss: 0.0223\n",
      "Epoch [249/500], Train Loss: 0.0223\n",
      "Epoch [250/500], Train Loss: 0.0224\n",
      "Epoch [251/500], Train Loss: 0.0220\n",
      "Epoch [252/500], Train Loss: 0.0219\n",
      "Epoch [253/500], Train Loss: 0.0219\n",
      "Epoch [254/500], Train Loss: 0.0220\n",
      "Epoch [255/500], Train Loss: 0.0227\n",
      "Epoch [256/500], Train Loss: 0.0225\n",
      "Epoch [257/500], Train Loss: 0.0224\n",
      "Epoch [258/500], Train Loss: 0.0225\n",
      "Epoch [259/500], Train Loss: 0.0224\n",
      "Epoch [260/500], Train Loss: 0.0221\n",
      "Epoch [261/500], Train Loss: 0.0225\n",
      "Epoch [262/500], Train Loss: 0.0225\n",
      "Epoch [263/500], Train Loss: 0.0221\n",
      "Epoch [264/500], Train Loss: 0.0220\n",
      "Epoch [265/500], Train Loss: 0.0225\n",
      "Epoch [266/500], Train Loss: 0.0225\n",
      "Epoch [267/500], Train Loss: 0.0227\n",
      "Epoch [268/500], Train Loss: 0.0234\n",
      "Epoch [269/500], Train Loss: 0.0228\n",
      "Epoch [270/500], Train Loss: 0.0222\n",
      "Epoch [271/500], Train Loss: 0.0221\n",
      "Epoch [272/500], Train Loss: 0.0221\n",
      "Epoch [273/500], Train Loss: 0.0225\n",
      "Early stopping at epoch 273\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr14/final_model_chr14.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr14/individual_r2_scores_chr14.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:06,437] A new study created in memory with name: no-name-54f2c98e-2294-49b0-bf27-be3766e69163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  10\n",
      "Known PRS313 SNPs:  4\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  444\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:12,226] Trial 0 finished with value: 0.49001934826374055 and parameters: {'learning_rate': 0.0011966211635450854, 'lasso_coef': 0.015195642999503142, 'patience': 20}. Best is trial 0 with value: 0.49001934826374055.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 215\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:14,688] Trial 1 finished with value: 0.07698174268007278 and parameters: {'learning_rate': 0.002708058683250029, 'lasso_coef': 3.118216381535944e-05, 'patience': 9}. Best is trial 1 with value: 0.07698174268007278.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 116\n",
      "Early stopping at epoch 55\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:17,123] Trial 2 finished with value: 0.624449959397316 and parameters: {'learning_rate': 0.002607404817517893, 'lasso_coef': 0.09845069950016856, 'patience': 14}. Best is trial 1 with value: 0.07698174268007278.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 42\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:34,841] Trial 3 finished with value: 0.33659839630126953 and parameters: {'learning_rate': 0.00023496337409718962, 'lasso_coef': 0.003526395258341412, 'patience': 15}. Best is trial 1 with value: 0.07698174268007278.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 308\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 231\n",
      "Early stopping at epoch 57\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:38,562] Trial 4 finished with value: 0.5566697835922241 and parameters: {'learning_rate': 0.002498299311162556, 'lasso_coef': 0.05184723505583942, 'patience': 20}. Best is trial 1 with value: 0.07698174268007278.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 57\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:39,668] Trial 5 finished with value: 0.06644775103777648 and parameters: {'learning_rate': 0.00936872357820755, 'lasso_coef': 1.3173132476761268e-05, 'patience': 12}. Best is trial 5 with value: 0.06644775103777648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 317\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 75\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:43,812] Trial 6 finished with value: 0.5073971331119538 and parameters: {'learning_rate': 0.0010693101665853243, 'lasso_coef': 0.0284990349747375, 'patience': 10}. Best is trial 5 with value: 0.06644775103777648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 407\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:48,732] Trial 7 finished with value: 0.53532924503088 and parameters: {'learning_rate': 0.001730733220882147, 'lasso_coef': 0.052742447094909405, 'patience': 18}. Best is trial 5 with value: 0.06644775103777648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:49,287] Trial 8 finished with value: 0.6110010594129562 and parameters: {'learning_rate': 0.05393757597315747, 'lasso_coef': 0.006770670695545883, 'patience': 5}. Best is trial 5 with value: 0.06644775103777648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:49,858] Trial 9 finished with value: 0.08664862364530564 and parameters: {'learning_rate': 0.06325785400738033, 'lasso_coef': 4.047290758404945e-05, 'patience': 8}. Best is trial 5 with value: 0.06644775103777648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 91\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:51,275] Trial 10 finished with value: 0.1372263863682747 and parameters: {'learning_rate': 0.023529912623291446, 'lasso_coef': 0.00022303276297441465, 'patience': 12}. Best is trial 5 with value: 0.06644775103777648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 64\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:52,301] Trial 11 finished with value: 0.06285888720303774 and parameters: {'learning_rate': 0.010707907307103696, 'lasso_coef': 1.236351422784369e-05, 'patience': 8}. Best is trial 11 with value: 0.06285888720303774.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 48\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:53,052] Trial 12 finished with value: 0.06644911859184503 and parameters: {'learning_rate': 0.011794386159368805, 'lasso_coef': 1.2189520865746394e-05, 'patience': 6}. Best is trial 11 with value: 0.06285888720303774.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 174\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:55,234] Trial 13 finished with value: 0.13363510333001613 and parameters: {'learning_rate': 0.008974936545277127, 'lasso_coef': 0.0002560255525427067, 'patience': 11}. Best is trial 11 with value: 0.06285888720303774.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 65\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:56,184] Trial 14 finished with value: 0.06290028747171164 and parameters: {'learning_rate': 0.00940926178634339, 'lasso_coef': 1.024057975322514e-05, 'patience': 7}. Best is trial 11 with value: 0.06285888720303774.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 34\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:20:56,846] Trial 15 finished with value: 0.1250489391386509 and parameters: {'learning_rate': 0.026329170491865495, 'lasso_coef': 0.00014668942468864304, 'patience': 7}. Best is trial 11 with value: 0.06285888720303774.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:06,941] Trial 16 finished with value: 0.21557717323303222 and parameters: {'learning_rate': 0.0002903267321193319, 'lasso_coef': 0.0009200463300157587, 'patience': 5}. Best is trial 11 with value: 0.06285888720303774.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 99\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:08,253] Trial 17 finished with value: 0.09119161330163479 and parameters: {'learning_rate': 0.005792013532146587, 'lasso_coef': 5.471753291685027e-05, 'patience': 8}. Best is trial 11 with value: 0.06285888720303774.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 81\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:09,758] Trial 18 finished with value: 0.2227640174329281 and parameters: {'learning_rate': 0.02325625393597991, 'lasso_coef': 0.0010142312402128598, 'patience': 14}. Best is trial 11 with value: 0.06285888720303774.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:15,116] Trial 19 finished with value: 0.10792679227888584 and parameters: {'learning_rate': 0.0005925342154723483, 'lasso_coef': 9.107773941524231e-05, 'patience': 10}. Best is trial 11 with value: 0.06285888720303774.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 42\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:15,834] Trial 20 finished with value: 0.06192018520087004 and parameters: {'learning_rate': 0.09625772462109966, 'lasso_coef': 1.0842456778477873e-05, 'patience': 7}. Best is trial 20 with value: 0.06192018520087004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 36\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:16,496] Trial 21 finished with value: 0.065420644544065 and parameters: {'learning_rate': 0.08937692276554157, 'lasso_coef': 1.1377460952595112e-05, 'patience': 7}. Best is trial 20 with value: 0.06192018520087004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:26,407] Trial 22 finished with value: 0.13127259872853755 and parameters: {'learning_rate': 0.00011168213089512546, 'lasso_coef': 2.5614945821376015e-05, 'patience': 7}. Best is trial 20 with value: 0.06192018520087004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 30\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:27,095] Trial 23 finished with value: 0.07150718420743943 and parameters: {'learning_rate': 0.032676356391501425, 'lasso_coef': 2.4425421587022028e-05, 'patience': 9}. Best is trial 20 with value: 0.06192018520087004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 130\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:28,599] Trial 24 finished with value: 0.09788790494203567 and parameters: {'learning_rate': 0.004946196102298454, 'lasso_coef': 7.53965476836219e-05, 'patience': 5}. Best is trial 20 with value: 0.06192018520087004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 127\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:30,271] Trial 25 finished with value: 0.1717190183699131 and parameters: {'learning_rate': 0.015982227482249166, 'lasso_coef': 0.0005209206920173456, 'patience': 8}. Best is trial 20 with value: 0.06192018520087004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 103\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:31,588] Trial 26 finished with value: 0.06722639426589012 and parameters: {'learning_rate': 0.004697392722858132, 'lasso_coef': 1.07099806905762e-05, 'patience': 6}. Best is trial 20 with value: 0.06192018520087004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 26\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:32,344] Trial 27 finished with value: 0.07005329467356206 and parameters: {'learning_rate': 0.04580772829604472, 'lasso_coef': 2.3306966670586866e-05, 'patience': 10}. Best is trial 20 with value: 0.06192018520087004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 58\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:33,204] Trial 28 finished with value: 0.11115786172449589 and parameters: {'learning_rate': 0.013467686305988874, 'lasso_coef': 0.00011125941425075252, 'patience': 6}. Best is trial 20 with value: 0.06192018520087004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 35\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:34,216] Trial 29 finished with value: 0.10012307614088059 and parameters: {'learning_rate': 0.08672693534332784, 'lasso_coef': 5.090346035221449e-05, 'patience': 16}. Best is trial 20 with value: 0.06192018520087004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Best hyperparameters: {'learning_rate': 0.09625772462109966, 'lasso_coef': 1.0842456778477873e-05, 'patience': 7}\n",
      "Best value: 0.06192018520087004\n",
      "Epoch [1/500], Train Loss: 0.9092\n",
      "Epoch [2/500], Train Loss: 0.3364\n",
      "Epoch [3/500], Train Loss: 0.2393\n",
      "Epoch [4/500], Train Loss: 0.2142\n",
      "Epoch [5/500], Train Loss: 0.1934\n",
      "Epoch [6/500], Train Loss: 0.1828\n",
      "Epoch [7/500], Train Loss: 0.1776\n",
      "Epoch [8/500], Train Loss: 0.1720\n",
      "Epoch [9/500], Train Loss: 0.1652\n",
      "Epoch [10/500], Train Loss: 0.1598\n",
      "Epoch [11/500], Train Loss: 0.1535\n",
      "Epoch [12/500], Train Loss: 0.1472\n",
      "Epoch [13/500], Train Loss: 0.1464\n",
      "Epoch [14/500], Train Loss: 0.1413\n",
      "Epoch [15/500], Train Loss: 0.1321\n",
      "Epoch [16/500], Train Loss: 0.1322\n",
      "Epoch [17/500], Train Loss: 0.1279\n",
      "Epoch [18/500], Train Loss: 0.1199\n",
      "Epoch [19/500], Train Loss: 0.1182\n",
      "Epoch [20/500], Train Loss: 0.0986\n",
      "Epoch [21/500], Train Loss: 0.0801\n",
      "Epoch [22/500], Train Loss: 0.0737\n",
      "Epoch [23/500], Train Loss: 0.0707\n",
      "Epoch [24/500], Train Loss: 0.0584\n",
      "Epoch [25/500], Train Loss: 0.0503\n",
      "Epoch [26/500], Train Loss: 0.0491\n",
      "Epoch [27/500], Train Loss: 0.0474\n",
      "Epoch [28/500], Train Loss: 0.0443\n",
      "Epoch [29/500], Train Loss: 0.0435\n",
      "Epoch [30/500], Train Loss: 0.0455\n",
      "Epoch [31/500], Train Loss: 0.0438\n",
      "Epoch [32/500], Train Loss: 0.0437\n",
      "Epoch [33/500], Train Loss: 0.0432\n",
      "Epoch [34/500], Train Loss: 0.0428\n",
      "Epoch [35/500], Train Loss: 0.0430\n",
      "Epoch [36/500], Train Loss: 0.0425\n",
      "Epoch [37/500], Train Loss: 0.0432\n",
      "Epoch [38/500], Train Loss: 0.0412\n",
      "Epoch [39/500], Train Loss: 0.0395\n",
      "Epoch [40/500], Train Loss: 0.0406\n",
      "Epoch [41/500], Train Loss: 0.0398\n",
      "Epoch [42/500], Train Loss: 0.0379\n",
      "Epoch [43/500], Train Loss: 0.0403\n",
      "Epoch [44/500], Train Loss: 0.0419\n",
      "Epoch [45/500], Train Loss: 0.0434\n",
      "Epoch [46/500], Train Loss: 0.0430\n",
      "Epoch [47/500], Train Loss: 0.0422\n",
      "Epoch [48/500], Train Loss: 0.0411\n",
      "Epoch [49/500], Train Loss: 0.0407\n",
      "Early stopping at epoch 49\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr15/final_model_chr15.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr15/individual_r2_scores_chr15.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:35,264] A new study created in memory with name: no-name-618e1f64-cf0b-4693-b805-3768f23bf77b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  22\n",
      "Known PRS313 SNPs:  6\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  882\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:36,346] Trial 0 finished with value: 0.1189997423440218 and parameters: {'learning_rate': 0.037070950122038114, 'lasso_coef': 2.9661011195005724e-05, 'patience': 11}. Best is trial 0 with value: 0.1189997423440218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 35\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:37,692] Trial 1 finished with value: 0.12488452605903148 and parameters: {'learning_rate': 0.03534605004562118, 'lasso_coef': 3.373163939773014e-05, 'patience': 15}. Best is trial 0 with value: 0.1189997423440218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:45,372] Trial 2 finished with value: 0.3557765483856201 and parameters: {'learning_rate': 0.0007574942845836575, 'lasso_coef': 0.0019238076029573753, 'patience': 11}. Best is trial 0 with value: 0.1189997423440218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 53\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:46,916] Trial 3 finished with value: 0.46386922895908356 and parameters: {'learning_rate': 0.011076893926081383, 'lasso_coef': 0.0025957269036884748, 'patience': 8}. Best is trial 0 with value: 0.1189997423440218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 353\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:52,148] Trial 4 finished with value: 0.15636441931128503 and parameters: {'learning_rate': 0.0014575446804907305, 'lasso_coef': 0.00012324872635080793, 'patience': 8}. Best is trial 0 with value: 0.1189997423440218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:21:53,138] Trial 5 finished with value: 3.310340440273285 and parameters: {'learning_rate': 0.06413974408122207, 'lasso_coef': 0.018787067985963222, 'patience': 9}. Best is trial 0 with value: 0.1189997423440218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:22:14,289] Trial 6 finished with value: 0.35256433486938477 and parameters: {'learning_rate': 0.0002021663130613477, 'lasso_coef': 0.0017091597836724833, 'patience': 18}. Best is trial 0 with value: 0.1189997423440218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:22:22,228] Trial 7 finished with value: 0.1088420644402504 and parameters: {'learning_rate': 0.00031324251688010326, 'lasso_coef': 1.1104448262418137e-05, 'patience': 19}. Best is trial 7 with value: 0.1088420644402504.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:22:41,922] Trial 8 finished with value: 0.4867041423916817 and parameters: {'learning_rate': 0.0001526084200354808, 'lasso_coef': 0.012951334563123315, 'patience': 9}. Best is trial 7 with value: 0.1088420644402504.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 447\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:22:55,296] Trial 9 finished with value: 0.2596587993204594 and parameters: {'learning_rate': 0.00043737054528326935, 'lasso_coef': 0.0007087304981313978, 'patience': 9}. Best is trial 7 with value: 0.1088420644402504.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 138\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:22:58,399] Trial 10 finished with value: 0.09290815740823746 and parameters: {'learning_rate': 0.0027589566046092896, 'lasso_coef': 1.127744254572015e-05, 'patience': 20}. Best is trial 10 with value: 0.09290815740823746.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 64\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:00,429] Trial 11 finished with value: 0.09093892015516758 and parameters: {'learning_rate': 0.006193308223114925, 'lasso_coef': 1.0659489777504536e-05, 'patience': 20}. Best is trial 11 with value: 0.09093892015516758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 190\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:03,901] Trial 12 finished with value: 0.16690803691744804 and parameters: {'learning_rate': 0.004636595273726944, 'lasso_coef': 0.00015133528423413425, 'patience': 16}. Best is trial 11 with value: 0.09093892015516758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 84\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:06,166] Trial 13 finished with value: 0.09188659396022558 and parameters: {'learning_rate': 0.00607246698451145, 'lasso_coef': 1.329708147303492e-05, 'patience': 20}. Best is trial 11 with value: 0.09093892015516758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 78\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:07,649] Trial 14 finished with value: 0.18077122792601585 and parameters: {'learning_rate': 0.007726840676637032, 'lasso_coef': 0.00016382939294006953, 'patience': 5}. Best is trial 11 with value: 0.09093892015516758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 52\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:09,310] Trial 15 finished with value: 0.13614836819469928 and parameters: {'learning_rate': 0.014491925390991067, 'lasso_coef': 5.693215234887753e-05, 'patience': 16}. Best is trial 11 with value: 0.09093892015516758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 178\n",
      "Early stopping at epoch 36\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:13,395] Trial 16 finished with value: 0.9267553210258483 and parameters: {'learning_rate': 0.0032011024070072195, 'lasso_coef': 0.06553399283959185, 'patience': 18}. Best is trial 11 with value: 0.09093892015516758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 32\n",
      "Early stopping at epoch 473\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:20,679] Trial 17 finished with value: 0.22862752750515938 and parameters: {'learning_rate': 0.0012193371164618504, 'lasso_coef': 0.0005027795106979666, 'patience': 14}. Best is trial 11 with value: 0.09093892015516758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 40\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:22,356] Trial 18 finished with value: 0.1034979522228241 and parameters: {'learning_rate': 0.020203677441447108, 'lasso_coef': 2.2139078039942533e-05, 'patience': 20}. Best is trial 11 with value: 0.09093892015516758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 163\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:25,607] Trial 19 finished with value: 0.13819791488349437 and parameters: {'learning_rate': 0.006917986218253713, 'lasso_coef': 7.328794129300736e-05, 'patience': 17}. Best is trial 11 with value: 0.09093892015516758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 342\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:31,002] Trial 20 finished with value: 0.21896922513842582 and parameters: {'learning_rate': 0.0023903300904909545, 'lasso_coef': 0.00043153496604342886, 'patience': 13}. Best is trial 11 with value: 0.09093892015516758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 207\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:34,898] Trial 21 finished with value: 0.09632759541273117 and parameters: {'learning_rate': 0.0025288481032705486, 'lasso_coef': 1.819619260874869e-05, 'patience': 20}. Best is trial 11 with value: 0.09093892015516758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 94\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:37,318] Trial 22 finished with value: 0.09130544885993004 and parameters: {'learning_rate': 0.0056589811414164476, 'lasso_coef': 1.342102488834291e-05, 'patience': 20}. Best is trial 11 with value: 0.09093892015516758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 147\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:40,474] Trial 23 finished with value: 0.12913952320814132 and parameters: {'learning_rate': 0.005322620596492215, 'lasso_coef': 5.818527350421137e-05, 'patience': 18}. Best is trial 11 with value: 0.09093892015516758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 36\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:42,246] Trial 24 finished with value: 0.0858852269127965 and parameters: {'learning_rate': 0.022205029436840558, 'lasso_coef': 1.0437368120371556e-05, 'patience': 19}. Best is trial 24 with value: 0.0858852269127965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 49\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:44,028] Trial 25 finished with value: 0.11599254757165908 and parameters: {'learning_rate': 0.02225491476973833, 'lasso_coef': 3.305237879563876e-05, 'patience': 17}. Best is trial 24 with value: 0.0858852269127965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 72\n",
      "Early stopping at epoch 37\n",
      "Early stopping at epoch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:47,255] Trial 26 finished with value: 3.8168938398361205 and parameters: {'learning_rate': 0.09252251472415689, 'lasso_coef': 1.0764974014958654e-05, 'patience': 19}. Best is trial 24 with value: 0.0858852269127965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 147\n",
      "Early stopping at epoch 23\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:50,386] Trial 27 finished with value: 0.21947124525904654 and parameters: {'learning_rate': 0.01497143270350515, 'lasso_coef': 0.0003266454131604908, 'patience': 19}. Best is trial 24 with value: 0.0858852269127965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 47\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:51,943] Trial 28 finished with value: 0.16086057126522063 and parameters: {'learning_rate': 0.033908855290929, 'lasso_coef': 6.75862754732899e-05, 'patience': 16}. Best is trial 24 with value: 0.0858852269127965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 59\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:53,437] Trial 29 finished with value: 0.1113219391554594 and parameters: {'learning_rate': 0.011500826537269854, 'lasso_coef': 3.038630855549404e-05, 'patience': 12}. Best is trial 24 with value: 0.0858852269127965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13\n",
      "Best hyperparameters: {'learning_rate': 0.022205029436840558, 'lasso_coef': 1.0437368120371556e-05, 'patience': 19}\n",
      "Best value: 0.0858852269127965\n",
      "Epoch [1/500], Train Loss: 0.6904\n",
      "Epoch [2/500], Train Loss: 0.3198\n",
      "Epoch [3/500], Train Loss: 0.2163\n",
      "Epoch [4/500], Train Loss: 0.1759\n",
      "Epoch [5/500], Train Loss: 0.1563\n",
      "Epoch [6/500], Train Loss: 0.1433\n",
      "Epoch [7/500], Train Loss: 0.1313\n",
      "Epoch [8/500], Train Loss: 0.1209\n",
      "Epoch [9/500], Train Loss: 0.1129\n",
      "Epoch [10/500], Train Loss: 0.1079\n",
      "Epoch [11/500], Train Loss: 0.1040\n",
      "Epoch [12/500], Train Loss: 0.0999\n",
      "Epoch [13/500], Train Loss: 0.0956\n",
      "Epoch [14/500], Train Loss: 0.0918\n",
      "Epoch [15/500], Train Loss: 0.0886\n",
      "Epoch [16/500], Train Loss: 0.0867\n",
      "Epoch [17/500], Train Loss: 0.0847\n",
      "Epoch [18/500], Train Loss: 0.0836\n",
      "Epoch [19/500], Train Loss: 0.0800\n",
      "Epoch [20/500], Train Loss: 0.0803\n",
      "Epoch [21/500], Train Loss: 0.0788\n",
      "Epoch [22/500], Train Loss: 0.0755\n",
      "Epoch [23/500], Train Loss: 0.0757\n",
      "Epoch [24/500], Train Loss: 0.0736\n",
      "Epoch [25/500], Train Loss: 0.0719\n",
      "Epoch [26/500], Train Loss: 0.0712\n",
      "Epoch [27/500], Train Loss: 0.0706\n",
      "Epoch [28/500], Train Loss: 0.0701\n",
      "Epoch [29/500], Train Loss: 0.0701\n",
      "Epoch [30/500], Train Loss: 0.0688\n",
      "Epoch [31/500], Train Loss: 0.0669\n",
      "Epoch [32/500], Train Loss: 0.0676\n",
      "Epoch [33/500], Train Loss: 0.0664\n",
      "Epoch [34/500], Train Loss: 0.0651\n",
      "Epoch [35/500], Train Loss: 0.0636\n",
      "Epoch [36/500], Train Loss: 0.0638\n",
      "Epoch [37/500], Train Loss: 0.0626\n",
      "Epoch [38/500], Train Loss: 0.0626\n",
      "Epoch [39/500], Train Loss: 0.0626\n",
      "Epoch [40/500], Train Loss: 0.0613\n",
      "Epoch [41/500], Train Loss: 0.0611\n",
      "Epoch [42/500], Train Loss: 0.0611\n",
      "Epoch [43/500], Train Loss: 0.0625\n",
      "Epoch [44/500], Train Loss: 0.0621\n",
      "Epoch [45/500], Train Loss: 0.0608\n",
      "Epoch [46/500], Train Loss: 0.0602\n",
      "Epoch [47/500], Train Loss: 0.0603\n",
      "Epoch [48/500], Train Loss: 0.0595\n",
      "Epoch [49/500], Train Loss: 0.0596\n",
      "Epoch [50/500], Train Loss: 0.0590\n",
      "Epoch [51/500], Train Loss: 0.0585\n",
      "Epoch [52/500], Train Loss: 0.0581\n",
      "Epoch [53/500], Train Loss: 0.0587\n",
      "Epoch [54/500], Train Loss: 0.0581\n",
      "Epoch [55/500], Train Loss: 0.0581\n",
      "Epoch [56/500], Train Loss: 0.0574\n",
      "Epoch [57/500], Train Loss: 0.0568\n",
      "Epoch [58/500], Train Loss: 0.0568\n",
      "Epoch [59/500], Train Loss: 0.0559\n",
      "Epoch [60/500], Train Loss: 0.0569\n",
      "Epoch [61/500], Train Loss: 0.0573\n",
      "Epoch [62/500], Train Loss: 0.0564\n",
      "Epoch [63/500], Train Loss: 0.0552\n",
      "Epoch [64/500], Train Loss: 0.0543\n",
      "Epoch [65/500], Train Loss: 0.0561\n",
      "Epoch [66/500], Train Loss: 0.0561\n",
      "Epoch [67/500], Train Loss: 0.0556\n",
      "Epoch [68/500], Train Loss: 0.0557\n",
      "Epoch [69/500], Train Loss: 0.0553\n",
      "Epoch [70/500], Train Loss: 0.0560\n",
      "Epoch [71/500], Train Loss: 0.0571\n",
      "Epoch [72/500], Train Loss: 0.0548\n",
      "Epoch [73/500], Train Loss: 0.0550\n",
      "Epoch [74/500], Train Loss: 0.0570\n",
      "Epoch [75/500], Train Loss: 0.0556\n",
      "Epoch [76/500], Train Loss: 0.0550\n",
      "Epoch [77/500], Train Loss: 0.0553\n",
      "Epoch [78/500], Train Loss: 0.0536\n",
      "Epoch [79/500], Train Loss: 0.0530\n",
      "Epoch [80/500], Train Loss: 0.0532\n",
      "Epoch [81/500], Train Loss: 0.0563\n",
      "Epoch [82/500], Train Loss: 0.0547\n",
      "Epoch [83/500], Train Loss: 0.0544\n",
      "Epoch [84/500], Train Loss: 0.0539\n",
      "Epoch [85/500], Train Loss: 0.0525\n",
      "Epoch [86/500], Train Loss: 0.0528\n",
      "Epoch [87/500], Train Loss: 0.0519\n",
      "Epoch [88/500], Train Loss: 0.0520\n",
      "Epoch [89/500], Train Loss: 0.0520\n",
      "Epoch [90/500], Train Loss: 0.0520\n",
      "Epoch [91/500], Train Loss: 0.0531\n",
      "Epoch [92/500], Train Loss: 0.0525\n",
      "Epoch [93/500], Train Loss: 0.0523\n",
      "Epoch [94/500], Train Loss: 0.0519\n",
      "Epoch [95/500], Train Loss: 0.0517\n",
      "Epoch [96/500], Train Loss: 0.0512\n",
      "Epoch [97/500], Train Loss: 0.0516\n",
      "Epoch [98/500], Train Loss: 0.0516\n",
      "Epoch [99/500], Train Loss: 0.0523\n",
      "Epoch [100/500], Train Loss: 0.0535\n",
      "Epoch [101/500], Train Loss: 0.0527\n",
      "Epoch [102/500], Train Loss: 0.0514\n",
      "Epoch [103/500], Train Loss: 0.0507\n",
      "Epoch [104/500], Train Loss: 0.0514\n",
      "Epoch [105/500], Train Loss: 0.0513\n",
      "Epoch [106/500], Train Loss: 0.0513\n",
      "Epoch [107/500], Train Loss: 0.0511\n",
      "Epoch [108/500], Train Loss: 0.0513\n",
      "Epoch [109/500], Train Loss: 0.0519\n",
      "Epoch [110/500], Train Loss: 0.0515\n",
      "Epoch [111/500], Train Loss: 0.0504\n",
      "Epoch [112/500], Train Loss: 0.0507\n",
      "Epoch [113/500], Train Loss: 0.0511\n",
      "Epoch [114/500], Train Loss: 0.0513\n",
      "Epoch [115/500], Train Loss: 0.0502\n",
      "Epoch [116/500], Train Loss: 0.0502\n",
      "Epoch [117/500], Train Loss: 0.0503\n",
      "Epoch [118/500], Train Loss: 0.0509\n",
      "Epoch [119/500], Train Loss: 0.0515\n",
      "Epoch [120/500], Train Loss: 0.0510\n",
      "Epoch [121/500], Train Loss: 0.0512\n",
      "Epoch [122/500], Train Loss: 0.0512\n",
      "Epoch [123/500], Train Loss: 0.0517\n",
      "Epoch [124/500], Train Loss: 0.0526\n",
      "Epoch [125/500], Train Loss: 0.0514\n",
      "Epoch [126/500], Train Loss: 0.0509\n",
      "Epoch [127/500], Train Loss: 0.0517\n",
      "Epoch [128/500], Train Loss: 0.0508\n",
      "Epoch [129/500], Train Loss: 0.0518\n",
      "Epoch [130/500], Train Loss: 0.0526\n",
      "Epoch [131/500], Train Loss: 0.0514\n",
      "Epoch [132/500], Train Loss: 0.0508\n",
      "Epoch [133/500], Train Loss: 0.0501\n",
      "Epoch [134/500], Train Loss: 0.0504\n",
      "Epoch [135/500], Train Loss: 0.0500\n",
      "Epoch [136/500], Train Loss: 0.0508\n",
      "Epoch [137/500], Train Loss: 0.0504\n",
      "Epoch [138/500], Train Loss: 0.0503\n",
      "Epoch [139/500], Train Loss: 0.0502\n",
      "Epoch [140/500], Train Loss: 0.0498\n",
      "Epoch [141/500], Train Loss: 0.0495\n",
      "Epoch [142/500], Train Loss: 0.0501\n",
      "Epoch [143/500], Train Loss: 0.0504\n",
      "Epoch [144/500], Train Loss: 0.0511\n",
      "Epoch [145/500], Train Loss: 0.0498\n",
      "Epoch [146/500], Train Loss: 0.0495\n",
      "Epoch [147/500], Train Loss: 0.0497\n",
      "Epoch [148/500], Train Loss: 0.0495\n",
      "Epoch [149/500], Train Loss: 0.0494\n",
      "Epoch [150/500], Train Loss: 0.0497\n",
      "Epoch [151/500], Train Loss: 0.0495\n",
      "Epoch [152/500], Train Loss: 0.0497\n",
      "Epoch [153/500], Train Loss: 0.0504\n",
      "Epoch [154/500], Train Loss: 0.0502\n",
      "Epoch [155/500], Train Loss: 0.0497\n",
      "Epoch [156/500], Train Loss: 0.0501\n",
      "Epoch [157/500], Train Loss: 0.0492\n",
      "Epoch [158/500], Train Loss: 0.0506\n",
      "Epoch [159/500], Train Loss: 0.0498\n",
      "Epoch [160/500], Train Loss: 0.0496\n",
      "Epoch [161/500], Train Loss: 0.0497\n",
      "Epoch [162/500], Train Loss: 0.0490\n",
      "Epoch [163/500], Train Loss: 0.0495\n",
      "Epoch [164/500], Train Loss: 0.0509\n",
      "Epoch [165/500], Train Loss: 0.0506\n",
      "Epoch [166/500], Train Loss: 0.0510\n",
      "Epoch [167/500], Train Loss: 0.0506\n",
      "Epoch [168/500], Train Loss: 0.0499\n",
      "Epoch [169/500], Train Loss: 0.0492\n",
      "Epoch [170/500], Train Loss: 0.0501\n",
      "Epoch [171/500], Train Loss: 0.0500\n",
      "Epoch [172/500], Train Loss: 0.0507\n",
      "Epoch [173/500], Train Loss: 0.0516\n",
      "Epoch [174/500], Train Loss: 0.0521\n",
      "Epoch [175/500], Train Loss: 0.0515\n",
      "Epoch [176/500], Train Loss: 0.0509\n",
      "Epoch [177/500], Train Loss: 0.0519\n",
      "Epoch [178/500], Train Loss: 0.0517\n",
      "Epoch [179/500], Train Loss: 0.0518\n",
      "Epoch [180/500], Train Loss: 0.0512\n",
      "Epoch [181/500], Train Loss: 0.0503\n",
      "Early stopping at epoch 181\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr16/final_model_chr16.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr16/individual_r2_scores_chr16.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:57,312] A new study created in memory with name: no-name-7aeceb34-4151-4ca8-9e14-c74c779fead1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../Data/model_results/logistic_regression/roc_curves/\n",
      "Performance metrics saved at: ../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n",
      "Unknown PRS313 SNPs:  18\n",
      "Known PRS313 SNPs:  4\n",
      "23AndMe SNPs with LD to Unknown PRS313 SNPs:  496\n",
      "Early stopping at epoch 109\n",
      "Early stopping at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:23:58,958] Trial 0 finished with value: 0.04163360726088285 and parameters: {'learning_rate': 0.009786204249462962, 'lasso_coef': 2.8247683215754874e-05, 'patience': 6}. Best is trial 0 with value: 0.04163360726088285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 7\n",
      "Early stopping at epoch 191\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:24:01,931] Trial 1 finished with value: 0.03226959183812141 and parameters: {'learning_rate': 0.009302657223310433, 'lasso_coef': 1.76814943371895e-05, 'patience': 19}. Best is trial 1 with value: 0.03226959183812141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 25\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:24:02,471] Trial 2 finished with value: 0.06051200050860643 and parameters: {'learning_rate': 0.03881579822830861, 'lasso_coef': 5.3326315940581305e-05, 'patience': 5}. Best is trial 1 with value: 0.03226959183812141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:24:08,717] Trial 3 finished with value: 0.041370919346809386 and parameters: {'learning_rate': 0.0024376367584129682, 'lasso_coef': 3.616572272623058e-05, 'patience': 20}. Best is trial 1 with value: 0.03226959183812141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 36\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 27\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:24:09,976] Trial 4 finished with value: 0.1494725912809372 and parameters: {'learning_rate': 0.06502827935721082, 'lasso_coef': 0.0004590656358668827, 'patience': 12}. Best is trial 1 with value: 0.03226959183812141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 65\n",
      "Early stopping at epoch 13\n",
      "Early stopping at epoch 29\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:24:11,841] Trial 5 finished with value: 1.7664901077747346 and parameters: {'learning_rate': 0.017441156550760936, 'lasso_coef': 0.08626536673823805, 'patience': 12}. Best is trial 1 with value: 0.03226959183812141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 38\n",
      "Early stopping at epoch 416\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:24:22,513] Trial 6 finished with value: 0.0980590220540762 and parameters: {'learning_rate': 0.0010644159741806207, 'lasso_coef': 0.00034849565999782255, 'patience': 16}. Best is trial 1 with value: 0.03226959183812141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 22\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:24:23,027] Trial 7 finished with value: 0.06448397226631641 and parameters: {'learning_rate': 0.0919507141208655, 'lasso_coef': 4.596822588554736e-05, 'patience': 5}. Best is trial 1 with value: 0.03226959183812141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 6\n",
      "Early stopping at epoch 237\n",
      "Early stopping at epoch 10\n",
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:24:25,988] Trial 8 finished with value: 0.13400210067629814 and parameters: {'learning_rate': 0.0039014693065524074, 'lasso_coef': 0.0007115484673206699, 'patience': 8}. Best is trial 1 with value: 0.03226959183812141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 9\n",
      "Early stopping at epoch 454\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:24:31,795] Trial 9 finished with value: 0.3358208179473877 and parameters: {'learning_rate': 0.0009588468378690833, 'lasso_coef': 0.026884987077462653, 'patience': 9}. Best is trial 1 with value: 0.03226959183812141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:24:58,559] Trial 10 finished with value: 0.3398582085967064 and parameters: {'learning_rate': 0.000118251618635623, 'lasso_coef': 0.006962712662432447, 'patience': 20}. Best is trial 1 with value: 0.03226959183812141.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:25:05,052] Trial 11 finished with value: 0.026047541573643685 and parameters: {'learning_rate': 0.001989891519116586, 'lasso_coef': 1.0323609119804059e-05, 'patience': 20}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:25:11,332] Trial 12 finished with value: 0.05639051031321287 and parameters: {'learning_rate': 0.00023657172835966832, 'lasso_coef': 1.0627292118549875e-05, 'patience': 16}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 217\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:25:14,642] Trial 13 finished with value: 0.026467369962483646 and parameters: {'learning_rate': 0.006649547050648736, 'lasso_coef': 1.0097793117280034e-05, 'patience': 17}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:25:21,202] Trial 14 finished with value: 0.06255611963570118 and parameters: {'learning_rate': 0.002621310488145092, 'lasso_coef': 0.00011195130749268088, 'patience': 17}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 63\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:25:33,396] Trial 15 finished with value: 0.2350621096789837 and parameters: {'learning_rate': 0.0005363802505508847, 'lasso_coef': 0.0031198484255811057, 'patience': 18}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 45\n",
      "Early stopping at epoch 334\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:25:37,796] Trial 16 finished with value: 0.06709854435175658 and parameters: {'learning_rate': 0.005646340708278732, 'lasso_coef': 0.0001312042685393561, 'patience': 14}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 98\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:25:39,653] Trial 17 finished with value: 0.026885801833122967 and parameters: {'learning_rate': 0.01830284401336909, 'lasso_coef': 1.0000970128767183e-05, 'patience': 14}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:25:46,521] Trial 18 finished with value: 0.2140733927488327 and parameters: {'learning_rate': 0.0014945367291116123, 'lasso_coef': 0.002432749505344414, 'patience': 18}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:25:53,909] Trial 19 finished with value: 0.08876291066408157 and parameters: {'learning_rate': 0.00041809898973563795, 'lasso_coef': 0.0001356929358217327, 'patience': 14}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 355\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:25:58,789] Trial 20 finished with value: 0.08408674523234368 and parameters: {'learning_rate': 0.005809503363940799, 'lasso_coef': 0.00023854350545739542, 'patience': 16}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 17\n",
      "Early stopping at epoch 79\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:26:00,363] Trial 21 finished with value: 0.028306335397064685 and parameters: {'learning_rate': 0.030118799060877537, 'lasso_coef': 1.0282234000435664e-05, 'patience': 14}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 15\n",
      "Early stopping at epoch 89\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:26:02,341] Trial 22 finished with value: 0.03585723796859384 and parameters: {'learning_rate': 0.017551986403948006, 'lasso_coef': 2.0143260397351732e-05, 'patience': 18}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 101\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:26:04,135] Trial 23 finished with value: 0.05600479803979397 and parameters: {'learning_rate': 0.013446180777040765, 'lasso_coef': 6.0118815050780966e-05, 'patience': 10}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11\n",
      "Early stopping at epoch 53\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:26:05,508] Trial 24 finished with value: 0.029642648436129092 and parameters: {'learning_rate': 0.035838635551670515, 'lasso_coef': 1.1851486106790058e-05, 'patience': 15}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16\n",
      "Early stopping at epoch 238\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:26:09,420] Trial 25 finished with value: 0.03917021155357361 and parameters: {'learning_rate': 0.006093935873705183, 'lasso_coef': 2.877491383603115e-05, 'patience': 20}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21\n",
      "Early stopping at epoch 460\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:26:15,962] Trial 26 finished with value: 0.05754041001200676 and parameters: {'learning_rate': 0.003044558798478279, 'lasso_coef': 8.782227150401065e-05, 'patience': 13}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 14\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:26:22,333] Trial 27 finished with value: 0.03384744692593813 and parameters: {'learning_rate': 0.0016667700555429935, 'lasso_coef': 1.9853549095712144e-05, 'patience': 11}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 12\n",
      "Early stopping at epoch 63\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 18\n",
      "Early stopping at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:26:23,913] Trial 28 finished with value: 0.20845429822802544 and parameters: {'learning_rate': 0.02633508254230128, 'lasso_coef': 0.0013321071280075858, 'patience': 17}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 167\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n",
      "Early stopping at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 16:26:26,558] Trial 29 finished with value: 0.04045498445630073 and parameters: {'learning_rate': 0.009160599607040455, 'lasso_coef': 3.0438674153997504e-05, 'patience': 19}. Best is trial 11 with value: 0.026047541573643685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 20\n",
      "Best hyperparameters: {'learning_rate': 0.001989891519116586, 'lasso_coef': 1.0323609119804059e-05, 'patience': 20}\n",
      "Best value: 0.026047541573643685\n",
      "Epoch [1/500], Train Loss: 0.3964\n",
      "Epoch [2/500], Train Loss: 0.2816\n",
      "Epoch [3/500], Train Loss: 0.2561\n",
      "Epoch [4/500], Train Loss: 0.2358\n",
      "Epoch [5/500], Train Loss: 0.2205\n",
      "Epoch [6/500], Train Loss: 0.2074\n",
      "Epoch [7/500], Train Loss: 0.1957\n",
      "Epoch [8/500], Train Loss: 0.1855\n",
      "Epoch [9/500], Train Loss: 0.1764\n",
      "Epoch [10/500], Train Loss: 0.1683\n",
      "Epoch [11/500], Train Loss: 0.1609\n",
      "Epoch [12/500], Train Loss: 0.1545\n",
      "Epoch [13/500], Train Loss: 0.1485\n",
      "Epoch [14/500], Train Loss: 0.1427\n",
      "Epoch [15/500], Train Loss: 0.1378\n",
      "Epoch [16/500], Train Loss: 0.1327\n",
      "Epoch [17/500], Train Loss: 0.1286\n",
      "Epoch [18/500], Train Loss: 0.1244\n",
      "Epoch [19/500], Train Loss: 0.1208\n",
      "Epoch [20/500], Train Loss: 0.1172\n",
      "Epoch [21/500], Train Loss: 0.1140\n",
      "Epoch [22/500], Train Loss: 0.1108\n",
      "Epoch [23/500], Train Loss: 0.1080\n",
      "Epoch [24/500], Train Loss: 0.1052\n",
      "Epoch [25/500], Train Loss: 0.1024\n",
      "Epoch [26/500], Train Loss: 0.1002\n",
      "Epoch [27/500], Train Loss: 0.0977\n",
      "Epoch [28/500], Train Loss: 0.0954\n",
      "Epoch [29/500], Train Loss: 0.0933\n",
      "Epoch [30/500], Train Loss: 0.0912\n",
      "Epoch [31/500], Train Loss: 0.0894\n",
      "Epoch [32/500], Train Loss: 0.0875\n",
      "Epoch [33/500], Train Loss: 0.0858\n",
      "Epoch [34/500], Train Loss: 0.0842\n",
      "Epoch [35/500], Train Loss: 0.0826\n",
      "Epoch [36/500], Train Loss: 0.0811\n",
      "Epoch [37/500], Train Loss: 0.0796\n",
      "Epoch [38/500], Train Loss: 0.0784\n",
      "Epoch [39/500], Train Loss: 0.0771\n",
      "Epoch [40/500], Train Loss: 0.0755\n",
      "Epoch [41/500], Train Loss: 0.0743\n",
      "Epoch [42/500], Train Loss: 0.0731\n",
      "Epoch [43/500], Train Loss: 0.0720\n",
      "Epoch [44/500], Train Loss: 0.0709\n",
      "Epoch [45/500], Train Loss: 0.0698\n",
      "Epoch [46/500], Train Loss: 0.0689\n",
      "Epoch [47/500], Train Loss: 0.0678\n",
      "Epoch [48/500], Train Loss: 0.0669\n",
      "Epoch [49/500], Train Loss: 0.0661\n",
      "Epoch [50/500], Train Loss: 0.0649\n",
      "Epoch [51/500], Train Loss: 0.0643\n",
      "Epoch [52/500], Train Loss: 0.0632\n",
      "Epoch [53/500], Train Loss: 0.0624\n",
      "Epoch [54/500], Train Loss: 0.0617\n",
      "Epoch [55/500], Train Loss: 0.0610\n",
      "Epoch [56/500], Train Loss: 0.0602\n",
      "Epoch [57/500], Train Loss: 0.0594\n",
      "Epoch [58/500], Train Loss: 0.0588\n",
      "Epoch [59/500], Train Loss: 0.0582\n",
      "Epoch [60/500], Train Loss: 0.0574\n",
      "Epoch [61/500], Train Loss: 0.0570\n",
      "Epoch [62/500], Train Loss: 0.0562\n",
      "Epoch [63/500], Train Loss: 0.0556\n",
      "Epoch [64/500], Train Loss: 0.0553\n",
      "Epoch [65/500], Train Loss: 0.0544\n",
      "Epoch [66/500], Train Loss: 0.0539\n",
      "Epoch [67/500], Train Loss: 0.0534\n",
      "Epoch [68/500], Train Loss: 0.0530\n",
      "Epoch [69/500], Train Loss: 0.0524\n",
      "Epoch [70/500], Train Loss: 0.0518\n",
      "Epoch [71/500], Train Loss: 0.0514\n",
      "Epoch [72/500], Train Loss: 0.0510\n",
      "Epoch [73/500], Train Loss: 0.0505\n",
      "Epoch [74/500], Train Loss: 0.0500\n",
      "Epoch [75/500], Train Loss: 0.0495\n",
      "Epoch [76/500], Train Loss: 0.0491\n",
      "Epoch [77/500], Train Loss: 0.0487\n",
      "Epoch [78/500], Train Loss: 0.0482\n",
      "Epoch [79/500], Train Loss: 0.0478\n",
      "Epoch [80/500], Train Loss: 0.0474\n",
      "Epoch [81/500], Train Loss: 0.0470\n",
      "Epoch [82/500], Train Loss: 0.0468\n",
      "Epoch [83/500], Train Loss: 0.0463\n",
      "Epoch [84/500], Train Loss: 0.0459\n",
      "Epoch [85/500], Train Loss: 0.0455\n",
      "Epoch [86/500], Train Loss: 0.0453\n",
      "Epoch [87/500], Train Loss: 0.0449\n",
      "Epoch [88/500], Train Loss: 0.0446\n",
      "Epoch [89/500], Train Loss: 0.0442\n",
      "Epoch [90/500], Train Loss: 0.0439\n",
      "Epoch [91/500], Train Loss: 0.0436\n",
      "Epoch [92/500], Train Loss: 0.0434\n",
      "Epoch [93/500], Train Loss: 0.0429\n",
      "Epoch [94/500], Train Loss: 0.0428\n",
      "Epoch [95/500], Train Loss: 0.0426\n",
      "Epoch [96/500], Train Loss: 0.0422\n",
      "Epoch [97/500], Train Loss: 0.0419\n",
      "Epoch [98/500], Train Loss: 0.0416\n",
      "Epoch [99/500], Train Loss: 0.0414\n",
      "Epoch [100/500], Train Loss: 0.0410\n",
      "Epoch [101/500], Train Loss: 0.0408\n",
      "Epoch [102/500], Train Loss: 0.0408\n",
      "Epoch [103/500], Train Loss: 0.0405\n",
      "Epoch [104/500], Train Loss: 0.0401\n",
      "Epoch [105/500], Train Loss: 0.0398\n",
      "Epoch [106/500], Train Loss: 0.0397\n",
      "Epoch [107/500], Train Loss: 0.0394\n",
      "Epoch [108/500], Train Loss: 0.0392\n",
      "Epoch [109/500], Train Loss: 0.0390\n",
      "Epoch [110/500], Train Loss: 0.0388\n",
      "Epoch [111/500], Train Loss: 0.0384\n",
      "Epoch [112/500], Train Loss: 0.0384\n",
      "Epoch [113/500], Train Loss: 0.0381\n",
      "Epoch [114/500], Train Loss: 0.0378\n",
      "Epoch [115/500], Train Loss: 0.0376\n",
      "Epoch [116/500], Train Loss: 0.0375\n",
      "Epoch [117/500], Train Loss: 0.0373\n",
      "Epoch [118/500], Train Loss: 0.0373\n",
      "Epoch [119/500], Train Loss: 0.0370\n",
      "Epoch [120/500], Train Loss: 0.0367\n",
      "Epoch [121/500], Train Loss: 0.0365\n",
      "Epoch [122/500], Train Loss: 0.0365\n",
      "Epoch [123/500], Train Loss: 0.0361\n",
      "Epoch [124/500], Train Loss: 0.0360\n",
      "Epoch [125/500], Train Loss: 0.0359\n",
      "Epoch [126/500], Train Loss: 0.0358\n",
      "Epoch [127/500], Train Loss: 0.0356\n",
      "Epoch [128/500], Train Loss: 0.0353\n",
      "Epoch [129/500], Train Loss: 0.0352\n",
      "Epoch [130/500], Train Loss: 0.0351\n",
      "Epoch [131/500], Train Loss: 0.0348\n",
      "Epoch [132/500], Train Loss: 0.0347\n",
      "Epoch [133/500], Train Loss: 0.0346\n",
      "Epoch [134/500], Train Loss: 0.0344\n",
      "Epoch [135/500], Train Loss: 0.0342\n",
      "Epoch [136/500], Train Loss: 0.0341\n",
      "Epoch [137/500], Train Loss: 0.0341\n",
      "Epoch [138/500], Train Loss: 0.0339\n",
      "Epoch [139/500], Train Loss: 0.0337\n",
      "Epoch [140/500], Train Loss: 0.0336\n",
      "Epoch [141/500], Train Loss: 0.0335\n",
      "Epoch [142/500], Train Loss: 0.0332\n",
      "Epoch [143/500], Train Loss: 0.0331\n",
      "Epoch [144/500], Train Loss: 0.0330\n",
      "Epoch [145/500], Train Loss: 0.0329\n",
      "Epoch [146/500], Train Loss: 0.0327\n",
      "Epoch [147/500], Train Loss: 0.0328\n",
      "Epoch [148/500], Train Loss: 0.0326\n",
      "Epoch [149/500], Train Loss: 0.0324\n",
      "Epoch [150/500], Train Loss: 0.0323\n",
      "Epoch [151/500], Train Loss: 0.0322\n",
      "Epoch [152/500], Train Loss: 0.0321\n",
      "Epoch [153/500], Train Loss: 0.0321\n",
      "Epoch [154/500], Train Loss: 0.0319\n",
      "Epoch [155/500], Train Loss: 0.0317\n",
      "Epoch [156/500], Train Loss: 0.0317\n",
      "Epoch [157/500], Train Loss: 0.0316\n",
      "Epoch [158/500], Train Loss: 0.0313\n",
      "Epoch [159/500], Train Loss: 0.0314\n",
      "Epoch [160/500], Train Loss: 0.0314\n",
      "Epoch [161/500], Train Loss: 0.0311\n",
      "Epoch [162/500], Train Loss: 0.0309\n",
      "Epoch [163/500], Train Loss: 0.0308\n",
      "Epoch [164/500], Train Loss: 0.0308\n",
      "Epoch [165/500], Train Loss: 0.0306\n",
      "Epoch [166/500], Train Loss: 0.0306\n",
      "Epoch [167/500], Train Loss: 0.0304\n",
      "Epoch [168/500], Train Loss: 0.0304\n",
      "Epoch [169/500], Train Loss: 0.0303\n",
      "Epoch [170/500], Train Loss: 0.0303\n",
      "Epoch [171/500], Train Loss: 0.0300\n",
      "Epoch [172/500], Train Loss: 0.0300\n",
      "Epoch [173/500], Train Loss: 0.0298\n",
      "Epoch [174/500], Train Loss: 0.0297\n",
      "Epoch [175/500], Train Loss: 0.0299\n",
      "Epoch [176/500], Train Loss: 0.0296\n",
      "Epoch [177/500], Train Loss: 0.0296\n",
      "Epoch [178/500], Train Loss: 0.0294\n",
      "Epoch [179/500], Train Loss: 0.0295\n",
      "Epoch [180/500], Train Loss: 0.0293\n",
      "Epoch [181/500], Train Loss: 0.0292\n",
      "Epoch [182/500], Train Loss: 0.0291\n",
      "Epoch [183/500], Train Loss: 0.0290\n",
      "Epoch [184/500], Train Loss: 0.0290\n",
      "Epoch [185/500], Train Loss: 0.0289\n",
      "Epoch [186/500], Train Loss: 0.0288\n",
      "Epoch [187/500], Train Loss: 0.0287\n",
      "Epoch [188/500], Train Loss: 0.0287\n",
      "Epoch [189/500], Train Loss: 0.0286\n",
      "Epoch [190/500], Train Loss: 0.0284\n",
      "Epoch [191/500], Train Loss: 0.0285\n",
      "Epoch [192/500], Train Loss: 0.0284\n",
      "Epoch [193/500], Train Loss: 0.0283\n",
      "Epoch [194/500], Train Loss: 0.0282\n",
      "Epoch [195/500], Train Loss: 0.0282\n",
      "Epoch [196/500], Train Loss: 0.0281\n",
      "Epoch [197/500], Train Loss: 0.0280\n",
      "Epoch [198/500], Train Loss: 0.0279\n",
      "Epoch [199/500], Train Loss: 0.0278\n",
      "Epoch [200/500], Train Loss: 0.0278\n",
      "Epoch [201/500], Train Loss: 0.0277\n",
      "Epoch [202/500], Train Loss: 0.0277\n",
      "Epoch [203/500], Train Loss: 0.0276\n",
      "Epoch [204/500], Train Loss: 0.0274\n",
      "Epoch [205/500], Train Loss: 0.0274\n",
      "Epoch [206/500], Train Loss: 0.0273\n",
      "Epoch [207/500], Train Loss: 0.0275\n",
      "Epoch [208/500], Train Loss: 0.0273\n",
      "Epoch [209/500], Train Loss: 0.0273\n",
      "Epoch [210/500], Train Loss: 0.0271\n",
      "Epoch [211/500], Train Loss: 0.0271\n",
      "Epoch [212/500], Train Loss: 0.0270\n",
      "Epoch [213/500], Train Loss: 0.0271\n",
      "Epoch [214/500], Train Loss: 0.0269\n",
      "Epoch [215/500], Train Loss: 0.0269\n",
      "Epoch [216/500], Train Loss: 0.0268\n",
      "Epoch [217/500], Train Loss: 0.0267\n",
      "Epoch [218/500], Train Loss: 0.0267\n",
      "Epoch [219/500], Train Loss: 0.0266\n",
      "Epoch [220/500], Train Loss: 0.0266\n",
      "Epoch [221/500], Train Loss: 0.0264\n",
      "Epoch [222/500], Train Loss: 0.0264\n",
      "Epoch [223/500], Train Loss: 0.0264\n",
      "Epoch [224/500], Train Loss: 0.0263\n",
      "Epoch [225/500], Train Loss: 0.0263\n",
      "Epoch [226/500], Train Loss: 0.0263\n",
      "Epoch [227/500], Train Loss: 0.0262\n",
      "Epoch [228/500], Train Loss: 0.0260\n",
      "Epoch [229/500], Train Loss: 0.0260\n",
      "Epoch [230/500], Train Loss: 0.0260\n",
      "Epoch [231/500], Train Loss: 0.0260\n",
      "Epoch [232/500], Train Loss: 0.0259\n",
      "Epoch [233/500], Train Loss: 0.0258\n",
      "Epoch [234/500], Train Loss: 0.0258\n",
      "Epoch [235/500], Train Loss: 0.0258\n",
      "Epoch [236/500], Train Loss: 0.0257\n",
      "Epoch [237/500], Train Loss: 0.0257\n",
      "Epoch [238/500], Train Loss: 0.0255\n",
      "Epoch [239/500], Train Loss: 0.0255\n",
      "Epoch [240/500], Train Loss: 0.0255\n",
      "Epoch [241/500], Train Loss: 0.0256\n",
      "Epoch [242/500], Train Loss: 0.0254\n",
      "Epoch [243/500], Train Loss: 0.0253\n",
      "Epoch [244/500], Train Loss: 0.0254\n",
      "Epoch [245/500], Train Loss: 0.0253\n",
      "Epoch [246/500], Train Loss: 0.0252\n",
      "Epoch [247/500], Train Loss: 0.0253\n",
      "Epoch [248/500], Train Loss: 0.0251\n",
      "Epoch [249/500], Train Loss: 0.0251\n",
      "Epoch [250/500], Train Loss: 0.0250\n",
      "Epoch [251/500], Train Loss: 0.0249\n",
      "Epoch [252/500], Train Loss: 0.0249\n",
      "Epoch [253/500], Train Loss: 0.0250\n",
      "Epoch [254/500], Train Loss: 0.0248\n",
      "Epoch [255/500], Train Loss: 0.0248\n",
      "Epoch [256/500], Train Loss: 0.0248\n",
      "Epoch [257/500], Train Loss: 0.0247\n",
      "Epoch [258/500], Train Loss: 0.0246\n",
      "Epoch [259/500], Train Loss: 0.0246\n",
      "Epoch [260/500], Train Loss: 0.0246\n",
      "Epoch [261/500], Train Loss: 0.0245\n",
      "Epoch [262/500], Train Loss: 0.0245\n",
      "Epoch [263/500], Train Loss: 0.0245\n",
      "Epoch [264/500], Train Loss: 0.0243\n",
      "Epoch [265/500], Train Loss: 0.0243\n",
      "Epoch [266/500], Train Loss: 0.0243\n",
      "Epoch [267/500], Train Loss: 0.0243\n",
      "Epoch [268/500], Train Loss: 0.0243\n",
      "Epoch [269/500], Train Loss: 0.0242\n",
      "Epoch [270/500], Train Loss: 0.0242\n",
      "Epoch [271/500], Train Loss: 0.0241\n",
      "Epoch [272/500], Train Loss: 0.0243\n",
      "Epoch [273/500], Train Loss: 0.0241\n",
      "Epoch [274/500], Train Loss: 0.0241\n",
      "Epoch [275/500], Train Loss: 0.0240\n",
      "Epoch [276/500], Train Loss: 0.0240\n",
      "Epoch [277/500], Train Loss: 0.0240\n",
      "Epoch [278/500], Train Loss: 0.0240\n",
      "Epoch [279/500], Train Loss: 0.0239\n",
      "Epoch [280/500], Train Loss: 0.0238\n",
      "Epoch [281/500], Train Loss: 0.0238\n",
      "Epoch [282/500], Train Loss: 0.0237\n",
      "Epoch [283/500], Train Loss: 0.0237\n",
      "Epoch [284/500], Train Loss: 0.0238\n",
      "Epoch [285/500], Train Loss: 0.0236\n",
      "Epoch [286/500], Train Loss: 0.0236\n",
      "Epoch [287/500], Train Loss: 0.0235\n",
      "Epoch [288/500], Train Loss: 0.0235\n",
      "Epoch [289/500], Train Loss: 0.0235\n",
      "Epoch [290/500], Train Loss: 0.0235\n",
      "Epoch [291/500], Train Loss: 0.0236\n",
      "Epoch [292/500], Train Loss: 0.0234\n",
      "Epoch [293/500], Train Loss: 0.0233\n",
      "Epoch [294/500], Train Loss: 0.0233\n",
      "Epoch [295/500], Train Loss: 0.0232\n",
      "Epoch [296/500], Train Loss: 0.0233\n",
      "Epoch [297/500], Train Loss: 0.0234\n",
      "Epoch [298/500], Train Loss: 0.0232\n",
      "Epoch [299/500], Train Loss: 0.0232\n",
      "Epoch [300/500], Train Loss: 0.0231\n",
      "Epoch [301/500], Train Loss: 0.0231\n",
      "Epoch [302/500], Train Loss: 0.0231\n",
      "Epoch [303/500], Train Loss: 0.0231\n",
      "Epoch [304/500], Train Loss: 0.0230\n",
      "Epoch [305/500], Train Loss: 0.0230\n",
      "Epoch [306/500], Train Loss: 0.0229\n",
      "Epoch [307/500], Train Loss: 0.0230\n",
      "Epoch [308/500], Train Loss: 0.0230\n",
      "Epoch [309/500], Train Loss: 0.0229\n",
      "Epoch [310/500], Train Loss: 0.0228\n",
      "Epoch [311/500], Train Loss: 0.0228\n",
      "Epoch [312/500], Train Loss: 0.0228\n",
      "Epoch [313/500], Train Loss: 0.0227\n",
      "Epoch [314/500], Train Loss: 0.0227\n",
      "Epoch [315/500], Train Loss: 0.0227\n",
      "Epoch [316/500], Train Loss: 0.0228\n",
      "Epoch [317/500], Train Loss: 0.0227\n",
      "Epoch [318/500], Train Loss: 0.0227\n",
      "Epoch [319/500], Train Loss: 0.0226\n",
      "Epoch [320/500], Train Loss: 0.0226\n",
      "Epoch [321/500], Train Loss: 0.0227\n",
      "Epoch [322/500], Train Loss: 0.0225\n",
      "Epoch [323/500], Train Loss: 0.0225\n",
      "Epoch [324/500], Train Loss: 0.0224\n",
      "Epoch [325/500], Train Loss: 0.0224\n",
      "Epoch [326/500], Train Loss: 0.0224\n",
      "Epoch [327/500], Train Loss: 0.0223\n",
      "Epoch [328/500], Train Loss: 0.0224\n",
      "Epoch [329/500], Train Loss: 0.0224\n",
      "Epoch [330/500], Train Loss: 0.0222\n",
      "Epoch [331/500], Train Loss: 0.0223\n",
      "Epoch [332/500], Train Loss: 0.0223\n",
      "Epoch [333/500], Train Loss: 0.0222\n",
      "Epoch [334/500], Train Loss: 0.0222\n",
      "Epoch [335/500], Train Loss: 0.0222\n",
      "Epoch [336/500], Train Loss: 0.0221\n",
      "Epoch [337/500], Train Loss: 0.0221\n",
      "Epoch [338/500], Train Loss: 0.0221\n",
      "Epoch [339/500], Train Loss: 0.0220\n",
      "Epoch [340/500], Train Loss: 0.0220\n",
      "Epoch [341/500], Train Loss: 0.0220\n",
      "Epoch [342/500], Train Loss: 0.0220\n",
      "Epoch [343/500], Train Loss: 0.0219\n",
      "Epoch [344/500], Train Loss: 0.0219\n",
      "Epoch [345/500], Train Loss: 0.0219\n",
      "Epoch [346/500], Train Loss: 0.0219\n",
      "Epoch [347/500], Train Loss: 0.0218\n",
      "Epoch [348/500], Train Loss: 0.0219\n",
      "Epoch [349/500], Train Loss: 0.0219\n",
      "Epoch [350/500], Train Loss: 0.0218\n",
      "Epoch [351/500], Train Loss: 0.0218\n",
      "Epoch [352/500], Train Loss: 0.0218\n",
      "Epoch [353/500], Train Loss: 0.0217\n",
      "Epoch [354/500], Train Loss: 0.0217\n",
      "Epoch [355/500], Train Loss: 0.0218\n",
      "Epoch [356/500], Train Loss: 0.0217\n",
      "Epoch [357/500], Train Loss: 0.0217\n",
      "Epoch [358/500], Train Loss: 0.0216\n",
      "Epoch [359/500], Train Loss: 0.0216\n",
      "Epoch [360/500], Train Loss: 0.0216\n",
      "Epoch [361/500], Train Loss: 0.0216\n",
      "Epoch [362/500], Train Loss: 0.0215\n",
      "Epoch [363/500], Train Loss: 0.0215\n",
      "Epoch [364/500], Train Loss: 0.0215\n",
      "Epoch [365/500], Train Loss: 0.0215\n",
      "Epoch [366/500], Train Loss: 0.0215\n",
      "Epoch [367/500], Train Loss: 0.0214\n",
      "Epoch [368/500], Train Loss: 0.0214\n",
      "Epoch [369/500], Train Loss: 0.0214\n",
      "Epoch [370/500], Train Loss: 0.0214\n",
      "Epoch [371/500], Train Loss: 0.0214\n",
      "Epoch [372/500], Train Loss: 0.0214\n",
      "Epoch [373/500], Train Loss: 0.0213\n",
      "Epoch [374/500], Train Loss: 0.0213\n",
      "Epoch [375/500], Train Loss: 0.0213\n",
      "Epoch [376/500], Train Loss: 0.0213\n",
      "Epoch [377/500], Train Loss: 0.0213\n",
      "Epoch [378/500], Train Loss: 0.0212\n",
      "Epoch [379/500], Train Loss: 0.0212\n",
      "Epoch [380/500], Train Loss: 0.0212\n",
      "Epoch [381/500], Train Loss: 0.0212\n",
      "Epoch [382/500], Train Loss: 0.0211\n",
      "Epoch [383/500], Train Loss: 0.0211\n",
      "Epoch [384/500], Train Loss: 0.0211\n",
      "Epoch [385/500], Train Loss: 0.0211\n",
      "Epoch [386/500], Train Loss: 0.0211\n",
      "Epoch [387/500], Train Loss: 0.0210\n",
      "Epoch [388/500], Train Loss: 0.0210\n",
      "Epoch [389/500], Train Loss: 0.0210\n",
      "Epoch [390/500], Train Loss: 0.0210\n",
      "Epoch [391/500], Train Loss: 0.0210\n",
      "Epoch [392/500], Train Loss: 0.0210\n",
      "Epoch [393/500], Train Loss: 0.0209\n",
      "Epoch [394/500], Train Loss: 0.0210\n",
      "Epoch [395/500], Train Loss: 0.0209\n",
      "Epoch [396/500], Train Loss: 0.0209\n",
      "Epoch [397/500], Train Loss: 0.0208\n",
      "Epoch [398/500], Train Loss: 0.0208\n",
      "Epoch [399/500], Train Loss: 0.0208\n",
      "Epoch [400/500], Train Loss: 0.0208\n",
      "Epoch [401/500], Train Loss: 0.0209\n",
      "Epoch [402/500], Train Loss: 0.0208\n",
      "Epoch [403/500], Train Loss: 0.0208\n",
      "Epoch [404/500], Train Loss: 0.0207\n",
      "Epoch [405/500], Train Loss: 0.0207\n",
      "Epoch [406/500], Train Loss: 0.0207\n",
      "Epoch [407/500], Train Loss: 0.0206\n",
      "Epoch [408/500], Train Loss: 0.0206\n",
      "Epoch [409/500], Train Loss: 0.0207\n",
      "Epoch [410/500], Train Loss: 0.0206\n",
      "Epoch [411/500], Train Loss: 0.0207\n",
      "Epoch [412/500], Train Loss: 0.0207\n",
      "Epoch [413/500], Train Loss: 0.0207\n",
      "Epoch [414/500], Train Loss: 0.0206\n",
      "Epoch [415/500], Train Loss: 0.0207\n",
      "Epoch [416/500], Train Loss: 0.0206\n",
      "Epoch [417/500], Train Loss: 0.0205\n",
      "Epoch [418/500], Train Loss: 0.0205\n",
      "Epoch [419/500], Train Loss: 0.0205\n",
      "Epoch [420/500], Train Loss: 0.0205\n",
      "Epoch [421/500], Train Loss: 0.0205\n",
      "Epoch [422/500], Train Loss: 0.0205\n",
      "Epoch [423/500], Train Loss: 0.0205\n",
      "Epoch [424/500], Train Loss: 0.0204\n",
      "Epoch [425/500], Train Loss: 0.0204\n",
      "Epoch [426/500], Train Loss: 0.0204\n",
      "Epoch [427/500], Train Loss: 0.0205\n",
      "Epoch [428/500], Train Loss: 0.0204\n",
      "Epoch [429/500], Train Loss: 0.0204\n",
      "Epoch [430/500], Train Loss: 0.0204\n",
      "Epoch [431/500], Train Loss: 0.0203\n",
      "Epoch [432/500], Train Loss: 0.0203\n",
      "Epoch [433/500], Train Loss: 0.0203\n",
      "Epoch [434/500], Train Loss: 0.0204\n",
      "Epoch [435/500], Train Loss: 0.0203\n",
      "Epoch [436/500], Train Loss: 0.0203\n",
      "Epoch [437/500], Train Loss: 0.0203\n",
      "Epoch [438/500], Train Loss: 0.0203\n",
      "Epoch [439/500], Train Loss: 0.0202\n",
      "Epoch [440/500], Train Loss: 0.0202\n",
      "Epoch [441/500], Train Loss: 0.0202\n",
      "Epoch [442/500], Train Loss: 0.0202\n",
      "Epoch [443/500], Train Loss: 0.0201\n",
      "Epoch [444/500], Train Loss: 0.0201\n",
      "Epoch [445/500], Train Loss: 0.0202\n",
      "Epoch [446/500], Train Loss: 0.0201\n",
      "Epoch [447/500], Train Loss: 0.0201\n",
      "Epoch [448/500], Train Loss: 0.0202\n",
      "Epoch [449/500], Train Loss: 0.0201\n",
      "Epoch [450/500], Train Loss: 0.0201\n",
      "Epoch [451/500], Train Loss: 0.0201\n",
      "Epoch [452/500], Train Loss: 0.0201\n",
      "Epoch [453/500], Train Loss: 0.0201\n",
      "Epoch [454/500], Train Loss: 0.0202\n",
      "Epoch [455/500], Train Loss: 0.0200\n",
      "Epoch [456/500], Train Loss: 0.0200\n",
      "Epoch [457/500], Train Loss: 0.0199\n",
      "Epoch [458/500], Train Loss: 0.0199\n",
      "Epoch [459/500], Train Loss: 0.0200\n",
      "Epoch [460/500], Train Loss: 0.0199\n",
      "Epoch [461/500], Train Loss: 0.0200\n",
      "Epoch [462/500], Train Loss: 0.0199\n",
      "Epoch [463/500], Train Loss: 0.0199\n",
      "Epoch [464/500], Train Loss: 0.0199\n",
      "Epoch [465/500], Train Loss: 0.0199\n",
      "Epoch [466/500], Train Loss: 0.0198\n",
      "Epoch [467/500], Train Loss: 0.0198\n",
      "Epoch [468/500], Train Loss: 0.0198\n",
      "Epoch [469/500], Train Loss: 0.0199\n",
      "Epoch [470/500], Train Loss: 0.0198\n",
      "Epoch [471/500], Train Loss: 0.0198\n",
      "Epoch [472/500], Train Loss: 0.0197\n",
      "Epoch [473/500], Train Loss: 0.0198\n",
      "Epoch [474/500], Train Loss: 0.0198\n",
      "Epoch [475/500], Train Loss: 0.0198\n",
      "Epoch [476/500], Train Loss: 0.0198\n",
      "Epoch [477/500], Train Loss: 0.0197\n",
      "Epoch [478/500], Train Loss: 0.0197\n",
      "Epoch [479/500], Train Loss: 0.0197\n",
      "Epoch [480/500], Train Loss: 0.0197\n",
      "Epoch [481/500], Train Loss: 0.0197\n",
      "Epoch [482/500], Train Loss: 0.0197\n",
      "Epoch [483/500], Train Loss: 0.0197\n",
      "Epoch [484/500], Train Loss: 0.0197\n",
      "Epoch [485/500], Train Loss: 0.0197\n",
      "Epoch [486/500], Train Loss: 0.0196\n",
      "Epoch [487/500], Train Loss: 0.0196\n",
      "Epoch [488/500], Train Loss: 0.0197\n",
      "Epoch [489/500], Train Loss: 0.0196\n",
      "Epoch [490/500], Train Loss: 0.0196\n",
      "Epoch [491/500], Train Loss: 0.0196\n",
      "Epoch [492/500], Train Loss: 0.0196\n",
      "Epoch [493/500], Train Loss: 0.0196\n",
      "Epoch [494/500], Train Loss: 0.0195\n",
      "Epoch [495/500], Train Loss: 0.0196\n",
      "Epoch [496/500], Train Loss: 0.0195\n",
      "Epoch [497/500], Train Loss: 0.0195\n",
      "Epoch [498/500], Train Loss: 0.0195\n",
      "Epoch [499/500], Train Loss: 0.0196\n",
      "Epoch [500/500], Train Loss: 0.0195\n",
      "Final model saved at: ../../Data/model_results/logistic_regression/models/chr17/final_model_chr17.pth\n",
      "Individual R^2 scores saved at: ../../Data/model_results/logistic_regression/csv_files/chr17/individual_r2_scores_chr17.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1133: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 251\u001b[0m\n\u001b[1;32m    249\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_test\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[:, i], test_outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[:, i])\n\u001b[1;32m    250\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m--> 251\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(fpr, tpr, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC ROC = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mtest_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    252\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFalse Positive Rate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    253\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue Positive Rate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:627\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    625\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[1;32m    626\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    636\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    637\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    640\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    641\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:382\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m     )\n\u001b[1;32m    387\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../Data/Filtered_split_training_data/'\n",
    "chromosome_number = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "false_positive_rates = []\n",
    "auc_rocs = []\n",
    "r2_scores = []\n",
    "\n",
    "\n",
    "# Create folders for saving files\n",
    "output_folder = \"../../Data/model_results/logistic_regression/\"\n",
    "model_folder = output_folder + \"models/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "curve_folder = output_folder + \"roc_curves/\"\n",
    "\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "os.makedirs(curve_folder, exist_ok=True)\n",
    "\n",
    "for chromosome_number in range(1, 23):\n",
    "\n",
    "    # Create subfolders for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_curve_folder = curve_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    os.makedirs(chr_model_folder, exist_ok=True)\n",
    "    os.makedirs(chr_csv_folder, exist_ok=True)\n",
    "    os.makedirs(chr_curve_folder, exist_ok=True)\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_split.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "    print(\"Unknown PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_Unknown\" in col]].shape[1])\n",
    "    print(\"Known PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_Known\" in col]].shape[1])\n",
    "    print(\"23AndMe SNPs with LD to Unknown PRS313 SNPs: \", data[[col for col in data.columns if \"PRS313_\" not in col]].shape[1])\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*Unknown)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='Unknown').values, dtype=torch.float32)\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the logistic regression model with lasso regularization\n",
    "    class LogisticRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, lasso_coef=0.0):\n",
    "            super(LogisticRegression, self).__init__()\n",
    "            self.linear = nn.Linear(input_dim, output_dim)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            self.lasso_coef = lasso_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.linear(x)\n",
    "            out = self.sigmoid(out)\n",
    "            return out\n",
    "\n",
    "        def lasso_loss(self):\n",
    "            return self.lasso_coef * torch.norm(self.linear.weight, p=1)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set the hyperparameters for tuning\n",
    "    input_dim = X_train_val.shape[1]\n",
    "    output_dim = y_train_val.shape[1]\n",
    "    num_epochs = 500\n",
    "    batch_size = 128\n",
    "\n",
    "    # Define the objective function for Optuna with cross-validation and early stopping\n",
    "    def objective(trial):\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "        lasso_coef = trial.suggest_float('lasso_coef', 1e-5, 1e-1, log=True)\n",
    "        patience = trial.suggest_int('patience', 5, 20)\n",
    "\n",
    "        model = LogisticRegression(input_dim, output_dim, lasso_coef).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold_losses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_val)):\n",
    "            X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "            y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "            train_dataset = TensorDataset(X_train, y_train)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "            best_val_loss = float('inf')\n",
    "            counter = 0\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = 0.0\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y) + model.lasso_loss()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                train_loss /= len(train_loader)\n",
    "\n",
    "                val_dataset = TensorDataset(X_val, y_val)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0.0\n",
    "                    for batch_X, batch_y in val_loader:\n",
    "                        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X)\n",
    "                        loss = criterion(outputs, batch_y) + model.lasso_loss()\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                    val_loss /= len(val_loader)\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= patience:\n",
    "                        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                        break\n",
    "\n",
    "            fold_losses.append(best_val_loss)\n",
    "\n",
    "        return np.mean(fold_losses)\n",
    "\n",
    "    # Create an Optuna study and optimize the hyperparameters\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=30)\n",
    "\n",
    "    # Print the best hyperparameters and best value\n",
    "    print(\"Best hyperparameters:\", study.best_params)\n",
    "    print(\"Best value:\", study.best_value)\n",
    "\n",
    "    # Train the final model with the best hyperparameters and early stopping\n",
    "    best_learning_rate = study.best_params['learning_rate']\n",
    "    best_lasso_coef = study.best_params['lasso_coef']\n",
    "    best_patience = study.best_params['patience']\n",
    "\n",
    "    model = LogisticRegression(input_dim, output_dim, best_lasso_coef).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_val, y_train_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y) + model.lasso_loss()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            best_train_loss = train_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= best_patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # Save the final model\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Final model saved at: {model_save_path}\")\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_preds = (test_outputs > 0.5).float()\n",
    "        test_accuracy = float(((test_preds > 0.5) == y_test).float().mean())\n",
    "        test_precision = precision_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_recall = recall_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_f1 = f1_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_roc_auc = roc_auc_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), average='micro')\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "\n",
    "        # Calculate false positive rate\n",
    "        cm = confusion_matrix(y_test.cpu().numpy().ravel(), test_preds.cpu().numpy().ravel())\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        test_fpr = fp / (fp + tn)\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        accuracies.append(test_accuracy)\n",
    "        precisions.append(test_precision)\n",
    "        recalls.append(test_recall)\n",
    "        false_positive_rates.append(test_fpr)\n",
    "        auc_rocs.append(test_roc_auc)\n",
    "        r2_scores.append(test_r2)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='Unknown').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual AUC ROC curves for each SNP\n",
    "        for i, snp in enumerate(snp_names):\n",
    "            fpr, tpr, _ = roc_curve(y_test.cpu().numpy()[:, i], test_outputs.cpu().numpy()[:, i])\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, label=f'AUC ROC = {roc_auc_score(y_test.cpu().numpy()[:, i], test_outputs.cpu().numpy()[:, i]):.4f}')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title(f'AUC ROC Curve - {snp}')\n",
    "            plt.legend()\n",
    "            \n",
    "            curve_file = chr_curve_folder + f'auc_roc_curve_{snp}_chr{chromosome_number}.png'\n",
    "            plt.savefig(curve_file)\n",
    "            plt.close()\n",
    "\n",
    "        print(f\"Individual AUC ROC curves saved in: {curve_folder}\")\n",
    "\n",
    "        # Create a DataFrame to store the performance metrics for each chromosome\n",
    "        performance_df = pd.DataFrame({\n",
    "            'Chromosome': list(range(1, chromosome_number + 1)),\n",
    "            'Accuracy': accuracies,\n",
    "            'Precision': precisions,\n",
    "            'Recall': recalls,\n",
    "            'False Positive Rate': false_positive_rates,\n",
    "            'AUC ROC': auc_rocs,\n",
    "            'R2 Score': r2_scores\n",
    "        })\n",
    "\n",
    "        # Save the performance metrics to a CSV file\n",
    "        performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "        performance_df.to_csv(performance_csv_file, index=False)\n",
    "        print(f\"Performance metrics saved at: {performance_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def imputation_quality_score(imputed_data, true_data):\n",
    "    \"\"\"\n",
    "    Calculates the Imputation Quality Score (IQS) between imputed data and true data.\n",
    "    \n",
    "    Args:\n",
    "        imputed_data (numpy.ndarray): The imputed data matrix.\n",
    "        true_data (numpy.ndarray): The true data matrix (with missing values).\n",
    "        \n",
    "    Returns:\n",
    "        float: The Imputation Quality Score (IQS).\n",
    "    \"\"\"\n",
    "    # Get the indices of missing values in the true data\n",
    "    missing_indices = np.isnan(true_data)\n",
    "    \n",
    "    # Extract the imputed values and true values at the missing indices\n",
    "    imputed_values = imputed_data[missing_indices]\n",
    "    true_values = true_data[missing_indices]\n",
    "    \n",
    "    # Calculate the sum of squared differences between imputed and true values\n",
    "    squared_diff_imputed = np.sum((imputed_values - true_values) ** 2)\n",
    "    \n",
    "    # Calculate the mean of the true values\n",
    "    mean_true = np.nanmean(true_data)\n",
    "    \n",
    "    # Calculate the sum of squared differences between mean and true values\n",
    "    squared_diff_mean = np.sum((mean_true - true_values) ** 2)\n",
    "    \n",
    "    # Calculate the Imputation Quality Score (IQS)\n",
    "    iqs = 1 - (squared_diff_imputed / squared_diff_mean)\n",
    "    \n",
    "    return iqs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
