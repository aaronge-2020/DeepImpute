{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQS Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_iqs(true_genotypes, imputed_dosages):\n",
    "    # Convert imputed dosages to discrete values\n",
    "    imputed_discrete = np.round(imputed_dosages).astype(int)\n",
    "\n",
    "    # Clip the imputed discrete values to be within the range of 0 to 2\n",
    "    imputed_discrete = np.clip(imputed_discrete, 0, 2)\n",
    "\n",
    "    # Create a contingency table\n",
    "    contingency_table = np.zeros((3, 3), dtype=int)\n",
    "\n",
    "    # Fill the contingency table\n",
    "    for true_geno, imputed_geno in zip(true_genotypes, imputed_discrete):\n",
    "        for true_allele, imputed_allele in zip(true_geno, imputed_geno):\n",
    "            contingency_table[int(true_allele), int(imputed_allele)] += 1\n",
    "\n",
    "    # Calculate the total number of genotypes\n",
    "    total_genotypes = np.sum(contingency_table)\n",
    "\n",
    "    # Calculate observed proportion of agreement (Po)\n",
    "    observed_agreement = np.trace(contingency_table) / total_genotypes\n",
    "\n",
    "    # Calculate marginal sums\n",
    "    row_marginals = np.sum(contingency_table, axis=1)\n",
    "    col_marginals = np.sum(contingency_table, axis=0)\n",
    "\n",
    "    # Calculate chance agreement (Pc)\n",
    "    chance_agreement = np.sum((row_marginals * col_marginals) / (total_genotypes ** 2))\n",
    "\n",
    "    # Calculate IQS\n",
    "    if chance_agreement == 1:  # To prevent division by zero in case of perfect chance agreement\n",
    "        iqs_score = 0\n",
    "    else:\n",
    "        iqs_score = (observed_agreement - chance_agreement) / (1 - chance_agreement)\n",
    "\n",
    "    return iqs_score\n",
    "\n",
    "# Example usage:\n",
    "true_genotypes = np.array([[0, 1, 2], [1, 2, 0], [2, 0, 1]])\n",
    "imputed_dosages = np.array([[0.1, 1.2, 1.9], [1.0, 1.8, 0.3], [2.0, 0.5, 1.4]])\n",
    "\n",
    "iqs_score = calculate_iqs(true_genotypes, imputed_dosages)\n",
    "print(f\"IQS Score: {iqs_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, StratifiedKFold\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Function to calculate Pearson's r² coefficient\n",
    "def pearson_r2(y_true, y_pred):\n",
    "    # Convert to numpy arrays if they aren't already\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Calculate Pearson correlation coefficient\n",
    "    correlation_matrix = np.corrcoef(y_true.flatten(), y_pred.flatten())\n",
    "    correlation = correlation_matrix[0, 1]\n",
    "    \n",
    "    # Square the correlation coefficient to get r²\n",
    "    r_squared = correlation ** 2\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# For multioutput cases (similar to sklearn's multioutput parameter)\n",
    "def pearson_r2_multioutput(y_true, y_pred, multioutput='uniform_average'):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Handle single output case\n",
    "    if y_true.ndim == 1 or y_true.shape[1] == 1:\n",
    "        return pearson_r2(y_true, y_pred)\n",
    "    \n",
    "    # Calculate r² for each output dimension\n",
    "    r2_scores = np.array([pearson_r2(y_true[:, i], y_pred[:, i]) for i in range(y_true.shape[1])])\n",
    "    \n",
    "    if multioutput == 'raw_values':\n",
    "        return r2_scores\n",
    "    elif multioutput == 'uniform_average':\n",
    "        return np.average(r2_scores)\n",
    "    else:\n",
    "        # Default to uniform average\n",
    "        return np.average(r2_scores)\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../../Data/Filtered_split_training_data/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "false_positive_rates = []\n",
    "auc_rocs = []\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "\n",
    "# Create folders for saving files\n",
    "output_folder = \"../../../Data/model_results/logistic_regression/\"\n",
    "model_folder = output_folder + \"models/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "curve_folder = output_folder + \"roc_curves/\"\n",
    "\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "os.makedirs(curve_folder, exist_ok=True)\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Create subfolders for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_curve_folder = curve_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    os.makedirs(chr_model_folder, exist_ok=True)\n",
    "    os.makedirs(chr_csv_folder, exist_ok=True)\n",
    "    os.makedirs(chr_curve_folder, exist_ok=True)\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_split.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.float32)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the logistic regression model with lasso regularization\n",
    "    class LogisticRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, l1_coef=0.0):\n",
    "            super(LogisticRegression, self).__init__()\n",
    "            self.linear = nn.Linear(input_dim, output_dim)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.linear(x)\n",
    "            out = self.sigmoid(out)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * torch.norm(self.linear.weight, p=1)\n",
    "        \n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set the hyperparameters for tuning\n",
    "    input_dim = X_train_val.shape[1]\n",
    "    output_dim = y_train_val.shape[1]\n",
    "    num_epochs = 500\n",
    "    batch_size = 128\n",
    "\n",
    "    # Define the objective function for Optuna with cross-validation and early stopping\n",
    "    def objective(trial):\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
    "        l1_coef = trial.suggest_float('l1_coef', 1e-5, 1e-1, log=True)\n",
    "        patience = trial.suggest_int('patience', 5, 20)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "\n",
    "        model = LogisticRegression(input_dim, output_dim, l1_coef).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.BCELoss()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=False)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold_losses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_val, y_train_val.argmax(dim=1))):\n",
    "            X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "            y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "            train_dataset = TensorDataset(X_train, y_train)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "            best_val_loss = float('inf')\n",
    "            counter = 0\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = 0.0\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                train_loss /= len(train_loader)\n",
    "\n",
    "                val_dataset = TensorDataset(X_val, y_val)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0.0\n",
    "                    for batch_X, batch_y in val_loader:\n",
    "                        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X)\n",
    "                        loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                    val_loss /= len(val_loader)\n",
    "                    scheduler.step(val_loss)\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= patience:\n",
    "                        break\n",
    "\n",
    "            fold_losses.append(best_val_loss)\n",
    "\n",
    "        return np.mean(fold_losses)\n",
    "\n",
    "    # Create the \"optuna_studies\" folder if it doesn't exist\n",
    "    os.makedirs(\"optuna_studies\", exist_ok=True)\n",
    "\n",
    "    # Create an Optuna study and optimize the hyperparameters\n",
    "    study_name = f\"chr{chromosome_number}_study\"\n",
    "    storage_name = f\"sqlite:///optuna_studies/{study_name}.db\"\n",
    "\n",
    "    # Check if the study exists\n",
    "    current_dir = os.getcwd()\n",
    "    study_exists = os.path.exists(current_dir + f\"/optuna_studies/{study_name}.db\")\n",
    "    \n",
    "    if study_exists:\n",
    "        # Load the existing study\n",
    "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "    else:\n",
    "        # Create a new study\n",
    "        study = optuna.create_study(direction='minimize', study_name=study_name, storage=storage_name)\n",
    "    \n",
    "    study.optimize(objective, n_trials=10, n_jobs=-1)\n",
    "\n",
    "    # Print the best hyperparameters and best value\n",
    "    print(f\"Chr {chromosome_number} - Best hyperparameters: {study.best_params}\")\n",
    "    print(f\"Chr {chromosome_number} - Best value: {study.best_value:.4f}\")\n",
    "\n",
    "    # Train the final model with the best hyperparameters and early stopping\n",
    "    best_learning_rate = study.best_params['learning_rate']\n",
    "    best_l1_coef = study.best_params['l1_coef']\n",
    "    best_patience = study.best_params['patience']\n",
    "    best_batch_size = study.best_params['batch_size']\n",
    "\n",
    "    model = LogisticRegression(input_dim, output_dim, best_l1_coef).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=False)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_val, y_train_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            best_train_loss = train_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= best_patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "    # Save the final model\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Final model saved at: {model_save_path}\")\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_preds = (test_outputs > 0.5).float()\n",
    "        test_accuracy = float(((test_preds > 0.5) == y_test).float().mean())\n",
    "        test_precision = precision_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_recall = recall_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_f1 = f1_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_roc_auc = roc_auc_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), average='micro')\n",
    "        \n",
    "        # Use Pearson's r² instead of sklearn's r2_score\n",
    "        test_r2 = pearson_r2(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "\n",
    "        # Calculate false positive rate\n",
    "        cm = confusion_matrix(y_test.cpu().numpy().ravel(), test_preds.cpu().numpy().ravel())\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        test_fpr = fp / (fp + tn)\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        accuracies.append(test_accuracy)\n",
    "        precisions.append(test_precision)\n",
    "        recalls.append(test_recall)\n",
    "        false_positive_rates.append(test_fpr)\n",
    "        auc_rocs.append(test_roc_auc)\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP using Pearson's r²\n",
    "        individual_r2_scores = pearson_r2_multioutput(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs(y_test.cpu().numpy()[:, i].reshape(-1, 1), test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='Unknown').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "        \n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "        # Save individual AUC ROC curves for each SNP\n",
    "        for i, snp in enumerate(snp_names):\n",
    "            try: \n",
    "                fpr, tpr, _ = roc_curve(y_test.cpu().numpy()[:, i], test_outputs.cpu().numpy()[:, i])\n",
    "                plt.figure()\n",
    "                plt.plot(fpr, tpr, label=f'AUC ROC = {roc_auc_score(y_test.cpu().numpy()[:, i], test_outputs.cpu().numpy()[:, i]):.4f}')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title(f'AUC ROC Curve - {snp}')\n",
    "                plt.legend()\n",
    "                \n",
    "                curve_file = chr_curve_folder + f'auc_roc_curve_{snp}_chr{chromosome_number}.png'\n",
    "                plt.savefig(curve_file)\n",
    "                plt.close()\n",
    "            except ValueError:\n",
    "                # Save a placeholder image if there is insufficient data\n",
    "                plt.figure()\n",
    "                plt.axis('off')\n",
    "                plt.text(0.5, 0.5, \"Insufficient data for ROC curve\", ha='center', va='center')\n",
    "                curve_file = chr_curve_folder + f'auc_roc_curve_{snp}_chr{chromosome_number}.png'\n",
    "                plt.savefig(curve_file)\n",
    "                plt.close()\n",
    "\n",
    "                print(f\"Skipping SNP {snp} due to insufficient data\")\n",
    "\n",
    "        print(f\"Individual AUC ROC curves saved in: {curve_folder}\")\n",
    "\n",
    "        # Create a DataFrame to store the performance metrics for each chromosome\n",
    "        performance_df = pd.DataFrame({\n",
    "            'Chromosome': list(range(start, chromosome_number + 1)),\n",
    "            'R2 Score': r2_scores,\n",
    "            'IQS Score': iqs_scores,\n",
    "            'Accuracy': accuracies,\n",
    "            # 'Precision': precisions,\n",
    "            # 'Recall': recalls,\n",
    "            # 'False Positive Rate': false_positive_rates,\n",
    "            'AUC ROC': auc_rocs,\n",
    "        })\n",
    "\n",
    "        # Save the performance metrics to a CSV file\n",
    "        performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "        performance_df.to_csv(performance_csv_file, index=False)\n",
    "        print(f\"Performance metrics saved at: {performance_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chromosome 1:\n",
      "Total SNPs:  4056\n",
      "PRS313 SNPs:  60\n",
      "Total SNPs used for Evaluation:  3996\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr1/final_model_chr1.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr1/individual_r2_scores_chr1.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr1/individual_iqs_scores_chr1.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr1/\n",
      "Chromosome 2:\n",
      "Total SNPs:  2088\n",
      "PRS313 SNPs:  42\n",
      "Total SNPs used for Evaluation:  2046\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr2/final_model_chr2.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr2/individual_r2_scores_chr2.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr2/individual_iqs_scores_chr2.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr2/\n",
      "Chromosome 3:\n",
      "Total SNPs:  2510\n",
      "PRS313 SNPs:  32\n",
      "Total SNPs used for Evaluation:  2478\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr3/final_model_chr3.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr3/individual_r2_scores_chr3.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr3/individual_iqs_scores_chr3.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr3/\n",
      "Chromosome 4:\n",
      "Total SNPs:  2976\n",
      "PRS313 SNPs:  22\n",
      "Total SNPs used for Evaluation:  2954\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr4/final_model_chr4.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr4/individual_r2_scores_chr4.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr4/individual_iqs_scores_chr4.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr4/\n",
      "Chromosome 5:\n",
      "Total SNPs:  4076\n",
      "PRS313 SNPs:  68\n",
      "Total SNPs used for Evaluation:  4008\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr5/final_model_chr5.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr5/individual_r2_scores_chr5.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr5/individual_iqs_scores_chr5.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr5/\n",
      "Chromosome 6:\n",
      "Total SNPs:  1706\n",
      "PRS313 SNPs:  40\n",
      "Total SNPs used for Evaluation:  1666\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr6/final_model_chr6.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr6/individual_r2_scores_chr6.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr6/individual_iqs_scores_chr6.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr6/\n",
      "Chromosome 7:\n",
      "Total SNPs:  1470\n",
      "PRS313 SNPs:  28\n",
      "Total SNPs used for Evaluation:  1442\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr7/final_model_chr7.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr7/individual_r2_scores_chr7.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr7/individual_iqs_scores_chr7.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr7/\n",
      "Chromosome 8:\n",
      "Total SNPs:  1598\n",
      "PRS313 SNPs:  42\n",
      "Total SNPs used for Evaluation:  1556\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr8/final_model_chr8.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr8/individual_r2_scores_chr8.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr8/individual_iqs_scores_chr8.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr8/\n",
      "Chromosome 9:\n",
      "Total SNPs:  1306\n",
      "PRS313 SNPs:  28\n",
      "Total SNPs used for Evaluation:  1278\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr9/final_model_chr9.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr9/individual_r2_scores_chr9.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr9/individual_iqs_scores_chr9.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr9/\n",
      "Chromosome 10:\n",
      "Total SNPs:  1884\n",
      "PRS313 SNPs:  36\n",
      "Total SNPs used for Evaluation:  1848\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr10/final_model_chr10.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr10/individual_r2_scores_chr10.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr10/individual_iqs_scores_chr10.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr10/\n",
      "Chromosome 11:\n",
      "Total SNPs:  2550\n",
      "PRS313 SNPs:  38\n",
      "Total SNPs used for Evaluation:  2512\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr11/final_model_chr11.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr11/individual_r2_scores_chr11.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr11/individual_iqs_scores_chr11.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr11/\n",
      "Chromosome 12:\n",
      "Total SNPs:  1704\n",
      "PRS313 SNPs:  34\n",
      "Total SNPs used for Evaluation:  1670\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr12/final_model_chr12.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr12/individual_r2_scores_chr12.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr12/individual_iqs_scores_chr12.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr12/\n",
      "Chromosome 13:\n",
      "Total SNPs:  304\n",
      "PRS313 SNPs:  10\n",
      "Total SNPs used for Evaluation:  294\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr13/final_model_chr13.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr13/individual_r2_scores_chr13.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr13/individual_iqs_scores_chr13.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr13/\n",
      "Chromosome 14:\n",
      "Total SNPs:  918\n",
      "PRS313 SNPs:  16\n",
      "Total SNPs used for Evaluation:  902\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr14/final_model_chr14.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr14/individual_r2_scores_chr14.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr14/individual_iqs_scores_chr14.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr14/\n",
      "Chromosome 15:\n",
      "Total SNPs:  620\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Evaluation:  606\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr15/final_model_chr15.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr15/individual_r2_scores_chr15.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr15/individual_iqs_scores_chr15.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr15/\n",
      "Chromosome 16:\n",
      "Total SNPs:  1212\n",
      "PRS313 SNPs:  28\n",
      "Total SNPs used for Evaluation:  1184\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr16/final_model_chr16.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr16/individual_r2_scores_chr16.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr16/individual_iqs_scores_chr16.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr16/\n",
      "Chromosome 17:\n",
      "Total SNPs:  760\n",
      "PRS313 SNPs:  18\n",
      "Total SNPs used for Evaluation:  742\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr17/final_model_chr17.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr17/individual_r2_scores_chr17.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr17/individual_iqs_scores_chr17.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaronge/Documents/GitHub/DeepImpute/.venv/lib/python3.9/site-packages/numpy/lib/_function_base_impl.py:2922: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/aaronge/Documents/GitHub/DeepImpute/.venv/lib/python3.9/site-packages/numpy/lib/_function_base_impl.py:2923: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/aaronge/Documents/GitHub/DeepImpute/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/Users/aaronge/Documents/GitHub/DeepImpute/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr17/\n",
      "Chromosome 18:\n",
      "Total SNPs:  1178\n",
      "PRS313 SNPs:  18\n",
      "Total SNPs used for Evaluation:  1160\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr18/final_model_chr18.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr18/individual_r2_scores_chr18.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr18/individual_iqs_scores_chr18.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr18/\n",
      "Chromosome 19:\n",
      "Total SNPs:  696\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Evaluation:  682\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr19/final_model_chr19.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr19/individual_r2_scores_chr19.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr19/individual_iqs_scores_chr19.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr19/\n",
      "Chromosome 20:\n",
      "Total SNPs:  216\n",
      "PRS313 SNPs:  8\n",
      "Total SNPs used for Evaluation:  208\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr20/final_model_chr20.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr20/individual_r2_scores_chr20.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr20/individual_iqs_scores_chr20.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr20/\n",
      "Chromosome 21:\n",
      "Total SNPs:  188\n",
      "PRS313 SNPs:  8\n",
      "Total SNPs used for Evaluation:  180\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr21/final_model_chr21.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr21/individual_r2_scores_chr21.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr21/individual_iqs_scores_chr21.csv\n",
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr21/\n",
      "Chromosome 22:\n",
      "Total SNPs:  1084\n",
      "PRS313 SNPs:  22\n",
      "Total SNPs used for Evaluation:  1062\n",
      "Model loaded from: ../../../Data/model_results/logistic_regression/models/chr22/final_model_chr22.pth\n",
      "Individual R^2 scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr22/individual_r2_scores_chr22.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results/logistic_regression/csv_files/chr22/individual_iqs_scores_chr22.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaronge/Documents/GitHub/DeepImpute/.venv/lib/python3.9/site-packages/numpy/lib/_function_base_impl.py:2922: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/aaronge/Documents/GitHub/DeepImpute/.venv/lib/python3.9/site-packages/numpy/lib/_function_base_impl.py:2923: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/Users/aaronge/Documents/GitHub/DeepImpute/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/Users/aaronge/Documents/GitHub/DeepImpute/.venv/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual AUC ROC curves saved in: ../../../Data/model_results/logistic_regression/roc_curves/chr22/\n",
      "Performance metrics saved at: ../../../Data/model_results/logistic_regression/csv_files/performance_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Function to calculate Pearson's r² coefficient\n",
    "def pearson_r2(y_true, y_pred):\n",
    "    # Convert to numpy arrays if they aren't already\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Calculate Pearson correlation coefficient\n",
    "    correlation_matrix = np.corrcoef(y_true.flatten(), y_pred.flatten())\n",
    "    correlation = correlation_matrix[0, 1]\n",
    "    \n",
    "    # Square the correlation coefficient to get r²\n",
    "    r_squared = correlation ** 2\n",
    "    \n",
    "    return r_squared\n",
    "\n",
    "# For multioutput cases\n",
    "def pearson_r2_multioutput(y_true, y_pred, multioutput='uniform_average'):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Handle single output case\n",
    "    if y_true.ndim == 1 or y_true.shape[1] == 1:\n",
    "        return pearson_r2(y_true, y_pred)\n",
    "    \n",
    "    # Calculate r² for each output dimension\n",
    "    r2_scores = np.array([pearson_r2(y_true[:, i], y_pred[:, i]) for i in range(y_true.shape[1])])\n",
    "    \n",
    "    if multioutput == 'raw_values':\n",
    "        return r2_scores\n",
    "    elif multioutput == 'uniform_average':\n",
    "        return np.average(r2_scores)\n",
    "    else:\n",
    "        # Default to uniform average\n",
    "        return np.average(r2_scores)\n",
    "\n",
    "# Define the logistic regression model class\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, l1_coef=0.0):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.l1_coef = l1_coef\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "    def l1_loss(self):\n",
    "        return self.l1_coef * torch.norm(self.linear.weight, p=1)\n",
    "\n",
    "# Function to load and evaluate the model\n",
    "def load_and_evaluate_model(chromosome_number, data_directory, model_folder, csv_folder, curve_folder):\n",
    "    # Create subfolders for the current chromosome\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_curve_folder = curve_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    os.makedirs(chr_csv_folder, exist_ok=True)\n",
    "    os.makedirs(chr_curve_folder, exist_ok=True)\n",
    "\n",
    "    # Load the data\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_split.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.float32)\n",
    "\n",
    "    print(f\"Chromosome {chromosome_number}:\")\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Evaluation: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    _, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the saved model\n",
    "    input_dim = X.shape[1]\n",
    "    output_dim = y.shape[1]\n",
    "    model_save_path = model_folder + f'chr{chromosome_number}/final_model_chr{chromosome_number}.pth'\n",
    "    \n",
    "    model = LogisticRegression(input_dim, output_dim).to(device)\n",
    "    model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Model loaded from: {model_save_path}\")\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_preds = (test_outputs > 0.5).float()\n",
    "        test_accuracy = float(((test_preds > 0.5) == y_test).float().mean())\n",
    "        test_precision = precision_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_recall = recall_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_f1 = f1_score(y_test.cpu().numpy(), test_preds.cpu().numpy(), average='micro')\n",
    "        test_roc_auc = roc_auc_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), average='micro')\n",
    "        \n",
    "        # Use Pearson's r² instead of sklearn's r2_score\n",
    "        test_r2 = pearson_r2(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "\n",
    "        # Calculate false positive rate\n",
    "        cm = confusion_matrix(y_test.cpu().numpy().ravel(), test_preds.cpu().numpy().ravel())\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        test_fpr = fp / (fp + tn)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = pearson_r2_multioutput(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs(y_test.cpu().numpy()[:, i].reshape(-1, 1), \n",
    "                                                       test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) \n",
    "                                         for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS313_').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "        \n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "        # Save individual AUC ROC curves for each SNP\n",
    "        for i, snp in enumerate(snp_names):\n",
    "            try: \n",
    "                fpr, tpr, _ = roc_curve(y_test.cpu().numpy()[:, i], test_outputs.cpu().numpy()[:, i])\n",
    "                plt.figure()\n",
    "                plt.plot(fpr, tpr, label=f'AUC ROC = {roc_auc_score(y_test.cpu().numpy()[:, i], test_outputs.cpu().numpy()[:, i]):.4f}')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title(f'AUC ROC Curve - {snp}')\n",
    "                plt.legend()\n",
    "                \n",
    "                curve_file = chr_curve_folder + f'auc_roc_curve_{snp}_chr{chromosome_number}.png'\n",
    "                plt.savefig(curve_file)\n",
    "                plt.close()\n",
    "            except ValueError:\n",
    "                # Save a placeholder image if there is insufficient data\n",
    "                plt.figure()\n",
    "                plt.axis('off')\n",
    "                plt.text(0.5, 0.5, \"Insufficient data for ROC curve\", ha='center', va='center')\n",
    "                curve_file = chr_curve_folder + f'auc_roc_curve_{snp}_chr{chromosome_number}.png'\n",
    "                plt.savefig(curve_file)\n",
    "                plt.close()\n",
    "\n",
    "                print(f\"Skipping SNP {snp} due to insufficient data\")\n",
    "\n",
    "        print(f\"Individual AUC ROC curves saved in: {chr_curve_folder}\")\n",
    "\n",
    "    return {\n",
    "        'Chromosome': chromosome_number,\n",
    "        'R2 Score': test_r2,\n",
    "        'IQS Score': test_iqs,\n",
    "        'Accuracy': test_accuracy,\n",
    "        # 'Precision': test_precision,\n",
    "        # 'Recall': test_recall,\n",
    "        # 'False Positive Rate': test_fpr,\n",
    "        'AUC ROC': test_roc_auc,\n",
    "    }\n",
    "\n",
    "# Main function to evaluate all chromosomes and save results to a CSV file\n",
    "def evaluate_all_chromosomes(start_chromosome, end_chromosome, data_directory, model_folder, output_folder):\n",
    "    # Create folders for saving files\n",
    "    csv_folder = output_folder + \"csv_files/\"\n",
    "    curve_folder = output_folder + \"roc_curves/\"\n",
    "\n",
    "    os.makedirs(csv_folder, exist_ok=True)\n",
    "    os.makedirs(curve_folder, exist_ok=True)\n",
    "    \n",
    "    results = []\n",
    "    for chromosome_number in range(start_chromosome, end_chromosome + 1):\n",
    "        result = load_and_evaluate_model(chromosome_number, data_directory, model_folder, csv_folder, curve_folder)\n",
    "        results.append(result)\n",
    "\n",
    "    # Create a DataFrame to store the performance metrics for each chromosome\n",
    "    performance_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save the performance metrics to a CSV file\n",
    "    performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "    performance_df.to_csv(performance_csv_file, index=False)\n",
    "    print(f\"Performance metrics saved at: {performance_csv_file}\")\n",
    "\n",
    "# Example usage\n",
    "start_chromosome = 1\n",
    "end_chromosome = 22\n",
    "data_directory = '../../../Data/Filtered_split_training_data/'\n",
    "model_folder = \"../../../Data/model_results/logistic_regression/models/\"\n",
    "output_folder = \"../../../Data/model_results/logistic_regression/\"\n",
    "\n",
    "evaluate_all_chromosomes(start_chromosome, end_chromosome, data_directory, model_folder, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
