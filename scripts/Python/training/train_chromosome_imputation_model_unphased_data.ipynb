{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQS Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_iqs_unphased(true_genotypes, imputed_dosages):\n",
    "    # Convert imputed dosages to discrete values\n",
    "    imputed_discrete = np.round(imputed_dosages).astype(int)\n",
    "\n",
    "    # Clip the imputed discrete values to be within the range of 0 to 2\n",
    "    imputed_discrete = np.clip(imputed_discrete, 0, 2)\n",
    "\n",
    "    # Create a contingency table\n",
    "    contingency_table = np.zeros((3, 3), dtype=int)\n",
    "\n",
    "    # Fill the contingency table\n",
    "    for true_geno, imputed_geno in zip(true_genotypes, imputed_discrete):\n",
    "        for true_allele, imputed_allele in zip(true_geno, imputed_geno):\n",
    "            contingency_table[int(true_allele), int(imputed_allele)] += 1\n",
    "\n",
    "    # Calculate the total number of genotypes\n",
    "    total_genotypes = np.sum(contingency_table)\n",
    "\n",
    "    # Calculate observed proportion of agreement (Po)\n",
    "    observed_agreement = np.trace(contingency_table) / total_genotypes\n",
    "\n",
    "    # Calculate marginal sums\n",
    "    row_marginals = np.sum(contingency_table, axis=1)\n",
    "    col_marginals = np.sum(contingency_table, axis=0)\n",
    "\n",
    "    # Calculate chance agreement (Pc)\n",
    "    chance_agreement = np.sum((row_marginals * col_marginals) / (total_genotypes ** 2))\n",
    "\n",
    "    # Calculate IQS\n",
    "    if chance_agreement == 1:  # To prevent division by zero in case of perfect chance agreement\n",
    "        iqs_score = 0\n",
    "    else:\n",
    "        iqs_score = (observed_agreement - chance_agreement) / (1 - chance_agreement)\n",
    "\n",
    "    return iqs_score\n",
    "\n",
    "# Example usage:\n",
    "true_genotypes = np.array([[0, 1, 2], [1, 2, 0], [2, 0, 1]])\n",
    "imputed_dosages = np.array([[0.1, 1.2, 1.9], [1.0, 1.8, 0.3], [2.0, 0.5, 1.4]])\n",
    "\n",
    "iqs_score = calculate_iqs_unphased(true_genotypes, imputed_dosages)\n",
    "print(f\"IQS Score: {iqs_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data\u001b[38;5;241m.\u001b[39mfilter(regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^(?!.*PRS313_)\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     44\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data\u001b[38;5;241m.\u001b[39mfilter(regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRS313_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal SNPs: \u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRS313 SNPs: \u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal SNPs used for Training: \u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[5], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data\u001b[38;5;241m.\u001b[39mfilter(regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^(?!.*PRS313_)\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     44\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data\u001b[38;5;241m.\u001b[39mfilter(regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRS313_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal SNPs: \u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRS313 SNPs: \u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal SNPs used for Training: \u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score, accuracy_score\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Create folders for saving files\n",
    "output_folder = \"../../../Data/model_results_unphased_all_PRS/linear_regression/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Create subfolders for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    os.makedirs(chr_model_folder, exist_ok=True)\n",
    "    os.makedirs(chr_csv_folder, exist_ok=True)\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.float32)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the linear regression model with L1 regularization\n",
    "    class LinearRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, l1_coef=0.0):\n",
    "            super(LinearRegression, self).__init__()\n",
    "            self.linear = nn.Linear(input_dim, output_dim)\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.linear(x)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * torch.norm(self.linear.weight, p=1)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set the hyperparameters for tuning\n",
    "    input_dim = X_train_val.shape[1]\n",
    "    output_dim = y_train_val.shape[1]\n",
    "    num_epochs = 500\n",
    "\n",
    "    # Define the objective function for Optuna with cross-validation and early stopping\n",
    "    def objective(trial):\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-1, log=True)\n",
    "        l1_coef = trial.suggest_float('l1_coef', 1e-10, 1e-1, log=True)\n",
    "        patience = trial.suggest_int('patience', 5, 20)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "        lr_factor = trial.suggest_float('lr_factor', 0.1, 0.9)\n",
    "        num_epochs = trial.suggest_int('num_epochs', 100, 500)\n",
    "\n",
    "        model = LinearRegression(input_dim, output_dim, l1_coef).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.MSELoss()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_factor, patience=patience, verbose=False)\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold_losses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_val)):\n",
    "            X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "            y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "            train_dataset = TensorDataset(X_train, y_train)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "            best_val_loss = float('inf')\n",
    "            counter = 0\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = 0.0\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                train_loss /= len(train_loader)\n",
    "\n",
    "                val_dataset = TensorDataset(X_val, y_val)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0.0\n",
    "                    for batch_X, batch_y in val_loader:\n",
    "                        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X)\n",
    "                        loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                    val_loss /= len(val_loader)\n",
    "                    scheduler.step(val_loss)\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= patience:\n",
    "                        break\n",
    "\n",
    "            fold_losses.append(best_val_loss)\n",
    "\n",
    "        return np.mean(fold_losses)\n",
    "    # Create the \"optuna_studies\" folder if it doesn't exist\n",
    "    os.makedirs(\"optuna_studies\", exist_ok=True)\n",
    "\n",
    "    # Create an Optuna study and optimize the hyperparameters\n",
    "    study_name = f\"unphased_full_23andMe_chr{chromosome_number}_study_linear_regression\"\n",
    "    storage_name = f\"sqlite:///optuna_studies/{study_name}.db\"\n",
    "\n",
    "    # Check if the study exists\n",
    "    current_dir = os.getcwd()\n",
    "    study_exists = os.path.exists(current_dir + f\"/optuna_studies/{study_name}.db\")\n",
    "\n",
    "    if study_exists:\n",
    "        # Load the existing study\n",
    "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "    else:\n",
    "        # Create a new study\n",
    "        study = optuna.create_study(direction='minimize', study_name=study_name, storage=storage_name)\n",
    "\n",
    "    study.optimize(objective, n_trials=1, n_jobs=-1)\n",
    "\n",
    "    # Print the best hyperparameters and best value\n",
    "    print(f\"Chr {chromosome_number} - Best hyperparameters: {study.best_params}\")\n",
    "    print(f\"Chr {chromosome_number} - Best value: {study.best_value:.4f}\")\n",
    "\n",
    "    # Train the final model with the best hyperparameters and early stopping\n",
    "    best_learning_rate = study.best_params['learning_rate']\n",
    "    best_l1_coef = study.best_params['l1_coef']\n",
    "    best_patience = study.best_params['patience']\n",
    "    best_batch_size = study.best_params['batch_size']\n",
    "    best_lr_factor = study.best_params['lr_factor']\n",
    "    best_num_epochs = study.best_params['num_epochs']\n",
    "\n",
    "    model = LinearRegression(input_dim, output_dim, best_l1_coef).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=best_lr_factor, patience=best_patience, verbose=False)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_val, y_train_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(best_num_epochs):\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            best_train_loss = train_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= best_patience:\n",
    "            break\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "    # Save the final model\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Final model saved at: {model_save_path}\")\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_accuracy = ((y_test == test_outputs.round()).sum() / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test.cpu().numpy()[:, i].reshape(-1, 1), test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "    # Create a DataFrame to store the performance metrics for each chromosome\n",
    "    performance_df = pd.DataFrame({\n",
    "        'Chromosome': list(range(start, chromosome_number + 1)),\n",
    "        'R2 Score': r2_scores,\n",
    "        'IQS Score': iqs_scores,\n",
    "        'Accuracy Score': accuracy_scores\n",
    "    })\n",
    "\n",
    "    # Save the performance metrics to a CSV file\n",
    "    performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "    performance_df.to_csv(performance_csv_file, index=False)\n",
    "    print(f\"Performance metrics saved at: {performance_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs:  929\n",
      "PRS313 SNPs:  30\n",
      "Total SNPs used for Training:  899\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr1/individual_r2_scores_chr1.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr1/individual_iqs_scores_chr1.csv\n",
      "Total SNPs:  629\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  608\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr2/individual_r2_scores_chr2.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr2/individual_iqs_scores_chr2.csv\n",
      "Total SNPs:  963\n",
      "PRS313 SNPs:  16\n",
      "Total SNPs used for Training:  947\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr3/individual_r2_scores_chr3.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr3/individual_iqs_scores_chr3.csv\n",
      "Total SNPs:  1261\n",
      "PRS313 SNPs:  11\n",
      "Total SNPs used for Training:  1250\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr4/individual_r2_scores_chr4.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr4/individual_iqs_scores_chr4.csv\n",
      "Total SNPs:  1289\n",
      "PRS313 SNPs:  34\n",
      "Total SNPs used for Training:  1255\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr5/individual_r2_scores_chr5.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr5/individual_iqs_scores_chr5.csv\n",
      "Total SNPs:  639\n",
      "PRS313 SNPs:  20\n",
      "Total SNPs used for Training:  619\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr6/individual_r2_scores_chr6.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr6/individual_iqs_scores_chr6.csv\n",
      "Total SNPs:  465\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  451\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr7/individual_r2_scores_chr7.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr7/individual_iqs_scores_chr7.csv\n",
      "Total SNPs:  454\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  433\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr8/individual_r2_scores_chr8.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr8/individual_iqs_scores_chr8.csv\n",
      "Total SNPs:  404\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  390\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr9/individual_r2_scores_chr9.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr9/individual_iqs_scores_chr9.csv\n",
      "Total SNPs:  608\n",
      "PRS313 SNPs:  18\n",
      "Total SNPs used for Training:  590\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr10/individual_r2_scores_chr10.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr10/individual_iqs_scores_chr10.csv\n",
      "Total SNPs:  919\n",
      "PRS313 SNPs:  19\n",
      "Total SNPs used for Training:  900\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr11/individual_r2_scores_chr11.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr11/individual_iqs_scores_chr11.csv\n",
      "Total SNPs:  641\n",
      "PRS313 SNPs:  17\n",
      "Total SNPs used for Training:  624\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr12/individual_r2_scores_chr12.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr12/individual_iqs_scores_chr12.csv\n",
      "Total SNPs:  112\n",
      "PRS313 SNPs:  5\n",
      "Total SNPs used for Training:  107\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr13/individual_r2_scores_chr13.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr13/individual_iqs_scores_chr13.csv\n",
      "Total SNPs:  164\n",
      "PRS313 SNPs:  8\n",
      "Total SNPs used for Training:  156\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr14/individual_r2_scores_chr14.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr14/individual_iqs_scores_chr14.csv\n",
      "Total SNPs:  200\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  193\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr15/individual_r2_scores_chr15.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr15/individual_iqs_scores_chr15.csv\n",
      "Total SNPs:  361\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  347\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr16/individual_r2_scores_chr16.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr16/individual_iqs_scores_chr16.csv\n",
      "Total SNPs:  188\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  179\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr17/individual_r2_scores_chr17.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr17/individual_iqs_scores_chr17.csv\n",
      "Total SNPs:  277\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  268\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr18/individual_r2_scores_chr18.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr18/individual_iqs_scores_chr18.csv\n",
      "Total SNPs:  288\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  281\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr19/individual_r2_scores_chr19.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr19/individual_iqs_scores_chr19.csv\n",
      "Total SNPs:  62\n",
      "PRS313 SNPs:  4\n",
      "Total SNPs used for Training:  58\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr20/individual_r2_scores_chr20.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr20/individual_iqs_scores_chr20.csv\n",
      "Total SNPs:  44\n",
      "PRS313 SNPs:  4\n",
      "Total SNPs used for Training:  40\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr21/individual_r2_scores_chr21.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr21/individual_iqs_scores_chr21.csv\n",
      "Total SNPs:  443\n",
      "PRS313 SNPs:  11\n",
      "Total SNPs used for Training:  432\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr22/individual_r2_scores_chr22.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr22/individual_iqs_scores_chr22.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/performance_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "auc_scores = []\n",
    "\n",
    "# Folders for saved models and CSV files\n",
    "output_folder = \"../../Data/model_results_unphased_all_PRS/linear_regression/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "\n",
    "def safe_auc_metric(y_pred, y_true):\n",
    "    if y_true.sum() == 0:\n",
    "        print(\"All true labels are negative. Returning NaN.\")\n",
    "        return np.NaN\n",
    "    return auc_metric(y_pred, y_true)\n",
    "\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Paths for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    file_name = data_directory + \\\n",
    "        f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(\n",
    "        regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.float32)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the linear regression model with L1 regularization\n",
    "    class LinearRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, l1_coef=0.0):\n",
    "            super(LinearRegression, self).__init__()\n",
    "            self.linear = nn.Linear(input_dim, output_dim)\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.linear(x)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * torch.norm(self.linear.weight, p=1)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the final model\n",
    "    model = LinearRegression(X_train_val.shape[1], y_train_val.shape[1])\n",
    "    model_save_path = chr_model_folder + \\\n",
    "        f'final_model_chr{chromosome_number}.pth'\n",
    "    model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_r2 = sklearn_r2_score(\n",
    "            y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(\n",
    "            y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_accuracy = ((y_test == test_outputs.round()).sum(\n",
    "        ) / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "        # Calculate the AUC for each SNP individually and then average them\n",
    "        y_test_np = y_test.cpu().numpy()\n",
    "        test_outputs_np = test_outputs.cpu().numpy()\n",
    "        auc_metric = BinaryAUROC(thresholds=None)\n",
    "\n",
    "        individual_aucs = [\n",
    "            [\n",
    "                safe_auc_metric(\n",
    "                    (test_outputs[:, j].round() == i).float(), (y_test[:, j] == i).float())\n",
    "                for i in range(3)\n",
    "            ]\n",
    "            for j in range(y_test_np.shape[1])\n",
    "        ]\n",
    "        # Flatten the list of individual AUCs\n",
    "        flattened_aucs = [auc for sublist in individual_aucs for auc in sublist]\n",
    "\n",
    "        # Calculate the mean while ignoring NaN values\n",
    "        test_auc = np.nanmean(flattened_aucs)\n",
    "        auc_scores.append(test_auc)\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(\n",
    "            y_test_np, test_outputs_np, multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test_np[:, i].reshape(\n",
    "            -1, 1), test_outputs_np[:, i].reshape(-1, 1)) for i in range(y_test_np.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + \\\n",
    "            f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + \\\n",
    "            f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "# Create a DataFrame to store the performance metrics for each chromosome\n",
    "performance_df = pd.DataFrame({\n",
    "    'Chromosome': list(range(start, 23)),\n",
    "    'R2 Score': r2_scores,\n",
    "    'IQS Score': iqs_scores,\n",
    "    'Accuracy Score': accuracy_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "# Save the performance metrics to a CSV file\n",
    "performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "performance_df.to_csv(performance_csv_file, index=False)\n",
    "print(f\"Performance metrics saved at: {performance_csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs:  361\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-29 13:55:58,111] A new study created in RDB with name: unphased_full_23andMe_chr16_study_logistic_regression\n",
      "/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "[I 2024-05-29 13:56:30,577] Trial 9 finished with value: 0.24898508079349996 and parameters: {'learning_rate': 0.04872641236887419, 'l1_coef': 2.6592495522505925e-08, 'patience': 7, 'batch_size': 128, 'lr_factor': 0.2990137707602612, 'num_epochs': 400}. Best is trial 9 with value: 0.24898508079349996.\n",
      "[I 2024-05-29 13:57:02,210] Trial 1 finished with value: 0.22615505531430244 and parameters: {'learning_rate': 0.007964323206459975, 'l1_coef': 2.2526348551581027e-08, 'patience': 14, 'batch_size': 128, 'lr_factor': 0.20020504421467733, 'num_epochs': 166}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 13:57:15,251] Trial 6 finished with value: 0.27919929027557366 and parameters: {'learning_rate': 0.01119513463884558, 'l1_coef': 3.715614219876556e-06, 'patience': 7, 'batch_size': 32, 'lr_factor': 0.7914019007622156, 'num_epochs': 276}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 13:58:05,485] Trial 10 finished with value: 0.23289248475006646 and parameters: {'learning_rate': 0.00472044966964745, 'l1_coef': 6.477308112404544e-07, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.8942675235234555, 'num_epochs': 171}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 13:58:19,473] Trial 0 finished with value: 1.783196645975113 and parameters: {'learning_rate': 0.015711969568559195, 'l1_coef': 0.08947438509188387, 'patience': 19, 'batch_size': 128, 'lr_factor': 0.5489307691170724, 'num_epochs': 348}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 13:58:58,682] Trial 14 finished with value: 0.24280470758676528 and parameters: {'learning_rate': 0.0380304444771611, 'l1_coef': 1.1799232583226754e-08, 'patience': 11, 'batch_size': 256, 'lr_factor': 0.6153828812962633, 'num_epochs': 106}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 13:59:29,337] Trial 13 finished with value: 0.35442547500133514 and parameters: {'learning_rate': 0.03654880727719641, 'l1_coef': 1.7401839120284644e-10, 'patience': 16, 'batch_size': 64, 'lr_factor': 0.8348548937789005, 'num_epochs': 322}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:01:32,754] Trial 15 finished with value: 0.4064425349235535 and parameters: {'learning_rate': 0.0020200143469040256, 'l1_coef': 0.0003932975179579167, 'patience': 8, 'batch_size': 64, 'lr_factor': 0.1931617565105797, 'num_epochs': 265}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:02:46,221] Trial 8 finished with value: 5.224677705764771 and parameters: {'learning_rate': 2.774339756947979e-06, 'l1_coef': 0.015220798090477283, 'patience': 7, 'batch_size': 256, 'lr_factor': 0.5135386541693224, 'num_epochs': 158}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:04:01,942] Trial 4 finished with value: 0.29969134330749514 and parameters: {'learning_rate': 0.0002934949490430271, 'l1_coef': 7.228921013967614e-05, 'patience': 15, 'batch_size': 64, 'lr_factor': 0.43617145421210946, 'num_epochs': 416}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:05:27,747] Trial 18 finished with value: 0.2380264479380388 and parameters: {'learning_rate': 0.006638210008113608, 'l1_coef': 6.393732873600316e-10, 'patience': 12, 'batch_size': 32, 'lr_factor': 0.7119294138025345, 'num_epochs': 390}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:05:39,167] Trial 17 finished with value: 0.42118805050849917 and parameters: {'learning_rate': 0.00012693339707102677, 'l1_coef': 1.1899204014996548e-09, 'patience': 9, 'batch_size': 256, 'lr_factor': 0.2865200371061046, 'num_epochs': 226}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:07:00,174] Trial 12 finished with value: 0.614828246831894 and parameters: {'learning_rate': 1.1510585938559408e-05, 'l1_coef': 0.00013991405033311137, 'patience': 14, 'batch_size': 128, 'lr_factor': 0.7187183934797398, 'num_epochs': 284}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:07:25,613] Trial 5 finished with value: 0.5041396588087081 and parameters: {'learning_rate': 1.9007740336299914e-05, 'l1_coef': 6.906373206882255e-05, 'patience': 16, 'batch_size': 128, 'lr_factor': 0.5854562831522213, 'num_epochs': 483}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:07:28,963] Trial 19 finished with value: 0.28725319132208826 and parameters: {'learning_rate': 0.00038990527779369697, 'l1_coef': 1.1063680761825808e-10, 'patience': 20, 'batch_size': 128, 'lr_factor': 0.10035397581695352, 'num_epochs': 213}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:08:08,750] Trial 21 finished with value: 0.2418808087706566 and parameters: {'learning_rate': 0.0011433174715554308, 'l1_coef': 2.0610161959339255e-07, 'patience': 15, 'batch_size': 128, 'lr_factor': 0.1008770459489498, 'num_epochs': 184}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:08:38,269] Trial 20 finished with value: 0.2939012490212917 and parameters: {'learning_rate': 0.0003956170499377468, 'l1_coef': 2.0618336859880833e-07, 'patience': 15, 'batch_size': 128, 'lr_factor': 0.11656602885170864, 'num_epochs': 196}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:08:53,578] Trial 22 finished with value: 0.2377690590918064 and parameters: {'learning_rate': 0.0016323592098159436, 'l1_coef': 3.021129138684483e-07, 'patience': 20, 'batch_size': 128, 'lr_factor': 0.11911749765927909, 'num_epochs': 487}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:09:11,372] Trial 24 finished with value: 0.24100804158619468 and parameters: {'learning_rate': 0.0014814618242466708, 'l1_coef': 5.218977326838793e-07, 'patience': 10, 'batch_size': 64, 'lr_factor': 0.899205029366101, 'num_epochs': 107}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:09:22,035] Trial 23 finished with value: 0.2309119190488543 and parameters: {'learning_rate': 0.0016771993001546185, 'l1_coef': 2.098523678539883e-07, 'patience': 19, 'batch_size': 64, 'lr_factor': 0.38984509668181566, 'num_epochs': 188}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:10:03,521] Trial 11 finished with value: 0.6654444013323102 and parameters: {'learning_rate': 3.844873179114244e-06, 'l1_coef': 3.9228868936941356e-08, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.5330795674593859, 'num_epochs': 196}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:10:50,165] Trial 2 finished with value: 1.1476156005492577 and parameters: {'learning_rate': 2.623894274482509e-06, 'l1_coef': 0.004999403319639727, 'patience': 11, 'batch_size': 32, 'lr_factor': 0.34662932185490836, 'num_epochs': 165}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:11:18,215] Trial 3 finished with value: 0.6504692792892456 and parameters: {'learning_rate': 2.1155666210327176e-06, 'l1_coef': 6.529901254464843e-07, 'patience': 6, 'batch_size': 64, 'lr_factor': 0.46124125660600124, 'num_epochs': 360}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:11:21,136] Trial 16 finished with value: 0.7104691863059998 and parameters: {'learning_rate': 1.2378999721821948e-06, 'l1_coef': 2.618632623544537e-08, 'patience': 13, 'batch_size': 64, 'lr_factor': 0.24274542343457572, 'num_epochs': 326}. Best is trial 1 with value: 0.22615505531430244.\n",
      "[I 2024-05-29 14:12:00,472] Trial 7 finished with value: 0.5823726658637707 and parameters: {'learning_rate': 1.8096254722466423e-06, 'l1_coef': 8.409033124662922e-08, 'patience': 19, 'batch_size': 32, 'lr_factor': 0.6630051507575886, 'num_epochs': 475}. Best is trial 1 with value: 0.22615505531430244.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 16 - Best hyperparameters: {'learning_rate': 0.007964323206459975, 'l1_coef': 2.2526348551581027e-08, 'patience': 14, 'batch_size': 128, 'lr_factor': 0.20020504421467733, 'num_epochs': 166}\n",
      "Chr 16 - Best value: 0.2262\n",
      "Final model saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/models_unphased/chr16/final_model_chr16.pth\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'calculate_iqs_unphased' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 229\u001b[0m\n\u001b[1;32m    227\u001b[0m test_outputs \u001b[38;5;241m=\u001b[39m test_outputs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    228\u001b[0m test_r2 \u001b[38;5;241m=\u001b[39m sklearn_r2_score(y_test\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), test_outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m--> 229\u001b[0m test_iqs \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_iqs_unphased\u001b[49m(y_test\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), test_outputs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    231\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m ((y_test \u001b[38;5;241m==\u001b[39m test_outputs)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m (test_outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m test_outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# Append performance metrics to the lists\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calculate_iqs_unphased' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score, accuracy_score\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 16\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Create folders for saving files\n",
    "output_folder = \"../../Data/model_results_unphased_all_PRS/logistic_regression/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Create subfolders for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    os.makedirs(chr_model_folder, exist_ok=True)\n",
    "    os.makedirs(chr_csv_folder, exist_ok=True)\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.long)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the multinomial logistic regression model with L1 regularization\n",
    "    class MulticlassLogisticRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, num_classes=3, l1_coef=0.0):\n",
    "            super(MulticlassLogisticRegression, self).__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.linear = nn.ModuleList([nn.Linear(input_dim, output_dim) for _ in range(num_classes)])\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = torch.stack([linear(x) for linear in self.linear], dim=-1)\n",
    "            # out = nn.functional.softmax(out, dim=-1)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * sum(torch.norm(linear.weight, p=1) for linear in self.linear)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set the hyperparameters for tuning\n",
    "    input_dim = X_train_val.shape[1]\n",
    "    output_dim = y_train_val.shape[1]\n",
    "    num_epochs = 500\n",
    "\n",
    "    # Define the objective function for Optuna with cross-validation and early stopping\n",
    "    def objective(trial):\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-1, log=True)\n",
    "        l1_coef = trial.suggest_float('l1_coef', 1e-10, 1e-1, log=True)\n",
    "        patience = trial.suggest_int('patience', 5, 20)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "        lr_factor = trial.suggest_float('lr_factor', 0.1, 0.9)\n",
    "        num_epochs = trial.suggest_int('num_epochs', 100, 500)\n",
    "\n",
    "        model = MulticlassLogisticRegression(input_dim, output_dim, l1_coef=l1_coef).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_factor, patience=patience, verbose=False)\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold_losses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_val)):\n",
    "            X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "            y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "            train_dataset = TensorDataset(X_train, y_train)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "            best_val_loss = float('inf')\n",
    "            counter = 0\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = 0.0\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs.transpose(1, 2), batch_y) + model.l1_loss()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                train_loss /= len(train_loader)\n",
    "\n",
    "                val_dataset = TensorDataset(X_val, y_val)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0.0\n",
    "                    for batch_X, batch_y in val_loader:\n",
    "                        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X)\n",
    "                        loss = criterion(outputs.transpose(1, 2), batch_y) + model.l1_loss()\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                    val_loss /= len(val_loader)\n",
    "                    scheduler.step(val_loss)\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= patience:\n",
    "                        break\n",
    "\n",
    "            fold_losses.append(best_val_loss)\n",
    "\n",
    "        return np.mean(fold_losses)\n",
    "    \n",
    "    # Create the \"optuna_studies\" folder if it doesn't exist\n",
    "    os.makedirs(\"optuna_studies\", exist_ok=True)\n",
    "\n",
    "    # Create an Optuna study and optimize the hyperparameters\n",
    "    study_name = f\"unphased_full_23andMe_chr{chromosome_number}_study_logistic_regression\"\n",
    "    storage_name = f\"sqlite:///optuna_studies/{study_name}.db\"\n",
    "\n",
    "    # Check if the study exists\n",
    "    current_dir = os.getcwd()\n",
    "    study_exists = os.path.exists(current_dir + f\"/optuna_studies/{study_name}.db\")\n",
    "\n",
    "    if study_exists:\n",
    "        # Load the existing study\n",
    "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "    else:\n",
    "        # Create a new study\n",
    "        study = optuna.create_study(direction='minimize', study_name=study_name, storage=storage_name)\n",
    "\n",
    "    study.optimize(objective, n_trials=25, n_jobs=-1)\n",
    "\n",
    "    # Print the best hyperparameters and best value\n",
    "    print(f\"Chr {chromosome_number} - Best hyperparameters: {study.best_params}\")\n",
    "    print(f\"Chr {chromosome_number} - Best value: {study.best_value:.4f}\")\n",
    "\n",
    "    # Train the final model with the best hyperparameters and early stopping\n",
    "    best_learning_rate = study.best_params['learning_rate']\n",
    "    best_l1_coef = study.best_params['l1_coef']\n",
    "    best_patience = study.best_params['patience']\n",
    "    best_batch_size = study.best_params['batch_size']\n",
    "    best_lr_factor = study.best_params['lr_factor']\n",
    "    best_num_epochs = study.best_params['num_epochs']\n",
    "\n",
    "    model = MulticlassLogisticRegression(input_dim, output_dim, l1_coef=best_l1_coef).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=best_lr_factor, patience=best_patience, verbose=False)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_val, y_train_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(best_num_epochs):\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs.transpose(1, 2), batch_y) + model.l1_loss()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            best_train_loss = train_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= best_patience:\n",
    "            break\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "    # Save the final model\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Final model saved at: {model_save_path}\")\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device)).softmax(dim=1)\n",
    "\n",
    "\n",
    "        test_outputs = test_outputs.argmax(dim=-1)\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "\n",
    "        test_accuracy = ((y_test == test_outputs).sum() / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test.cpu().numpy()[:, i].reshape(-1, 1), test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "    # Create a DataFrame to store the performance metrics for each chromosome\n",
    "    performance_df = pd.DataFrame({\n",
    "        'Chromosome': list(range(start, chromosome_number + 1)),\n",
    "        'R2 Score': r2_scores,\n",
    "        'IQS Score': iqs_scores,\n",
    "        'Accuracy Score': accuracy_scores\n",
    "    })\n",
    "\n",
    "    # Save the performance metrics to a CSV file\n",
    "    performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "    performance_df.to_csv(performance_csv_file, index=False)\n",
    "    print(f\"Performance metrics saved at: {performance_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs:  929\n",
      "PRS313 SNPs:  30\n",
      "Total SNPs used for Training:  899\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr1/individual_r2_scores_chr1.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr1/individual_iqs_scores_chr1.csv\n",
      "Total SNPs:  629\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  608\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr2/individual_r2_scores_chr2.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr2/individual_iqs_scores_chr2.csv\n",
      "Total SNPs:  963\n",
      "PRS313 SNPs:  16\n",
      "Total SNPs used for Training:  947\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr3/individual_r2_scores_chr3.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr3/individual_iqs_scores_chr3.csv\n",
      "Total SNPs:  1261\n",
      "PRS313 SNPs:  11\n",
      "Total SNPs used for Training:  1250\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr4/individual_r2_scores_chr4.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr4/individual_iqs_scores_chr4.csv\n",
      "Total SNPs:  1289\n",
      "PRS313 SNPs:  34\n",
      "Total SNPs used for Training:  1255\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr5/individual_r2_scores_chr5.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr5/individual_iqs_scores_chr5.csv\n",
      "Total SNPs:  639\n",
      "PRS313 SNPs:  20\n",
      "Total SNPs used for Training:  619\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr6/individual_r2_scores_chr6.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr6/individual_iqs_scores_chr6.csv\n",
      "Total SNPs:  465\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  451\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr7/individual_r2_scores_chr7.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr7/individual_iqs_scores_chr7.csv\n",
      "Total SNPs:  454\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  433\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr8/individual_r2_scores_chr8.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr8/individual_iqs_scores_chr8.csv\n",
      "Total SNPs:  404\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  390\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr9/individual_r2_scores_chr9.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr9/individual_iqs_scores_chr9.csv\n",
      "Total SNPs:  608\n",
      "PRS313 SNPs:  18\n",
      "Total SNPs used for Training:  590\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr10/individual_r2_scores_chr10.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr10/individual_iqs_scores_chr10.csv\n",
      "Total SNPs:  919\n",
      "PRS313 SNPs:  19\n",
      "Total SNPs used for Training:  900\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr11/individual_r2_scores_chr11.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr11/individual_iqs_scores_chr11.csv\n",
      "Total SNPs:  641\n",
      "PRS313 SNPs:  17\n",
      "Total SNPs used for Training:  624\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr12/individual_r2_scores_chr12.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr12/individual_iqs_scores_chr12.csv\n",
      "Total SNPs:  112\n",
      "PRS313 SNPs:  5\n",
      "Total SNPs used for Training:  107\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr13/individual_r2_scores_chr13.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr13/individual_iqs_scores_chr13.csv\n",
      "Total SNPs:  164\n",
      "PRS313 SNPs:  8\n",
      "Total SNPs used for Training:  156\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr14/individual_r2_scores_chr14.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr14/individual_iqs_scores_chr14.csv\n",
      "Total SNPs:  200\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  193\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr15/individual_r2_scores_chr15.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr15/individual_iqs_scores_chr15.csv\n",
      "Total SNPs:  361\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  347\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr16/individual_r2_scores_chr16.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr16/individual_iqs_scores_chr16.csv\n",
      "Total SNPs:  188\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  179\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr17/individual_r2_scores_chr17.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr17/individual_iqs_scores_chr17.csv\n",
      "Total SNPs:  277\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  268\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr18/individual_r2_scores_chr18.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr18/individual_iqs_scores_chr18.csv\n",
      "Total SNPs:  288\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  281\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr19/individual_r2_scores_chr19.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr19/individual_iqs_scores_chr19.csv\n",
      "Total SNPs:  62\n",
      "PRS313 SNPs:  4\n",
      "Total SNPs used for Training:  58\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr20/individual_r2_scores_chr20.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr20/individual_iqs_scores_chr20.csv\n",
      "Total SNPs:  44\n",
      "PRS313 SNPs:  4\n",
      "Total SNPs used for Training:  40\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr21/individual_r2_scores_chr21.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr21/individual_iqs_scores_chr21.csv\n",
      "Total SNPs:  443\n",
      "PRS313 SNPs:  11\n",
      "Total SNPs used for Training:  432\n",
      "Individual R^2 scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr22/individual_r2_scores_chr22.csv\n",
      "Individual IQS scores saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/chr22/individual_iqs_scores_chr22.csv\n",
      "Performance metrics saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/performance_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score, accuracy_score\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Folders for saved models and CSV files\n",
    "output_folder = \"../../Data/model_results_unphased_all_PRS/logistic_regression/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "def calculate_iqs_unphased(y_true, y_pred):\n",
    "    # Dummy implementation of IQS calculation, replace with the actual function\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Paths for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.long)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the multinomial logistic regression model with L1 regularization\n",
    "    class MulticlassLogisticRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, num_classes=3, l1_coef=0.0):\n",
    "            super(MulticlassLogisticRegression, self).__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.linear = nn.ModuleList([nn.Linear(input_dim, output_dim) for _ in range(num_classes)])\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = torch.stack([linear(x) for linear in self.linear], dim=-1)\n",
    "            out = nn.functional.softmax(out, dim=-1)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * sum(torch.norm(linear.weight, p=1) for linear in self.linear)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the final model\n",
    "    model = MulticlassLogisticRegression(X_train_val.shape[1], y_train_val.shape[1])\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_outputs = test_outputs.argmax(dim=-1)\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_accuracy = ((y_test == test_outputs).sum() / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test.cpu().numpy()[:, i].reshape(-1, 1), test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "# Create a DataFrame to store the performance metrics for each chromosome\n",
    "performance_df = pd.DataFrame({\n",
    "    'Chromosome': list(range(start, 23)),\n",
    "    'R2 Score': r2_scores,\n",
    "    'IQS Score': iqs_scores,\n",
    "    'Accuracy Score': accuracy_scores\n",
    "})\n",
    "\n",
    "# Save the performance metrics to a CSV file\n",
    "performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "performance_df.to_csv(performance_csv_file, index=False)\n",
    "print(f\"Performance metrics saved at: {performance_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRS313 SNPs saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/prs313_snps.csv\n",
      "Total number of PRS313 SNPs: 313\n"
     ]
    }
   ],
   "source": [
    "# Loop through all the training datasets and document the PRS313 SNPs in each dataset. Save this to a CSV file.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_directory = '../../Data/Filtered_unphased_training_data_union_final/'\n",
    "output_folder = \"../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize a list to store the PRS313 SNPs in each dataset\n",
    "prs313_snps = []\n",
    "\n",
    "for chromosome_number in range(1, 23):\n",
    "    file_name = data_directory + \\\n",
    "        f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    prs313_snps.append(data.filter(regex='PRS313_').columns)\n",
    "\n",
    "# Create a DataFrame to store the PRS313 SNPs in each dataset\n",
    "prs313_df = pd.DataFrame({\n",
    "    'Chromosome': list(range(1, 23)),\n",
    "    'PRS313 SNPs': prs313_snps,\n",
    "    \"Number of PRS313 SNPs\": [len(snps) for snps in prs313_snps]\n",
    "})\n",
    "\n",
    "# Save the PRS313 SNPs to a CSV file\n",
    "prs313_csv_file = output_folder + 'prs313_snps.csv'\n",
    "prs313_df.to_csv(prs313_csv_file, index=False)\n",
    "print(f\"PRS313 SNPs saved at: {prs313_csv_file}\")\n",
    "\n",
    "# Print the total number of PRS313 SNPs in all datasets\n",
    "total_prs313_snps = sum(prs313_df[\"Number of PRS313 SNPs\"])\n",
    "print(f\"Total number of PRS313 SNPs: {total_prs313_snps}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
