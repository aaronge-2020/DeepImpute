{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQS Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_iqs_unphased(true_genotypes, imputed_dosages):\n",
    "    # Convert imputed dosages to discrete values\n",
    "    imputed_discrete = np.round(imputed_dosages).astype(int)\n",
    "\n",
    "    # Clip the imputed discrete values to be within the range of 0 to 2\n",
    "    imputed_discrete = np.clip(imputed_discrete, 0, 2)\n",
    "\n",
    "    # Create a contingency table\n",
    "    contingency_table = np.zeros((3, 3), dtype=int)\n",
    "\n",
    "    # Fill the contingency table\n",
    "    for true_geno, imputed_geno in zip(true_genotypes, imputed_discrete):\n",
    "        for true_allele, imputed_allele in zip(true_geno, imputed_geno):\n",
    "            contingency_table[int(true_allele), int(imputed_allele)] += 1\n",
    "\n",
    "    # Calculate the total number of genotypes\n",
    "    total_genotypes = np.sum(contingency_table)\n",
    "\n",
    "    # Calculate observed proportion of agreement (Po)\n",
    "    observed_agreement = np.trace(contingency_table) / total_genotypes\n",
    "\n",
    "    # Calculate marginal sums\n",
    "    row_marginals = np.sum(contingency_table, axis=1)\n",
    "    col_marginals = np.sum(contingency_table, axis=0)\n",
    "\n",
    "    # Calculate chance agreement (Pc)\n",
    "    chance_agreement = np.sum((row_marginals * col_marginals) / (total_genotypes ** 2))\n",
    "\n",
    "    # Calculate IQS\n",
    "    if chance_agreement == 1:  # To prevent division by zero in case of perfect chance agreement\n",
    "        iqs_score = 0\n",
    "    else:\n",
    "        iqs_score = (observed_agreement - chance_agreement) / (1 - chance_agreement)\n",
    "\n",
    "    return iqs_score\n",
    "\n",
    "# Example usage:\n",
    "true_genotypes = np.array([[0, 1, 2], [1, 2, 0], [2, 0, 1]])\n",
    "imputed_dosages = np.array([[0.1, 1.2, 1.9], [1.0, 1.8, 0.3], [2.0, 0.5, 1.4]])\n",
    "\n",
    "iqs_score = calculate_iqs_unphased(true_genotypes, imputed_dosages)\n",
    "print(f\"IQS Score: {iqs_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs:  799\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "[I 2024-06-05 16:28:08,002] Trial 96 finished with value: 0.05541983060538769 and parameters: {'learning_rate': 0.00019056110021230626, 'l1_coef': 3.8522093805753517e-13, 'patience': 27, 'batch_size': 32, 'lr_factor': 0.520215164942225, 'num_epochs': 660}. Best is trial 96 with value: 0.05541983060538769.\n",
      "[I 2024-06-05 16:28:16,639] Trial 100 finished with value: 0.05530618572464356 and parameters: {'learning_rate': 0.00017386414252804717, 'l1_coef': 3.467578245678735e-13, 'patience': 28, 'batch_size': 32, 'lr_factor': 0.5371224461393395, 'num_epochs': 658}. Best is trial 100 with value: 0.05530618572464356.\n",
      "[I 2024-06-05 16:28:20,684] Trial 99 finished with value: 0.05547161363065243 and parameters: {'learning_rate': 0.00018150422057031822, 'l1_coef': 2.667762052540304e-13, 'patience': 28, 'batch_size': 32, 'lr_factor': 0.5488942522737796, 'num_epochs': 659}. Best is trial 100 with value: 0.05530618572464356.\n",
      "[I 2024-06-05 16:28:26,142] Trial 102 finished with value: 0.054780216658344635 and parameters: {'learning_rate': 0.00018886460009047496, 'l1_coef': 2.8011080196655184e-13, 'patience': 28, 'batch_size': 32, 'lr_factor': 0.5344823907717787, 'num_epochs': 681}. Best is trial 102 with value: 0.054780216658344635.\n",
      "[I 2024-06-05 16:28:34,661] Trial 103 finished with value: 0.05484732787769574 and parameters: {'learning_rate': 0.00017168093513837517, 'l1_coef': 3.9793957273024217e-13, 'patience': 28, 'batch_size': 32, 'lr_factor': 0.5202174535635714, 'num_epochs': 658}. Best is trial 102 with value: 0.054780216658344635.\n",
      "[I 2024-06-05 16:28:35,250] Trial 97 finished with value: 0.054745780390042534 and parameters: {'learning_rate': 0.00017869211140510044, 'l1_coef': 2.2953117775176035e-13, 'patience': 29, 'batch_size': 32, 'lr_factor': 0.5346538416192776, 'num_epochs': 655}. Best is trial 97 with value: 0.054745780390042534.\n",
      "[I 2024-06-05 16:28:35,735] Trial 94 finished with value: 0.054690294999342706 and parameters: {'learning_rate': 0.0001763983937875857, 'l1_coef': 2.2411909243636193e-13, 'patience': 28, 'batch_size': 32, 'lr_factor': 0.5313998846632214, 'num_epochs': 650}. Best is trial 94 with value: 0.054690294999342706.\n",
      "[I 2024-06-05 16:28:35,744] Trial 98 finished with value: 0.05505088599255452 and parameters: {'learning_rate': 0.00016773697144491229, 'l1_coef': 1.1617107887283823e-13, 'patience': 28, 'batch_size': 32, 'lr_factor': 0.5220026261677803, 'num_epochs': 654}. Best is trial 94 with value: 0.054690294999342706.\n",
      "[I 2024-06-05 16:28:42,983] Trial 101 finished with value: 0.05419941722200468 and parameters: {'learning_rate': 0.00019624094776564416, 'l1_coef': 2.509886005086065e-13, 'patience': 28, 'batch_size': 32, 'lr_factor': 0.5378940851188481, 'num_epochs': 646}. Best is trial 101 with value: 0.05419941722200468.\n",
      "[I 2024-06-05 16:28:58,910] Trial 95 finished with value: 0.05453832991994344 and parameters: {'learning_rate': 0.00017523263640720248, 'l1_coef': 2.8023819608680037e-13, 'patience': 28, 'batch_size': 32, 'lr_factor': 0.5329829672253867, 'num_epochs': 661}. Best is trial 101 with value: 0.05419941722200468.\n",
      "[I 2024-06-05 16:33:14,963] Trial 105 finished with value: 0.05516458890185906 and parameters: {'learning_rate': 0.0001771068815440236, 'l1_coef': 2.7541170749184403e-13, 'patience': 30, 'batch_size': 32, 'lr_factor': 0.5631110976485222, 'num_epochs': 661}. Best is trial 101 with value: 0.05419941722200468.\n",
      "[I 2024-06-05 16:33:18,093] Trial 104 finished with value: 0.055768450435537555 and parameters: {'learning_rate': 0.00017252592229752316, 'l1_coef': 1.641661576310126e-13, 'patience': 30, 'batch_size': 32, 'lr_factor': 0.5499831680340821, 'num_epochs': 665}. Best is trial 101 with value: 0.05419941722200468.\n",
      "[I 2024-06-05 16:34:05,143] Trial 106 finished with value: 0.05495558621791693 and parameters: {'learning_rate': 0.00012664285497626237, 'l1_coef': 1.7813737195747545e-13, 'patience': 33, 'batch_size': 32, 'lr_factor': 0.5668241004272463, 'num_epochs': 677}. Best is trial 101 with value: 0.05419941722200468.\n",
      "[I 2024-06-05 16:34:12,747] Trial 107 finished with value: 0.054307353095366405 and parameters: {'learning_rate': 0.0001462690489120357, 'l1_coef': 1.6762959912944575e-13, 'patience': 32, 'batch_size': 32, 'lr_factor': 0.5657297305134834, 'num_epochs': 680}. Best is trial 101 with value: 0.05419941722200468.\n",
      "[I 2024-06-05 16:34:24,092] Trial 109 finished with value: 0.0545797754652225 and parameters: {'learning_rate': 0.00013880022047131046, 'l1_coef': 1.7873912460670286e-13, 'patience': 32, 'batch_size': 32, 'lr_factor': 0.5798137361892365, 'num_epochs': 686}. Best is trial 101 with value: 0.05419941722200468.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 162\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# Create a new study\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m, study_name\u001b[38;5;241m=\u001b[39mstudy_name, storage\u001b[38;5;241m=\u001b[39mstorage_name, load_if_exists\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 162\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# Print the best hyperparameters and best value\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChr \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Best hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:81\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     78\u001b[0m time_start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m     79\u001b[0m futures: \u001b[38;5;28mset\u001b[39m[Future] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m---> 81\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn_submitted_trials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stop_flag\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score, accuracy_score\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 8\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Create folders for saving files\n",
    "output_folder = \"../../../Data/model_results_unphased_all_PRS/linear_regression/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Create subfolders for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    os.makedirs(chr_model_folder, exist_ok=True)\n",
    "    os.makedirs(chr_csv_folder, exist_ok=True)\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.float32)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the linear regression model with L1 regularization\n",
    "    class LinearRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, l1_coef=0.0):\n",
    "            super(LinearRegression, self).__init__()\n",
    "            self.linear = nn.Linear(input_dim, output_dim)\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.linear(x)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * torch.norm(self.linear.weight, p=1)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set the hyperparameters for tuning\n",
    "    input_dim = X_train_val.shape[1]\n",
    "    output_dim = y_train_val.shape[1]\n",
    "    num_epochs = 500\n",
    "\n",
    "    # Define the objective function for Optuna with cross-validation and early stopping\n",
    "    def objective(trial):\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-3, log=True)\n",
    "        l1_coef = trial.suggest_float('l1_coef', 1e-20, 1e-1, log=True)\n",
    "        patience = trial.suggest_int('patience', 5, 50)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "        lr_factor = trial.suggest_float('lr_factor', 0.1, 0.7)\n",
    "        num_epochs = trial.suggest_int('num_epochs', 200, 800)\n",
    "\n",
    "        model = LinearRegression(input_dim, output_dim, l1_coef).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.MSELoss()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_factor, patience=patience, verbose=False)\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold_losses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_val)):\n",
    "            X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "            y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "            train_dataset = TensorDataset(X_train, y_train)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "            best_val_loss = float('inf')\n",
    "            counter = 0\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = 0.0\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                train_loss /= len(train_loader)\n",
    "\n",
    "                val_dataset = TensorDataset(X_val, y_val)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0.0\n",
    "                    for batch_X, batch_y in val_loader:\n",
    "                        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X)\n",
    "                        loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                    val_loss /= len(val_loader)\n",
    "                    scheduler.step(val_loss)\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= patience:\n",
    "                        break\n",
    "\n",
    "            fold_losses.append(best_val_loss)\n",
    "\n",
    "        return np.mean(fold_losses)\n",
    "    # Create the \"optuna_studies\" folder if it doesn't exist\n",
    "    os.makedirs(\"optuna_studies\", exist_ok=True)\n",
    "\n",
    "    # Create an Optuna study and optimize the hyperparameters\n",
    "    study_name = f\"unphased_full_23andMe_chr{chromosome_number}_study_linear_regression\"\n",
    "    storage_name = f\"sqlite:///optuna_studies/{study_name}.db\"\n",
    "\n",
    "    # Check if the study exists\n",
    "    current_dir = os.getcwd()\n",
    "    study_exists = os.path.exists(current_dir + f\"/optuna_studies/{study_name}.db\")\n",
    "\n",
    "    if study_exists:\n",
    "        # Load the existing study\n",
    "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "    else:\n",
    "        # Create a new study\n",
    "        study = optuna.create_study(direction='minimize', study_name=study_name, storage=storage_name, load_if_exists= True)\n",
    "\n",
    "    study.optimize(objective, n_trials=25, n_jobs=-1)\n",
    "\n",
    "    # Print the best hyperparameters and best value\n",
    "    print(f\"Chr {chromosome_number} - Best hyperparameters: {study.best_params}\")\n",
    "    print(f\"Chr {chromosome_number} - Best value: {study.best_value:.4f}\")\n",
    "\n",
    "    # Train the final model with the best hyperparameters and early stopping\n",
    "    best_learning_rate = study.best_params['learning_rate']\n",
    "    best_l1_coef = study.best_params['l1_coef']\n",
    "    best_patience = study.best_params['patience']\n",
    "    best_batch_size = study.best_params['batch_size']\n",
    "    best_lr_factor = study.best_params['lr_factor']\n",
    "    best_num_epochs = study.best_params['num_epochs']\n",
    "\n",
    "    model = LinearRegression(input_dim, output_dim, best_l1_coef).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=best_lr_factor, patience=best_patience, verbose=False)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_val, y_train_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(best_num_epochs):\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y) + model.l1_loss()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            best_train_loss = train_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= best_patience:\n",
    "            break\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "    # Save the final model\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Final model saved at: {model_save_path}\")\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_accuracy = ((y_test == test_outputs.round()).sum() / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test.cpu().numpy()[:, i].reshape(-1, 1), test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "    # Create a DataFrame to store the performance metrics for each chromosome\n",
    "    performance_df = pd.DataFrame({\n",
    "        'Chromosome': list(range(start, chromosome_number + 1)),\n",
    "        'R2 Score': r2_scores,\n",
    "        'IQS Score': iqs_scores,\n",
    "        'Accuracy Score': accuracy_scores\n",
    "    })\n",
    "\n",
    "    # Save the performance metrics to a CSV file\n",
    "    performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "    performance_df.to_csv(performance_csv_file, index=False)\n",
    "    print(f\"Performance metrics saved at: {performance_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs:  2028\n",
      "PRS313 SNPs:  30\n",
      "Total SNPs used for Training:  1998\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr1/individual_r2_scores_chr1.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr1/individual_iqs_scores_chr1.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr1/individual_accuracy_scores_chr1.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr1/individual_auc_scores_chr1.csv\n",
      "Total SNPs:  1044\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  1023\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr2/individual_r2_scores_chr2.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr2/individual_iqs_scores_chr2.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr2/individual_accuracy_scores_chr2.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr2/individual_auc_scores_chr2.csv\n",
      "Total SNPs:  1255\n",
      "PRS313 SNPs:  16\n",
      "Total SNPs used for Training:  1239\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr3/individual_r2_scores_chr3.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr3/individual_iqs_scores_chr3.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr3/individual_accuracy_scores_chr3.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr3/individual_auc_scores_chr3.csv\n",
      "Total SNPs:  1488\n",
      "PRS313 SNPs:  11\n",
      "Total SNPs used for Training:  1477\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr4/individual_r2_scores_chr4.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr4/individual_iqs_scores_chr4.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr4/individual_accuracy_scores_chr4.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr4/individual_auc_scores_chr4.csv\n",
      "Total SNPs:  2038\n",
      "PRS313 SNPs:  34\n",
      "Total SNPs used for Training:  2004\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr5/individual_r2_scores_chr5.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr5/individual_iqs_scores_chr5.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr5/individual_accuracy_scores_chr5.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr5/individual_auc_scores_chr5.csv\n",
      "Total SNPs:  853\n",
      "PRS313 SNPs:  20\n",
      "Total SNPs used for Training:  833\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr6/individual_r2_scores_chr6.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr6/individual_iqs_scores_chr6.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr6/individual_accuracy_scores_chr6.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr6/individual_auc_scores_chr6.csv\n",
      "Total SNPs:  735\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  721\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr7/individual_r2_scores_chr7.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr7/individual_iqs_scores_chr7.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr7/individual_accuracy_scores_chr7.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr7/individual_auc_scores_chr7.csv\n",
      "Total SNPs:  799\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  778\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr8/individual_r2_scores_chr8.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr8/individual_iqs_scores_chr8.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr8/individual_accuracy_scores_chr8.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr8/individual_auc_scores_chr8.csv\n",
      "Total SNPs:  653\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  639\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr9/individual_r2_scores_chr9.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr9/individual_iqs_scores_chr9.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr9/individual_accuracy_scores_chr9.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr9/individual_auc_scores_chr9.csv\n",
      "Total SNPs:  942\n",
      "PRS313 SNPs:  18\n",
      "Total SNPs used for Training:  924\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr10/individual_r2_scores_chr10.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr10/individual_iqs_scores_chr10.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr10/individual_accuracy_scores_chr10.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr10/individual_auc_scores_chr10.csv\n",
      "Total SNPs:  1275\n",
      "PRS313 SNPs:  19\n",
      "Total SNPs used for Training:  1256\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr11/individual_r2_scores_chr11.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr11/individual_iqs_scores_chr11.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr11/individual_accuracy_scores_chr11.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr11/individual_auc_scores_chr11.csv\n",
      "Total SNPs:  852\n",
      "PRS313 SNPs:  17\n",
      "Total SNPs used for Training:  835\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr12/individual_r2_scores_chr12.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr12/individual_iqs_scores_chr12.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr12/individual_accuracy_scores_chr12.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr12/individual_auc_scores_chr12.csv\n",
      "Total SNPs:  152\n",
      "PRS313 SNPs:  5\n",
      "Total SNPs used for Training:  147\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr13/individual_r2_scores_chr13.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr13/individual_iqs_scores_chr13.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr13/individual_accuracy_scores_chr13.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr13/individual_auc_scores_chr13.csv\n",
      "Total SNPs:  459\n",
      "PRS313 SNPs:  8\n",
      "Total SNPs used for Training:  451\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr14/individual_r2_scores_chr14.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr14/individual_iqs_scores_chr14.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr14/individual_accuracy_scores_chr14.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr14/individual_auc_scores_chr14.csv\n",
      "Total SNPs:  310\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  303\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr15/individual_r2_scores_chr15.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr15/individual_iqs_scores_chr15.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr15/individual_accuracy_scores_chr15.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr15/individual_auc_scores_chr15.csv\n",
      "Total SNPs:  606\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  592\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr16/individual_r2_scores_chr16.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr16/individual_iqs_scores_chr16.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr16/individual_accuracy_scores_chr16.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr16/individual_auc_scores_chr16.csv\n",
      "Total SNPs:  380\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  371\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr17/individual_r2_scores_chr17.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr17/individual_iqs_scores_chr17.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr17/individual_accuracy_scores_chr17.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr17/individual_auc_scores_chr17.csv\n",
      "Total SNPs:  589\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  580\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr18/individual_r2_scores_chr18.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr18/individual_iqs_scores_chr18.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr18/individual_accuracy_scores_chr18.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr18/individual_auc_scores_chr18.csv\n",
      "Total SNPs:  348\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  341\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr19/individual_r2_scores_chr19.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr19/individual_iqs_scores_chr19.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr19/individual_accuracy_scores_chr19.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr19/individual_auc_scores_chr19.csv\n",
      "Total SNPs:  108\n",
      "PRS313 SNPs:  4\n",
      "Total SNPs used for Training:  104\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr20/individual_r2_scores_chr20.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr20/individual_iqs_scores_chr20.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr20/individual_accuracy_scores_chr20.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr20/individual_auc_scores_chr20.csv\n",
      "Total SNPs:  94\n",
      "PRS313 SNPs:  4\n",
      "Total SNPs used for Training:  90\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr21/individual_r2_scores_chr21.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr21/individual_iqs_scores_chr21.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr21/individual_accuracy_scores_chr21.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr21/individual_auc_scores_chr21.csv\n",
      "Total SNPs:  542\n",
      "PRS313 SNPs:  11\n",
      "Total SNPs used for Training:  531\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr22/individual_r2_scores_chr22.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr22/individual_iqs_scores_chr22.csv\n",
      "Individual Accuracy scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr22/individual_accuracy_scores_chr22.csv\n",
      "Individual AUC scores saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/chr22/individual_auc_scores_chr22.csv\n",
      "All predictions saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/all_predictions.csv\n",
      "Performance metrics saved at: ../../../Data/model_results_unphased_all_PRS/linear_regression/csv_files/performance_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "auc_scores = []\n",
    "\n",
    "# Initialize a dictionary to store predictions and sample IDs\n",
    "predictions_dict = {}\n",
    "\n",
    "# Folders for saved models and CSV files\n",
    "output_folder = \"../../../Data/model_results_unphased_all_PRS/linear_regression/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "def safe_auc_metric(y_pred, y_true):\n",
    "    if y_true.sum() == 0:\n",
    "        print(\"All true labels are negative. Returning NaN.\")\n",
    "        return np.NaN\n",
    "    return auc_metric(y_pred, y_true)\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Paths for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    file_name = data_directory + \\\n",
    "        f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Extract sample IDs\n",
    "    sample_ids = data.index.values\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(\n",
    "        regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.float32)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test, sample_ids_train_val, sample_ids_test = train_test_split(\n",
    "        X, y, sample_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the linear regression model with L1 regularization\n",
    "    class LinearRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, l1_coef=0.0):\n",
    "            super(LinearRegression, self).__init__()\n",
    "            self.linear = nn.Linear(input_dim, output_dim)\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.linear(x)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * torch.norm(self.linear.weight, p=1)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the final model\n",
    "    model = LinearRegression(X_train_val.shape[1], y_train_val.shape[1])\n",
    "    model_save_path = chr_model_folder + \\\n",
    "        f'final_model_chr{chromosome_number}.pth'\n",
    "    model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_outputs = torch.clamp(test_outputs, min=0, max=2)\n",
    "        test_r2 = sklearn_r2_score(\n",
    "            y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(\n",
    "            y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_accuracy = ((y_test == test_outputs.round()).sum(\n",
    "        ) / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "        # Calculate the AUC for each SNP individually and then average them\n",
    "        y_test_np = y_test.cpu().numpy()\n",
    "        test_outputs_np = test_outputs.cpu().numpy()\n",
    "        auc_metric = BinaryAUROC(thresholds=None)\n",
    "\n",
    "        individual_aucs = [\n",
    "            [\n",
    "                safe_auc_metric(\n",
    "                    (test_outputs[:, j].round() == i).float(), (y_test[:, j] == i).float())\n",
    "                for i in range(3)\n",
    "            ]\n",
    "            for j in range(y_test_np.shape[1])\n",
    "        ]\n",
    "        # Flatten the list of individual AUCs\n",
    "        flattened_aucs = [auc for sublist in individual_aucs for auc in sublist]\n",
    "\n",
    "        # Calculate the mean while ignoring NaN values\n",
    "        test_auc = np.nanmean(flattened_aucs)\n",
    "        auc_scores.append(test_auc)\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(\n",
    "            y_test_np, test_outputs_np, multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test_np[:, i].reshape(\n",
    "            -1, 1), test_outputs_np[:, i].reshape(-1, 1)) for i in range(y_test_np.shape[1])])\n",
    "\n",
    "        # Calculate individual accuracy for each SNP\n",
    "        individual_accuracy_scores = np.array([\n",
    "            ((y_test_np[:, i] == np.round(test_outputs_np[:, i])).sum() / y_test_np.shape[0])\n",
    "            for i in range(y_test_np.shape[1])\n",
    "        ])\n",
    "\n",
    "        # Flatten individual AUC scores into a single array for each SNP\n",
    "        individual_auc_scores = np.nanmean(np.array(individual_aucs), axis=1)\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "        # Store predictions and sample IDs in the dictionary\n",
    "        for sample_id, prediction in zip(sample_ids_test, test_outputs_np):\n",
    "            if sample_id not in predictions_dict:\n",
    "                predictions_dict[sample_id] = {}\n",
    "            for snp, value in zip(snp_names, prediction):\n",
    "                predictions_dict[sample_id][snp] = value\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + \\\n",
    "            f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + \\\n",
    "            f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "        # Save individual accuracy scores to a CSV file\n",
    "        accuracy_csv_file = chr_csv_folder + \\\n",
    "            f'individual_accuracy_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(accuracy_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'Accuracy Score'])\n",
    "            for snp, accuracy_score in zip(snp_names, individual_accuracy_scores):\n",
    "                writer.writerow([snp, accuracy_score])\n",
    "\n",
    "        print(f\"Individual Accuracy scores saved at: {accuracy_csv_file}\")\n",
    "\n",
    "        # Save individual AUC scores to a CSV file\n",
    "        auc_csv_file = chr_csv_folder + \\\n",
    "            f'individual_auc_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(auc_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'AUC Score'])\n",
    "            for snp, auc_score in zip(snp_names, individual_auc_scores):\n",
    "                writer.writerow([snp, auc_score])\n",
    "\n",
    "        print(f\"Individual AUC scores saved at: {auc_csv_file}\")\n",
    "\n",
    "# Convert the predictions dictionary to a DataFrame\n",
    "all_predictions_df = pd.DataFrame.from_dict(predictions_dict, orient='index')\n",
    "all_predictions_df.reset_index(inplace=True)\n",
    "all_predictions_df.rename(columns={'index': 'SampleID'}, inplace=True)\n",
    "\n",
    "# Save the combined predictions to a single CSV file\n",
    "all_predictions_df.to_csv(csv_folder + 'all_predictions.csv', index=False)\n",
    "print(f\"All predictions saved at: {csv_folder + 'all_predictions.csv'}\")\n",
    "\n",
    "# Create a DataFrame to store the performance metrics for each chromosome\n",
    "performance_df = pd.DataFrame({\n",
    "    'Chromosome': list(range(start, 23)),\n",
    "    'R2 Score': r2_scores,\n",
    "    'IQS Score': iqs_scores,\n",
    "    'Accuracy Score': accuracy_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "# Save the performance metrics to a CSV file\n",
    "performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "performance_df.to_csv(performance_csv_file, index=False)\n",
    "print(f\"Performance metrics saved at: {performance_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs:  2028\n",
      "PRS313 SNPs:  30\n",
      "Total SNPs used for Training:  1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-05 16:14:02,096] Using an existing study with name 'unphased_full_23andMe_chr1_study_logistic_regression' instead of creating a new one.\n",
      "/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score, accuracy_score\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Create folders for saving files\n",
    "output_folder = \"../../../Data/model_results_unphased_all_PRS/logistic_regression/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Create subfolders for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    os.makedirs(chr_model_folder, exist_ok=True)\n",
    "    os.makedirs(chr_csv_folder, exist_ok=True)\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.long)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the multinomial logistic regression model with L1 regularization\n",
    "    class MulticlassLogisticRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, num_classes=3, l1_coef=0.0):\n",
    "            super(MulticlassLogisticRegression, self).__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.linear = nn.ModuleList([nn.Linear(input_dim, output_dim) for _ in range(num_classes)])\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = torch.stack([linear(x) for linear in self.linear], dim=-1)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * sum(torch.norm(linear.weight, p=1) for linear in self.linear)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set the hyperparameters for tuning\n",
    "    input_dim = X_train_val.shape[1]\n",
    "    output_dim = y_train_val.shape[1]\n",
    "    num_epochs = 500\n",
    "\n",
    "    # Define the objective function for Optuna with cross-validation and early stopping\n",
    "    def objective(trial):\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-1, log=True)\n",
    "        l1_coef = trial.suggest_float('l1_coef', 1e-10, 1e-1, log=True)\n",
    "        patience = trial.suggest_int('patience', 5, 20)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n",
    "        lr_factor = trial.suggest_float('lr_factor', 0.1, 0.9)\n",
    "        num_epochs = trial.suggest_int('num_epochs', 100, 500)\n",
    "\n",
    "        model = MulticlassLogisticRegression(input_dim, output_dim, l1_coef=l1_coef).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_factor, patience=patience, verbose=False)\n",
    "\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        fold_losses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_val)):\n",
    "            X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "            y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "            train_dataset = TensorDataset(X_train, y_train)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "            best_val_loss = float('inf')\n",
    "            counter = 0\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = 0.0\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs.transpose(1, 2), batch_y) + model.l1_loss()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                train_loss /= len(train_loader)\n",
    "\n",
    "                val_dataset = TensorDataset(X_val, y_val)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0.0\n",
    "                    for batch_X, batch_y in val_loader:\n",
    "                        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X)\n",
    "                        loss = criterion(outputs.transpose(1, 2), batch_y) + model.l1_loss()\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                    val_loss /= len(val_loader)\n",
    "                    scheduler.step(val_loss)\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= patience:\n",
    "                        break\n",
    "\n",
    "            fold_losses.append(best_val_loss)\n",
    "\n",
    "        return np.mean(fold_losses)\n",
    "    \n",
    "    # Create the \"optuna_studies\" folder if it doesn't exist\n",
    "    os.makedirs(\"optuna_studies_logistic\", exist_ok=True)\n",
    "\n",
    "    # Create an Optuna study and optimize the hyperparameters\n",
    "    study_name = f\"unphased_full_23andMe_chr{chromosome_number}_study_logistic_regression\"\n",
    "    storage_name = f\"sqlite:///optuna_studies_logistic/{study_name}.db\"\n",
    "\n",
    "    # Check if the study exists\n",
    "    current_dir = os.getcwd()\n",
    "    study_exists = os.path.exists(current_dir + f\"/optuna_studies/{study_name}.db\")\n",
    "\n",
    "    if study_exists:\n",
    "        # Load the existing study\n",
    "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "    else:\n",
    "        # Create a new study\n",
    "        study = optuna.create_study(direction='minimize', study_name=study_name, storage=storage_name, load_if_exists= True)\n",
    "\n",
    "    study.optimize(objective, n_trials=25, n_jobs=-1)\n",
    "\n",
    "    # Print the best hyperparameters and best value\n",
    "    print(f\"Chr {chromosome_number} - Best hyperparameters: {study.best_params}\")\n",
    "    print(f\"Chr {chromosome_number} - Best value: {study.best_value:.4f}\")\n",
    "\n",
    "    # Train the final model with the best hyperparameters and early stopping\n",
    "    best_learning_rate = study.best_params['learning_rate']\n",
    "    best_l1_coef = study.best_params['l1_coef']\n",
    "    best_patience = study.best_params['patience']\n",
    "    best_batch_size = study.best_params['batch_size']\n",
    "    best_lr_factor = study.best_params['lr_factor']\n",
    "    best_num_epochs = study.best_params['num_epochs']\n",
    "\n",
    "    model = MulticlassLogisticRegression(input_dim, output_dim, l1_coef=best_l1_coef).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=best_lr_factor, patience=best_patience, verbose=False)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_val, y_train_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(best_num_epochs):\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs.transpose(1, 2), batch_y) + model.l1_loss()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            best_train_loss = train_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= best_patience:\n",
    "            break\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "    # Save the final model\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Final model saved at: {model_save_path}\")\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device)).softmax(dim=2)\n",
    "\n",
    "        test_outputs = test_outputs.argmax(dim=-1)\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "\n",
    "        test_accuracy = ((y_test == test_outputs).sum() / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test.cpu().numpy()[:, i].reshape(-1, 1), test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "    # Create a DataFrame to store the performance metrics for each chromosome\n",
    "    performance_df = pd.DataFrame({\n",
    "        'Chromosome': list(range(start, chromosome_number + 1)),\n",
    "        'R2 Score': r2_scores,\n",
    "        'IQS Score': iqs_scores,\n",
    "        'Accuracy Score': accuracy_scores\n",
    "    })\n",
    "\n",
    "    # Save the performance metrics to a CSV file\n",
    "    performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "    performance_df.to_csv(performance_csv_file, index=False)\n",
    "    print(f\"Performance metrics saved at: {performance_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../Data/Filtered_unphased_training_data_union_final/23AndMe_PRS313_merged_chr1_matching_combined.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m chr_csv_folder \u001b[38;5;241m=\u001b[39m csv_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m file_name \u001b[38;5;241m=\u001b[39m data_directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m23AndMe_PRS313_merged_chr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_matching_combined.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 35\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Split the data into features and target\u001b[39;00m\n\u001b[1;32m     38\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(data\u001b[38;5;241m.\u001b[39mfilter(regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^(?!.*PRS313_)\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/pandas/io/parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    275\u001b[0m         path_or_handle,\n\u001b[1;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/pandas/io/parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../Data/Filtered_unphased_training_data_union_final/23AndMe_PRS313_merged_chr1_matching_combined.parquet'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score, accuracy_score\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Initialize lists to store predictions and SNP names for all chromosomes\n",
    "all_predictions = []\n",
    "all_snp_names = []\n",
    "\n",
    "# Folders for saved models and CSV files\n",
    "output_folder = \"../../Data/model_results_unphased_all_PRS/logistic_regression/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Paths for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.long)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the multinomial logistic regression model with L1 regularization\n",
    "    class MulticlassLogisticRegression(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, num_classes=3, l1_coef=0.0):\n",
    "            super(MulticlassLogisticRegression, self).__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.linear = nn.ModuleList([nn.Linear(input_dim, output_dim) for _ in range(num_classes)])\n",
    "            self.l1_coef = l1_coef\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = torch.stack([linear(x) for linear in self.linear], dim=-1)\n",
    "            out = nn.functional.softmax(out, dim=-1)\n",
    "            return out\n",
    "\n",
    "        def l1_loss(self):\n",
    "            return self.l1_coef * sum(torch.norm(linear.weight, p=1) for linear in self.linear)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the final model\n",
    "    model = MulticlassLogisticRegression(X_train_val.shape[1], y_train_val.shape[1])\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device))\n",
    "        test_outputs = test_outputs.argmax(dim=-1)\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_accuracy = ((y_test == test_outputs).sum() / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "        # Append predictions and SNP names to the respective lists\n",
    "        all_predictions.append(test_outputs.cpu().numpy())\n",
    "        all_snp_names.extend(snp_names)\n",
    "\n",
    "# Concatenate all predictions and SNP names\n",
    "all_predictions = np.concatenate(all_predictions, axis=1)\n",
    "all_snp_names = np.array(all_snp_names)\n",
    "\n",
    "# Create a DataFrame for the concatenated predictions and SNP names\n",
    "predictions_df = pd.DataFrame(all_predictions, columns=all_snp_names)\n",
    "\n",
    "# Save the concatenated predictions and SNP names to a single CSV file\n",
    "predictions_csv_file = csv_folder + 'imputed_snps_all_chromosomes.csv'\n",
    "predictions_df.to_csv(predictions_csv_file, index=False)\n",
    "print(f\"Imputed SNPs saved at: {predictions_csv_file}\")\n",
    "\n",
    "# Create a DataFrame to store the performance metrics for each chromosome\n",
    "performance_df = pd.DataFrame({\n",
    "    'Chromosome': list(range(start, 23)),\n",
    "    'R2 Score': r2_scores,\n",
    "    'IQS Score': iqs_scores,\n",
    "    'Accuracy Score': accuracy_scores\n",
    "})\n",
    "\n",
    "# Save the performance metrics to a CSV file\n",
    "performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "performance_df.to_csv(performance_csv_file, index=False)\n",
    "print(f\"Performance metrics saved at: {performance_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRS313 SNPs saved at: ../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/prs313_snps.csv\n",
      "Total number of PRS313 SNPs: 313\n"
     ]
    }
   ],
   "source": [
    "# Loop through all the training datasets and document the PRS313 SNPs in each dataset. Save this to a CSV file.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_directory = '../../Data/Filtered_unphased_training_data_union_final/'\n",
    "output_folder = \"../../Data/model_results_unphased_all_PRS/logistic_regression/csv_files/\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize a list to store the PRS313 SNPs in each dataset\n",
    "prs313_snps = []\n",
    "\n",
    "for chromosome_number in range(1, 23):\n",
    "    file_name = data_directory + \\\n",
    "        f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    prs313_snps.append(data.filter(regex='PRS313_').columns)\n",
    "\n",
    "# Create a DataFrame to store the PRS313 SNPs in each dataset\n",
    "prs313_df = pd.DataFrame({\n",
    "    'Chromosome': list(range(1, 23)),\n",
    "    'PRS313 SNPs': prs313_snps,\n",
    "    \"Number of PRS313 SNPs\": [len(snps) for snps in prs313_snps]\n",
    "})\n",
    "\n",
    "# Save the PRS313 SNPs to a CSV file\n",
    "prs313_csv_file = output_folder + 'prs313_snps.csv'\n",
    "prs313_df.to_csv(prs313_csv_file, index=False)\n",
    "print(f\"PRS313 SNPs saved at: {prs313_csv_file}\")\n",
    "\n",
    "# Print the total number of PRS313 SNPs in all datasets\n",
    "total_prs313_snps = sum(prs313_df[\"Number of PRS313 SNPs\"])\n",
    "print(f\"Total number of PRS313 SNPs: {total_prs313_snps}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
