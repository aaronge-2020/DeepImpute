{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQS Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_iqs_unphased(true_genotypes, imputed_dosages):\n",
    "    # Convert imputed dosages to discrete values\n",
    "    imputed_discrete = np.round(imputed_dosages).astype(int)\n",
    "\n",
    "    # Clip the imputed discrete values to be within the range of 0 to 2\n",
    "    imputed_discrete = np.clip(imputed_discrete, 0, 2)\n",
    "\n",
    "    # Create a contingency table\n",
    "    contingency_table = np.zeros((3, 3), dtype=int)\n",
    "\n",
    "    # Fill the contingency table\n",
    "    for true_geno, imputed_geno in zip(true_genotypes, imputed_discrete):\n",
    "        for true_allele, imputed_allele in zip(true_geno, imputed_geno):\n",
    "            contingency_table[int(true_allele), int(imputed_allele)] += 1\n",
    "\n",
    "    # Calculate the total number of genotypes\n",
    "    total_genotypes = np.sum(contingency_table)\n",
    "\n",
    "    # Calculate observed proportion of agreement (Po)\n",
    "    observed_agreement = np.trace(contingency_table) / total_genotypes\n",
    "\n",
    "    # Calculate marginal sums\n",
    "    row_marginals = np.sum(contingency_table, axis=1)\n",
    "    col_marginals = np.sum(contingency_table, axis=0)\n",
    "\n",
    "    # Calculate chance agreement (Pc)\n",
    "    chance_agreement = np.sum((row_marginals * col_marginals) / (total_genotypes ** 2))\n",
    "\n",
    "    # Calculate IQS\n",
    "    if chance_agreement == 1:  # To prevent division by zero in case of perfect chance agreement\n",
    "        iqs_score = 0\n",
    "    else:\n",
    "        iqs_score = (observed_agreement - chance_agreement) / (1 - chance_agreement)\n",
    "\n",
    "    return iqs_score\n",
    "\n",
    "# Example usage:\n",
    "true_genotypes = np.array([[0, 1, 2], [1, 2, 0], [2, 0, 1]])\n",
    "imputed_dosages = np.array([[0.1, 1.2, 1.9], [1.0, 1.8, 0.3], [2.0, 0.5, 1.4]])\n",
    "\n",
    "iqs_score = calculate_iqs_unphased(true_genotypes, imputed_dosages)\n",
    "print(f\"IQS Score: {iqs_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs:  2028\n",
      "PRS313 SNPs:  30\n",
      "Total SNPs used for Training:  1998\n",
      "Scaler saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/models_unphased/chr1/scaler_chr1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-06-05 11:35:08,603] Trial 85 failed with parameters: {'hidden_layers': 5, 'n_units_l0': 1200, 'n_units_l1': 289, 'n_units_l2': 1174, 'n_units_l3': 295, 'n_units_l4': 1430, 'dropout_rate': 0.03088787491878156, 'learning_rate': 1.0756286763330967e-10, 'weight_decay': 1.6971654416703372e-09} because of the following error: ValueError('CategoricalDistribution does not support dynamic value space.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/530268578.py\", line 97, in objective\n",
      "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 404, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 635, in _suggest\n",
      "    storage.set_trial_param(trial_id, name, param_value_in_internal_repr, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_cached_storage.py\", line 171, in set_trial_param\n",
      "    self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 568, in set_trial_param\n",
      "    self._set_trial_param_without_commit(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 603, in _set_trial_param_without_commit\n",
      "    trial_param.check_and_add(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 360, in check_and_add\n",
      "    self._check_compatibility_with_previous_trial_param_distributions(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 376, in _check_compatibility_with_previous_trial_param_distributions\n",
      "    distributions.check_distribution_compatibility(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/distributions.py\", line 670, in check_distribution_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: CategoricalDistribution does not support dynamic value space.\n",
      "[W 2024-06-05 11:35:08,777] Trial 85 failed with value None.\n",
      "[W 2024-06-05 11:35:08,837] Trial 88 failed with parameters: {'hidden_layers': 5, 'n_units_l0': 1274, 'n_units_l1': 1629, 'n_units_l2': 1351, 'n_units_l3': 298, 'n_units_l4': 1551, 'dropout_rate': 0.03434688203191559, 'learning_rate': 3.9698473383971476e-11, 'weight_decay': 1.88705306943395e-09} because of the following error: ValueError('CategoricalDistribution does not support dynamic value space.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/530268578.py\", line 97, in objective\n",
      "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 404, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 635, in _suggest\n",
      "    storage.set_trial_param(trial_id, name, param_value_in_internal_repr, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_cached_storage.py\", line 171, in set_trial_param\n",
      "    self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 568, in set_trial_param\n",
      "    self._set_trial_param_without_commit(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 603, in _set_trial_param_without_commit\n",
      "    trial_param.check_and_add(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 360, in check_and_add\n",
      "    self._check_compatibility_with_previous_trial_param_distributions(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 376, in _check_compatibility_with_previous_trial_param_distributions\n",
      "    distributions.check_distribution_compatibility(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/distributions.py\", line 670, in check_distribution_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: CategoricalDistribution does not support dynamic value space.\n",
      "[W 2024-06-05 11:35:08,874] Trial 88 failed with value None.\n",
      "[W 2024-06-05 11:35:08,898] Trial 87 failed with parameters: {'hidden_layers': 5, 'n_units_l0': 1144, 'n_units_l1': 1962, 'n_units_l2': 400, 'n_units_l3': 307, 'n_units_l4': 1324, 'dropout_rate': 0.031203763547980767, 'learning_rate': 1.0766144300315827e-10, 'weight_decay': 2.9813314507169527e-09} because of the following error: ValueError('CategoricalDistribution does not support dynamic value space.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/530268578.py\", line 97, in objective\n",
      "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 404, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 635, in _suggest\n",
      "    storage.set_trial_param(trial_id, name, param_value_in_internal_repr, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_cached_storage.py\", line 171, in set_trial_param\n",
      "    self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 568, in set_trial_param\n",
      "    self._set_trial_param_without_commit(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 603, in _set_trial_param_without_commit\n",
      "    trial_param.check_and_add(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 360, in check_and_add\n",
      "    self._check_compatibility_with_previous_trial_param_distributions(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 376, in _check_compatibility_with_previous_trial_param_distributions\n",
      "    distributions.check_distribution_compatibility(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/distributions.py\", line 670, in check_distribution_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: CategoricalDistribution does not support dynamic value space.\n",
      "[W 2024-06-05 11:35:08,903] Trial 87 failed with value None.\n",
      "[W 2024-06-05 11:35:08,920] Trial 91 failed with parameters: {'hidden_layers': 5, 'n_units_l0': 478, 'n_units_l1': 287, 'n_units_l2': 1188, 'n_units_l3': 297, 'n_units_l4': 1323, 'dropout_rate': 0.03291055856698561, 'learning_rate': 2.925103642641748e-10, 'weight_decay': 3.765510419427351e-08} because of the following error: ValueError('CategoricalDistribution does not support dynamic value space.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/530268578.py\", line 97, in objective\n",
      "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 404, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 635, in _suggest\n",
      "    storage.set_trial_param(trial_id, name, param_value_in_internal_repr, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_cached_storage.py\", line 171, in set_trial_param\n",
      "    self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 568, in set_trial_param\n",
      "    self._set_trial_param_without_commit(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 603, in _set_trial_param_without_commit\n",
      "    trial_param.check_and_add(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 360, in check_and_add\n",
      "    self._check_compatibility_with_previous_trial_param_distributions(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 376, in _check_compatibility_with_previous_trial_param_distributions\n",
      "    distributions.check_distribution_compatibility(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/distributions.py\", line 670, in check_distribution_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: CategoricalDistribution does not support dynamic value space.\n",
      "[W 2024-06-05 11:35:08,930] Trial 91 failed with value None.\n",
      "[W 2024-06-05 11:35:08,937] Trial 93 failed with parameters: {'hidden_layers': 5, 'n_units_l0': 1194, 'n_units_l1': 1834, 'n_units_l2': 394, 'n_units_l3': 302, 'n_units_l4': 1439, 'dropout_rate': 0.031584537416318184, 'learning_rate': 1.1021314265967778e-10, 'weight_decay': 3.237749103153255e-08} because of the following error: ValueError('CategoricalDistribution does not support dynamic value space.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/530268578.py\", line 97, in objective\n",
      "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 404, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 635, in _suggest\n",
      "    storage.set_trial_param(trial_id, name, param_value_in_internal_repr, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_cached_storage.py\", line 171, in set_trial_param\n",
      "    self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 568, in set_trial_param\n",
      "    self._set_trial_param_without_commit(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 603, in _set_trial_param_without_commit\n",
      "    trial_param.check_and_add(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 360, in check_and_add\n",
      "    self._check_compatibility_with_previous_trial_param_distributions(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 376, in _check_compatibility_with_previous_trial_param_distributions\n",
      "    distributions.check_distribution_compatibility(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/distributions.py\", line 670, in check_distribution_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: CategoricalDistribution does not support dynamic value space.\n",
      "[W 2024-06-05 11:35:08,981] Trial 93 failed with value None.\n",
      "[W 2024-06-05 11:35:09,108] Trial 84 failed with parameters: {'hidden_layers': 5, 'n_units_l0': 1305, 'n_units_l1': 286, 'n_units_l2': 1926, 'n_units_l3': 301, 'n_units_l4': 1596, 'dropout_rate': 0.03283193231898553, 'learning_rate': 4.642368681219649e-06, 'weight_decay': 2.4036980246974504e-08} because of the following error: ValueError('CategoricalDistribution does not support dynamic value space.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/530268578.py\", line 97, in objective\n",
      "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 404, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 635, in _suggest\n",
      "    storage.set_trial_param(trial_id, name, param_value_in_internal_repr, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_cached_storage.py\", line 171, in set_trial_param\n",
      "    self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 568, in set_trial_param\n",
      "    self._set_trial_param_without_commit(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 603, in _set_trial_param_without_commit\n",
      "    trial_param.check_and_add(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 360, in check_and_add\n",
      "    self._check_compatibility_with_previous_trial_param_distributions(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 376, in _check_compatibility_with_previous_trial_param_distributions\n",
      "    distributions.check_distribution_compatibility(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/distributions.py\", line 670, in check_distribution_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: CategoricalDistribution does not support dynamic value space.\n",
      "[W 2024-06-05 11:35:09,150] Trial 84 failed with value None.\n",
      "[W 2024-06-05 11:35:09,330] Trial 90 failed with parameters: {'hidden_layers': 5, 'n_units_l0': 1431, 'n_units_l1': 1562, 'n_units_l2': 406, 'n_units_l3': 300, 'n_units_l4': 1517, 'dropout_rate': 0.03841241351955459, 'learning_rate': 8.350368521747914e-11, 'weight_decay': 5.1494612046867604e-08} because of the following error: ValueError('CategoricalDistribution does not support dynamic value space.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/530268578.py\", line 97, in objective\n",
      "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 404, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 635, in _suggest\n",
      "    storage.set_trial_param(trial_id, name, param_value_in_internal_repr, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_cached_storage.py\", line 171, in set_trial_param\n",
      "    self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 568, in set_trial_param\n",
      "    self._set_trial_param_without_commit(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 603, in _set_trial_param_without_commit\n",
      "    trial_param.check_and_add(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 360, in check_and_add\n",
      "    self._check_compatibility_with_previous_trial_param_distributions(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 376, in _check_compatibility_with_previous_trial_param_distributions\n",
      "    distributions.check_distribution_compatibility(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/distributions.py\", line 670, in check_distribution_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: CategoricalDistribution does not support dynamic value space.\n",
      "[W 2024-06-05 11:35:09,337] Trial 90 failed with value None.\n",
      "[W 2024-06-05 11:35:09,448] Trial 86 failed with parameters: {'hidden_layers': 5, 'n_units_l0': 1584, 'n_units_l1': 288, 'n_units_l2': 1543, 'n_units_l3': 299, 'n_units_l4': 1420, 'dropout_rate': 0.03164308855027661, 'learning_rate': 2.9318642232164084e-11, 'weight_decay': 2.699750576696089e-09} because of the following error: ValueError('CategoricalDistribution does not support dynamic value space.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/530268578.py\", line 97, in objective\n",
      "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 404, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 635, in _suggest\n",
      "    storage.set_trial_param(trial_id, name, param_value_in_internal_repr, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_cached_storage.py\", line 171, in set_trial_param\n",
      "    self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 568, in set_trial_param\n",
      "    self._set_trial_param_without_commit(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 603, in _set_trial_param_without_commit\n",
      "    trial_param.check_and_add(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 360, in check_and_add\n",
      "    self._check_compatibility_with_previous_trial_param_distributions(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 376, in _check_compatibility_with_previous_trial_param_distributions\n",
      "    distributions.check_distribution_compatibility(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/distributions.py\", line 670, in check_distribution_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: CategoricalDistribution does not support dynamic value space.\n",
      "[W 2024-06-05 11:35:09,531] Trial 86 failed with value None.\n",
      "[W 2024-06-05 11:35:09,528] Trial 92 failed with parameters: {'hidden_layers': 5, 'n_units_l0': 1181, 'n_units_l1': 2056, 'n_units_l2': 392, 'n_units_l3': 300, 'n_units_l4': 1439, 'dropout_rate': 0.027443034154560335, 'learning_rate': 1.593063769147518e-10, 'weight_decay': 1.4350638159524546e-09} because of the following error: ValueError('CategoricalDistribution does not support dynamic value space.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/530268578.py\", line 97, in objective\n",
      "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 404, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 635, in _suggest\n",
      "    storage.set_trial_param(trial_id, name, param_value_in_internal_repr, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_cached_storage.py\", line 171, in set_trial_param\n",
      "    self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 568, in set_trial_param\n",
      "    self._set_trial_param_without_commit(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 603, in _set_trial_param_without_commit\n",
      "    trial_param.check_and_add(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 360, in check_and_add\n",
      "    self._check_compatibility_with_previous_trial_param_distributions(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 376, in _check_compatibility_with_previous_trial_param_distributions\n",
      "    distributions.check_distribution_compatibility(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/distributions.py\", line 670, in check_distribution_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: CategoricalDistribution does not support dynamic value space.\n",
      "[W 2024-06-05 11:35:09,540] Trial 92 failed with value None.\n",
      "[W 2024-06-05 11:35:09,451] Trial 89 failed with parameters: {'hidden_layers': 5, 'n_units_l0': 1260, 'n_units_l1': 290, 'n_units_l2': 1270, 'n_units_l3': 302, 'n_units_l4': 1352, 'dropout_rate': 0.03393334584080415, 'learning_rate': 1.4362232119235896e-11, 'weight_decay': 2.4945146558264966e-09} because of the following error: ValueError('CategoricalDistribution does not support dynamic value space.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/530268578.py\", line 97, in objective\n",
      "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 404, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/trial/_trial.py\", line 635, in _suggest\n",
      "    storage.set_trial_param(trial_id, name, param_value_in_internal_repr, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_cached_storage.py\", line 171, in set_trial_param\n",
      "    self._backend.set_trial_param(trial_id, param_name, param_value_internal, distribution)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 568, in set_trial_param\n",
      "    self._set_trial_param_without_commit(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/storage.py\", line 603, in _set_trial_param_without_commit\n",
      "    trial_param.check_and_add(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 360, in check_and_add\n",
      "    self._check_compatibility_with_previous_trial_param_distributions(session)\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/storages/_rdb/models.py\", line 376, in _check_compatibility_with_previous_trial_param_distributions\n",
      "    distributions.check_distribution_compatibility(\n",
      "  File \"/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/distributions.py\", line 670, in check_distribution_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: CategoricalDistribution does not support dynamic value space.\n",
      "[W 2024-06-05 11:35:09,550] Trial 89 failed with value None.\n",
      "/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr 1 - Best hyperparameters: {'hidden_layers': 5, 'n_units_l0': 428, 'n_units_l1': 105, 'n_units_l2': 459, 'n_units_l3': 99, 'n_units_l4': 1028, 'dropout_rate': 0.0068400271532692535, 'learning_rate': 0.0005433655967430965, 'weight_decay': 9.46911482240261e-08, 'batch_size': 64}\n",
      "Chr 1 - Best value: 0.0676\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 217\u001b[0m\n\u001b[1;32m    214\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m), batch_y)\n\u001b[1;32m    216\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 217\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    220\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Create folders for saving files\n",
    "output_folder = \"../../../Data/model_results_unphased_all_PRS/neural_network/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Create subfolders for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    os.makedirs(chr_model_folder, exist_ok=True)\n",
    "    os.makedirs(chr_csv_folder, exist_ok=True)\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.long)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Normalize the features\n",
    "    scaler = StandardScaler()\n",
    "    X = torch.tensor(scaler.fit_transform(X), dtype=torch.float32)\n",
    "    import joblib\n",
    "\n",
    "    # Save the scaler to disk\n",
    "    scaler_filename = f'{chr_model_folder}scaler_chr{chromosome_number}.pkl'\n",
    "    joblib.dump(scaler, scaler_filename)\n",
    "    print(f\"Scaler saved at: {scaler_filename}\")\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the neural network model\n",
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, hidden_dims, dropout_rate):\n",
    "            super(NeuralNetwork, self).__init__()\n",
    "            layers = []\n",
    "            prev_dim = input_dim\n",
    "            for hidden_dim in hidden_dims:\n",
    "                layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "                prev_dim = hidden_dim\n",
    "            layers.append(nn.Linear(prev_dim, output_dim * 3))\n",
    "            self.net = nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.net(x)\n",
    "            out = out.view(out.size(0), -1, 3)\n",
    "            return out\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set the hyperparameters for tuning\n",
    "    input_dim = X_train_val.shape[1]\n",
    "    output_dim = y_train_val.shape[1]\n",
    "\n",
    "    # Define the objective function for Optuna with cross-validation and early stopping\n",
    "    def objective(trial):\n",
    "        hidden_layers = trial.suggest_int('hidden_layers', 1, 5)\n",
    "        hidden_dims = [trial.suggest_int(f'n_units_l{i}', 256, 2056, log=True) for i in range(hidden_layers)]\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 1e-11, 0.25)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-11, 1e-5, log=True)\n",
    "        patience = 40\n",
    "        weight_decay = trial.suggest_float('weight_decay', 1e-11, 1e-5, log=True)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [ 32, 64, 128, 256])\n",
    "        lr_factor = 0.1\n",
    "        num_epochs = 300\n",
    "\n",
    "        model = NeuralNetwork(input_dim, output_dim, hidden_dims, dropout_rate).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_factor, patience=patience, verbose=False)\n",
    "\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        fold_losses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_val)):\n",
    "            X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "            y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "            train_dataset = TensorDataset(X_train, y_train)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "            best_val_loss = float('inf')\n",
    "            counter = 0\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = 0.0\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs.transpose(1, 2), batch_y)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                train_loss /= len(train_loader)\n",
    "\n",
    "                val_dataset = TensorDataset(X_val, y_val)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0.0\n",
    "                    for batch_X, batch_y in val_loader:\n",
    "                        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X)\n",
    "                        loss = criterion(outputs.transpose(1, 2), batch_y)\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                    val_loss /= len(val_loader)\n",
    "                    scheduler.step(val_loss)\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= patience:\n",
    "                        break\n",
    "\n",
    "            fold_losses.append(best_val_loss)\n",
    "\n",
    "        return np.mean(fold_losses)\n",
    "    \n",
    "    # Create the \"optuna_studies\" folder if it doesn't exist\n",
    "    os.makedirs(\"optuna_studies_nn\", exist_ok=True)\n",
    "\n",
    "    # Create an Optuna study and optimize the hyperparameters\n",
    "    study_name = f\"unphased_full_23andMe_chr{chromosome_number}_study_nn\"\n",
    "    storage_name = f\"sqlite:///optuna_studies_nn/{study_name}.db\"\n",
    "\n",
    "    # Check if the study exists\n",
    "    current_dir = os.getcwd()\n",
    "    study_exists = os.path.exists(current_dir + f\"/optuna_studies_nn/{study_name}.db\")\n",
    "\n",
    "    if study_exists:\n",
    "        # Load the existing study\n",
    "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "    else:\n",
    "        # Create a new study\n",
    "        study = optuna.create_study(direction='minimize', study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "\n",
    "    study.optimize(objective, n_trials=10, n_jobs=-1)\n",
    "\n",
    "    # Print the best hyperparameters and best value\n",
    "    print(f\"Chr {chromosome_number} - Best hyperparameters: {study.best_params}\")\n",
    "    print(f\"Chr {chromosome_number} - Best value: {study.best_value:.4f}\")\n",
    "\n",
    "    # Train the final model with the best hyperparameters and early stopping\n",
    "    best_hidden_layers = study.best_params['hidden_layers']\n",
    "    best_hidden_dims = [study.best_params[f'n_units_l{i}'] for i in range(best_hidden_layers)]\n",
    "    best_dropout_rate = study.best_params['dropout_rate']\n",
    "    best_learning_rate = study.best_params['learning_rate']\n",
    "    best_patience = 20\n",
    "    best_weight_decay = study.best_params['weight_decay']\n",
    "    best_batch_size = study.best_params['batch_size']\n",
    "    best_lr_factor = 0.25\n",
    "    best_num_epochs = 300\n",
    "\n",
    "    model = NeuralNetwork(input_dim, output_dim, best_hidden_dims, best_dropout_rate).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate, weight_decay=best_weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=best_lr_factor, patience=best_patience, verbose=False)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_val, y_train_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(best_num_epochs):\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs.transpose(1, 2), batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            best_train_loss = train_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= best_patience:\n",
    "            break\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "    # Save the final model\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Final model saved at: {model_save_path}\")\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device)).softmax(dim=2)\n",
    "        test_outputs = test_outputs.argmax(dim=-1)\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "\n",
    "        test_accuracy = ((y_test == test_outputs).sum() / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test.cpu().numpy()[:, i].reshape(-1, 1), test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "    # Create a DataFrame to store the performance metrics for each chromosome\n",
    "    performance_df = pd.DataFrame({\n",
    "        'Chromosome': list(range(start, chromosome_number + 1)),\n",
    "        'R2 Score': r2_scores,\n",
    "        'IQS Score': iqs_scores,\n",
    "        'Accuracy Score': accuracy_scores\n",
    "    })\n",
    "\n",
    "    # Save the performance metrics to a CSV file\n",
    "    performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "    performance_df.to_csv(performance_csv_file, index=False)\n",
    "    print(f\"Performance metrics saved at: {performance_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs:  2028\n",
      "PRS313 SNPs:  30\n",
      "Total SNPs used for Training:  1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr1/individual_r2_scores_chr1.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr1/individual_iqs_scores_chr1.csv\n",
      "Total SNPs:  1044\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr2/individual_r2_scores_chr2.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr2/individual_iqs_scores_chr2.csv\n",
      "Total SNPs:  1255\n",
      "PRS313 SNPs:  16\n",
      "Total SNPs used for Training:  1239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr3/individual_r2_scores_chr3.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr3/individual_iqs_scores_chr3.csv\n",
      "Total SNPs:  1488\n",
      "PRS313 SNPs:  11\n",
      "Total SNPs used for Training:  1477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr4/individual_r2_scores_chr4.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr4/individual_iqs_scores_chr4.csv\n",
      "Total SNPs:  2038\n",
      "PRS313 SNPs:  34\n",
      "Total SNPs used for Training:  2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr5/individual_r2_scores_chr5.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr5/individual_iqs_scores_chr5.csv\n",
      "Total SNPs:  853\n",
      "PRS313 SNPs:  20\n",
      "Total SNPs used for Training:  833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr6/individual_r2_scores_chr6.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr6/individual_iqs_scores_chr6.csv\n",
      "Total SNPs:  735\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr7/individual_r2_scores_chr7.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr7/individual_iqs_scores_chr7.csv\n",
      "Total SNPs:  799\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr8/individual_r2_scores_chr8.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr8/individual_iqs_scores_chr8.csv\n",
      "Total SNPs:  653\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr9/individual_r2_scores_chr9.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr9/individual_iqs_scores_chr9.csv\n",
      "Total SNPs:  942\n",
      "PRS313 SNPs:  18\n",
      "Total SNPs used for Training:  924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr10/individual_r2_scores_chr10.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr10/individual_iqs_scores_chr10.csv\n",
      "Total SNPs:  1275\n",
      "PRS313 SNPs:  19\n",
      "Total SNPs used for Training:  1256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr11/individual_r2_scores_chr11.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr11/individual_iqs_scores_chr11.csv\n",
      "Total SNPs:  852\n",
      "PRS313 SNPs:  17\n",
      "Total SNPs used for Training:  835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr12/individual_r2_scores_chr12.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr12/individual_iqs_scores_chr12.csv\n",
      "Total SNPs:  152\n",
      "PRS313 SNPs:  5\n",
      "Total SNPs used for Training:  147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr13/individual_r2_scores_chr13.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr13/individual_iqs_scores_chr13.csv\n",
      "Total SNPs:  459\n",
      "PRS313 SNPs:  8\n",
      "Total SNPs used for Training:  451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr14/individual_r2_scores_chr14.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr14/individual_iqs_scores_chr14.csv\n",
      "Total SNPs:  310\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr15/individual_r2_scores_chr15.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr15/individual_iqs_scores_chr15.csv\n",
      "Total SNPs:  606\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr16/individual_r2_scores_chr16.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr16/individual_iqs_scores_chr16.csv\n",
      "Total SNPs:  380\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr17/individual_r2_scores_chr17.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr17/individual_iqs_scores_chr17.csv\n",
      "Total SNPs:  589\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr18/individual_r2_scores_chr18.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr18/individual_iqs_scores_chr18.csv\n",
      "Total SNPs:  348\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr19/individual_r2_scores_chr19.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr19/individual_iqs_scores_chr19.csv\n",
      "Total SNPs:  108\n",
      "PRS313 SNPs:  4\n",
      "Total SNPs used for Training:  104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 108\u001b[0m\n\u001b[1;32m    105\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m X_train_val\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    106\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m y_train_val\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 108\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_dim, output_dim, best_hidden_dims, best_dropout_rate)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    110\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m chr_model_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_model_chr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    111\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_save_path, map_location\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[8], line 108\u001b[0m\n\u001b[1;32m    105\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m X_train_val\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    106\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m y_train_val\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 108\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_dim, output_dim, best_hidden_dims, best_dropout_rate)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    110\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m chr_model_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_model_chr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    111\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_save_path, map_location\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "import os\n",
    "import csv\n",
    "import joblib\n",
    "import optuna\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "auc_scores = []\n",
    "\n",
    "# Folders for saved models and CSV files\n",
    "output_folder = \"../../../Data/model_results_unphased_all_PRS/neural_network/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "def safe_auc_metric(y_pred, y_true):\n",
    "    if y_true.sum() == 0:\n",
    "        print(\"All true labels are negative. Returning NaN.\")\n",
    "        return np.NaN\n",
    "    return auc_metric(y_pred, y_true)\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Paths for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = data.filter(regex='^(?!.*PRS313_)').values\n",
    "    y = data.filter(regex='PRS313_').values\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Load the scaler\n",
    "    scaler_filename = f'{chr_model_folder}scaler_chr{chromosome_number}.pkl'\n",
    "    scaler = joblib.load(scaler_filename)\n",
    "    X = torch.tensor(scaler.transform(X), dtype=torch.float32)\n",
    "\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the neural network model\n",
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, hidden_dims, dropout_rate):\n",
    "            super(NeuralNetwork, self).__init__()\n",
    "            layers = []\n",
    "            prev_dim = input_dim\n",
    "            for hidden_dim in hidden_dims:\n",
    "                layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "                prev_dim = hidden_dim\n",
    "            layers.append(nn.Linear(prev_dim, output_dim * 3))\n",
    "            self.net = nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.net(x)\n",
    "            out = out.view(out.size(0), -1, 3)\n",
    "            return out\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load Optuna study\n",
    "    study_name = f\"unphased_full_23andMe_chr{chromosome_number}_study_nn\"\n",
    "    storage_name = f\"sqlite:///optuna_studies_nn/{study_name}.db\"\n",
    "\n",
    "    # Check if the study exists\n",
    "    current_dir = os.getcwd()\n",
    "    study_exists = os.path.exists(current_dir + f\"/optuna_studies_nn/{study_name}.db\")\n",
    "\n",
    "    if study_exists:\n",
    "        # Load the existing study\n",
    "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "        best_hidden_layers = study.best_params['hidden_layers']\n",
    "        best_hidden_dims = [study.best_params[f'n_units_l{i}'] for i in range(best_hidden_layers)]\n",
    "        best_dropout_rate = study.best_params['dropout_rate']\n",
    "        best_learning_rate = study.best_params['learning_rate']\n",
    "        best_patience = 20\n",
    "        best_weight_decay = study.best_params['weight_decay']\n",
    "        best_batch_size = study.best_params['batch_size']\n",
    "        best_lr_factor = 0.25\n",
    "        best_num_epochs = 300\n",
    "\n",
    "        input_dim = X_train_val.shape[1]\n",
    "        output_dim = y_train_val.shape[1]\n",
    "\n",
    "        model = NeuralNetwork(input_dim, output_dim, best_hidden_dims, best_dropout_rate).to(device)\n",
    "\n",
    "        model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "        state_dict = torch.load(model_save_path, map_location=device)\n",
    "\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        # Evaluate the final model on the test set\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test.to(device)).softmax(dim=2)\n",
    "            test_outputs = test_outputs.argmax(dim=-1)\n",
    "            test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "            test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "            test_accuracy = ((y_test == test_outputs).sum() / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "            # Calculate the AUC for each SNP individually and then average them\n",
    "            y_test_np = y_test.cpu().numpy()\n",
    "            test_outputs_np = test_outputs.cpu().numpy()\n",
    "            auc_metric = BinaryAUROC(thresholds=None)\n",
    "\n",
    "            individual_aucs = [\n",
    "                [\n",
    "                    safe_auc_metric((test_outputs[:, j].round() == i).float(), (y_test[:, j] == i).float())\n",
    "                    for i in range(3)\n",
    "                ]\n",
    "                for j in range(y_test_np.shape[1])\n",
    "            ]\n",
    "            # Flatten the list of individual AUCs\n",
    "            flattened_aucs = [auc for sublist in individual_aucs for auc in sublist]\n",
    "\n",
    "            # Calculate the mean while ignoring NaN values\n",
    "            test_auc = np.nanmean(flattened_aucs)\n",
    "            auc_scores.append(test_auc)\n",
    "\n",
    "            # Append performance metrics to the lists\n",
    "            r2_scores.append(test_r2)\n",
    "            iqs_scores.append(test_iqs)\n",
    "            accuracy_scores.append(test_accuracy)\n",
    "\n",
    "            # Calculate individual R^2 scores for each SNP\n",
    "            individual_r2_scores = sklearn_r2_score(y_test_np, test_outputs_np, multioutput='raw_values')\n",
    "\n",
    "            # Calculate individual IQS scores for each SNP\n",
    "            individual_iqs_scores = np.array([calculate_iqs_unphased(y_test_np[:, i].reshape(-1, 1), test_outputs_np[:, i].reshape(-1, 1)) for i in range(y_test_np.shape[1])])\n",
    "\n",
    "            # Get the names of the SNPs from the original dataframe\n",
    "            snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "            # Save individual R^2 scores to a CSV file\n",
    "            csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "            with open(csv_file, 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['SNP', 'R2 Score'])\n",
    "                for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                    writer.writerow([snp, r2_score])\n",
    "\n",
    "            print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "            # Save individual IQS scores to a CSV file\n",
    "            iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "            with open(iqs_csv_file, 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['SNP', 'IQS Score'])\n",
    "                for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                    writer.writerow([snp, iqs_score])\n",
    "\n",
    "            print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "# Create a DataFrame to store the performance metrics for each chromosome\n",
    "performance_df = pd.DataFrame({\n",
    "    'Chromosome': list(range(start, 23)),\n",
    "    'R2 Score': r2_scores,\n",
    "    'IQS Score': iqs_scores,\n",
    "    'Accuracy Score': accuracy_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "# Save the performance metrics to a CSV file\n",
    "performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "performance_df.to_csv(performance_csv_file, index=False)\n",
    "print(f\"Performance metrics saved at: {performance_csv_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
