{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQS Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_iqs_unphased(true_genotypes, imputed_dosages):\n",
    "    # Convert imputed dosages to discrete values\n",
    "    imputed_discrete = np.round(imputed_dosages).astype(int)\n",
    "\n",
    "    # Clip the imputed discrete values to be within the range of 0 to 2\n",
    "    imputed_discrete = np.clip(imputed_discrete, 0, 2)\n",
    "\n",
    "    # Create a contingency table\n",
    "    contingency_table = np.zeros((3, 3), dtype=int)\n",
    "\n",
    "    # Fill the contingency table\n",
    "    for true_geno, imputed_geno in zip(true_genotypes, imputed_discrete):\n",
    "        for true_allele, imputed_allele in zip(true_geno, imputed_geno):\n",
    "            contingency_table[int(true_allele), int(imputed_allele)] += 1\n",
    "\n",
    "    # Calculate the total number of genotypes\n",
    "    total_genotypes = np.sum(contingency_table)\n",
    "\n",
    "    # Calculate observed proportion of agreement (Po)\n",
    "    observed_agreement = np.trace(contingency_table) / total_genotypes\n",
    "\n",
    "    # Calculate marginal sums\n",
    "    row_marginals = np.sum(contingency_table, axis=1)\n",
    "    col_marginals = np.sum(contingency_table, axis=0)\n",
    "\n",
    "    # Calculate chance agreement (Pc)\n",
    "    chance_agreement = np.sum((row_marginals * col_marginals) / (total_genotypes ** 2))\n",
    "\n",
    "    # Calculate IQS\n",
    "    if chance_agreement == 1:  # To prevent division by zero in case of perfect chance agreement\n",
    "        iqs_score = 0\n",
    "    else:\n",
    "        iqs_score = (observed_agreement - chance_agreement) / (1 - chance_agreement)\n",
    "\n",
    "    return iqs_score\n",
    "\n",
    "# Example usage:\n",
    "true_genotypes = np.array([[0, 1, 2], [1, 2, 0], [2, 0, 1]])\n",
    "imputed_dosages = np.array([[0.1, 1.2, 1.9], [1.0, 1.8, 0.3], [2.0, 0.5, 1.4]])\n",
    "\n",
    "iqs_score = calculate_iqs_unphased(true_genotypes, imputed_dosages)\n",
    "print(f\"IQS Score: {iqs_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs:  2028\n",
      "PRS313 SNPs:  30\n",
      "Total SNPs used for Training:  1998\n",
      "Scaler saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/models_unphased/chr1/scaler_chr1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gea2/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 180\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# Create a new study\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m, study_name\u001b[38;5;241m=\u001b[39mstudy_name, storage\u001b[38;5;241m=\u001b[39mstorage_name, load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 180\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Print the best hyperparameters and best value\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChr \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Best hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/optuna/study/_optimize.py:81\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     78\u001b[0m time_start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m     79\u001b[0m futures: \u001b[38;5;28mset\u001b[39m[Future] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m---> 81\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn_submitted_trials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stop_flag\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Create folders for saving files\n",
    "output_folder = \"../../../Data/model_results_unphased_all_PRS/neural_network/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "os.makedirs(csv_folder, exist_ok=True)\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Create subfolders for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    os.makedirs(chr_model_folder, exist_ok=True)\n",
    "    os.makedirs(chr_csv_folder, exist_ok=True)\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = torch.tensor(data.filter(regex='^(?!.*PRS313_)').values, dtype=torch.float32)\n",
    "    y = torch.tensor(data.filter(regex='PRS313_').values, dtype=torch.long)\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Normalize the features\n",
    "    scaler = StandardScaler()\n",
    "    X = torch.tensor(scaler.fit_transform(X), dtype=torch.float32)\n",
    "    import joblib\n",
    "\n",
    "    # Save the scaler to disk\n",
    "    scaler_filename = f'{chr_model_folder}scaler_chr{chromosome_number}.pkl'\n",
    "    joblib.dump(scaler, scaler_filename)\n",
    "    print(f\"Scaler saved at: {scaler_filename}\")\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the neural network model\n",
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, hidden_dims, dropout_rate):\n",
    "            super(NeuralNetwork, self).__init__()\n",
    "            layers = []\n",
    "            prev_dim = input_dim\n",
    "            for hidden_dim in hidden_dims:\n",
    "                layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "                prev_dim = hidden_dim\n",
    "            layers.append(nn.Linear(prev_dim, output_dim * 3))\n",
    "            self.net = nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.net(x)\n",
    "            out = out.view(out.size(0), -1, 3)\n",
    "            return out\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set the hyperparameters for tuning\n",
    "    input_dim = X_train_val.shape[1]\n",
    "    output_dim = y_train_val.shape[1]\n",
    "\n",
    "    # Define the objective function for Optuna with cross-validation and early stopping\n",
    "    def objective(trial):\n",
    "        hidden_layers = trial.suggest_int('hidden_layers', 1, 5)\n",
    "        hidden_dims = [trial.suggest_int(f'n_units_l{i}', 256, 1028, log=True) for i in range(hidden_layers)]\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 1e-11, 0.25)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 1e-11, 1e-5, log=True)\n",
    "        patience = 40\n",
    "        weight_decay = trial.suggest_float('weight_decay', 1e-11, 1e-5, log=True)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [ 32, 64, 128, 256])\n",
    "        lr_factor = 0.1\n",
    "        num_epochs = 300\n",
    "\n",
    "        model = NeuralNetwork(input_dim, output_dim, hidden_dims, dropout_rate).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_factor, patience=patience, verbose=False)\n",
    "\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        fold_losses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_val)):\n",
    "            X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "            y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "            train_dataset = TensorDataset(X_train, y_train)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "            best_val_loss = float('inf')\n",
    "            counter = 0\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_loss = 0.0\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs.transpose(1, 2), batch_y)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                train_loss /= len(train_loader)\n",
    "\n",
    "                val_dataset = TensorDataset(X_val, y_val)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0.0\n",
    "                    for batch_X, batch_y in val_loader:\n",
    "                        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X)\n",
    "                        loss = criterion(outputs.transpose(1, 2), batch_y)\n",
    "                        val_loss += loss.item()\n",
    "\n",
    "                    val_loss /= len(val_loader)\n",
    "                    scheduler.step(val_loss)\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        counter = 0\n",
    "                    else:\n",
    "                        counter += 1\n",
    "\n",
    "                    if counter >= patience:\n",
    "                        break\n",
    "\n",
    "            fold_losses.append(best_val_loss)\n",
    "\n",
    "        return np.mean(fold_losses)\n",
    "    \n",
    "    # Create the \"optuna_studies\" folder if it doesn't exist\n",
    "    os.makedirs(\"optuna_studies_nn\", exist_ok=True)\n",
    "\n",
    "    # Create an Optuna study and optimize the hyperparameters\n",
    "    study_name = f\"unphased_full_23andMe_chr{chromosome_number}_study_nn\"\n",
    "    storage_name = f\"sqlite:///optuna_studies_nn/{study_name}.db\"\n",
    "\n",
    "    # Check if the study exists\n",
    "    current_dir = os.getcwd()\n",
    "    study_exists = os.path.exists(current_dir + f\"/optuna_studies_nn/{study_name}.db\")\n",
    "\n",
    "    if study_exists:\n",
    "        # Load the existing study\n",
    "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "    else:\n",
    "        # Create a new study\n",
    "        study = optuna.create_study(direction='minimize', study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "\n",
    "    study.optimize(objective, n_trials=10, n_jobs=-1)\n",
    "\n",
    "    # Print the best hyperparameters and best value\n",
    "    print(f\"Chr {chromosome_number} - Best hyperparameters: {study.best_params}\")\n",
    "    print(f\"Chr {chromosome_number} - Best value: {study.best_value:.4f}\")\n",
    "\n",
    "    # Train the final model with the best hyperparameters and early stopping\n",
    "    best_hidden_layers = study.best_params['hidden_layers']\n",
    "    best_hidden_dims = [study.best_params[f'n_units_l{i}'] for i in range(best_hidden_layers)]\n",
    "    best_dropout_rate = study.best_params['dropout_rate']\n",
    "    best_learning_rate = study.best_params['learning_rate']\n",
    "    best_patience = 20\n",
    "    best_weight_decay = study.best_params['weight_decay']\n",
    "    best_batch_size = study.best_params['batch_size']\n",
    "    best_lr_factor = 0.25\n",
    "    best_num_epochs = 300\n",
    "\n",
    "    model = NeuralNetwork(input_dim, output_dim, best_hidden_dims, best_dropout_rate).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate, weight_decay=best_weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=best_lr_factor, patience=best_patience, verbose=False)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_val, y_train_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(best_num_epochs):\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs.transpose(1, 2), batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        if train_loss < best_train_loss:\n",
    "            best_train_loss = train_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= best_patience:\n",
    "            break\n",
    "\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "    # Save the final model\n",
    "    model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Final model saved at: {model_save_path}\")\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test.to(device)).softmax(dim=2)\n",
    "        test_outputs = test_outputs.argmax(dim=-1)\n",
    "        test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "        test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "\n",
    "        test_accuracy = ((y_test == test_outputs).sum() / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "        # Append performance metrics to the lists\n",
    "        r2_scores.append(test_r2)\n",
    "        iqs_scores.append(test_iqs)\n",
    "        accuracy_scores.append(test_accuracy)\n",
    "\n",
    "        # Calculate individual R^2 scores for each SNP\n",
    "        individual_r2_scores = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy(), multioutput='raw_values')\n",
    "\n",
    "        # Calculate individual IQS scores for each SNP\n",
    "        individual_iqs_scores = np.array([calculate_iqs_unphased(y_test.cpu().numpy()[:, i].reshape(-1, 1), test_outputs.cpu().numpy()[:, i].reshape(-1, 1)) for i in range(y_test.shape[1])])\n",
    "\n",
    "        # Get the names of the SNPs from the original dataframe\n",
    "        snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "        # Save individual R^2 scores to a CSV file\n",
    "        csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'R2 Score'])\n",
    "            for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                writer.writerow([snp, r2_score])\n",
    "\n",
    "        print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "        # Save individual IQS scores to a CSV file\n",
    "        iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "        with open(iqs_csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['SNP', 'IQS Score'])\n",
    "            for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                writer.writerow([snp, iqs_score])\n",
    "\n",
    "        print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "    # Create a DataFrame to store the performance metrics for each chromosome\n",
    "    performance_df = pd.DataFrame({\n",
    "        'Chromosome': list(range(start, chromosome_number + 1)),\n",
    "        'R2 Score': r2_scores,\n",
    "        'IQS Score': iqs_scores,\n",
    "        'Accuracy Score': accuracy_scores\n",
    "    })\n",
    "\n",
    "    # Save the performance metrics to a CSV file\n",
    "    performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "    performance_df.to_csv(performance_csv_file, index=False)\n",
    "    print(f\"Performance metrics saved at: {performance_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs:  2028\n",
      "PRS313 SNPs:  30\n",
      "Total SNPs used for Training:  1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr1/individual_r2_scores_chr1.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr1/individual_iqs_scores_chr1.csv\n",
      "Total SNPs:  1044\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr2/individual_r2_scores_chr2.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr2/individual_iqs_scores_chr2.csv\n",
      "Total SNPs:  1255\n",
      "PRS313 SNPs:  16\n",
      "Total SNPs used for Training:  1239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr3/individual_r2_scores_chr3.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr3/individual_iqs_scores_chr3.csv\n",
      "Total SNPs:  1488\n",
      "PRS313 SNPs:  11\n",
      "Total SNPs used for Training:  1477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr4/individual_r2_scores_chr4.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr4/individual_iqs_scores_chr4.csv\n",
      "Total SNPs:  2038\n",
      "PRS313 SNPs:  34\n",
      "Total SNPs used for Training:  2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr5/individual_r2_scores_chr5.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr5/individual_iqs_scores_chr5.csv\n",
      "Total SNPs:  853\n",
      "PRS313 SNPs:  20\n",
      "Total SNPs used for Training:  833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr6/individual_r2_scores_chr6.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr6/individual_iqs_scores_chr6.csv\n",
      "Total SNPs:  735\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr7/individual_r2_scores_chr7.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr7/individual_iqs_scores_chr7.csv\n",
      "Total SNPs:  799\n",
      "PRS313 SNPs:  21\n",
      "Total SNPs used for Training:  778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr8/individual_r2_scores_chr8.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr8/individual_iqs_scores_chr8.csv\n",
      "Total SNPs:  653\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr9/individual_r2_scores_chr9.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr9/individual_iqs_scores_chr9.csv\n",
      "Total SNPs:  942\n",
      "PRS313 SNPs:  18\n",
      "Total SNPs used for Training:  924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr10/individual_r2_scores_chr10.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr10/individual_iqs_scores_chr10.csv\n",
      "Total SNPs:  1275\n",
      "PRS313 SNPs:  19\n",
      "Total SNPs used for Training:  1256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr11/individual_r2_scores_chr11.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr11/individual_iqs_scores_chr11.csv\n",
      "Total SNPs:  852\n",
      "PRS313 SNPs:  17\n",
      "Total SNPs used for Training:  835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr12/individual_r2_scores_chr12.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr12/individual_iqs_scores_chr12.csv\n",
      "Total SNPs:  152\n",
      "PRS313 SNPs:  5\n",
      "Total SNPs used for Training:  147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr13/individual_r2_scores_chr13.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr13/individual_iqs_scores_chr13.csv\n",
      "Total SNPs:  459\n",
      "PRS313 SNPs:  8\n",
      "Total SNPs used for Training:  451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr14/individual_r2_scores_chr14.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr14/individual_iqs_scores_chr14.csv\n",
      "Total SNPs:  310\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr15/individual_r2_scores_chr15.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr15/individual_iqs_scores_chr15.csv\n",
      "Total SNPs:  606\n",
      "PRS313 SNPs:  14\n",
      "Total SNPs used for Training:  592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr16/individual_r2_scores_chr16.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr16/individual_iqs_scores_chr16.csv\n",
      "Total SNPs:  380\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr17/individual_r2_scores_chr17.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr17/individual_iqs_scores_chr17.csv\n",
      "Total SNPs:  589\n",
      "PRS313 SNPs:  9\n",
      "Total SNPs used for Training:  580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr18/individual_r2_scores_chr18.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr18/individual_iqs_scores_chr18.csv\n",
      "Total SNPs:  348\n",
      "PRS313 SNPs:  7\n",
      "Total SNPs used for Training:  341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All true labels are negative. Returning NaN.\n",
      "Individual R^2 scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr19/individual_r2_scores_chr19.csv\n",
      "Individual IQS scores saved at: ../../../Data/model_results_unphased_all_PRS/neural_network/csv_files/chr19/individual_iqs_scores_chr19.csv\n",
      "Total SNPs:  108\n",
      "PRS313 SNPs:  4\n",
      "Total SNPs used for Training:  104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/ipykernel_9484/3639561551.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 108\u001b[0m\n\u001b[1;32m    105\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m X_train_val\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    106\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m y_train_val\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 108\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_dim, output_dim, best_hidden_dims, best_dropout_rate)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    110\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m chr_model_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_model_chr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    111\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_save_path, map_location\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[8], line 108\u001b[0m\n\u001b[1;32m    105\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m X_train_val\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    106\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m y_train_val\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 108\u001b[0m model \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_dim, output_dim, best_hidden_dims, best_dropout_rate)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    110\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m chr_model_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_model_chr\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosome_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    111\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_save_path, map_location\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/medicaid/DeepImpute/.venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score as sklearn_r2_score\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "import os\n",
    "import csv\n",
    "import joblib\n",
    "import optuna\n",
    "\n",
    "# Load and preprocess the data\n",
    "data_directory = '../../../Data/Filtered_unphased_training_data_union_final/'\n",
    "start = 1\n",
    "\n",
    "# Initialize lists to store the performance metrics for each chromosome\n",
    "r2_scores = []\n",
    "iqs_scores = []\n",
    "accuracy_scores = []\n",
    "auc_scores = []\n",
    "\n",
    "# Folders for saved models and CSV files\n",
    "output_folder = \"../../../Data/model_results_unphased_all_PRS/neural_network/\"\n",
    "model_folder = output_folder + \"models_unphased/\"\n",
    "csv_folder = output_folder + \"csv_files/\"\n",
    "\n",
    "def safe_auc_metric(y_pred, y_true):\n",
    "    if y_true.sum() == 0:\n",
    "        print(\"All true labels are negative. Returning NaN.\")\n",
    "        return np.NaN\n",
    "    return auc_metric(y_pred, y_true)\n",
    "\n",
    "for chromosome_number in range(start, 23):\n",
    "    # Paths for the current chromosome\n",
    "    chr_model_folder = model_folder + f\"chr{chromosome_number}/\"\n",
    "    chr_csv_folder = csv_folder + f\"chr{chromosome_number}/\"\n",
    "\n",
    "    file_name = data_directory + f\"23AndMe_PRS313_merged_chr{chromosome_number}_matching_combined.parquet\"\n",
    "    data = pd.read_parquet(file_name)\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = data.filter(regex='^(?!.*PRS313_)').values\n",
    "    y = data.filter(regex='PRS313_').values\n",
    "\n",
    "    print(\"Total SNPs: \", data.shape[1])\n",
    "    print(\"PRS313 SNPs: \", y.shape[1])\n",
    "    print(\"Total SNPs used for Training: \", X.shape[1])\n",
    "\n",
    "    # Load the scaler\n",
    "    scaler_filename = f'{chr_model_folder}scaler_chr{chromosome_number}.pkl'\n",
    "    scaler = joblib.load(scaler_filename)\n",
    "    X = torch.tensor(scaler.transform(X), dtype=torch.float32)\n",
    "\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    # Split the data into train-validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the neural network model\n",
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, hidden_dims, dropout_rate):\n",
    "            super(NeuralNetwork, self).__init__()\n",
    "            layers = []\n",
    "            prev_dim = input_dim\n",
    "            for hidden_dim in hidden_dims:\n",
    "                layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "                prev_dim = hidden_dim\n",
    "            layers.append(nn.Linear(prev_dim, output_dim * 3))\n",
    "            self.net = nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.net(x)\n",
    "            out = out.view(out.size(0), -1, 3)\n",
    "            return out\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load Optuna study\n",
    "    study_name = f\"unphased_full_23andMe_chr{chromosome_number}_study_nn\"\n",
    "    storage_name = f\"sqlite:///optuna_studies_nn/{study_name}.db\"\n",
    "\n",
    "    # Check if the study exists\n",
    "    current_dir = os.getcwd()\n",
    "    study_exists = os.path.exists(current_dir + f\"/optuna_studies_nn/{study_name}.db\")\n",
    "\n",
    "    if study_exists:\n",
    "        # Load the existing study\n",
    "        study = optuna.load_study(study_name=study_name, storage=storage_name)\n",
    "        best_hidden_layers = study.best_params['hidden_layers']\n",
    "        best_hidden_dims = [study.best_params[f'n_units_l{i}'] for i in range(best_hidden_layers)]\n",
    "        best_dropout_rate = study.best_params['dropout_rate']\n",
    "        best_learning_rate = study.best_params['learning_rate']\n",
    "        best_patience = 20\n",
    "        best_weight_decay = study.best_params['weight_decay']\n",
    "        best_batch_size = study.best_params['batch_size']\n",
    "        best_lr_factor = 0.25\n",
    "        best_num_epochs = 300\n",
    "\n",
    "        input_dim = X_train_val.shape[1]\n",
    "        output_dim = y_train_val.shape[1]\n",
    "\n",
    "        model = NeuralNetwork(input_dim, output_dim, best_hidden_dims, best_dropout_rate).to(device)\n",
    "\n",
    "        model_save_path = chr_model_folder + f'final_model_chr{chromosome_number}.pth'\n",
    "        state_dict = torch.load(model_save_path, map_location=device)\n",
    "\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        # Evaluate the final model on the test set\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test.to(device)).softmax(dim=2)\n",
    "            test_outputs = test_outputs.argmax(dim=-1)\n",
    "            test_r2 = sklearn_r2_score(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "            test_iqs = calculate_iqs_unphased(y_test.cpu().numpy(), test_outputs.cpu().numpy())\n",
    "            test_accuracy = ((y_test == test_outputs).sum() / (test_outputs.shape[0] * test_outputs.shape[1])).numpy()\n",
    "\n",
    "            # Calculate the AUC for each SNP individually and then average them\n",
    "            y_test_np = y_test.cpu().numpy()\n",
    "            test_outputs_np = test_outputs.cpu().numpy()\n",
    "            auc_metric = BinaryAUROC(thresholds=None)\n",
    "\n",
    "            individual_aucs = [\n",
    "                [\n",
    "                    safe_auc_metric((test_outputs[:, j].round() == i).float(), (y_test[:, j] == i).float())\n",
    "                    for i in range(3)\n",
    "                ]\n",
    "                for j in range(y_test_np.shape[1])\n",
    "            ]\n",
    "            # Flatten the list of individual AUCs\n",
    "            flattened_aucs = [auc for sublist in individual_aucs for auc in sublist]\n",
    "\n",
    "            # Calculate the mean while ignoring NaN values\n",
    "            test_auc = np.nanmean(flattened_aucs)\n",
    "            auc_scores.append(test_auc)\n",
    "\n",
    "            # Append performance metrics to the lists\n",
    "            r2_scores.append(test_r2)\n",
    "            iqs_scores.append(test_iqs)\n",
    "            accuracy_scores.append(test_accuracy)\n",
    "\n",
    "            # Calculate individual R^2 scores for each SNP\n",
    "            individual_r2_scores = sklearn_r2_score(y_test_np, test_outputs_np, multioutput='raw_values')\n",
    "\n",
    "            # Calculate individual IQS scores for each SNP\n",
    "            individual_iqs_scores = np.array([calculate_iqs_unphased(y_test_np[:, i].reshape(-1, 1), test_outputs_np[:, i].reshape(-1, 1)) for i in range(y_test_np.shape[1])])\n",
    "\n",
    "            # Get the names of the SNPs from the original dataframe\n",
    "            snp_names = data.filter(regex='PRS').columns\n",
    "\n",
    "            # Save individual R^2 scores to a CSV file\n",
    "            csv_file = chr_csv_folder + f'individual_r2_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "            with open(csv_file, 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['SNP', 'R2 Score'])\n",
    "                for snp, r2_score in zip(snp_names, individual_r2_scores):\n",
    "                    writer.writerow([snp, r2_score])\n",
    "\n",
    "            print(f\"Individual R^2 scores saved at: {csv_file}\")\n",
    "\n",
    "            # Save individual IQS scores to a CSV file\n",
    "            iqs_csv_file = chr_csv_folder + f'individual_iqs_scores_chr{chromosome_number}.csv'\n",
    "\n",
    "            with open(iqs_csv_file, 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['SNP', 'IQS Score'])\n",
    "                for snp, iqs_score in zip(snp_names, individual_iqs_scores):\n",
    "                    writer.writerow([snp, iqs_score])\n",
    "\n",
    "            print(f\"Individual IQS scores saved at: {iqs_csv_file}\")\n",
    "\n",
    "# Create a DataFrame to store the performance metrics for each chromosome\n",
    "performance_df = pd.DataFrame({\n",
    "    'Chromosome': list(range(start, 23)),\n",
    "    'R2 Score': r2_scores,\n",
    "    'IQS Score': iqs_scores,\n",
    "    'Accuracy Score': accuracy_scores,\n",
    "    'AUC Score': auc_scores\n",
    "})\n",
    "\n",
    "# Save the performance metrics to a CSV file\n",
    "performance_csv_file = csv_folder + 'performance_metrics.csv'\n",
    "performance_df.to_csv(performance_csv_file, index=False)\n",
    "print(f\"Performance metrics saved at: {performance_csv_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
